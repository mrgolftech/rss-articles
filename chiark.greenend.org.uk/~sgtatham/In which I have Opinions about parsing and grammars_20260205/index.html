
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="技术博客文章聚合 - Hacker News 2025年最受欢迎的博客">
      
      
        <meta name="author" content="OpenClaw">
      
      
        <link rel="canonical" href="https://mrgolftech.github.io/rss-articles/chiark.greenend.org.uk/~sgtatham/In%20which%20I%20have%20Opinions%20about%20parsing%20and%20grammars_20260205/">
      
      
      
      
        
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.1">
    
    
      
        <title>In which I have Opinions about parsing and grammars - Hacker News 精选博客</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#in-which-i-have-opinions-about-parsing-and-grammars" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../../.." title="Hacker News 精选博客" class="md-header__button md-logo" aria-label="Hacker News 精选博客" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Hacker News 精选博客
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              In which I have Opinions about parsing and grammars
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="切换到深色模式"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="切换到深色模式" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="切换到浅色模式"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="切换到浅色模式" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="分享" aria-label="分享" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/mrgolftech/rss-articles" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    rss-articles
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../.." class="md-tabs__link">
        
  
  
    
  
  首页

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../blogs/" class="md-tabs__link">
        
  
  
    
  
  所有博客

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Hacker News 精选博客" class="md-nav__button md-logo" aria-label="Hacker News 精选博客" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Hacker News 精选博客
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/mrgolftech/rss-articles" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    rss-articles
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    首页
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../blogs/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    所有博客
  

    
  </span>
  
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/mrgolftech/rss-articles/edit/master/docs/chiark.greenend.org.uk/~sgtatham/In which I have Opinions about parsing and grammars_20260205.md" title="编辑此页" class="md-content__button md-icon" rel="edit">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75z"/></svg>
    </a>
  
  


<h1 id="in-which-i-have-opinions-about-parsing-and-grammars">In which I have Opinions about parsing and grammars<a class="headerlink" href="#in-which-i-have-opinions-about-parsing-and-grammars" title="Permanent link">&para;</a></h1>
<p><strong>来源:</strong> https://chiark.greenend.org.uk/~sgtatham
<strong>链接:</strong> https://www.chiark.greenend.org.uk/~sgtatham/quasiblog/parsing/
<strong>日期:</strong> 2025-06-05T00:00:00+00:00</p>
<hr />
<h1 id="in-which-i-have-opinions-about-parsing-and-grammars_1">In which I have Opinions about parsing and grammars<a class="headerlink" href="#in-which-i-have-opinions-about-parsing-and-grammars_1" title="Permanent link">&para;</a></h1>
<p>[Simon Tatham, 2025-06-05]</p>
<ul>
<li>Introduction</li>
<li>Context-free grammars are less declarative than youâd like<ul>
<li>A simple grammatical concept becomes complicated when written as a CFG</li>
<li>CFGs must be tailored to the parser technology</li>
</ul>
</li>
<li>You probably want to handwrite your production parser</li>
<li>Name a parser generation technology in your language spec</li>
<li>Use LR parser generators during language design<ul>
<li>Because they can point out design errors</li>
<li>Because they can generate test cases</li>
</ul>
</li>
<li>Stop doing LALR</li>
<li>Grammars should be synthetic as well as analytic</li>
<li>OK, what <em>should</em> you do?<ul>
<li>Compile a simpler form into an LR grammar?</li>
<li>LR with attributes?</li>
</ul>
</li>
<li>Bodges to handle non-LR languages</li>
<li>Conclusion</li>
<li>Footnotes</li>
</ul>
<h2 id="introduction">Introduction<a class="headerlink" href="#introduction" title="Permanent link">&para;</a></h2>
<p>Iâve been interested in parsing since I was a teenager. I first got into the subject by reading the <a href="https://en.wikipedia.org/wiki/Compilers:_Principles,_Techniques,_and_Tools">dragon book</a> in the early 1990s. (Thatâs about compilers in general, but the parsing chapter is a major part of it.) Then I played around with parser generators; my first one was <a href="https://github.com/jmrcpn/tply/">TPLY</a>, since as a teenager I was a Turbo Pascal programmer.</p>
<p>In my time, Iâve designed and implemented entire (small, toy, personal-project) programming languages from scratch, which of course needed parsers along with all the other components of a compiler or interpreter. Iâve tried to write parsers for existing languages, and found some of the ways that can go wrong. Iâve put some effort into understanding the theory of parser generators (particularly LR). Iâve used automated parser generators, hand-written my own parsers, and even tried <em>writing</em> an automated parser generator.</p>
<p>In all that activity, Iâve formed a lot of opinions. This article attempts to get all of them off my chest at once, in a series of not entirely connected rants.</p>
<h2 id="context-free-grammars-are-less-declarative-than-youad-like">Context-free grammars are less declarative than youâd like<a class="headerlink" href="#context-free-grammars-are-less-declarative-than-youad-like" title="Permanent link">&para;</a></h2>
<p>Context-free grammars â either written out directly as a list of rules (sometimes also known as âBackus-Naur Formâ or BNF), or converted into the slightly more graphical form of a <a href="https://en.wikipedia.org/wiki/Syntax_diagram">syntax diagram</a> â are more or less the gold standard for specifying the syntax of a language.</p>
<p>One reason theyâre popular is that the specification doesnât itself look like a <em>program</em>. It looks as if you just specify the rules of the grammar in a more or less natural way, and donât have to confuse the reader with any of the difficult algorithms that actually figures out what the input means. The usual term for this is âdeclarative programmingâ: I just specify <em>what I want</em> in a simple and direct way, and the language doesnât force me to engage with the details of <em>how to calculate it</em>.</p>
<p>When this works, itâs great. This (slightly simplified) list of statement types in a language like C, for example, could hardly be clearer:</p>
<p>statement â expression ;</p>
<p>statement â return expression ;</p>
<p>statement â { declarations-and-statements }</p>
<p>statement â if ( expression ) statement</p>
<p>statement â if ( expression ) statement else statement</p>
<p>statement â while ( expression ) statement</p>
<p>statement â do statement while ( expression ) ;</p>
<p>statement â for ( expression ; expression ; expression ) statement</p>
<p>statement â continue ;</p>
<p>statement â break ;</p>
<p>statement â switch ( expression ) statement</p>
<p>statement â case expression : statement</p>
<p>statement â default : statement</p>
<p>statement â goto label ;</p>
<p>statement â label : statement</p>
<p>(Iâll reuse this notation for grammars throughout this article. In case itâs not already obvious, Iâm using a bolded word or punctuation mark in a green box, like while or {, to represent an individual <em>token</em> communicated from the lexer to the parser, otherwise known as a <em>terminal symbol</em> of the grammar; and Iâm using an italic word in a rounded blue box, like statement, to represent a <em>nonterminal</em> symbol â one representing a larger subsection of the input program, potentially consisting of a string of many tokens, or sometimes even none.)</p>
<p>This is a straightforward enough description that you can learn this aspect of the language directly from it. If I want to <em>write</em> , say, a <code>do</code>-<code>while</code> statement in C, and I havenât learned what one looks like yet, I have only to find the right line of the above and work my way along it writing each token or grammatical subcomponent as I go. And at the same time it can also be handed to an automated parser generator. Ideal, right?</p>
<p>Unfortunately, not always. Iâve cherry-picked a particularly successful example here, but in other cases, CFGs <em>donât</em> achieve the ideals of declarative programming1My other example of a thing advertised as âdeclarativeâ which doesnât deliver on its promise is functional programming. Iâm not saying FP has no virtues, but declarative it is not. For example, to write a sorting function in a language like Haskell, you must decide which actual sorting algorithm you want to use; you can write very different Haskell functions that look like quicksort or mergesort or some other sort, and the compiler will generate the algorithm you asked for. My litmus test for a language worth calling âdeclarativeâ would be that I can write a sorting function by simply specifying the <em>properties</em> I want the output list to have, without saying anything about <em>how</em> to achieve it: it should be a permutation of the input list, such that <em>a</em>[<em>i</em>] â¤ <em>a</em>[<em>i</em> +1] for all <em>i</em>.1. When youâre writing a CFG, you <em>do</em> have to think about implementation, in two separate senses, which Iâll discuss below.</p>
<h3 id="a-simple-grammatical-concept-becomes-complicated-when-written-as-a-cfg">A simple grammatical concept becomes complicated when written as a CFG<a class="headerlink" href="#a-simple-grammatical-concept-becomes-complicated-when-written-as-a-cfg" title="Permanent link">&para;</a></h3>
<p>The first part of the notion of âdeclarativeâ is that I should be able to say what I want, in a simple and direct way. Transferring the idea in my head to the source file should be easy, and reading the source code to recover the idea should be equally easy.</p>
<p>But itâs not, in every case.</p>
<p>Translating your mental notion of the languageâs grammar into CFG rules is itself an exercise in programming: you have to know the non-obvious pitfalls and the tricky rewordings needed to avoid them, and you have the usual tension between wanting to factor out commonly used idioms into explicit subthings, and wanting to keep each grammar rule self-contained and clear. Itâs entirely possible to write <em>bugs</em> in grammars.</p>
<p>Even in the clear-looking C example above, the seeds of this problem are already sown. My example <code>for</code> statement was in the C89 style, where all three clauses are plain expressions. But C99 introduced the option to declare a new variable in the initialisation clause: â<code>for (**int i** = 0; â¦)</code>â. The grammar rule for <em>that</em> version of <code>for</code>, in the C99 standard, is already less clear.</p>
<p>statement â for ( declaration expression ; expression ) statement</p>
<p>Whereâs the semicolon gone, in between the first two clauses? Itâs included in the nonterminal declaration: because of the way that symbol is used in other contexts, itâs defined so that it expands to a sequence of tokens that <em>includes</em> the trailing semicolon, and so it would be a mistake for this rule to write a ; after the declaration, or youâd end up accidentally specifying a language in which <em>two</em> semicolons were needed between the first two clauses. As a grammar author, you could easily make this mistake â and if you werenât <em>testing</em> your grammar in some way, you might miss the error completely, and publish a nonsense specification. Meanwhile, as a grammar <em>reader</em> , you see this and scratch your head, and then have to go and look up the definition of declaration elsewhere to figure out what you missed.</p>
<p>Similarly, some of the grammar rules above <em>end</em> with a ;, and some donât â because some of the statement types end with another entire statement, which includes its own trailing ; and so another one isnât needed. When a beginner learns C (or any other language with even slightly similar syntax), one of the earliest rules they must internalise is that <em>every</em> statement ends with a semicolon2Except that a braced block counts as a statement by this grammar, and doesnât have a semicolon after the closing brace. So even this âobviousâ fact about C syntax depends a bit on your point of view.2. And yet you have to look carefully, and think hard, to convince yourself from the list of rules above that this is true.</p>
<p>Another pitfall in the example above is the well-known if-else ambiguity, arising from these two rules:</p>
<p>statement â if ( expression ) statement</p>
<p>statement â if ( expression ) statement else statement</p>
<p>because the grammar doesnât explain which way to interpret an input sequence of symbols such as this:</p>
<p>if ( expression )</p>
<p>if ( expression )</p>
<p>statement else statement</p>
<p>Is that an outer if-without-else, whose then-clause contains an if-with-else? Or is it an outer if-<em>with</em> -else, whose then-clause is an if-without-else? In other words, which of the two <code>if</code>s does the single <code>else</code> bind to? Thereâs a very standard answer to this question in practice: the <code>else</code> is always considered to bind to the the last unmatched <code>if</code>. But the grammar as written doesnât <em>say</em> that thatâs the answer. That information is communicated separately. In the C standard itâs written in prose, alongside the list of grammar rules. If you feed the same set of rules to an automated parser generator, youâll have to look up how your parser generator resolves ambiguities, and whether in this case it will do the thing you want, and if not, how to tell it to do something different.</p>
<p>You <em>can</em> write an unambiguous context-free grammar for a language containing both types of if-statement. But it requires some puzzle-solving ingenuity to come up with. And it <em>hugely</em> impacts comprehension, to a reader whoâs trying to learn <em>what the language is</em> from the written grammar.</p>
<p>The gory details: an unambiguous grammar for C statements</p>
<p>You do it by dividing the nonterminal statement into two subclasses: one representing a âbalancedâ statement, in which there are no ifs without else clauses, and one representing an âunbalancedâ statement. The idea is that an unbalanced statement is precisely a token sequence that you only chose to parse as a complete statement <em>because</em> it wasnât followed by an else token; if it had been, youâd have parsed a longer token sequence as a different statement.</p>
<p>So you start with the top-level rules that say that the overall category statement can be whichever it likes:</p>
<p>statement â balanced-statement</p>
<p>statement â unbalanced-statement</p>
<p>Many statement types are automatically balanced. These include a braced block containing other statements, because any imbalance <em>inside</em> the block is safely wrapped up by the braces â thereâs no way that an else <em>outside</em> a pair of braces would ever be considered to bind to an if <em>inside</em> them. Similarly, the do and while tokens have the same bracketing effect, so that a do-while statement is balanced no matter what kind of statement it contains.</p>
<p>balanced-statement â expression ;</p>
<p>balanced-statement â return expression ;</p>
<p>balanced-statement â { declarations-and-statements }</p>
<p>balanced-statement â do statement while ( expression ) ;</p>
<p>balanced-statement â continue ;</p>
<p>balanced-statement â break ;</p>
<p>balanced-statement â goto label ;</p>
<p>Thereâs just one statement type which is automatically <em>not</em> balanced, no matter whether its final statement is balanced or not:</p>
<p>unbalanced-statement â if ( expression ) statement</p>
<p>The remaining statement types, like <code>while</code> and <code>for</code> loops, are balance-preserving: each one ends with a statement, and is balanced if and only if that sub-statement is. We could write out each rule twice, for balanced and unbalanced statements. But I think itâs more convenient to introduce a third nonterminal, describing a âstatement prefixâ: anything you can stick on the front of an existing statement to make a larger statement, in such a way that balance and imbalance are preserved.</p>
<p>So we can express <em>just once</em> the idea that statement prefixes preserve balance:</p>
<p>balanced-statement â statement-prefix balanced-statement</p>
<p>unbalanced-statement â statement-prefix unbalanced-statement</p>
<p>And then we can write out each of the actual statement prefixes just once:</p>
<p>statement-prefix â if ( expression ) balanced-statement else</p>
<p>statement-prefix â while ( expression )</p>
<p>statement-prefix â for ( expression ; expression ; expression )</p>
<p>statement-prefix â switch ( expression )</p>
<p>statement-prefix â case expression :</p>
<p>statement-prefix â default :</p>
<p>statement-prefix â label :</p>
<p>The key detail in the above list is: in the if statement <em>with</em> an else-clause, the then-clause has to be a balanced-statement. So itâs just not <em>legal</em> to insert an elseless if in that slot, because that would be an unbalanced-statement, and wouldnât match the rule.</p>
<p>I hope you see what I mean about readability! This doesnât look like a simple description of the language syntax any more. It looks like a complicated computer program.</p>
<p>Perhaps it would have been more readable to a language learner if I hadnât done the statement-prefix business, and instead just written the duplications out longhand, e.g.</p>
<p>balanced-statement â while ( expression ) balanced-statement</p>
<p>unbalanced-statement â while ( expression ) unbalanced-statement</p>
<p>and the same for all the rest of the statement prefixes? But even if thatâs true, now weâre trading off good programming practice against readability. When the next version of the C standard adds another statement prefix, the DRY version of this grammar with a statement-prefix nonterminal offers less risk of mistakes when updating the grammar. But a reader trying to learn <em>this</em> version of the language might well prefer the WET version which doesnât factor out the statement prefixes.</p>
<p>The other very common example of needing a complicated grammar for a simple syntax is the problem of operator precedence in infix expressions. If you just write something like this:</p>
<p>expression â variable-name</p>
<p>expression â literal-constant</p>
<p>expression â ( expression )</p>
<p>expression â expression + expression</p>
<p>expression â expression â expression</p>
<p>expression â expression Ã expression</p>
<p>expression â expression Ã· expression</p>
<p>then you have the usual problems. Is an expression like <code>1+2Ã3</code> interpreted as <code>1+(2Ã3)</code>, or as <code>(1+2)Ã3</code>? Does <code>1â2â3</code> mean <code>1â(2â3)</code> or <code>(1â2)â3</code>? Of course, we know which one we want in each case, but the above grammar certainly doesnât <em>say</em> it. If you write the grammar as above, then you have to either communicate that information out of band, perhaps using a precedence table in a written specification, or magic directives to your automated parser generator, like <code>%prec</code> in Bison.</p>
<p>So, again, the context-free grammar <em>itself</em> doesnât make it easy to âjust write what you meanâ. You <em>can</em> write a CFG that makes operator precedence unambiguous, but itâs long and verbose and involves introducing a lot of extra nonterminal symbols.</p>
<p>Further details: an unambiguous grammar for infix expressions</p>
<p>The way to deal with this is to add a nonterminal symbol for each precedence level. The innermost one is an âatomicâ expression, describing a token sequence that <em>absolutely must</em> form a self-contained subexpression: it canât possibly be split up and re-parsed differently, no matter what operator appears next to it on either side. This includes any single token thatâs a subexpression by itself, and anything in brackets:</p>
<p>atomic-expression â variable-name</p>
<p>atomic-expression â literal-constant</p>
<p>atomic-expression â ( expression )</p>
<p>Then we work down the precedence levels, highest to lowest. In our simple four-operator example, the highest precedence level is shared by the Ã and Ã· operators. So we define a symbol for a âmultiplicative expressionâ, which is an expression that takes one or more atomic expressions, and does multiplications and divisions to them:</p>
<p>multiplicative-expression â multiplicative-expression Ã atomic-expression</p>
<p>multiplicative-expression â multiplicative-expression Ã· atomic-expression</p>
<p>The right-hand side of each of those rules is asymmetric. On the left of the operator is another <em>multiplicative</em> expression: one thatâs allowed to contain another unbracketed Ã or Ã· operator. But on the right is an <em>atomic</em> expression, which canât contain any infix operators at all unless it safely wraps them up in brackets. This asymmetry expresses the fact that, at this precedence level, the operators âassociate to the leftâ: <code>aÃ·bÃc</code> is parsed as a multiplication whose left operand is a division, i.e. like <code>(aÃ·b)Ãc</code>. If Iâd written the rules the other way round, with the multiplicative-expression on the right instead of the left, then Iâd have made the operators âassociate to the rightâ.</p>
<p>Associating to the right is the normal choice for <em>some</em> mathematical operators. In particular, the âraise to a powerâ operator: itâs better to interpret <code>2^3^4</code> as <code>2^(3^4)</code>, because if you interpret it as <code>(2^3)^4</code> then thatâs saying the same thing as <code>2^(3Ã4)</code>, which you already had a way to say. So there isnât one right way to write each of these rule sets: for each precedence level, you have to decide how the operators associate, and write the rules differently depending on your choice.</p>
<p>(There are other options! If Iâd put an atomic-expression on <em>both</em> sides of each rule, Iâd have defined a syntax in which you just arenât <em>allowed</em> to chain the same operator twice, without adding brackets to say which way you mean it to be interpreted. More subtly, by introducing yet more nonterminals, itâs possible to define a set of operators each of which can associate with <em>itself</em> freely, but they canât associate with <em>each other</em>. In languages I design myself I like to use this trick for the <code>AND</code> and <code>OR</code> operators: you can write <code>a AND b AND c</code>, but if you write <code>a AND b OR c</code> you must add brackets to clarify.)</p>
<p>Iâve left out one rule. A multiplicative expression is <em>allowed</em> to contain an unbracketed Ã or Ã· operator. But it doesnât <em>have</em> to. We must also specify that a multiplicative-expression is allowed to do <em>zero</em> multiplications and divisions to its input atomic expressions: it can contain just <em>one</em> atomic-expression, and pass it through without doing anything to it.</p>
<p>multiplicative-expression â atomic-expression</p>
<p>Now weâre done with the multiplicative operators, and we move on to the additive ones, + and â. These work exactly the same way, except that the inputs to an additive expression donât have to be <em>atomic</em> expressions: they can be multiplications or divisions, without the Ã or Ã· operators inside them having to be bracketed. In other words, they can be any multiplicative-expression:</p>
<p>additive-expression â additive-expression + multiplicative-expression</p>
<p>additive-expression â additive-expression â multiplicative-expression</p>
<p>additive-expression â multiplicative-expression</p>
<p>If there were more levels of operator precedence, weâd continue down the list, inventing yet another name at each stage, with each new nonterminal consuming instances of the previous nonterminal and chaining them together with operators of the next lower priority. In the full C expression grammar, there are a staggering <em>seventeen!</em></p>
<p>Which of these nonterminals should have the honour of being called just plain expression? Generally the outermost one, dealing with the lowest-priority operators. Where the syntax of the rest of the language calls for an expression, thereâs normally no restriction on what operators you can use, so the grammar would specify the nonterminal that allows <em>any</em> operator to appear without brackets. In particular, thatâs certainly the right nonterminal to use for the <em>contents</em> of a pair of brackets, back up there in the rule that turns a bracketed expression into an atomic-expression: the whole point of brackets is that they should let you wrap up anything at all safely.</p>
<p>In C, in fact, this is only <em>mostly</em> true. The outermost, lowest-priority nonterminal is used in <em>most</em> contexts where the language as a whole calls for an expression. But thereâs an exception. The lowest-priority operator in C is the comma operator: the expression <code>x,y</code> means âevaluate <code>x</code>, performing any side effects like output or modifying a variable, and then return the value of <code>y</code>â. But commas are also used to separate the arguments of a function call. So in the argument list of a function call, the reference C grammar says that each argument must be the expression nonterminal for the <em>second</em> -lowest precedence level: the nonterminal thatâs allowed to contain any operator unbracketed <em>except</em> a comma. (Which doesnât mean you <em>canât</em> use the comma operator in a C function argument â it just means you have to put brackets around it, to prevent the language from seeing it as an argument separator.)</p>
<p>So, despite the initial promise, writing a context-free grammar in a way that is unambiguous is just like using a programming language. You <em>canât</em> just âwrite what you meanâ. You have to know all the tricks for how to translate the simple ideas in your head into the details that will actually work. And those tricks involve introducing extra complexity, which trades off readability in return for ease of maintenance and reducing the probability of making mistakes: refactoring, reorganising, adding internal identifiers that arenât particularly meaningful to an end user.</p>
<h3 id="cfgs-must-be-tailored-to-the-parser-technology">CFGs must be tailored to the parser technology<a class="headerlink" href="#cfgs-must-be-tailored-to-the-parser-technology" title="Permanent link">&para;</a></h3>
<p>The second element of âdeclarativeâ is that I shouldnât have to worry about the algorithm used to compute what I asked for. Itâs my job to say what it is, and the softwareâs job to find a way to get it for me.</p>
<p>CFGs donât reliably satisfy that aspect either!</p>
<p>You also have to consider the implementation of the parser generator your grammar will be fed to, and depending which one it is, extra constraints arise.</p>
<p>Some parser generation strategies allow you to write each individual rule in a way thatâs more expressive than a plain list of symbols. You can use some regular-expression-like operators, tagging a symbol as optional, or allowed to be repeated any number of times. This tends to be a feature supported by LL parsing tools, because in the LL strategy, you know early which production for a symbol youâre looking at, and can concentrate on just that one production. LR finds this harder because it tries to keep multiple possibilities in mind until the last moment.</p>
<p>For example, in my example list of C statement types above, I simplified the real syntax by leaving out some of those âoptionalâ markers. For example, the <code>for</code> statement ought to have all three of its expressions optional:</p>
<p>statement â for ( expressionopt ; expressionopt ; expressionopt ) statement</p>
<p>(Iâve used the notation of the C standard here: a subscript âoptâ to indicate that a symbol is optional. Some parser generators will use a suffix <code>?</code>, like a regular expression.)</p>
<p>Not all parser generators support this extended syntax. If one doesnât, you have to make an extra symbol to use instead:</p>
<p>statement â for ( expression-opt ; expression-opt ; expression-opt ) statement</p>
<p>expression-opt â expression</p>
<p>expression-opt â Îµ</p>
<p>(The Îµ on the right-hand side is mathematical notation for the empty string. It doesnât represent a true symbol of the grammar: you wonât ever find one pushed on the LR parse stack, for example. In code, youâd just have a zero-length list of symbols on the right-hand side of that production. The Îµ is just a marker in the written notation, indicating that this grammar production <em>intentionally</em> has an empty right-hand side, and I didnât accidentally leave it half-written!)</p>
<p>Similarly, if your parser generator wonât let you write a <code>*</code> or <code>+</code> suffix to indicate that a RHS symbol is repeatable, you have to make a special symbol for a list of them. For example, in the C statement list, I used the symbol declarations-and-statements inside the braced block statement (expecting that it would be obvious what it meant). If you were encoding this properly in an LR system like Bison, youâd have to expand it like this:</p>
<p>declarations-and-statements â declarations-and-statements declaration</p>
<p>declarations-and-statements â declarations-and-statements statement</p>
<p>declarations-and-statements â Îµ</p>
<p>which says that a declarations-and-statements can be empty, or else it can consist of another instance of itself followed by a declaration or a statement. In other words, you end up with a list of zero or more declarations and statements, intermixed in any order.</p>
<p>But this brings me to the next point: for different parser generation technologies, you donât even write <em>that</em> the same way.</p>
<p>You could equally well have chosen to write this list symbol with the recursion on the right-hand side rather than the left:</p>
<p>declarations-and-statements â declaration declarations-and-statements</p>
<p>declarations-and-statements â statement declarations-and-statements</p>
<p>declarations-and-statements â Îµ</p>
<p>This has exactly the same meaning in terms of what sequences of tokens are allowed. But if youâre using an LL parser generator (and it doesnât have a repetition operator you can use instead), you need to write it this way round, because LL grammars fundamentally arenât allowed to <em>left-recurse</em> : a production for a symbol foo may not start with another foo, or even with another symbol capable of becoming a foo again after further expansions.</p>
<p>So maybe you should write this kind of list symbol with the recursion on the right <em>always</em> , so that LL and LR parser generators can both cope with it? Not a good idea, unfortunately. Itâs true that LR <em>can</em> handle the right-recursive form, but itâs less efficient, because a long list of statements would all have to be pushed on the parse stack in sequence before the parser could start combining them into larger and larger declarations-and-statements instances. Using the left-recursive form, the parser immediately makes an empty declarations-and-statements on the stack, and then folds each incoming declaration or statement into it, so the stack size stays bounded.</p>
<p>In this case, efficiency is the only consideration when deciding whether to write a thing one way round or the other, because these statements are just being combined into a plain list, and <em>after</em> youâve constructed the whole list, it doesnât matter whether you built it up from the right-hand end or the left. But in some cases it makes a semantic difference which way round you write one of these constructions. For example, consider this simplified grammar for infix subtraction:</p>
<p>expression â NUMBER</p>
<p>expression â expression â NUMBER</p>
<p>If Iâd written <em>that</em> rule the other way round, as NUMBER â expression, it would make a difference to the meaning. An expression like â<code>123â234â345</code>â would have to be parsed as 123 â (234 â 345), whereas the original rule parses it as (123 â 234) â 345, the way we wanted it.</p>
<p>So this subtraction grammar <em>must</em> left-recurse in order to mean what we want it to mean. But then how do you express it at all in an LL system, under the constraint that you <em>mustnât</em> ever left-recurse?</p>
<p>You have to introduce a âtailâ symbol, something like this:</p>
<p>expression â NUMBER expr-tail</p>
<p>expr-tail â â NUMBER expr-tail</p>
<p>expr-tail â Îµ</p>
<p>This avoids left-recursion, and matches the right set of strings of tokens. But converting it into an abstract syntax tree has to be done by more awkward methods than usual: you canât just associate each nonterminal symbol with an AST node in the usual way, because expr-tail by itself <em>doesnât</em> represent an AST node for a subexpression! Instead, it represents some kind of <em>function</em> , transforming one AST node into another.</p>
<p>So a lot of common constructions in language syntax have to be expressed using quite different context-free grammars, depending on the parser technology you plan to feed the grammar to. And some of those grammars look very confusing and unintuitive, compared to the simple idea of the languageâs syntax that you had in your head before you sat down to write a formal grammar.</p>
<p>Hereâs another annoying case. Going back a bit to the âoptionalâ thing I mentioned at the start of this section, supposing I wanted to write a syntax for specifying a range of numbers, with one or other end of the range allowed to be omitted, but not both. That is, I could write <code>[50,100]</code>, or <code>[50,]</code>, or <code>[,100]</code>, but not <code>[,]</code> with both endpoints missing.</p>
<p>If youâre allowed the âoptionalâ suffix, you might try writing something like this:</p>
<p>interval â [ endpointopt , endpoint ]</p>
<p>interval â [ endpoint , endpointopt ]</p>
<p>But this is ambiguous â if <em>both</em> endpoints are provided, then the parser generator will report that it doesnât know which of the two productions to use, because both match! This is a phenomenon I think of as a âbenign ambiguityâ: the grammar is formally ambiguous, but both parses translate into the same AST, so it doesnât really matter. Even so, one normally wants to avoid even <em>formal</em> ambiguities, to keep the parser generator happy, so perhaps we write this instead:</p>
<p>interval â [ endpointopt , endpoint ]</p>
<p>interval â [ endpoint , ]</p>
<p>This is formally unambiguous, because the rules clearly canât both match: the first rule only matches intervals where the right endpoint is present, and the second only matches where the right endpoint is absent.</p>
<p>But now try translating this into pure LR, where youâre not allowed the âoptionalâ suffix. You get this:</p>
<p>interval â [ endpoint-opt , endpoint ]</p>
<p>interval â [ endpoint , ]</p>
<p>endpoint-opt â endpoint</p>
<p>endpoint-opt â Îµ</p>
<p>This grammar is unambiguous, and avoids using any extensions of the CFG concept. But, annoyingly, itâs not LR(1)!</p>
<p>An LR parser for this grammar, if itâs given an input in which the first interval endpoint is present, will reach a state in which it has [ endpoint on its parse stack, and is looking at the , that follows it. Now it must make a decision: shift the , immediately, or reduce the endpoint into an endpoint-opt first?</p>
<p>Whichever way it decides, it might regret it when it sees the next symbol. If thereâs another endpoint, then it will need to have reduced the first one into an endpoint-opt; if there isnât, it will need <em>not</em> to have done that. And it canât go back and change its mind once it finds out which: the LR parsing system only permits reductions at the top of the parse stack. Once youâve shifted the , on top, itâs too late to go back and do a reduction lower down.</p>
<p>In this case, the grammar isnât LR(1), but it <em>is</em> LR(2): with <em>two</em> tokens of lookahead, the parser could see whether the token following the , is a ] or not, and make its decision based on that. But in a more complicated case where the separating , token is replaced by some other nonterminal that can expand to arbitrarily many tokens, a grammar of this kind wouldnât be LR(<em>anything</em>).</p>
<p>If you get into this kind of situation when designing your grammar, there are a couple of ways to fix it. One is to avoid using an intermediate nonterminal, by instead expanding out the two possibilities in full as parallel productions for interval:</p>
<p>interval â [ endpoint , endpoint ]</p>
<p>interval â [ , endpoint ]</p>
<p>interval â [ endpoint , ]</p>
<p>That avoids the indecision between endpoint and endpoint-opt, because there <em>is</em> no endpoint-opt any more. But itâs more verbose, and makes the grammar harder to maintain or read. (Imagine if you had to do this to more than two optional things â say, the three clauses of a C <code>for</code> statement. Youâd expand into 8 separate productions, or whatever subset of them you wanted.)</p>
<p>Perhaps a <em>better</em> approach is to make the grammar deliberately match <em>too much</em> , by not forbidding the case where both endpoints are missing! Then you only need one production for interval (plus the definition of endpoint-opt as above):</p>
<p>interval â [ endpoint-opt , endpoint-opt ]</p>
<p>Of course, now your parser will accept some token sequences that you didnât intend to be legal. But you can detect them afterwards, when you examine the finished parse tree (or eagerly in a Bison action at the moment of the reduction, if you prefer), and give a custom error message of your own instead of relying on the parser generatorâs general method of reporting syntax errors. That seems inelegant because now you need an extra error-checking pass on top of your autogenerated parser â but donât forget that in any nontrivial language youâre likely to follow up the parsing phase with a lot of semantic analysis and error checking anyway: matching up variable references to definitions, figuring out the type of everything, and reporting errors if anything doesnât match. So this is just another check that goes into the semantic analysis phase. Plus, writing the message yourself allows you to make it clearer to a reader: you can explain âan interval must specify at least one of its endpointsâ instead of just âparse error, expected [some token]â.</p>
<p>There is one parsing strategy that will <em>never</em> require you to contort your grammar in the ways described in this section (although you still have to worry about the things in the <em>previous</em> section, where you have to contort the grammar just to make it unambiguous in the first place). Thatâs the <a href="https://en.wikipedia.org/wiki/Earley_parser">Earley parser</a>, which can handle any context-free grammar at all, without insisting that you convert it into any particular restricted form. But you pay for it in speed: an Earley parser can take quadratic time to run (or cubic if the grammar is ambiguous). I donât know of anyone whoâs actually taken this option in a production compiler.</p>
<h2 id="you-probably-want-to-handwrite-your-production-parser">You probably want to handwrite your production parser<a class="headerlink" href="#you-probably-want-to-handwrite-your-production-parser" title="Permanent link">&para;</a></h2>
<p>Automated parser generators sound like a great way to write parsers. They have the same advantages as automating anything else: faster, easier, and less chance of human error.</p>
<p>But generally, if youâre writing a <em>serious</em> tool that involves a parser â one that you hope will be used by many users, because you aim for it to become a widely used free software project, or are going to sell it to paying customers â it isnât a good idea to use an autogenerated parser.</p>
<p>For example, GCC â the very widely used GNU C compiler â started off using autogenerated parsers, but switched to handwritten ones (in <a href="https://gcc.gnu.org/gcc-3.4/changes.html#cplusplus">GCC 3.4</a> for C++, and in <a href="https://gcc.gnu.org/gcc-4.1/changes.html">GCC 4.1</a> for C).</p>
<p>There are a couple of reasons why you might do this. One is that it gives you greater flexibility to keep the parser working if the language spec does something weird: if the next version of C decides to have a grammar that doesnât go through <code>yacc</code> successfully any more, youâll be glad you didnât commit 100% to <code>yacc</code> as your parsing strategy. (I expect that was why GCC had to rewrite their C++ parser more urgently than C.)</p>
<p>But the really big reason is that autogenerated parsers just donât write good error messages.</p>
<p>Automated parser generators are usually very good at reliable error <em>detection</em>. For example, the LR algorithm will report an error on precisely the first input symbol which rules out the possibility that the input can be continued in any way that completes a syntactically legal program. But when it comes to explaining to the user what the error <em>is</em> , theyâre not so great.</p>
<p>Traditional Yacc would just report something content-free like âparse errorâ: it would cite a specific location in the input, but beyond that, it was up to you to work out what the problem was. More up-to-date Bison can manage âI expected one of [these] tokens, but saw [this] one insteadâ, which is at least a bit more information than the content-free âparse errorâ, but it can still be difficult for a user to understand <em>why</em> the parser was expecting a different set of tokens, because it canât say anything about what context it thought those tokens were in.</p>
<p>Hereâs a concrete example. Suppose youâre writing a parser for C. In C, function definitions canât be nested. Now suppose a user has written some code like this, which accidentally leaves out the closing brace of a <code>for</code> statement:</p>
<div class="language-text highlight"><pre><span></span><code>int first_function(int *array, size_t size) {
    int result = 0;
    for (size_t i = 0; i &lt; size; i++) {
        result *= 37;
        result += array[i];
    // here the user should have written } but accidentally didnât
}

int second_function(void) {
    return 42;
}
</code></pre></div>
<p>Any parser that consumes the source file from start to end will be happy as far as the opening brace of <code>second_function</code>. But that brace is syntactically invalid, because according to the actual source file, weâre still inside <code>first_function</code> at this point (we need to see another <code>}</code> to finish it), and you canât start defining a function inside another function.</p>
<p>The <em>ideal</em> compiler error message in this situation would point at the location at the end of the <code>for</code> statement in <code>first_function</code>, where the missing brace should be. But it would take a truly mind-reading C compiler to reliably give <em>that</em> error message! It might be possible to suggest a likely error location based on the indentation, but not with 100% certainty.</p>
<p>If youâre not imagining a mind-reading compiler, then youâre probably constrained to give an error message pointing at the place where the parser stopped being able to make sense of the code: the opening brace of <code>second_function</code>. What should the message say?</p>
<p>I think a reasonable error message is something like âyou canât define a function inside another functionâ. The location we point at is not where the actual mistake is, but the user will see this message and think âWait, why do you think this is inside another function? Itâs supposed to be at the top level. Perhaps I havenât closed all the braces?â They may not instantly know where to look for the missing <code>}</code>, but the hint that the parser <em>thinks</em> itâs still inside a function is enough to make them go and look for one <em>somewhere.</em></p>
<p>But an automated parser generator, with automated error messages, would only be able to point at the brace and report something like âParse error, expected <code>;</code> or <code>,</code> insteadâ. (A semicolon in place of the brace would make <code>int second_function(void);</code> a <em>declaration</em> â stating that a function exists and what its type is, but not providing its body â and function declarations <em>are</em> legal inside a function. A comma would be fine too, because a declaration can contain a comma-separated list of things to declare.)</p>
<p>So, given <em>that</em> error message, the user has to solve a puzzle game: given <em>that</em> list of acceptable next tokens, what context does the parser imagine itâs in?</p>
<p>To some extent this difficulty is inherent in the LR parsing techniques, because part of the point of the LR automaton is to keep an open mind until the last minute about <em>what</em> context itâs in. In terms of being able to parse a larger set of grammars, this is precisely LRâs <em>advantage</em> over LL: LL needs to be able to tell near the start of a statement what kind of statement it is, but in many cases LR can deal with not knowing the answer until the end, or even one symbol <em>after</em> the end. So even if a user was happy to receive a description of context in terms of the grammar symbols rather than natural language, LR would still have trouble, because it canât always narrow down to just one.</p>
<p>LL techniques narrow down to a single context earlier, so it would be easier to give a message describing that context. Indeed, handwritten recursive-descent parsers are often <em>structured</em> in the LL style, allowing the author to know enough about the context to think of a good wording for each error message. But itâs still hard for an automated parser to produce a <em>human-readable</em> description of the context. (Perhaps you could annotate a formal LL grammar with text descriptions of contexts which could be included in autogenerated error messages? But Iâve never seen this approach tried.)</p>
<p>So if weâre not going to use automated parser generators in our final production compilers, are they good for anything at all?</p>
<p>Yes, I think they still are. Theyâre good for rapid development â getting a parser up and running in the first place <em>before</em> it reaches production quality, or one thatâs never going to need to reach production quality at all. But also, more importantly, theyâre good during language <em>design</em> , when you havenât finalised the language syntax yet and keep changing your mind. Iâll discuss that in a <a href="design">later section</a>.</p>
<h2 id="name-a-parser-generation-technology-in-your-language-spec">Name a parser generation technology in your language spec<a class="headerlink" href="#name-a-parser-generation-technology-in-your-language-spec" title="Permanent link">&para;</a></h2>
<p>In a previous section Iâve described various ways in which a context-free grammar has to be written in a different style, depending on what parsing tool you intend to feed it to. In other words, not every context-free grammar is suitable for every parsing tool.</p>
<p>So, suppose Iâm reading the specification for a programming language, and it describes the language syntax using a context-free grammar. If Iâm planning to write an implementation, then probably one of the first things I might do is to feed that grammar to a parsing tool, to autogenerate a parser for it.</p>
<p>(As I said earlier, I might well not keep that parser for ever. But itâs useful to get <em>some</em> kind of parser up and running quickly; I can polish it later, once all the more interesting parts of my implementation are working.)</p>
<p>OK â so <em>which</em> parsing tool do I feed your language specâs grammar to? It probably wonât work with all of them, for all the reasons I mentioned earlier â left versus right recursion, extensions of the CFG notation, etc.</p>
<p>One particular annoyance in a language specification is if it provides a context-free grammar and <em>doesnât say</em> what parsing technology the author thinks that grammar is compatible with. Now Iâve got to solve a puzzle game! Maybe Iâll study the grammar rules looking for left-recursion (which would mean the LL algorithm canât handle it), or notice whether there are any âoptionalâ or ârepeatedâ markers (LR systems usually donât provide those). Or maybe I just paste the grammar into every tool I can find and see which one doesnât give an error message.</p>
<p>Thereâs no purpose to making every implementor solve this puzzle game. The author of the grammar surely <em>knew</em> of a specific parsing tool that itâs compatible with. All they had to do was <em>write that down!</em></p>
<p>So my ranty opinion is: <strong>if you include a BNF grammar in your language spec, state what technology you expect it to be compatible with.</strong></p>
<p>As Iâll discuss in the next section, <em>I</em> think that the best choice is LR. But if you donât like LR for some reason â even if you prefer LL, or PEGs, or something I havenât even thought of â then say what you <em>did</em> use.</p>
<p>Better still, provide the grammar <strong>in a machine-readable form</strong> 3Since Iâve used C as an example already in this article: the C standard scores one out of two points here. Annex A of the C standard provides a full context-free grammar, and states specifically that itâs acceptable to <code>yacc</code>, i.e. to the LALR algorithm. Or rather, itâs <em>nearly</em> LALR; thereâs a parsing action conflict due to the if-else ambiguity, and a fundamental issue with <code>typedef</code> which requires the parser to feed back to the lexer â but the standard warns you about both of those things. Thatâs all fine; top marks. On the other hand, you do have to paste the grammar out of the PDF and fix up paste issues, because the C standard (unlike C++) isnât available in the form of the input markup, only the PDF standard.3. Donât make everyone copy-type the grammar out of the PDF, or copy-paste it and then have to fix up all the paste wreckage. Not every parsing tool accepts the same exact syntax for grammars, but if you provide <em>some</em> machine-readable form of the grammar, it can easily be autoconverted into the syntax of a particular parser generator, with not much risk of introducing typos.</p>
<p>Another advantage of having your reference grammar in a machine-readable form is that <em>you</em> can feed it to an actual parser generator. If your chosen parsing technology is one which proves the grammar is unambiguous (like LR or LL), then this gives you (the specification author) an extra assurance that <em>you</em> didnât make a typo and write an unimplementable specification. You could also check your grammar against a set of reference inputs, to make sure it really says what you wanted it to say (and you didnât, for example, accidentally write a grammar that expects two ; in a row, as I discussed earlier in the C <code>for</code> statement).</p>
<p>(Even if your choice of parsing technology isnât self-checking, like a PEG, I think itâs still worth doing this. You still get <em>some</em> checking â you at least check that the PEG parser tool doesnât report any more obvious kinds of error like a nonterminal you completely forgot to define. And you can still check your grammar against the test inputs.)</p>
<p>So ranty opinion #2 for language spec writers is: <strong>test your reference grammar before writing it in the spec</strong>. Ideally via a check that runs at typesetting time, to ensure you canât even build the specification PDF at all until the grammar in it is sensible.</p>
<h2 id="use-lr-parser-generators-during-language-design">Use LR parser generators during language design<a class="headerlink" href="#use-lr-parser-generators-during-language-design" title="Permanent link">&para;</a></h2>
<p>Iâve discussed the use of formal grammars and parser generators in language <em>specifications</em> , when someone has already designed the language and youâre writing it down as precisely as you can. And Iâve discussed their use in <em>implementations</em>.</p>
<p>But thereâs another place I think parser generators are useful â perhaps even <em>more</em> useful â and thatâs when youâre <em>designing</em> a language in the first place, and coevolving the design, the initial test implementation, and the corpus of example input programs. If youâre changing your mind about the language syntax every day, or several times a day, the rapid-development advantages of an automated parser generator become overwhelming.</p>
<p>I think LR parser generators are a particularly good tool for this job â the best one I currently know of.</p>
<h3 id="because-they-can-point-out-design-errors">Because they can point out design errors<a class="headerlink" href="#because-they-can-point-out-design-errors" title="Permanent link">&para;</a></h3>
<p>When youâre designing a language syntax, itâs easy to introduce ambiguities by mistake.</p>
<p>For example (as I mentioned above in a fine-details section): in C, the comma is a valid binary operator in expressions. But arguments in a function call are also separated by commas. If you were designing a language with both of those properties, and youâd absentmindedly written your grammar to say that a function call contains a comma-separated list of expression inside the brackets, then youâd have written an ambiguity, perhaps without even noticing. You meant to say (and the real C grammar <em>does</em> say) that if a comma operator occurs within a function argument, it must be protected by parentheses, to prevent it from being taken to be an argument separator.</p>
<p>Itâs helpful to catch things like this early, by running your draft grammar through a tool which can check that itâs unambiguous. Unfortunately, the general problem of checking a context-free grammar for ambiguity is formally undecidable. (Not even just âNP-completeâ â no algorithm, not <em>even</em> a slow one, can do it reliably.) So your best bet is to restrict yourself to some subclass of grammars which <em>can</em> be checked for ambiguity.</p>
<p>Some parser generation algorithms can detect and report ambiguity in their input grammar. LL and LR both can. Of those, LR can handle a strict superset of grammars; so my personal preference â and my advice to anyone else undecided â is to commit to making your languageâs grammar some form of LR, and verifying your draft grammars using an LR parser generator.</p>
<p>Another popular grammar formalism is a PEG. This has some superficially nice properties, like being able to fold lexing and parsing into one unified whole. But one thing I really dislike about it is that it completely lacks the much more important property of pointing out mistakes in the grammar design. <em>By definition</em> , a PEG has no ambiguities, because any time a nonterminal has two or more productions, the grammar author must prioritise them, so that if both productions <em>could</em> match a given input string, the grammar specifies which one <em>does</em> match it.</p>
<p>As a result, thereâs no way for the grammar author to <em>find out</em> that two of their productions are capable of matching the same input string. During the design of a language syntax, thatâs a thing you might very easily do <em>by mistake</em> , and want to find out about, so that you can fix it!</p>
<p>For this same reason, I dislike parser-generator features that accept ambiguities in the grammar and specify how to resolve them, like <code>%prec</code>. Those arenât <em>so</em> bad, because at least you wait to find out about each specific ambiguity, and decide whether to fix it or to use <code>%prec</code> to resolve it on purpose. But it seems to me that thereâs still some risk of accidentally missing a case.</p>
<p>Thereâs another reason I dislike leaving formal ambiguities in your LR grammar, which Iâll mention later.</p>
<h3 id="because-they-can-generate-test-cases">Because they can generate test cases<a class="headerlink" href="#because-they-can-generate-test-cases" title="Permanent link">&para;</a></h3>
<p>I mentioned earlier that production compilers often donât autogenerate their parsers from a grammar using an LR parser generator, because if you handwrite the parser, you can handwrite its error reporting too, and often do a better job.</p>
<p>But of course when you hand-write something, thereâs a risk of mistakes, compared to (traditional, formal, reliable forms of) computer generation. If youâre hand-writing a pile of code which you <em>could</em> have used a generation tool for instead, you want to have some way of checking you didnât introduce bugs.</p>
<p>Well, another thing LR parsing automatons are good for is generating test cases. If you have a reference grammar for your language which is compatible with an LR generator, you can use the state machine output from the grammar as a test-case constructor, by finding a path from the start state to every possible state and to every possible transition. For each of those paths, you can automatically generate a full syntactically legal string of tokens and its expected formal parse tree. If your handwritten parser can parse all of those in the expected way, that should give you pretty good confidence.</p>
<p>Not only that, but in a similar way, you can also generate a path from the start state to every possible <em>illegal</em> state transition, creating a similarly exhaustive set of error tests, to check that your handwritten parser <em>rejects</em> all the things it ought to reject, as well as accepting the things it ought to accept.</p>
<p>However, this technique doesnât play nicely with <code>%prec</code> â see  later.</p>
<h2 id="stop-doing-lalr">Stop doing LALR<a class="headerlink" href="#stop-doing-lalr" title="Permanent link">&para;</a></h2>
<p>LR parsers were not supposed to have mysterious conflicts!</p>
<p>Perhaps the most famous book about compilers is the âdragon bookâ, which I mentioned in the introduction as my own first reading on the subject. (Itâs properly known as Compilers: Principles, Techniques and Tools; the colloquial name is because itâs traditionally had a picture of a dragon on the cover.) The parsing chapter ends in a presentation of LR-based techniques, and gives a choice of two4OK, three: they also present SLR, which is a <em>particularly</em> horrible bodge and doesnât really deserve mentioning.4: CLR (or âcanonical LRâ), and LALR (âlookahead LRâ). The tradeoff is that LALR produces a much smaller state machine, but fails on a small class of languages, by introducing âmysterious conflictsâ which are a consequence of a bug in the generation algorithm and not a genuine problem with the grammar. CLR avoids those mysterious conflicts, but you pay for it by increasing the size of the parsing tables by a large factor.</p>
<p>The dragon book was published in 1986, and has a second edition dated 2007. But its presentation of LR parsing was out of date even the first time round. In 1977, David Pager published the paper âA Practical General Method for Constructing LR(<em>k</em>) Parsersâ, which presents a technique for avoiding the dilemma: it lets you construct parsing tables almost as small as LALRâs, without the bug that introduces spurious conflicts.</p>
<p>This ought to be the LR algorithm <em>everyone</em> is using (or descendants of it that share those good properties). But well known books ignore it, and widely used parser generators are <em>still</em> using LALR instead of Pagerâs PGM! At least, by default. For example, in GNU Bison, you can write â<code>%define lr.type ielr</code>â to avoid LALRâs bug (IELR is a later algorithm descended from PGM), but you have to ask for it â if you donât ask, you can still get error messages about reduce/reduce conflicts in situations where it wasnât actually your fault.</p>
<p>Fair enough, the dragon book is not the last word in books <em>about parsing</em>. If youâre a parsing specialist, or want to become one, then I expect you look at a book <em>all</em> about parsing, instead of a general compilers work like the dragon book in which parsing is just one chapter. Iâm sure that specialist parsing books havenât overlooked PGM and its descendants. But non-specialists will probably go for the more general overview, and it seems wrong to mislead them all into thinking this is still a problem!</p>
<p>Gory details: a non-LALR grammar, and brief discussion of Pagerâs PGM</p>
<p>Hereâs a concrete example of a small non-LALR grammar, describing English-language commands to read and write a file, given one variable containing the file name and another containing (or receiving) the fileâs contents. Anticipating that users might not all agree on the natural order to write one of these commands, the syntax allows you to put the two inputs either way round, with a preposition in the middle indicating which way they are:</p>
<p>command â write data to file</p>
<p>command â write file from data</p>
<p>command â read data from file</p>
<p>command â read file to data</p>
<p>file â IDENTIFIER</p>
<p>data â IDENTIFIER</p>
<p>When the parser receives any of these four types of commands as input, it will reach a point where itâs seen the initial verb (write or read), and then an IDENTIFIER, and it must decide whether to reduce the identifier to a data nonterminal or to a file. It must do this based on the <em>next</em> token of lookahead (which is either to or from), but it must also remember which verb itâs parsing, because those two tokens work the opposite way round in the two commands: the lookahead to indicates that the thing before it is data if the verb was write, but file if the verb was read, and similarly for from.</p>
<p>CLR has no trouble with this. Its parsing state machine has separate states depending on the verb, and in each state, the parser generator can write the appropriate reduction for the lookaheads to and from. But LALR merges those two states into one, so that â intuitively â the parser has temporarily âforgottenâ which verb started the command. (Itâs still somewhere on the parse stack, but reduction decisions are made entirely based on the current automaton state.) So a LALR parser generator throws up its hands and says it canât decide which reduction to perform if it sees to, or if it sees from.</p>
<p>But this is LALRâs own fault, for merging the states! All it had to do was <em>not do that</em> , and it would have been fine.</p>
<p>(In this case, a workaround would be to change the grammar so that it doesnât have separate nonterminals for data and file. Instead, just write all four top-level productions for command so that each one has two explicit IDENTIFIERs. Once the parser has found out which of the four commands itâs dealing with, <em>then</em> it knows which identifier is the data and which is the file name. But this is a workaround for a parser generation bug that shouldnât have existed in the first place: itâs not <em>wrong</em> to write the grammar as Iâve shown it above â and it might be necessary, if each of file and data had some <em>extra</em> productions that allowed them to be specified in syntactically different ways from each other. Better is to fix the generator so that the grammar author doesnât have to work around the bug in the first place.)</p>
<p>OK, what <em>is</em> Pagerâs PGM?</p>
<p>One way to understand LALR (though not the only way) is that it effectively generates all the states of the larger CLR automaton, but as it generates each one, it merges it into a previous state if it can. Thereâs a basic compatibility constraint that says when two states are <em>candidates</em> for potential merging, which Iâll describe below. LALR simply merges <em>all</em> pairs of states which meet that basic constraint, without checking to see if that introduces a more subtle bug. On the other hand, CLR <em>never</em> merges states of its automaton, so it avoids introducing any bugs of that kind, but you end up with a <em>much</em> larger number of states, hence a huge lookup table.</p>
<p>What you want is to merge states <em>whenever itâs safe</em> , but detect and avoid the rare cases like this where it isnât safe. Then you get the same space saving as LALR (or very nearly), but your parser still <em>works properly</em>.</p>
<p>Pagerâs paper presents two different techniques for detecting when itâs safe to merge states, described as âweakâ and âstrongâ. The strong one is more precise: it will only detect genuine unsafety. So youâll end up with the same minimal-sized parsing table as LALR, in any case where LALR <em>doesnât</em> introduce a bogus conflict; it only adds extra states to the state machine when theyâre absolutely necessary to prevent a bug. But the strong algorithm is fairly complicated, and tricky to get right.</p>
<p>Pagerâs weak algorithm is a conservative approximation, <em>much</em> simpler to calculate. It will sometimes err on the side of caution, and refuse to merge two states when it would actually have been perfectly safe. But this happens rarely: a weak-PGM automaton might have 2 states more than the smallest possible LALR one, when the CLR automaton might have five <em>times</em> more. So this is absolutely fine in practice.</p>
<p>The weak algorithm can be <em>described</em> quite quickly, at least for LR(1), though I donât have space here to go into the details of <em>why</em> it works. Two CLR states are candidates for merging if they contain exactly the same set of âmarked productionsâ. (Thatâs a production of the grammar, with a mark indicating how far through it the parser currently is, either between two symbols or at the start or end. In textbooks itâs usually written with a â¢ showing the mark, like foo â bar â¢ baz; in an implementation the mark is more likely to be a numeric index into the array representing the productionâs right-hand side.) A CLR state augments each marked production with a collection of possible <em>contexts</em> â possible tokens that could come after the end of the grammar symbol described by the production. The weak PGM condition is: itâs safe to merge states if, after the merge, no two marked productions have a context token in common <em>unless</em> they had that context in common already in one of the two original states before merging them.</p>
<p>In the example above, the two CLR states that are dangerous to merge are the ones containing the marked productions file â IDENTIFIER â¢ and data â IDENTIFIER â¢. In each case the â¢ is at the end, indicating that in this state weâve already seen all the tokens making up the file or the data, and our next action will be a reduction. Each of these two CLR states assigns the context token to to one of those marked productions and from to the other â but opposite ways round. So if you merge them, then you end up with to being a valid context token for <em>both</em> productions, and similarly from. If each context had appeared on both productions in one of the <em>original</em> states, then it would still be OK to merge them, because either the shared context wasnât a problem at all, or it was going to be a problem even in CLR. But here, <em>neither</em> context token is shared between the two productions in the original states, and itâs only the merging that introduces the clash. Therefore, itâs dangerous â donât merge those states!</p>
<h2 id="grammars-should-be-synthetic-as-well-as-analytic">Grammars should be synthetic as well as analytic<a class="headerlink" href="#grammars-should-be-synthetic-as-well-as-analytic" title="Permanent link">&para;</a></h2>
<p>Context-free grammar terminology is full of words like âstart symbolâ, âproductionâ, ânonterminal symbolâ and âterminal symbolâ. All of these words suggest that youâre <em>starting</em> from a single most-generic symbol representing âa whole programâ, and expanding it gradually â by <em>producing</em> extra symbols â into a more and more detailed description of some specific program. A <em>non-terminal</em> symbol is one that indicates that you havenât finished yet. When everything in the string is a <em>terminal</em> symbol, the <em>production</em> of code has terminated.</p>
<p>Itâs odd that the terminology should be that way round, because of course <em>most</em> uses of a grammar formalism are exactly the other way round! You use a grammar to generate a parser, and a parser doesnât <em>create</em> a program: it <em>receives</em> one as input, and tries to make sense of it, by breaking it up into its component parts and mapping the hierarchy of parts and sub-parts and sub-sub-parts. The normal use of a grammar for parsing is <em>analytic</em> , even though the terminology all suggests grammars are supposed to be <em>synthetic</em>.</p>
<p>But the synthetic use of grammars is actually useful. The ability to start from a parse tree and transform it into a program has two uses I can think of, and there are very likely more.</p>
<p>Firstly, the test-case generator I mentioned <a href="test-generator">in a previous section</a>: if you have an LR grammar, then by an easy search through its parsing automaton, you can autogenerate a set of complete input sequences that between them exercise every shift and reduction, and every illegal token in every automaton state. Then you can use those as test cases for another parser (say, a handwritten one with nicer error messages) thatâs supposed to accept exactly the same grammar.</p>
<p>But this only works if <em>every</em> formal parse tree that you can make out of the grammar productions, translated into a token sequence in the obvious way, is a legal string of the language and parses back into the same parse tree. If thatâs not true, then your corpus of autogenerated test cases will contain some invalid ones, and now you have to go through and figure out which ones they are!</p>
<p>So thatâs the other reason I mentioned earlier why Iâm not a fan of the common pattern of having an ambiguous grammar plus hints to the parser generator about which way to resolve the ambiguities. The use of <code>%prec</code> in Bison to specify your operator precedences, or the entirely implicit resolution of the if-else ambiguity by relying on Bisonâs default of taking the shift action if thereâs a shift/reduce conflict, have exactly this effect: it makes the grammar <em>only</em> good for parsing an input token sequence, and no longer reliable for generating an output one. It makes your grammar only analytic, where it should be both analytic <em>and</em> synthetic.</p>
<p>You could âsolveâ this by a round-trip test: after you autogenerate your test cases by exploring the parsing automaton, run all of them back through the reference LR parser, and filter out the ones which donât deliver an output parse tree identical to the input one. But now you have some edge cases of the LR automaton that you donât have tests for any more. If the grammar had been formally unambiguous in the first place, then your collection of test cases would be complete.</p>
<p>(On the other hand, perhaps the <em>misleading</em> test cases â where one formal parse tree round-trips to a different one â might be worthwhile in their own right, because they precisely test that some other parser <em>does</em> resolve the ambiguities correctly? But I donât think you can <em>rely</em> on this generation technique finding all the cases that are difficult in that sense. You probably do better by thinking those up yourself.)</p>
<p>A second application for generative use of grammars starts from an <em>abstract</em> syntax tree, rather than a formal parse tree. The difference is that a formal parse tree is tightly tied to the details of the grammar, with each node naming a specific grammar production and having one child node for each nonterminal on its RHS, whereas an AST simplifies away as many details as possible of the syntax and reduces to <em>just</em> enough information to convey the semantics. For example, parentheses around a subexpression would show up as a node in the formal parse tree, naming some production like atomic-expression â ( expression ); but the AST representation of an expression has no node at all for the parentheses, because theyâre not needed to determine the semantics of the expression. Both <code>1+2*3</code> and <code>1+(2*3)</code> would be represented as the same AST, consisting of an addition node with one of its children being a multiplication.</p>
<p>The usefulness of <em>abstracting</em> away the details of syntax to make a cut-down AST is that you might have <em>two</em> grammars for different language syntaxes, both mapping to the same AST â and then you could automatically translate from one syntax into the other, by parsing an input file into an AST via one grammar, and âunparsingâ again via the other grammar. (You couldnât really have two different grammars deliver the same <em>formal</em> parse tree, because the formal parse tree includes so many details of the grammar.)</p>
<p>Itâs probably not useful to use this to translate between two completely different programming languages, because the semantics too would differ too much. But I could see it being useful during language design. Suppose Iâve got a draft language grammar, and a bunch of test programs written in that language. Now I change my mind about the grammar, because it was only a draft. Iâve got to rewrite all my test programs, probably by hand! But if both the old and new grammars provided a mapping to the same AST representation, then I could do the rewriting automatically, by parsing each input program to the common AST using the old grammar, and then unparsing again using the new grammar.</p>
<p>In this application you probably have to augment your grammar with some hints about how to wrap up a thing safely, because it might be too much to expect the automation to figure it out in every case. If your production for wrapping a subexpression in parentheses indicates that the parenthesised expression has the same semantics as the expression inside the parens, then maybe the parser can figure that one out by itself; but itâs harder to figure out that (for example) the way to protect an if-without-else statement inside another if is to wrap it in braces, because the production for wrapping a thing in braces accepts <em>multiple</em> statements.</p>
<p>But, again, this entire technique only works if the grammar guarantees that any token sequence you can make by following productions from the start symbol <em>is</em> valid and parses as you expect. So this too only works if youâve avoided the use of <code>%prec</code> or implicit conflict resolutions.</p>
<h2 id="ok-what-should-you-do">OK, what <em>should</em> you do?<a class="headerlink" href="#ok-what-should-you-do" title="Permanent link">&para;</a></h2>
<p>Iâve painted myself into a bit of a corner by now.</p>
<p>On the one hand, I think you should write your languageâs reference grammar in the form of an <em>unambiguous</em> CFG, without using ambiguity-resolving features like <code>%prec</code>. On the other hand, I donât like the way that, if you do that, your grammar looks like a complicated computer program rather than a natural and declarative description of the underlying ideas in the syntax, so that you risk introducing bugs while writing your spec, and itâs difficult to learn the language by reading it.</p>
<p>Sounds as if Iâve found a reason not to like <em>anything!</em></p>
<p>And itâs true â every well-known way of dealing with grammars is a bit unsatisfactory. If this collection of thoughts has an overall point, itâs not so much that people use CFGs wrongly, but that thereâs no <em>really good</em> way to use them at all. Everything has downsides.</p>
<p>Well, in computing, if you think somethingâs hard to use, you can always try to redesign it better. You may not succeed, but at least you can try. So, if I were designing a language, what alternatives might I consider trying?</p>
<p>I have a couple of thoughts about this, but Iâve never tried out either for real, so they might turn out not to work. (Also either or both of them might very well have been done by someone else â I donât have a deep knowledge of the current state of the art.)</p>
<h3 id="compile-a-simpler-form-into-an-lr-grammar">Compile a simpler form into an LR grammar?<a class="headerlink" href="#compile-a-simpler-form-into-an-lr-grammar" title="Permanent link">&para;</a></h3>
<p>One option Iâve considered is to decouple the grammar you actually <em>write</em> from the formally unambiguous grammar you use for all the automation purposes â test case generation, unparsing from an AST, making a reference parser for implementors to compare against.</p>
<p>I mentioned in an earlier section some standard things you often want to write in a language spec, which are complicated to represent as an unambiguous CFG. So one possibility is to have some kind of macro library that automatically generates the tedious parts of the grammar. For example, you might write down your table of infix operators with their precedence levels and associativity, and then pass that table as input to a macro that autogenerates a nonterminal for each precedence level, saving any human from having to write all that boilerplate.</p>
<p>Macros are ugly, though. Perhaps a more interesting idea is to have a kind of grammar compiler which takes a CFG augmented with ambiguity-resolution rules as input, and outputs a plain unambiguous one? Then you could write your <code>%prec</code> directives, or something quite similar, and still get all the advantages of a pure, unambiguous, synthetic CFG, because the compiler output <em>would</em> be one of those.</p>
<p>I havenât worked out the details of what such a compiler would look like, though! I think the starting point would be to <em>try</em> making an LR automaton out of the input grammar, and see where the ambiguities arise. Then youâd make local tweaks to the grammar to fix each one in accordance with the userâs directives.</p>
<p>In both of my example cases â operator precedence and the if-else ambiguity â the usual solution is to clone nonterminals. The ambiguous grammar has just one nonterminal for statement or expression, and the unambiguous version has multiple ones, for a balanced or unbalanced statement, or for an expression at a particular level of the precedence hierarchy. So I think the basic idea would be that any time you see a conflict between two productions, you find a nonterminal involved with the conflict, split it into two clones, and assign one of the conflicting actions to each clone. Then you try â¦ errrr, <em>somehow</em> â¦ to decide which clone to use where, in the rest of the grammar, in such a way that the choice of parses ends up corresponding to the userâs intended resolution of the ambiguity.</p>
<p>But, as you can tell, I havenât thought this out in full!</p>
<p>Another possible approach, which I also havenât thought out fully, might be to start by processing the input grammar into the same LR automaton that Bison would output, with all the conflicts resolved according to the precedence directives, and then try to reconstruct a completely different unambiguous CFG that matches the language <em>really</em> recognised by that automaton. My intuitive sense is that thatâs probably either fairly easy, or formally undecidable, but I canât quite work out which. If it could be done, though, it would allow any analytic-only grammar to be turned back into a synthetic one, which would be very nice.</p>
<h3 id="lr-with-attributes">LR with attributes?<a class="headerlink" href="#lr-with-attributes" title="Permanent link">&para;</a></h3>
<p>Hereâs a different thought Iâve had about this, which requires extending the concept of what a grammar <em>is</em>. I havenât got an implementation of this working either, but if I had a spare year to work on stuff like this, Iâd like to give it a try.</p>
<p>Iâll start by showing an example of a completely naÃ¯ve context-free grammar, representing a simple syntax for infix expressions, involving only binary operators and some kind of atomic subexpression like a variable or a constant. (A real grammar would probably have some unary operators too, and also support parenthesised subexpressions, but this is enough to show the idea I have in mind.)</p>
<p>expr â ATOM</p>
<p>expr â expr BINOP expr</p>
<p>This grammar is <em>of course</em> ambiguous. If you feed it to Bison, it will report a shift/reduce conflict, in the obvious location: if you have expr BINOP expr on the parse stack already, and you see another BINOP next, do you reduce the existing three symbols into a higher-order expr, or do you shift the second BINOP in order to reduce that one first?</p>
<p>Of course, thereâs no fixed answer that works for all operators: it depends on the relative precedence of the two binary operators, or if those are the same, it tie-breaks on whether the operator is left- or right-associative.</p>
<p>Normally, youâd fix that by replacing BINOP with a whole set of more specific tokens, each representing a specific operator with a known precedence. Then, as Iâve discussed earlier, youâd either leave the conflicts in the theoretical grammar and use <code>%prec</code> to tell the parser generator which way you want them resolved during parsing, or else, youâd also replace expr with a set of more specific <em>nonterminals</em> , one for each precedence level.</p>
<p>What if you <em>didnât</em> split BINOP into lots of different token types?</p>
<p>Instead, annotate each BINOP with information about the operatorâs precedence, and also annotate each expr with similar information, based on the outermost (non-bracketed) operator in it. Then you have an augmented grammar that looks something like this:</p>
<p>exprâ¤ â ATOM</p>
<p>expr <em>Î²</em> â expr <em>Î±</em> BINOP <em>Î²</em> expr <em>Î³</em> provided that <em>Î±</em> â¥ <em>Î²</em> and <em>Î³</em> &gt; <em>Î²</em></p>
<p>where the Greek letters <em>Î±</em> , <em>Î²</em> , <em>Î³</em> represent elements of some ordered set of operator precedences, and â¤ represents an element that compares greater than the precedence of any actual operator. The constraints <em>Î±</em> â¥ <em>Î²</em> and <em>Î³</em> &gt; <em>Î²</em> on the second production enforce that higher-precedence operators are evaluated first. They also enforce that (in this example) all types of BINOP associate to the left, because the <em>left</em> operand to BINOP <em>Î²</em> is allowed to reuse the same precedence level <em>Î²</em> , whereas the right operand must have a strictly higher one. In a more complete example Iâd want to extend the annotations so that they also allowed each precedence level to be independently specified as left-, right- or non-associative, but this is enough for now.</p>
<p>My idea is that it should be possible to extend the LR(1) parser construction algorithm to operate on this kind of augmented grammar, in such a way that each automaton state carries some extra parameter variables and some required relationships between them, and annotates the stateâs marked productions and their contexts with those parameters. At some point in the automaton there will be a state that has to make the key decision: it contains the marked productions expr â expr â¢ BINOP expr and expr â expr BINOP expr â¢, and has to decide whether to shift or reduce if it sees BINOP next. Propagating the annotations through the automaton <em>ought</em> to arrange that each of those parsing actions is only valid according to some relationship between the annotation on the next BINOP and the annotations in the state parameters, and thus, resolve the conflict.</p>
<p>This relies on the parser generator being able to recognise that the conditions on the various actions are mutually exclusive. In this case, it has to <em>know</em> that precedence annotations on expr and BINOP are partially ordered, and therefore, that if it finds a shift action conditional on <em>Î²</em> â¥ <em>Î³</em> and a reduce action conditional on <em>Î²</em> &lt; <em>Î³</em> , it can be sure that thereâs no way both can be valid at once. That way it can still prove that the augmented grammar is unambiguous, even if it doesnât know anything else about what the annotations actually <em>are</em>.</p>
<p>This is a much more ambitious idea than the previous one, requiring a rethink of the whole concept of a context-free grammar. But if it can be done, it would deliver extra advantages.</p>
<p>To begin with, it restores the ability to write an infix grammar declaratively. You really <em>could</em> write down a childishly simple grammar for the actual expressions, and separately, write down a set of rules specifying the precedence and associativity of each operator â just like <code>%prec</code>, but in a way that still keeps the grammar synthetic as well as analytic. Perhaps youâd do that by turning BINOP into a nonterminal binop, and having a set of productions such as binop <em>Î±</em> â +, each one specifying an appropriate annotation <em>Î±</em> for that operator.</p>
<p>Similarly, you could sort out the if-else ambiguity without having to do any duplication or refactoring: you wouldnât have to separate statement into two nonterminals. Instead you could keep it as just one, with a boolean attribute âbalanced?â, and propagate balance through things like <code>while</code> loops by simply setting the flag to the same value on left and right:</p>
<p>statement <em>Î²</em> â while ( expression ) statement <em>Î²</em></p>
<p>But this system of annotations <em>also</em> opens up the possibility of augmenting the parser with code that figures out the annotations <em>at run time</em>. What if you wanted a programming language that would let you <em>reconfigure</em> the set of infix operators within a particular lexical scope, by adding new ones, or changing the priorities (because in some particular context the same symbols meant something different)? In this system, you could annotate each open scope (corresponding to some state on the parse stack) with configuration indicating how its operators had been reconfigured, and use the topmost stack state of that kind to choose the priority of each binary operator token. Because the parser automaton itself doesnât have to change at all to accommodate a different set of operators and different precedences, you can reconfigure them without having to regenerate the parser, even dynamically.</p>
<p>Similarly, a system of this kind would be able to solve the C <code>typedef</code> problem in a more principled way than the usual pragmatic approach. In the usual approach, the lexer keeps track of a list of tokens that are currently typedef names, and emits those to the parser as a separate token type, say TYPENAME in place of IDENTIFIER; the parser, when it processes the reduction that completes a typedef declaration, feeds the new name to the lexer to add to its set, and when it closes a scope, tells the lexer to discard new typedefs opened since the start of the scope. That setup relies on the precise flow of control between parser and lexer â if the parser notified the lexer <em>too late</em> about a new typedef or a scope closure, a token that should have been recognised as one thing would be misidentified as the other.</p>
<p>But in <em>this</em> setup, the lexer is kept simple. Identifiers and typedef names come from the lexer as a single token type. That token type has a boolean annotation, âis this a typedef name?â And the answer is determined only when the parser needs to know it, by searching up the <em>parse stack</em> for states annotated with an attribute saying theyâve brought a typedef name into scope. This automatically takes care of descoping typedefs when a scope closes, because those states are popped off the parse stack. And it no longer relies on the lexer and parser being tightly interleaved: you could lex the C program in whatever size block you happened to read from the source file, or even lex the <em>whole</em> translation unit in advance before even starting to parse the resulting list of tokens, and it would still work exactly the same.</p>
<h2 id="bodges-to-handle-non-lr-languages">Bodges to handle non-LR languages<a class="headerlink" href="#bodges-to-handle-non-lr-languages" title="Permanent link">&para;</a></h2>
<p>Thereâs a big problem with my recommendation that people should use a LR parser generator as a tool for language design: a lot of widely used modern languages <em>canât</em> be parsed by the orthodox strategy of a regex-based lexer followed by a pure LR grammar. In fact, when I tried to find an example of a well-known language which <em>can</em> be parsed using that strategy without any hacks, it was hard to find one! (Discussion among my friends eventually decided OCaml might qualify, although I donât know it well myself.)</p>
<p>There are lots of common reasons why not. Here are a few examples.</p>
<p>Type name ambiguity
    I mentioned this in the previous section: Câs grammar depends on the lexer knowing what typedefs are currently in scope, so that it can distinguish type names from variable names reliably. C and C++ arenât the only languages with this feature; some Pascal flavours have it too (at least the Borland-derived dialects â 1990s Turbo Pascal, Delphi, Free Pascal). Iâve even managed to <em>accidentally</em> design a language myself with a similar property: itâs a surprisingly easy mistake to make! (The expression language in <a href="https://www.chiark.greenend.org.uk/~sgtatham/spigot/">spigot</a> requires the lexer to tell variable and function names apart, which initially didnât seem worrying because the set of functions was fixed, but later I added the ability to define your own functions, oops).
Angle brackets vs shift operators
    In all of C++, Java and Rust, you write a parametric type by writing its parameters in angle brackets after it, like <code>std::vector&lt;int&gt;</code> or <code>Vec&lt;i32&gt;</code>. If the parameter type is parametrised in turn, you have to write two consecutive closing angle brackets, e.g. <code>Vec&lt;Option&lt;i32&gt;&gt;</code>. In this situation <code>&gt;&gt;</code> wants to be treated as two separate âclosing angle bracketâ tokens â but in a different context, <code>&gt;&gt;</code> is the right-shift operator, which is a single token. So the lexer needs to know something about the parsing context, to decide how it should treat <code>&gt;&gt;</code>.
Significant whitespace
    If your language assigns semantic meaning to indentation, like Python or Haskell, itâs very hard to even represent that within the model of a <em>sequence of tokens</em> at all, let alone teach an LR parser to understand the result!
<em>Sometimes</em> significant newlines
    If newlines were <em>always</em> syntactically significant, then thereâs no reason an orthodox parser would have trouble with it: the lexer simply emits newlines as a token, and the grammar says where one is acceptable, just like the way semicolons work in C or Java or Rust or whatever. But many languages take the view that newlines count as a vital syntactic token in <em>some</em> locations, but are completely ignored in others. For example, Python will ignore newlines as long as they appear within some pair of matched delimiters like <code>()</code> or <code>[]</code> or <code>{}</code>, so that you can break a long array declaration or list of function call parameters across lines without needing an ugly <code>\</code> at the end of each line â but <em>outside</em> any delimiters of those kind, a newline ends the current statement. I donât know if itâs actually <em>impossible</em> to write an LR grammar in such a way that it consistently ignores newlines in some contexts, but itâs certainly at least very difficult and unergonomic.</p>
<p>What can be done about these, if you also want to stick as close as possible to LR, for all the advantages Iâve mentioned (rapid development, grammar validation, test case generation)?</p>
<p>Iâve discussed the type-name ambiguity already, in the previous section. If my âLR with attributesâ idea can be made to work, then it can give a formal account of how you know whatâs a type name and whatâs not, and a way of determining it at run time.</p>
<p>I understand that significant whitespace is often handled by some kind of preprocessing step, which takes in (say) a Python program with significant indentation, and re-emits it in a modified internal form that has explicit block delimiters, which <em>can</em> be handled by an LR parser. In Haskell this is surely even easier, because the language itself defines explicit block delimiters, which you can use in place of significant whitespace if you prefer â so the preprocessor doesnât even need to emit a <em>different</em> internal syntax. But I wonder if the âLR with attributesâ approach might be able to do better: if nonterminals such as block were annotated with an integer parameter giving their indentation, and the lexer emitted start-of-line whitespace as a token with the same integer parameter, perhaps you <em>could</em> get an augmented-LR parser to directly handle block scope specified by indentation? Something like:</p>
<ul>
<li>every production for statement <em>n</em> starts with an INITIAL-WHITESPACE <em>n</em> token (and ends with a NEWLINE)</li>
<li>a block <em>n</em> is a list of statement <em>n</em> (so that every statement in the block is indented the same)</li>
<li>productions for statement <em>n</em> which include one or more block <em>k</em> have the constraint <em>k</em> &gt; <em>n</em> (so that the sub-statements are indented to some deeper level). If your language were more prescriptive you might even require <em>k</em> = <em>n</em> + 4 or something.</li>
</ul>
<p>For the other two cases â conditionally significant newlines, and conditionally lexing <code>&gt;&gt;</code> as either a single token or two separate <code>&gt;</code> tokens â my best thought is to interpose a âfilterâ layer <em>between</em> the lexer and parser, which is aware of the current state of the LR automaton itâs talking to, and can query its transition tables.</p>
<p>For example, you could handle conditionally significant newlines by making the filter do something really simple: <strong>if the current state of the LR automaton would be able to shift a newline token, emit the newline, otherwise discard it</strong>. So a newline appearing in the source <em>in a location where the grammar permits one</em> would be treated as syntactically significant, but a newline <em>anywhere else at all</em> would be treated as mere line-splitting for readability, and quietly ignored.</p>
<p>(The automaton might have to reduce one or more times before shifting a newline, and the filter would have to take that into account. The question is, if it were given a newline token, then <em>after</em> it finishes doing reductions, will it shift the newline, or give an error? Or if you used the extra-big tables of a CLR parser you wouldnât have to imagine the in-between reductions.)</p>
<p>Similarly, if the lexer sees <code>&gt;&gt;</code> coming up, it could query the LR automaton to ask whether thereâs a legal transition on a <code>&gt;&gt;</code> token right now, and also whether there would be legal transitions for two <code>&gt;</code> in sequence. Then it could decide what to do based on the answers. Easy, right?</p>
<p>Well, not quite. If only <em>one</em> of those two options is legal, then sure, no problem. But if <em>both</em> token sequences would be legal, there <em>is</em> a problem. What if the user has a type parametrised by an integer expression? What if the user writes an integer expression like <code>i &gt;&gt; 3</code> inside the angle brackets?</p>
<p>If you want <code>&gt;&gt;</code> to win, then the filter between the lexer and the parser has an easy choice: <strong>if thereâs a shift transition available for<code>&gt;&gt;</code>, emit <code>&gt;&gt;</code>, else emit two <code>&gt;</code> instead</strong>.</p>
<p>But I think more normally languages of this kind want <code>&gt;&gt;</code> to <em>lose</em>. Itâs considered too confusing to let users write anything like <code>Vec&lt;MyType&lt;i &gt;&gt; 3&gt;&gt;</code> at all: instead, theyâre supposed to protect the shift operator with parentheses, to make it clear that itâs not a template bracket. You write <code>Vec&lt;MyType&lt;(i &gt;&gt; 3)&gt;&gt;</code> instead.</p>
<p>But this is harder for the filter to cope with. You could certainly ask whether the LR automaton would be able to (eventually, ignoring intermediate reductions) shift <em>two</em> <code>&gt;</code> tokens, and if so, split up the <code>&gt;&gt;</code>. But then youâre in the extra confusing situation where you <em>do</em> permit an unguarded right shift operator in <em>one</em> layer of template brackets: that filter would allow <code>MyType&lt;i &gt;&gt; 3&gt;</code> without complaint, but if you tried to put that text inside a second pair of template brackets to get <code>Vec&lt;MyType&lt;i &gt;&gt; 3&gt;&gt;</code>, <em>then</em> itâs an error. I donât think that was what we wanted!</p>
<p>So, in this case, perhaps a more sensible idea is to rewrite the actual grammar to resolve the ambiguity. Introduce some extra nonterminals for expressions, which behave like the existing ones except that they enforce that no right-shift operator appears outside parentheses. (The nonterminals for precedence levels <em>higher</em> than the right shift token already have this property; each nonterm at or below the right-shift priority level would have to be duplicated.)</p>
<p>After you modify the grammar like that, the aim is that there should <em>never</em> be a situation in which <em>both</em> of <code>&gt;&gt;</code> (one token) and <code>&gt; &gt;</code> are acceptable in the same location. You could <em>prove</em> that statically â for example, by running the CLR(2) algorithm, and then checking no state of the output automaton has a valid parsing action on the lookahead pair &gt; &gt; <em>and</em> a valid action on any lookahead pair whose first token is &gt;&gt;. And then the filter between lexer and parser will have no trouble making its decision, because thereâs always (at most) one right decision.</p>
<p>(What about the âsynthetic, not just analyticâ property Iâve been making such a fuss about? With the filters Iâve described here, thereâs always <em>some</em> way to emit an output program which will be re-parsed the same way. You could never emit a newline <em>unless</em> itâs significant; you could never emit <code>&gt;&gt;</code> without a space in between unless you mean it as a right-shift operator. So <em>technically</em> the property I wanted is still available. But maybe you donât think thatâs high-quality unparsing? In that case perhaps an output filter could re-parse the emitted text and figure out when it was safe to cut cornersâ¦)</p>
<h2 id="conclusion">Conclusion<a class="headerlink" href="#conclusion" title="Permanent link">&para;</a></h2>
<p>Context-free grammars and automated parser generation give me a strong sense of âso near, and yet so farâ. They seem like such a clean, nice idea, with so many advantages â and yet they fall short of being a sensible way to write your real-world production parsers, <em>or</em> to write your clear language specification.</p>
<p>With normal programming languages itâs common to blame the language designers. (Not necessarily with justification â itâs easy to find something you donât like and shout about it, and much harder to find a design that fixes it without breaking something else. But this doesnât generally stop people.)</p>
<p>But context-free grammars are <em>barely</em> a language at all. There were almost no choices made in the design. So itâs much harder to say that someone should have made this or that small detailed decision differently â there <em>werenât</em> any small detailed decisions to make differently. Itâs as if <em>mathematics itself</em> did a not-quite-good-enough job of giving us an ideal way to specify languages!</p>
<h2 id="footnotes">Footnotes<a class="headerlink" href="#footnotes" title="Permanent link">&para;</a></h2>
<p>With any luck, you should be able to read the footnotes of this article in place, by clicking on the superscript footnote number or the corresponding numbered tab on the right side of the page.</p>
<p>But just in case the CSS didnât do the right thing, hereâs the text of all the footnotes again:</p>
<ol>
<li>
<p>My other example of a thing advertised as âdeclarativeâ which doesnât deliver on its promise is functional programming. Iâm not saying FP has no virtues, but declarative it is not. For example, to write a sorting function in a language like Haskell, you must decide which actual sorting algorithm you want to use; you can write very different Haskell functions that look like quicksort or mergesort or some other sort, and the compiler will generate the algorithm you asked for. My litmus test for a language worth calling âdeclarativeâ would be that I can write a sorting function by simply specifying the <em>properties</em> I want the output list to have, without saying anything about <em>how</em> to achieve it: it should be a permutation of the input list, such that <em>a</em>[<em>i</em>] â¤ <em>a</em>[<em>i</em> +1] for all <em>i</em>.</p>
</li>
<li>
<p>Except that a braced block counts as a statement by this grammar, and doesnât have a semicolon after the closing brace. So even this âobviousâ fact about C syntax depends a bit on your point of view.</p>
</li>
<li>
<p>Since Iâve used C as an example already in this article: the C standard scores one out of two points here. Annex A of the C standard provides a full context-free grammar, and states specifically that itâs acceptable to <code>yacc</code>, i.e. to the LALR algorithm. Or rather, itâs <em>nearly</em> LALR; thereâs a parsing action conflict due to the if-else ambiguity, and a fundamental issue with <code>typedef</code> which requires the parser to feed back to the lexer â but the standard warns you about both of those things. Thatâs all fine; top marks. On the other hand, you do have to paste the grammar out of the PDF and fix up paste issues, because the C standard (unlike C++) isnât available in the form of the input markup, only the PDF standard.</p>
</li>
<li>
<p>OK, three: they also present SLR, which is a <em>particularly</em> horrible bodge and doesnât really deserve mentioning.</p>
</li>
</ol>







  
    
  
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="最后更新">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_date" title="2026年2月12日 22:03:02 UTC">2026-02-12</span>
  </span>

    
    
    
    
  </aside>


  



  <form class="md-feedback" name="feedback" hidden>
    <fieldset>
      <legend class="md-feedback__title">
        这篇文章有帮助吗？
      </legend>
      <div class="md-feedback__inner">
        <div class="md-feedback__list">
          
            <button class="md-feedback__icon md-icon" type="submit" title="有帮助" data-md-value="1">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M5 9v12H1V9zm4 12a2 2 0 0 1-2-2V9c0-.55.22-1.05.59-1.41L14.17 1l1.06 1.06c.27.27.44.64.44 1.05l-.03.32L14.69 8H21a2 2 0 0 1 2 2v2c0 .26-.05.5-.14.73l-3.02 7.05C19.54 20.5 18.83 21 18 21zm0-2h9.03L21 12v-2h-8.79l1.13-5.32L9 9.03z"/></svg>
            </button>
          
            <button class="md-feedback__icon md-icon" type="submit" title="没帮助" data-md-value="0">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 15V3h4v12zM15 3a2 2 0 0 1 2 2v10c0 .55-.22 1.05-.59 1.41L9.83 23l-1.06-1.06c-.27-.27-.44-.64-.44-1.06l.03-.31.95-4.57H3a2 2 0 0 1-2-2v-2c0-.26.05-.5.14-.73l3.02-7.05C4.46 3.5 5.17 3 6 3zm0 2H5.97L3 12v2h8.78l-1.13 5.32L15 14.97z"/></svg>
            </button>
          
        </div>
        <div class="md-feedback__note">
          
            <div data-md-value="1" hidden>
              
              
                
              
              
              
                
                
              
              感谢反馈！
            </div>
          
            <div data-md-value="0" hidden>
              
              
                
              
              
              
                
                
              
              感谢反馈！我们会改进。
            </div>
          
        </div>
      </div>
    </fieldset>
  </form>


                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  回到页面顶部
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2026 - OpenClaw
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
    <a href="https://github.com/mrgolftech" target="_blank" rel="noopener" title="GitHub" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../../..", "features": ["navigation.instant", "navigation.tracking", "navigation.tabs", "navigation.sections", "navigation.expand", "navigation.top", "search.suggest", "search.highlight", "search.share", "content.code.copy", "content.action.edit"], "search": "../../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
    
  </body>
</html>