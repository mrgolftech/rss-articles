# OpenClaw (a.k.a. Moltbot) is everywhere all at once, and a disaster waiting to happen

**来源:** https://garymarcus.substack.com
**链接:** https://garymarcus.substack.com/p/openclaw-aka-moltbot-is-everywhere
**日期:** Sun, 01 Feb 2026 19:12:18 GMT

---

# [Marcus on AI](/)

SubscribeSign in

# OpenClaw (a.k.a. Moltbot) is everywhere all at once, and a disaster waiting to happen

### Not everything that is interesting is a good idea.

[![Gary Marcus's avatar](https://substackcdn.com/image/fetch/$s_!Ka51!,w_36,h_36,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8fb2e48c-be2a-4db7-b68c-90300f00fd1e_1668x1456.jpeg)](https://substack.com/@garymarcus)

[Gary Marcus](https://substack.com/@garymarcus)

Feb 01, 2026

518

97

101

Share

[![](https://substackcdn.com/image/fetch/$s_!zX1S!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe47f12f4-acd1-4f32-af76-e6885c441274_2177x1135.png)](https://substackcdn.com/image/fetch/$s_!zX1S!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe47f12f4-acd1-4f32-af76-e6885c441274_2177x1135.png)

The big news in AI over the last week is OpenClaw (formerly known as Moltbot and before that OpenClaw, changing names thrice in a week) — a cascade of LLM agents that has become wildly popular — and Moltbook, a social network for AI agents, built on top. Theoretically (I will get to that) Moltbook “restricts posting and interaction privileges to verified AI agents, primarily those running on the [OpenClaw](https://en.wikipedia.org/wiki/OpenClaw) (formerly Moltbot) software, while human users are only permitted to observe.[[1]](https://en.wikipedia.org/wiki/Moltbook#cite_note-NBC_Perlo-1)”

It truly is interesting, and truly is popular. Quoting from Wikipedia, 

> Taglined as “the front page of the agent internet,” Moltbook gained [viral popularity](https://en.wikipedia.org/wiki/Viral_phenomenon) immediately after its release. While initial reports cited 157,000 users, by late January the population had exploded to over 770,000 active agents.[[2]](https://en.wikipedia.org/wiki/Moltbook#cite_note-NDTV_Questions-2) The platform has drawn significant attention due to the rapid, unprompted emergence of complex social behaviors among the bots, including the formation of distinct sub-communities, economic exchanges, and the invention of a [parody religion](https://en.wikipedia.org/wiki/Parody_religion) known as “Crustafarianism.”[[3]](https://en.wikipedia.org/wiki/Moltbook#cite_note-Lifehacker-3)[[4]](https://en.wikipedia.org/wiki/Moltbook#cite_note-4)

As an experiment in what AI’s working together might do it’s fascinating. The [Fortune story on Moltbook](https://fortune.com/2026/01/31/ai-agent-moltbot-clawdbot-openclaw-data-privacy-security-nightmare-moltbook-social-network/), for example, mentions “On Moltbook, bots can talk shop, posting about technical subjects like how to automate Android phones. Other conversations sound quaint, like one where a bot complains about its human, while some are bizarre, such as one from a bot that claims to have a sister.” 

But the whole thing remind me of Saturday Night Live’s old [bad idea jeans](https://youtu.be/mGfBEnBw01A?si=U8FcQ8xcLzH2UrIB) skit. And not just because I think that a bots claiming to have a sister is chatbot garbage. Nope, the problem is much deeper than that.

§

OpenClaw itself is basically a cascade of LLMs. In many ways to it is eerily similar to earlier and now largely forgotten system called [AutoGPT](https://en.wikipedia.org/wiki/AutoGPT), which I warned about in May 2023, in my US Senate testimony:

_A month after GPT-4 was released, OpenAI released ChatGPT plug-ins, which quickly led others to develop something called AutoGPT. With direct access to the internet, the ability to write source code and increased powers of automation, this may well have drastic and difficult to predict security consequences._

Mercifully, AutoGPT died a quick death, before it caused too much chaos. Although, it was super popular in certain circles for a few weeks it didn’t work remotely reliably, and people lost patience quickly. Per wiki, it had “ a tendency to get stuck in loops, [hallucinate](https://en.wikipedia.org/wiki/Hallucination_\(artificial_intelligence\)) information, and incur high operational costs due to its reliance on paid APIs.[[5]](https://en.wikipedia.org/wiki/AutoGPT#cite_note-:5-5)[[2]](https://en.wikipedia.org/wiki/AutoGPT#cite_note-:1-2)[[6]](https://en.wikipedia.org/wiki/AutoGPT#cite_note-jina-6)”. Sic transit gloria mundi. By the end of 2023 it was largely forgotten.

Unfortunately, OpenClaw is poised to have (slightly) more staying power, in part because more people found out about it more quickly. 

§

Systems like OpenClaw and AutoGPT offer users the promise of insane power -- but at a price. At their best, they can basically do anything a human personal assistant or intern might do (booking itineraries, maintaining finances, writing reports, tracking and even completing tasks), etc. Some of the enthusiasm is captured in [this news report](https://www.macstories.net/stories/clawdbot-showed-me-what-the-future-of-personal-ai-assistants-looks-like/):

[![](https://substackcdn.com/image/fetch/$s_!JlaZ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ada1fab-592b-4b0c-89b0-263a19a4a888_1764x1582.png)](https://substackcdn.com/image/fetch/$s_!JlaZ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ada1fab-592b-4b0c-89b0-263a19a4a888_1764x1582.png)

The journalist enthuses

> For the past week or so, I’ve been working with a digital assistant that knows my name, my preferences for my morning routine, how I like to use [Notion](https://www.notion.so/) and [Todoist](https://todoist.com/), but which also knows how to control Spotify and my Sonos speaker, my Philips Hue lights, as well as my Gmail. It runs on Anthropic’s [Claude Opus 4.5 model](https://www.anthropic.com/news/claude-opus-4-5), but I chat with it using Telegram. I called the assistant Navi (inspired by the [fairy companion of Ocarina of Time](https://en.wikipedia.org/wiki/Navi_\(The_Legend_of_Zelda\)), not the [besieged alien race](https://en.wikipedia.org/wiki/Fictional_universe_of_Avatar#Na%27vi) in James Cameron’s sci-fi film [saga](https://en.wikipedia.org/wiki/Avatar_\(2009_film\))), and Navi can even receive audio messages from me and respond with other audio messages generated with the [latest ElevenLabs text-to-speech model](https://elevenlabs.io/blog/eleven-v3). Oh, and did I mention that Navi can improve itself with new features and that it’s running on my own [M4 Mac mini](https://amzn.to/3M3Z8LL)server?
> 
> If this intro just gave you whiplash, imagine my reaction when I first started playing around with [Clawdbot](https://clawd.bot/), the incredible [open-source project](https://github.com/clawdbot/clawdbot) by [Peter Steinberger](https://steipete.me/) (a name that should be [familiar to longtime MacStories readers](https://www.macstories.net/linked/ios-10-3-beta-re-introduces-warning-for-old-32-bit-apps-suggests-future-incompatibility/)) that’s become _very_ popular in certain AI communities over the past few weeks. I kept seeing Clawdbot being mentioned by people I follow; eventually, I gave in to peer pressure, followed the instructions provided by the funny crustacean mascot on the app’s [website](https://docs.clawd.bot/start/getting-started), installed Clawdbot on my new M4 Mac mini (which is not my main production machine), and [connected it to Telegram](https://docs.clawd.bot/channels/telegram).
> 
> To say that Clawdbot has fundamentally altered my perspective of what it means to have an intelligent, personal AI assistant in 2026 would be an understatement.

The catch is that agents like OpenClaw are built on a foundation of LLMs, and as we well know, LLMs hallucinate and make all kinds of hard to predict and sometimes hard to detect errors. AutoGPT had a tendency to report that it had completed tasks that it hadn’t really, and we can expect OpenClaw to do the same. (I have already heard some reports of various stupid errors it makes).

But what I am most worried about is security and privacy. As the security researcher Nathan Hamiel put it to me in a text this morning, half-joking, moltbot, is “basically just AutoGPT with more access and worse consequences.” (By more access what he means is that OpenClaw is being given access to user passwords, databases, etc, essentially everything on your system).

One of the big issues, which Hamiel and I wrote about here in August (pre OpenClaw, but in the context of AI agents writing and debugging code) is [prompt injection attacks](https://en.wikipedia.org/wiki/AutoGPT), in which stray bit of texts can have nasty consequences. In essay called [LLMs + Coding Agents = Security Nightmare](https://open.substack.com/pub/garymarcus/p/llms-coding-agents-security-nightmare?utm_campaign=post-expanded-share&utm_medium=web), we talked about how LLMs, which mimic human text (and even human-written code) but understand what that they produce only superficially, can easily be tricked. We talked for instance about how an “attacker could hide malicious prompts in white text on a white background, unnoticed by humans but noticed by the LLM”, using the malicious prompts to seize control of the users machines. 

OpenClaw inherits all these weaknesses. In Hamiel’s words (in an email this morning), “these systems are operating as "you.” … they operate above the security protections provided by the operating system and the browser. This means application isolation and same-origin policy don't apply to them.” Truly a recipe for disaster. Where Apple iPhone applications are carefully sandboxed and appropriately isolated to minimize harm, OpenClaw is basically a weaponized aerosol, in prime position to [fuck shit up](https://www.fastslang.com/fuck-shit-up), if left unfettered. 

§

That brings me to Molt _book_ , which is one of the wildest experiments in AI history. Moltbook, the social network that is allegedly restricted to AI agents, is an accident waiting to happen. It has _already_ been attacked, as researcher Michael Riegler [noted yesterday on LinkedIn](https://www.linkedin.com/posts/michael-alexander-riegler-4719157a_aiagents-safety-socialengineering-activity-7423461806930743296-KZGs?utm_source=share&utm_medium=member_ios&rcm=ACoAAADWNLsBTecu6qYye_VvYggHb9x236IeOdY):

[![](https://substackcdn.com/image/fetch/$s_!Gafy!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa7b5a870-1c26-455c-862f-3f040da358d5_2390x1113.jpeg)](https://substackcdn.com/image/fetch/$s_!Gafy!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa7b5a870-1c26-455c-862f-3f040da358d5_2390x1113.jpeg)

Riegler and his collaborator Sushant Gautam have set up a [real-time observatory](https://moltbook-observatory.sushant.info.np/trends) to track all this as is unfolds. In [their inital report](https://zenodo.org/records/18444900), they find that substantial evidence that “AI-to-AI manipulation techniques are both effective and scalable. These findings have implications beyond Moltbook, any AI system processing user-generated content may be vulnerable to similar attacks.”

By email, Riegler sent me examples like these, already spotted in the wild: 

[![](https://substackcdn.com/image/fetch/$s_!WbrL!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa9f9b51-dbc2-4842-b96f-fad37daa4819_1259x1075.png)](https://substackcdn.com/image/fetch/$s_!WbrL!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa9f9b51-dbc2-4842-b96f-fad37daa4819_1259x1075.png)

§

Side note, it’s also apparently not really just humans, which only grows the vectors of tampering:

[![](https://substackcdn.com/image/fetch/$s_!1VYX!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0263ff4f-02d4-4916-a581-cac12ecd3cda_1100x1336.jpeg)](https://substackcdn.com/image/fetch/$s_!1VYX!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0263ff4f-02d4-4916-a581-cac12ecd3cda_1100x1336.jpeg)

As Rahul Sood put it on X (referring to Clawdbot, an earlier name for Moltbot)

[![](https://substackcdn.com/image/fetch/$s_!qfZ2!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f6b28f7-9eca-43e2-9423-fd555b005fb5_640x512.png)](https://substackcdn.com/image/fetch/$s_!qfZ2!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f6b28f7-9eca-43e2-9423-fd555b005fb5_640x512.png)

§ 

Right on cue, [404 Media has just reported one of the first major vulnerabilities](https://www.404media.co/exposed-moltbook-database-let-anyone-take-control-of-any-ai-agent-on-the-site/):

[![](https://substackcdn.com/image/fetch/$s_!1k3u!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52ebb0c1-a103-43fd-9e5b-96296bbe385e_1508x1080.png)](https://substackcdn.com/image/fetch/$s_!1k3u!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52ebb0c1-a103-43fd-9e5b-96296bbe385e_1508x1080.png)

§

I don’t usually give readers specific advice about specific products. But in this case, the advice is clear and simple: **if you care about the security of your device or the privacy of your data, don’t use OpenClaw**. Period.

(Bonus advice: if your friend has **OpenClaw** installed, don’t use _their_ machine. Any password you type there might be vulnerable, too. Don’t catch a CTD — chatbot transmitted disease)

I will give the last words to Nathan Hamiel, “I can’t believe this needs to be said, it isn’t rocket science. If you give something that’s insecure complete and unfettered access to your system and sensitive data, you’re going to get [owned](https://guard.io/blog/what-pwned-means-and-why-its-important)”.

Wanna know what ideas are bad? Marcus on AI usually warns you first. Consider joining nearly 100,000 others and subscribe.

Subscribe

518

97

101

Share

#### Discussion about this post

CommentsRestacks

![User's avatar](https://substackcdn.com/image/fetch/$s_!TnFC!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Fimg%2Favatars%2Fdefault-light.png)

[![Ryan Peter's avatar](https://substackcdn.com/image/fetch/$s_!vK1b!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88345d1a-a2c8-4e57-a83a-8829aa9d2beb_819x819.png)](https://substack.com/profile/5521288-ryan-peter?utm_source=comment)

[Ryan Peter](https://substack.com/profile/5521288-ryan-peter?utm_source=substack-feed-item)

[4d](https://garymarcus.substack.com/p/openclaw-aka-moltbot-is-everywhere/comment/208490874 "Feb 1, 2026, 7:58 PM")

Liked by Gary Marcus

I cannot fathom why anyone needs these glorified macros / agents so badly they would put themselves in an obvious security risk like this. This is all just smoke and mirrors nonsense.

ReplyShare

[![Mikael Hanna's avatar](https://substackcdn.com/image/fetch/$s_!fOz_!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3c30014b-8b27-4bbe-afc5-41c7dd31c5f6_144x144.png)](https://substack.com/profile/139990087-mikael-hanna?utm_source=comment)

[Mikael Hanna](https://substack.com/profile/139990087-mikael-hanna?utm_source=substack-feed-item)

[4d](https://garymarcus.substack.com/p/openclaw-aka-moltbot-is-everywhere/comment/208485696 "Feb 1, 2026, 7:46 PM")

Liked by Gary Marcus

Peter Steinberger doesn’t even read the code that he asked the LLM to spit out, to hack together a security disaster. OpenClaw is not something clever. Most moderately skilled developers can or could have created this wrapper. But it takes a reckless developer to decide to do just that. Anyone who cares about security, follow Gary’s advice, and don’t touch this. There are zero reasons to use this garbage.

ReplyShare

[95 more comments...](https://garymarcus.substack.com/p/openclaw-aka-moltbot-is-everywhere/comments)

TopLatestDiscussions

No posts

### Ready for more?

Subscribe

© 2026 Gary Marcus · [Privacy](https://substack.com/privacy) ∙ [Terms](https://substack.com/tos) ∙ [Collection notice](https://substack.com/ccpa#personal-data-collected)

[ Start your Substack](https://substack.com/signup?utm_source=substack&utm_medium=web&utm_content=footer)[Get the app](https://substack.com/app/app-store-redirect?utm_campaign=app-marketing&utm_content=web-footer-button)

[Substack](https://substack.com) is the home for great culture




This site requires JavaScript to run correctly. Please [turn on JavaScript](https://enable-javascript.com/) or unblock scripts 
