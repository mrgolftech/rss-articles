# Why smart instruction-following makes prompt injection easier

**原文链接**: https://www.gilesthomas.com/2025/11/smart-instruction-following-and-prompt-injection
**发布日期**: Wed, 12 Nov 2025 19:00:00 +0000

---

Back when I first started looking into LLMs , I noticed that I could use what I've since called the transcript hack to get LLMs to work as chatbots without specific fine-tuning. It's occurred to me th...

---

*本文内容版权归原作者所有，仅供学习交流使用。*
