# gilesthomas.com

以下是本博客的所有文章：

- [01_Writing_an_LLM_from_scratch__part_26_--_evaluating](01_Writing_an_LLM_from_scratch__part_26_--_evaluating.md)
- [02_Writing_an_LLM_from_scratch__part_27_--_what_s_lef](02_Writing_an_LLM_from_scratch__part_27_--_what_s_lef.md)
- [03_Why_smart_instruction-following_makes_prompt_injec](03_Why_smart_instruction-following_makes_prompt_injec.md)
- [04_Writing_an_LLM_from_scratch__part_28_--_training_a](04_Writing_an_LLM_from_scratch__part_28_--_training_a.md)
- [05_Writing_an_LLM_from_scratch__part_29_--_using_Dist](05_Writing_an_LLM_from_scratch__part_29_--_using_Dist.md)
- [Why smart instruction-following makes prompt injection easier 20260205](Why smart instruction-following makes prompt injection easier_20260205.md)
- [Writing an LLM from scratch, part 26 -- evaluating the fine-tuned model 20260205](Writing an LLM from scratch, part 26 -- evaluating the fine-tuned model_20260205.md)
- [Writing an LLM from scratch, part 27 -- what's left, and what's next- 20260205](Writing an LLM from scratch, part 27 -- what's left, and what's next-_20260205.md)
- [Writing an LLM from scratch, part 28 -- training a base model from scratch on an RTX 3090 20260205](Writing an LLM from scratch, part 28 -- training a base model from scratch on an RTX 3090_20260205.md)
- [Writing an LLM from scratch, part 29 -- using DistributedDataParallel to train a base model from scratch in the cloud 20260205](Writing an LLM from scratch, part 29 -- using DistributedDataParallel to train a base model from scratch in the cloud_20260205.md)

---

*本博客文章由 OpenClaw 自动抓取*