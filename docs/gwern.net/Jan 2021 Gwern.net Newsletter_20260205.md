# Jan 2021 Gwern.net Newsletter

**æ¥æº:** https://gwern.net
**é“¾æ¥:** https://gwern.substack.com/p/jan-2021-gwernnet-newsletter
**æ—¥æœŸ:** Thu, 04 Feb 2021 20:23:01 GMT

---

[![Gwern.net Newsletter](https://substackcdn.com/image/fetch/$s_!rpC9!,w_40,h_40,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F5860611c-2de0-45a7-99a0-dc1b248b0199_1280x1280.png)](/)

# [Gwern.net Newsletter](/)

SubscribeSign in

# Jan 2021 Gwern.net Newsletter

### January 2021 gwern.net newsletter with links on AI scaling up and down.

[![gwern's avatar](https://substackcdn.com/image/fetch/$s_!jpKC!,w_36,h_36,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F3a41d1b8-0e3c-44d4-b99a-8f52362678eb_1592x1800.png)](https://substack.com/@gwern)

[gwern](https://substack.com/@gwern)

Feb 04, 2021

17

Share

January 2021â€™s [Gwern.net](https://www.gwern.net/newsletter/2021/01) [newsletter](https://gwern.substack.com) is now out; previous, [December 2020](https://www.gwern.net/newsletter/2020/12) ([archives](https://www.gwern.net/tags/newsletter)). This is a summary of the revision-history RSS feed, overlapping with my [Changelog](https://www.gwern.net/Changelog) & /r/gwern; brought to you by my donors on [Patreon](https://www.patreon.com/gwern).

# 1 Writings

  * [â€œDanbooru2020: A Large-Scale Crowdsourced and Tagged Anime Illustration Datasetâ€](https://www.gwern.net/Danbooru2020 "Danbooru2020 is a large-scale anime image database with 4.2m+ images annotated with 130m+ tags; it can be useful for machine learning purposes such as image recognition and generation.")

  * [This Anime Does Not Exist.ai (TADNE)](https://thisanimedoesnotexist.ai/) ([discussion](https://www.gwern.net/Faces#extended-stylegan2-danbooru2019-aydao))

  * **Gwern.net** : +return-to-top floating button; _popups_ : can now be disabled (use the â€˜gearâ€™ icon); final reimplementation (dynamic JS now; memoizing the recursive inlining, however clever & elegant, turns out to have painful edge-cases & still not be efficient enoughâ€”web browsers _really_ donâ€™t like loading hundreds of kilobytes of extra HTML)




# 2 Links

## 2.1 AI

[Matters Of Scale](https://old.reddit.com/r/mlscaling/):

  * **Scaling up** :

    * [â€œDALLÂ·E: Creating Images from Textâ€](https://openai.com/blog/dall-e/), OpenAI (GPT-3-12.5b generating 1280 tokens â†’ [VQ-VAE](https://arxiv.org/abs/1906.00446#deepmind "'Generating Diverse High-Fidelity Images with VQ-VAE-2', Razavi et al 2019") pixels; generates illustration & photos); [â€œCLIP (Contrastive Language-Image Pre-training): Connecting Text and Imagesâ€](https://openai.com/blog/clip/), OpenAI ([Radford et al 2021](https://cdn.openai.com/papers/Learning_Transferable_Visual_Models_From_Natural_Language_Supervision.pdf "Learning Transferable Visual Models From Natural Language Supervision"): zero-shot image understanding via text descriptionâ€”useful for much more than just ranking DALLÂ·E samples by quality)

Further [blessings of scale](https://www.gwern.net/newsletter/2020/05#blessings-of-scale): simple [contrastive](https://arxiv.org/abs/2010.05113 "'Contrastive Representation Learning: A Framework and Review', Le-Khac et al 2020") training on _n_ = 400m leads to remarkable generalization & combinatorial flexibility of image generation by DALLÂ·E, and CLIP learns to reach image classification SOTA by zero-shot on many datasets, with more human-like errors & less degradation out of samples than rivals, while costing the same to train. OpenAI released their smallest CLIP model (the â€œ[ViT](https://openreview.net/forum?id=YicbFdNTTy#google "Vision Transformer \(ViT\): An Image is Worth 16Ã—16 Words: Transformers for Image Recognition at Scale")-B/32â€-equivalent) and people are discovering it seems able to do just about anything without any further trainingâ€”the paper notes that it does everything from â€œfine-grained object classification, geo-localization, action recognition in videos, and OCRâ€, but thereâ€™s so much more, and you can use it to generate image captions/descriptions, classify your anime images, pull a specific target image description by gradient ascent or out of another neural network such as an ImageNet [BigGAN](https://arxiv.org/abs/1809.11096#deepmind "'BigGAN: Large Scale GAN Training for High Fidelity Natural Image Synthesis', Brock et al 2018") or TADNE StyleGAN2-ext (or, why not, synthesize images images embodying abstract concepts like emoji or words like â€œnightmare fuelâ€ or â€œconfusionâ€!), search your image datasets by embedding, find mislabeled images (eg by [using â€œupside downâ€ as the prompt](https://twitter.com/quasimondo/status/1351191660059832320))â€¦ One wonders, like GPT-3, how much better the largest CLIP (â€œL/14-336pxâ€) is and how many ways of using it (or DALLÂ·E) remain to be found? And why prediction losses work so well in one place, but then contrastive elsewhere?

For perspective: there are newly-minted PhDs going on the job market who got excited about deep learning because of these new [â€œresnetâ€](https://arxiv.org/abs/1512.03385 "'Deep Residual Learning for Image Recognition', He et al 2015") things; undergrads who applied to grad school because [BERT](https://arxiv.org/abs/1810.04805#google "'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding', Devlin et al 2018") et al were blowing open NLP & extending neural supremacy to natural language would not yet have passed quals; and it has been only 1 academic semester since [GPT-3](https://arxiv.org/abs/2005.14165#openai "'GPT-3: Language Models are Few-Shot Learners', Brown et al 2020") was announced. Or to put it quantitatively, for just sequence modeling: it has been 8,478 days since [LSTM](https://www.gwern.net/docs/ai/1997-hochreiter.pdf "'Long Short-Term Memory', Hochreiter & Schmidhuber 1997") RNNs were published; 3,045 days since [AlexNetâ€™s](https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf "'ImageNet Classification with Deep Convolutional Neural Networks', Krizhevsky et al 2012") ImageNet scores were released; 1,880 days since residual networks were published in a paper; 1,330 days since [â€œAttention Is All You Needâ€](https://arxiv.org/abs/1706.03762#google "Vaswani et al 2017") hit Arxiv; 844 days since BERTâ€™s paper was published; 718 days since [GPT-2](https://openai.com/blog/better-language-models/ "'Better Language Models and Their Implications', OpenAI 2019") was announced; 353 days since [SimCLR](https://arxiv.org/abs/2002.05709#google "'A Simple Framework for Contrastive Learning of Visual Representations', Chen et al 2020"), and 249 days since GPT-3 was; and 27 days since CLIP/DALLÂ·E.^1^ [Spring is coming.](https://jetpress.org/volume1/moravec.htm "'When will computer hardware match the human brain?', Moravec 1998") (Some still insist we need not worry about â€œoverpopulation on Marsâ€ for >18,264 more daysâ€¦)

    * [â€œMeta Pseudo Labelsâ€](https://arxiv.org/abs/2003.10580#google), Pham et al 2020 (90% on ImageNet by pretraining a meta-learning teacher using JFT-300M on a TPUv3-2048)

    * [â€œSwitch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsityâ€](https://arxiv.org/abs/2101.03961#google), Fedus et al 2021 (1.57t-parameter [GShard](https://arxiv.org/abs/2006.16668#google "'GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding', Lepikhin et al 2020") followup; the mixture-of-experts approach, while scaling stably, starts showing its limits)

  * **Scaling down** :

    * [â€œDeiT: Training data-efficient image transformers & distillation through attentionâ€](https://arxiv.org/abs/2012.12877#facebook), Touvron et al 2020 (scaling Transformer classifiers down to ImageNet+1-GPU); [â€œBoTNet: Bottleneck Transformers for Visual Recognitionâ€](https://arxiv.org/abs/2101.11605#google), Srinivas et al 2021/[â€œTokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNetâ€](https://arxiv.org/abs/2101.11986), Yuan et al 2021 (hybrids); [â€œnot-so-BigGAN: Generating High-Fidelity Images on Small Compute with Wavelet-based Super-Resolutionâ€](https://arxiv.org/abs/2009.04433), Han et al 2020/[â€œVQGAN: Taming Transformers for High-Resolution Image Synthesisâ€](https://compvis.github.io/taming-transformers/), Esser et al 2020 (training >1024px Transformer GANs on just 2 GPUs)

Transformer supremacy in image-related tasks continues, and GANs are becoming increasingly hybridized. Do pure-GANs have a future, now that VAEs and autoregressive models are making such inroads into both the highest-quality & lowest-compute sample generation? To take the GAN/DRL analogy seriously, perhaps they were they ultimately a dead end, akin to trying to learn everything from rewards, and an adversarial GAN loss ought to be only [the cherry on the cake](https://www.gwern.net/images/ai/2019-lecun-isscctalk-cake.png) of a large unsupervised/semi-supervised generative model.

    * [â€œZeRO-Offload: Democratizing Billion-Scale Model Trainingâ€](https://arxiv.org/abs/2101.06840#microsoft), Ren et al 2021 (partial CPU training for 13b-parameter models on 1 V100 GPU, scaling to 128 GPUs)

    * [â€œPrefix-Tuning: Optimizing Continuous Prompts for Generationâ€](https://arxiv.org/abs/2101.00190), Li & Liang 2021 (could the [PET](https://arxiv.org/abs/2009.07118 "'It's Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners', Schick & SchÃ¼tze et al 2020") & CLIP trick of averaging multiple embeddings to yield much better performance be reused for GPT-3 prompts to greatly improve prompting? The fact that the prefix-tuning, by directly optimizing the prompt embeddings, yields better performance than even single optimized text prompts, suggests so. The user could provide 3 or 4 similar prompts, and synthesize them into a single super-prompt to better program GPT-3â€¦)

    * [â€œScaling down Deep Learningâ€](https://greydanus.github.io/2020/12/01/scaling-down/), Greydanus 2020 (cute: parametric simplified-MNIST for rapid iteration on tiny NNs: experiments in lottery-ticket & meta-learning of LRs/activations)

    * [â€œThe neural network of the Stockfish chess engineâ€](https://cp4space.hatsya.com/2021/01/08/the-neural-network-of-the-stockfish-chess-engine/) (very lightweight NN designed for incremental recomputation over changing board states)

  * [â€œTransformers in Vision: A Surveyâ€](https://arxiv.org/abs/2101.01169), Khan et al 2021

  * [OpenAI departures](https://openai.com/blog/organizational-update/): Dario Amodei, Sam McCandlish, Tom Brown, Tom Henighan, Chris Olah, Jack Clark, Ben Mann, Paul Christiano et al leaveâ€”most for an unspecified new entity ([â€œthe elves leave Middle Earthâ€](https://steveblank.com/2009/12/21/the-elves-leave-middle-earth-%E2%80%93-soda%E2%80%99s-are-no-longer-free/)?)




And the rest:

  * [â€œ2020 AI Alignment Literature Review and Charity Comparisonâ€](https://www.lesswrong.com/posts/pTYDdcag9pTzFQ7vw/2020-ai-alignment-literature-review-and-charity-comparison), Larks

  * [â€œGrounded Language Learning Fast and Slowâ€](https://arxiv.org/abs/2009.01719#deepmind), Hill et al 2020

  * [â€œDeBERTa: Decoding-enhanced BERT with Disentangled Attentionâ€](https://arxiv.org/abs/2006.03654#microsoft), He et al 2020 ([SuperGLUE](https://arxiv.org/abs/1905.00537 "'SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems', Wang et al 2019") falls)

  * [â€œSolving Mixed Integer Programs Using Neural Networksâ€](https://arxiv.org/abs/2012.13349#deepmind), Nair et al 2020

  * [â€œTowards Fully Automated Manga Translationâ€](https://arxiv.org/abs/2012.14271), Hinami et al 2020

  * [â€œUPDeT: Universal Multi-agent Reinforcement Learning via Policy Decoupling with Transformersâ€](https://arxiv.org/abs/2101.08001#baidu), Hu et al 2021

  * [â€œFERM: A Framework for Efficient Robotic Manipulationâ€](https://arxiv.org/abs/2012.07975#bair), Zhan et al 2021 (contrastive semi-supervised learning + data augmentation for sample-efficiency)

  * [â€œXMC-GAN: Cross-Modal Contrastive Learning for Text-to-Image Generationâ€](https://arxiv.org/abs/2101.04702#google), Zhang et al 2021




## 2.2 Genetics

Everything Is Heritable:

  * [â€œNurture might be nature: cautionary tales and proposed solutionsâ€](https://www.nature.com/articles/s41539-020-00079-z), Hart et al 2021

  * [â€œA genetic perspective on the association between exercise and mental health in the era of genome-wide association studiesâ€](https://www.sciencedirect.com/science/article/pii/S1755296620300624), de Geus 2020; [â€œEvidence for shared genetics between physical activity, sedentary behaviour and adiposity-related traitsâ€](https://www.gwern.net/docs/genetics/correlation/2020-schnurr.pdf), Schnurr et al 2020

  * [â€œAntidepressant Response in Major Depressive Disorder: A Genome-wide Association Studyâ€](https://www.medrxiv.org/content/10.1101/2020.12.11.20245035v1), Pain et al 2020

  * [â€œGenome wide analysis of gene dosage in 24,092 individuals shows that 10,000 genes modulate cognitive abilityâ€](https://www.biorxiv.org/content/10.1101/2020.04.03.024554v3), Huguet et al 2020 (yep, still polygenic)

  * [â€œGWAS of three molecular traits highlights core genes and pathways alongside a highly polygenic backgroundâ€](https://www.biorxiv.org/content/10.1101/2020.04.20.051631v2), Sinnott-Armstrong et al 2021

  * [â€œGenome-scale sequencing and analysis of human, wolf and bison DNA from 25,000 year-old sedimentâ€](https://www.biorxiv.org/content/10.1101/2021.01.08.425895v1), Gelabert et al 2021 (incredible this is possible)

  * [â€œDisentangling sex differences in the shared genetic architecture of PTSD, traumatic experiences, and social support with body size and compositionâ€](https://www.medrxiv.org/content/10.1101/2021.01.25.21249961v1), Carvalho et al 2021 ([LCV](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6684375/ "'Distinguishing genetic correlation from causation across 52 diseases and complex traits', O'Connor & Price 2018"))




Recent Evolution:

  * [â€œAfrican genetic diversity and adaptation inform a precision medicine agendaâ€](https://www.gwern.net/docs/genetics/selection/2021-pereira.pdf), Pereira et al 2021; [â€œThe influence of evolutionary history on human health and diseaseâ€](https://www.nature.com/articles/s41576-020-00305-9), Benton et al 2021; [â€œLocal adaptation and archaic introgression shape global diversity at human structural variant lociâ€](https://www.biorxiv.org/content/10.1101/2021.01.26.428314v1), Yan et al 2021

  * [â€œGenome scans of dog behavior implicate a gene network underlying psychopathology in mammals, including humansâ€](https://www.biorxiv.org/content/10.1101/2020.07.19.211078v2), Zapata et al 2021

  * [â€œNatural Selection in Contemporary Humans is Linked to Income and Substitution Effectsâ€](https://ideas.repec.org/p/uea/ueaeco/2021-02.html), Hugh-Jones & Abdellaoui 2021

  * [â€œThe diversity and function of sourdough starter microbiomesâ€](https://elifesciences.org/articles/61644), Landis et al 2021 (crowdsourced sourdough show little trace of geographic origins?)




Engineering:

  * [â€œIn vivo base editing rescues Hutchinson-Gilford progeria syndrome in miceâ€](https://www.gwern.net/docs/genetics/editing/2021-koblan.pdf), Koblan et al 2021

  * [â€œFrom Genotype to Phenotype: polygenic prediction of complex human traitsâ€](https://arxiv.org/abs/2101.05870), Raben et al 2021




## 2.3 Statistics/Meta-Science/Math

  * [â€œThe Quantum Field Theory on Which the Everyday World Supervenesâ€](https://arxiv.org/abs/2101.07884), Carroll 2021 (â€œâ€¦we have reason to be confident that the laws of physics underlying the phenomena of everyday life are completely knownâ€ because all unknown particles/fields are constrained to being extremely rare/weak, eg by [Adelberger et al 2009](https://www.gwern.net/docs/science/2009-adelberger.pdf "Torsion balance experiments: A low--energy frontier of particle physics"))

  * [â€œHow accurate are citations of frequently cited papers in biomedical literature?â€](https://www.biorxiv.org/content/10.1101/2020.12.10.419424v1), Pavlovic et al 2020 (includes original authorâ€™s evaluation of whether a citation of their work is correct)

  * [â€œEnergy-Efficient Algorithmsâ€](https://arxiv.org/abs/1605.08448), Demaine et al 2016 ([reversible computing](https://en.wikipedia.org/wiki/Reversible_computing) asymptotics: constant-factor [stacks](https://en.wikipedia.org/wiki/Stack_\(abstract_data_type\))/[arrays](https://en.wikipedia.org/wiki/Dynamic_array), ğ’ª(log _n_) time/energy [AVL trees](https://en.wikipedia.org/wiki/AVL_tree), ğ’ª(_n_) space [sorts](https://en.wikipedia.org/wiki/Comparison_sort), & various ğ’ª(Vertex+Edge) time/space/energy [graph searches](https://en.wikipedia.org/wiki/Graph_traversal))

  * [â€œThe Optimizerâ€™s Curse: Skepticism and Postdecision Surprise in Decision Analysisâ€](https://www.gwern.net/docs/statistics/decision/2006-smith.pdf), Smith & Winkler 2006 (regression to the mean is everywhere; another example of why Bayes & decision theory are two great flavors that go great together)




## 2.4 Politics/Religion

  * [â€œThe Mechanisms of Cult Production: An Overviewâ€](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3650704), Xavier Marquez 2020 (see previously his [blog roundup](https://www.gwern.net/newsletter/2019/02#abandoned-footnotes))

  * [â€œWhen Prophecy Fails and Faith Persists: A Theoretical Overviewâ€](https://www.gwern.net/docs/sociology/1999-dawson.pdf), Dawson 1999

  * [â€œWhy We Fight Over Fictionâ€](https://www.overcomingbias.com/2020/11/why-we-fight-over-fiction.html), Robin Hanson

  * [The All-Woman Supreme Court](https://en.wikipedia.org/wiki/All-Woman_Supreme_Court)




## 2.5 Psychology/Biology

  * [â€œStill Aliveâ€](https://astralcodexten.substack.com/p/still-alive), Scott Alexander (announcement of SSC return as Substack newsletter â€˜Astral Codex Tenâ€™ & launching a low-cost psychiatry clinic â€˜Lorien Psychiatryâ€™)

  * [â€œThe Temporal Dynamics of Opportunity Costs: A Normative Account of Cognitive Fatigue and Boredomâ€](https://www.biorxiv.org/content/10.1101/2020.09.08.287276v1), Agrawal et al 2020

  * [â€œA unified framework for association and prediction from vertex-wise grey-matter structureâ€](https://onlinelibrary.wiley.com/doi/full/10.1002/hbm.25109), Couvy-Duchesne et al 2020 (more [morphometricity](https://www.gwern.net/Questions#variance-components))

  * **Common phenomena** : [â€œSounds from seeing silent motion: Who hears them, and what looks loudest?â€](https://www.gwern.net/docs/psychology/2018-fassnidge.pdf), Fassnidge & Freeman 2018 (on â€˜visual earâ€™; previously: [Saenz & Koch 2008](https://www.sciencedirect.com/science/article/pii/S0960982208007343 "The sound of change: visually-induced auditory synaesthesia"), [Fassnidge et al 2017](https://www.gwern.net/docs/psychology/2017-fassnidge.pdf "A deafening flash! Visual interference of auditory signal detection"))

  * [â€œPredicting Mental Health From Followed Accounts on Twitterâ€](https://online.ucpress.edu/collabra/article/7/1/18731/115925/Predicting-Mental-Health-From-Followed-Accounts-on), Costelli et al 2021 ([Registered Report](https://en.wikipedia.org/wiki/Preregistration_\(science\)#Registered_reports): who you choose to follow says a lot about youâ€”[everything is correlated](https://www.gwern.net/Everything))

  * [â€œNo evidence for general intelligence in a fishâ€](https://www.biorxiv.org/content/10.1101/2021.01.08.425841v1), Aellen et al 2021

  * [Delirium tremens](https://en.wikipedia.org/wiki/Delirium_tremens)

  * [â€œMicrobiome connections with host metabolism and habitual diet from 1,098 deeply phenotyped individualsâ€](https://www.gwern.net/docs/biology/2021-asnicar.pdf), Asnicar et al 2021

  * [â€œUniversal DNA methylation age across mammalian tissuesâ€](https://www.biorxiv.org/content/10.1101/2021.01.18.426733v1), Lu et al 2021; [â€œWhole-body senescent cell clearance alleviates age-related brain inflammation and cognitive impairment in miceâ€](https://onlinelibrary.wiley.com/doi/full/10.1111/acel.13296), Ogrodnik et al 2021

  * [â€œBENDR: using transformers and a contrastive self-supervised learning task to learn from massive amounts of EEG dataâ€](https://arxiv.org/abs/2101.12037), Kostas et al 2021 (towards brain imitation learning)

  * [Parker-Hulme murder case](https://en.wikipedia.org/wiki/Parker%E2%80%93Hulme_murder_case); [The Slender Man stabbing](https://en.wikipedia.org/wiki/Slender_Man_stabbing) ([paracosms?](https://en.wikipedia.org/wiki/Paracosm))

  * **Correction** : [Programming competition skills do not inversely correlate with job performance](https://news.ycombinator.com/item?id=25426329) after all




## 2.6 Technology

  * [Natural nuclear fission reactors (Oklo)](https://en.wikipedia.org/wiki/Natural_nuclear_fission_reactor)

  * [â€œBaffles and Bastions: The Universal Features of Fortificationsâ€](https://www.gwern.net/docs/history/2007-keeley.pdf), Keeley et al 2007

  * [The Corrupted Blood incident](https://en.wikipedia.org/wiki/Corrupted_Blood_incident)

  *  _[Footnote](https://www.gwern.net/docs/design/2020-jeremytankard-footnote-36-redisturbed.pdf)_[ 36: â€œRedisturbedâ€](https://www.gwern.net/docs/design/2020-jeremytankard-footnote-36-redisturbed.pdf): a _unicase_ font experiment




## 2.7 Economics

  * [â€œBusinesses Aim to Pull Greenhouse Gases From the Air. Itâ€™s a Gambleâ€](https://www.nytimes.com/2021/01/18/climate/carbon-removal-technology.html)

  * ["Does Advertising](https://freakonomics.com/podcast/advertising-part-1/) [Actually Work?"](https://freakonomics.com/podcast/advertising-part-2/) (what could be more obvious than â€œadvertising worksâ€, and trivial to confirm with correlational data? Yet, the tedious saying â€œcorrelation â‰  causationâ€ stubbornly insists on being true); [â€œDigital Paywall Design: Implications for Content Demand and Subscriptionsâ€](https://www.gwern.net/docs/traffic/2020-aral.pdf), Aral & Dhillon 2020 (NYT nag-paywall caused âˆ’9.9% reading; in line with [all the other results](https://www.gwern.net/Ads))

  * [â€œWho Gains and Who Loses from Credit Card Payments? Theory and Calibrationsâ€](https://www.gwern.net/docs/economics/2010-schuh.pdf), Schuh et al 2010 (a compelling case for getting a rewards credit card if youâ€™re a [debit card](https://en.wikipedia.org/wiki/Debit_card) userâ€”why subsidize them so much?)

  * [â€œSqueezing the bears: cornering risk and limits on arbitrage during the â€˜British bicycle maniaâ€™, 1896â€“1898â€](https://www.gwern.net/docs/economics/2019-quinn.pdf), Quinn 2019




## 2.8 Fiction

  * [â€œOn Venus, Have We Got a Rabbi!â€](https://www.tabletmag.com/sections/arts-letters/articles/on-venus-have-we-got-a-rabbi "A long-lost space age satire about what it means to be a Jew from one of science fictionâ€™s greatest humorists"), [William Tenn](https://en.wikipedia.org/wiki/William_Tenn) 2016

  * [â€œSt Martinâ€™s Four Wishesâ€](https://www.gwern.net/docs/history/2013-dubin-fabliauxtranslations-stmartinsfourwishes.pdf), Anonymous [medieval poet](https://en.wikipedia.org/wiki/Fabliau) (trans. Dubin 2013)




## 2.9 Miscellaneous

  * The [Anglo-Japanese style](https://en.wikipedia.org/wiki/Anglo-Japanese_style)

  * [Stalag Luft III](https://en.wikipedia.org/wiki/Stalag_Luft_III)

  * [Ferdinandea](https://en.wikipedia.org/wiki/Graham_Island_\(Mediterranean_Sea\))




* * *

  1. But itâ€™ll still be too many days â€™till we say weâ€™re sorry.




17

Share

TopLatestDiscussions

No posts

### Ready for more?

Subscribe

Â© 2026 Gwern Branwen Â· [Privacy](https://substack.com/privacy) âˆ™ [Terms](https://substack.com/tos) âˆ™ [Collection notice](https://substack.com/ccpa#personal-data-collected)

[ Start your Substack](https://substack.com/signup?utm_source=substack&utm_medium=web&utm_content=footer)[Get the app](https://substack.com/app/app-store-redirect?utm_campaign=app-marketing&utm_content=web-footer-button)

[Substack](https://substack.com) is the home for great culture




This site requires JavaScript to run correctly. Please [turn on JavaScript](https://enable-javascript.com/) or unblock scripts 
