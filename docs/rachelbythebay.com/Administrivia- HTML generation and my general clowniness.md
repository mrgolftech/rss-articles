# Administrivia: HTML generation and my general clowniness

**来源:** [rachelbythebay.com](https://rachelbythebay.com)
**发布时间:** 
**链接:** https://rachelbythebay.com/w/2023/03/31/html/

---

{'type': 'application/xhtml+xml', 'language': 'en', 'base': 'https://rachelbythebay.com/w/atom.xml', 'value': '<p>\nI\'ve been kind of quiet these past few weeks.  Part of that has been \nfrom plowing a bunch of work into getting serious about how all of the \n/w/ posts get generated.  I figure if I\'m going to start leaning on \npeople to not do goofy things with their feed readers, the least I can \ndo is make sure I\'m not sending them broken garbage.\n</p>\n<p>\nTo really explain this, I need to back up to 2011 when this whole thing \nwas just getting off the ground.  I started writing here in order to \nkeep the momentum from the writing I had been doing inside the company I \nwas about to leave.  I figured that anything was better than nothing, \nand so those posts were all done by hand.  The posts themselves were \nhand-formatted: I\'d type it up, slap on the header and footer, and then \nit\'d get a link from the top-level index page.\n</p>\n<p>\nThen people asked for an Atom feed, and I delivered on that too... ALSO \ndoing it by hand at first.  Yeah, that was about as awful as you can \npossibly imagine.  Obviously that could not stand, but it did get me \nthrough the first couple of days and posts, and then my little generator \ncame together and it picked up most of the load for me.\n</p>\n<p>\nBut there\'s a dirty little secret here: this generator has been little \nmore than a loop that slaps HTML paragraph ("p") tags around everything.  \nIt doesn\'t really understand what\'s going on, and any time it sees a \nblank line, it assumes one ended and another one just began.\n</p>\n<p>\nIf you\'ve ever looked at the source of some of the more complicated \nposts with embedded tables, audio players, PRE blocks or anything else \nof the sort, you\'ve probably wondered what kind of crazy I was smoking.  \nNow you know why.  The only reason it works at all is because the web as \na whole is terrible and browsers have had to adapt to our collective \nhuman clownery.  HTML parsers tend to ignore the botched tags, and it \ngenerally looks right anyway.\n</p>\n<p>\nI still find myself doing stupid things to work around the nuances of \nthe ridiculous state machine that I created.  If you\'ve seen PRE blocks \nwhere for some reason there are lines with a single space in them, this \nis why!  A blank line would trip the "stick on a /p and then a p" \nthing, but a line with a single space would not.  So, I\'ve been doing \nthat.\n</p>\n<p>\nWorse still, see how I\'m calling it /p and p?  I\'m not using the actual \nangle brackets?  Yeah, that\'s because there\'s no entity encoding in this \nthing at the moment.  I\'d have to manually do the whole "ampersand l t \nsemicolon" thing... and HAVE been doing this all this time.  I don\'t \nfeel like doing that at the moment.  (Because I\'d have to fix it when \nit\'s time to convert this very post, but I\'m getting ahead of myself.)\n</p>\n<p>\nBoth publog (the thing that is responsible for what you\'re seeing now) \nand my own diary software share a similar heritage, and I\'ve been bitten \nby the lack of proper handling of this stuff over the years.  For \nwhatever reason, I decided it was time to do something about it, and \nfinally got traction with an approach around the time of the new year.\n</p>\n<p>\nHere\'s what\'s coming: every single post will be run through a generator \nthat actually functions like a "real" parser - tokens and rules and \nput_backs and all of this!  It\'s not just a "am I in a paragraph right \nnow" state machine.  It\'ll accumulate text, and when it\'s ready to emit \na paragraph, it will do that with all of the rules it\'s been told about, \nlike how to handle attributes, their values, AND when (and what) to \nescape/encode in the actual body of the tag/container.\n</p>\n<p>\nThis also goes for some of the "commands" that have been part of the \ninput files all this time.  When I include an image, I\'ve been doing a \nspecial little thing that says "generate the IMG SRC gunk with the right \npath for this file with this height and width".  This lets me ensure \nthat the http and https feeds don\'t get cross-protocol URLs, among other \nthings.  The "this post has an update" lines and the backwards links to \nolder posts also work this way.\n</p>\n<p>\nThis HAD been working with a bunch of nasty stuff that was basically \nbuilding HTML from strings.  You know the type, right?  You print the \nleft bracket, IMG SRC=, then you have to do a \\" to get a literal " in \nthere without ending the string... and then you end the string.  Then \nyou add the filename, and start another string and put a \\" in it to \ncap off the SRC attribute of the IMG tag, and so on and so forth...\n</p>\n<img alt="This kind of crap!" height="34" src="https://rachelbythebay.com/w/2023/03/31/html/imgsrc.png?feed" width="528" />\n<p>\nI\'m kind of wondering who\'s reading this and thinks I\'m a clown vs. how \nmany people are reading this and are just nodding their heads like \n"yeah, totally, that\'s how we do HTML all over the place".  But I \ndigress.\n</p>\n<p>\nNow, actually doing this has meant coding it up, but it\'s also meant \ngoing back and converting all of the damn posts, too.  Any place where I \nhad raw HTML shenanigans going on (like doing my own "ampersand + l + t \n+ semicolon" stuff) had to be found and changed back to the actual \ncharacter I want there.  The program itself will do that encoding for \nme now.  It\'s nice to have it, but it\'s a chore to go and do it without \nbreaking anything, like a place where I WANT the literal gunk there.\n</p>\n<p>\nWith almost 5.5 MB of input text across 1400 posts, that was a \nnon-trivial amount of work.  I would not be surprised if I missed things \nthat will pop up down the road and which will need to be hammered back \ndown.\n</p>\n<p>\nSo yes, for a while, it will be "same clown, different circus".  But, at \nleast this time, I\'ll be trying to emit the right stuff.\n</p>\n<p>\nI haven\'t set a date or anything for this.  There\'s this possibility of \nalso trying to solve some other dumb problems that also vex certain \n(broken) feed readers at the same time, and I haven\'t decided whether to \nblock the rollout of the one thing on the rollout of the other one.  \nThis matters because I\'d rather not rewrite every single \n/w/YYYY/MM/DD/whatever/index.html page multiple times.  Ideally, they\'ll \nonly change the one time.  (What can I say, I care about these things.)\n</p>\n<p>\n...\n</p>\n<p>\nWhile waiting on that, if you\'re a feed reader author, you can at least \ncheck on a few things.  You aren\'t honestly taking the "updated" time \nfrom inside the feed and using that in the HTTP transaction \n(If-Modified-Since), right?  Right??  You know those are two totally \ndifferent things from different layers of the stack, and aren\'t \ninterchangeable, right?  The IMS value should come from the \n"Last-Modified" header I sent you in the first place.\n</p>\n<p>\nRight, Akregator?  Right, NextCloud-News?\n</p>\n<p>\nIt\'s crazy how long it took me to figure out why they were sending me \nreasonable-looking "IMS" values that I had never handed out.  It wasn\'t \nuntil I looked inside the actual feed that the penny dropped.  \n</p>\n<p>\nWant to know how the sausage is made and why this happens?  Okay, settle \nin.\n</p>\n<p>\nThe web pages and the feed files (yep, plural: http and https) are made \nby running the generator on my laptop.  The wall time on that system \nwinds up being used in the "updated" fields in the XML gunk that is the \nAtom feed.  The files also get a mtime that\'s about the same... on the \nlaptop.  More on that in a bit.\n</p>\n<p>\nThis writes to a directory tree that\'s a git repo, and a few moments \nlater there\'s a git add + git commit + git push that captures the \nchanges and schleps it off to my usual git storage space.\n</p>\n<p>\nLater on, I jump on snowgoose (that\'s my current web server machine) and \nhave it pull from that same git storage space into a local directory and \nthen rsync the new stuff out of that tree into the various document \nroots - there are multiple web sites on this box.\n</p>\n<p>\nIf you didn\'t know this already, git does not preserve mtimes.  The \nmtimes on files it writes out are just "now", whatever that may be.  \nIt\'s usually a minute or two later than when I did the generation on my \nlaptop, just because I don\'t usually push to "production" right away.  I \nusually eyeball things on an internal machine first.\n</p>\n<p>\nNow, rsync DOES preserve mtimes, but it\'s preserving values that aren\'t \nparticularly interesting.  They are just the time when "git pull" ran on \nthe web server and brought in the new/updated versions of the files.  \nIt\'s not the same time that the actual feed was updated on my laptop.\n</p>\n<p>\nApache uses the mtime on the files, so it\'s handing out "Last-Modified: \n(whatever)" based on that "git pull".  This is not going to match the \n"updated" XML blob in the feed itself.\n</p>\n<p>\nSo, what I get to consider is whether I want to go nuclear on this and \ncome up with something that will actually *SET* the mtimes explicitly \nand make sure they stay set all the way to the document root, no matter \nwhere it is.\n</p>\n<p>\nBesides the broken feed fetchers, there\'s another reason to care about \nthis sort of thing.  What if I get a second web server, and put it \nbehind a load balancer?  Requests could be served by one or the other.  \nImagine if the two web heads did their "git pull" at two different \ntimes.  Clients would get one Last-Modified value from server #1 and \nanother value from server #2.  Chaos!  Madness!  Insanity!\n</p>\n<p>\nNow, I don\'t have a second web server, and in fact have no plans to do \nthat unless people want to start throwing a LOT of money at me to run \none in a colocation rack somewhere.  But, it\'s the principle of the \nthing: controlling important values explicitly instead of leaving them \nto chance, *especially* since I\'m expecting other people to do their \npart with those same values.\n</p>\n<p>\nIt\'s funny, right.  I never thought I\'d miss XHP until I started doing \nthis project, and I didn\'t even do that many (internal) web pages at FB \n- just the ones I absolutely needed because nothing else would do.\n</p>'}

---

*抓取时间: 2026-02-09 06:02:19*
