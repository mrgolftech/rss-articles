# Introducing GPT‑5.3‑Codex‑Spark

**来源:** [simonwillison.net](https://simonwillison.net)
**发布时间:** 2026-02-12T21:16:07+00:00
**链接:** https://simonwillison.net/2026/Feb/12/codex-spark/#atom-everything

---

<p><strong><a href="https://openai.com/index/introducing-gpt-5-3-codex-spark/">Introducing GPT‑5.3‑Codex‑Spark</a></strong></p>
OpenAI announced a partnership with Cerebras <a href="https://openai.com/index/cerebras-partnership/">on January 14th</a>. Four weeks later they're already launching the first integration, "an ultra-fast model for real-time coding in Codex".</p>
<p>Despite being named GPT-5.3-Codex-Spark it's not purely an accelerated alternative to GPT-5.3-Codex - the blog post calls it "a smaller version of GPT‑5.3-Codex" and clarifies that "at launch, Codex-Spark has a 128k context window and is text-only."</p>
<p>I had some preview access to this model and I can confirm that it's significantly faster than their other models.</p>
<p>Here's what that speed looks like running in Codex CLI:</p>
<div>
    <video controls="controls" poster="https://static.simonwillison.net/static/2026/gpt-5.3-codex-spark-medium-last.jpg" preload="none" style="width: 100%; height: auto;">
        <source src="https://static.simonwillison.net/static/2026/gpt-5.3-codex-spark-medium.mp4" type="video/mp4" />
    </video>
</div>

<p>That was the "Generate an SVG of a pelican riding a bicycle" prompt - here's the rendered result:</p>
<p><img alt="Whimsical flat illustration of an orange duck merged with a bicycle, where the duck's body forms the seat and frame area while its head extends forward over the handlebars, set against a simple light blue sky and green grass background." src="https://static.simonwillison.net/static/2026/gpt-5.3-codex-spark-pelican.png" /></p>
<p>Compare that to the speed of regular GPT-5.3 Codex medium:</p>
<div>
    <video controls="controls" poster="https://static.simonwillison.net/static/2026/gpt-5.3-codex-medium-last.jpg" preload="none" style="width: 100%; height: auto;">
        <source src="https://static.simonwillison.net/static/2026/gpt-5.3-codex-medium.mp4" type="video/mp4" />
    </video>
</div>

<p>Significantly slower, but the pelican is a lot better:</p>
<p><img alt="Whimsical flat illustration of a white pelican riding a dark blue bicycle at speed, with motion lines behind it, its long orange beak streaming back in the wind, set against a light blue sky and green grass background." src="https://static.simonwillison.net/static/2026/gpt-5.3-codex-pelican.png" /></p>
<p>What's interesting about this model isn't the quality though, it's the <em>speed</em>. When a model responds this fast you can stay in flow state and iterate with the model much more productively.</p>
<p>I showed a demo of Cerebras running Llama 3.1 70 B at 2,000 tokens/second against Val Town <a href="https://simonwillison.net/2024/Oct/31/cerebras-coder/">back in October 2024</a>. OpenAI claim 1,000 tokens/second for their new model, and I expect it will prove to be a ferociously useful partner for hands-on iterative coding sessions.</p>
<p>It's not yet clear what the pricing will look like for this new model.


    <p>Tags: <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/openai">openai</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/cerebras">cerebras</a>, <a href="https://simonwillison.net/tags/pelican-riding-a-bicycle">pelican-riding-a-bicycle</a>, <a href="https://simonwillison.net/tags/llm-release">llm-release</a>, <a href="https://simonwillison.net/tags/codex-cli">codex-cli</a></p>

---

*抓取时间: 2026-02-13 06:03:00*
