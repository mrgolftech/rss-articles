# Taalas serves Llama 3.1 8B at 17,000 tokens/second

**来源:** [simonwillison.net](https://simonwillison.net)
**发布时间:** 2026-02-20T22:10:04+00:00
**链接:** https://simonwillison.net/2026/Feb/20/taalas/#atom-everything

---

<p><strong><a href="https://taalas.com/the-path-to-ubiquitous-ai/">Taalas serves Llama 3.1 8B at 17,000 tokens/second</a></strong></p>
This new Canadian hardware startup just announced their first product - a custom hardware implementation of the Llama 3.1 8B model (from <a href="https://simonwillison.net/2024/Jul/23/introducing-llama-31/">July 2024</a>) that can run at a staggering 17,000 tokens/second.</p>
<p>I was going to include a video of their demo but it's so fast it would look more like a screenshot. You can try it out at <a href="https://chatjimmy.ai">chatjimmy.ai</a>.</p>
<p>They describe their Silicon Llama as “aggressively quantized, combining 3-bit and 6-bit parameters.” Their next generation will use 4-bit - presumably they have quite a long lead time for baking out new models!

    <p><small></small>Via <a href="https://news.ycombinator.com/item?id=47086181">Hacker News</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/llama">llama</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/llm-performance">llm-performance</a></p>

---

*抓取时间: 2026-02-22 00:02:38*
