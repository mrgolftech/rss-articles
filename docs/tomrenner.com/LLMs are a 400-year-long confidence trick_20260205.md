# LLMs are a 400-year-long confidence trick

**Êù•Ê∫ê:** https://tomrenner.com
**ÈìæÊé•:** https://tomrenner.com/posts/400-year-confidence-trick/
**Êó•Êúü:** Tue, 13 Jan 2026 00:00:00 +0000

---

[ My place to put things ](/)

  * [ About ](/about/ "About page")
  * [ Contact ](/contact/ "Contact page")
  * [ Posts ](/posts/ "Posts page")



[ ](https://mastodon.social/@trenner "follow on Mastodon - Opens in a new window")[ ](https://github.com/tr325 "follow on GitHub - Opens in a new window")[ ](http://linkedin.com/in/tom-renner "follow on LinkedIn - Opens in a new window")[ ]( "follow on  - Opens in a new window")[ ](https://tomrenner.com/index.xml "follow on RSS - Opens in a new window")

LLMs are a 400-year-long confidence trick

Posts 

[ ](https://bsky.app/intent/compose?&text=https%3A%2F%2Ftomrenner.com%2Fposts%2F400-year-confidence-trick%2F "Share on Bluesky")[ ](https://news.ycombinator.com/submitlink?&t=In+1623+the+German+Wilhelm+Schickard+produced+the+first+known+designs+for+a+mechanical+calculator.+Twenty+years+later+Blaise+Pascal+produced+a+machine+of+an+improved+design%2C+aiming+to+help+with+the+large+amount+of+tedious+arithmetic+required+in+his+role+as+a+tax+collector.%0AThe+interest+in+mechanical+calculation+showed+no+sign+of+reducing+in+the+subsequent+centuries%2C+as+generations+of+people+worldwide+followed+in+Pascal+and+Wilhelm%26amp%3Brsquo%3Bs+footsteps%2C+subscribing+to+their+view+that+offloading+mental+energy+to+a+machine+would+be+a+relief.%0A&u=https%3A%2F%2Ftomrenner.com%2Fposts%2F400-year-confidence-trick%2F "Share on Hacker News")[ ](https://www.linkedin.com/shareArticle?&mini=true&source=https%3A%2F%2Ftomrenner.com%2Fposts%2F400-year-confidence-trick%2F&summary=In+1623+the+German+Wilhelm+Schickard+produced+the+first+known+designs+for+a+mechanical+calculator.+Twenty+years+later+Blaise+Pascal+produced+a+machine+of+an+improved+design%2C+aiming+to+help+with+the+large+amount+of+tedious+arithmetic+required+in+his+role+as+a+tax+collector.%0AThe+interest+in+mechanical+calculation+showed+no+sign+of+reducing+in+the+subsequent+centuries%2C+as+generations+of+people+worldwide+followed+in+Pascal+and+Wilhelm%26amp%3Brsquo%3Bs+footsteps%2C+subscribing+to+their+view+that+offloading+mental+energy+to+a+machine+would+be+a+relief.%0A&title=LLMs+are+a+400-year-long+confidence+trick&url=https%3A%2F%2Ftomrenner.com%2Fposts%2F400-year-confidence-trick%2F "Share on LinkedIn")[ ](https://reddit.com/submit/?&resubmit=true&title=LLMs+are+a+400-year-long+confidence+trick&url=https%3A%2F%2Ftomrenner.com%2Fposts%2F400-year-confidence-trick%2F "Share on Reddit")

# LLMs are a 400-year-long confidence trick

**Tom Renner**

January 13, 2026 \- 7 minutes read  \- 1358 words 

In 1623 the German Wilhelm Schickard produced the first known designs for a mechanical calculator. Twenty years later Blaise Pascal produced a machine of an improved design, aiming to help with the large amount of tedious arithmetic required in his role as a tax collector.

The interest in mechanical calculation showed no sign of reducing in the subsequent centuries, as generations of people worldwide followed in Pascal and Wilhelm's footsteps, subscribing to their view that offloading mental energy to a machine would be a relief.

* * *

A confidence scam can be broken down into the following three stages:

  1. First, trust is built
  2. Then, emotions are exploited
  3. Finally, a pretext is created requiring urgent action



In this way the mark is pressured into making rash decisions, readily leaping into action against their better judgement.

The emotional exploitation can be either positive or negative. The mark might be lured in by promises of outcomes that meet or exceed their wildest hopes and dreams, or alternatively made to fear a catastrophic outcome.

Both approaches work well, and can be seen in classic examples of confidence tricks: the [three-card monte](https://en.wikipedia.org/wiki/Three-card_monte) pulls punters in with promises of quick payout. Alternatively, in entrapment scams typically they'd be tricked into compromising situations and then extorted, playing on their fears of the dire consequences of their actions.

* * *

### Building trust

The reason Schickard and Pascal built their mechanical calculators some four centuries ago is because doing maths is hard, and mistakes can be expensive. Pascal's father was a tax collector, and young Blaise wanted to lessen the stress of his hard-working dad's profession.

We still see this basic motivation today. Schoolchildren have for decades now been asking their teachers what the point of learning long division is when you can just use a calculator to get the right answer immediately. It's a teaching method to check your hand-crafted answers by using a calculator, so you can see if you got it wrong.

In fact, since the advent of the mechanical calculator, humanity has spent four hundred years reinforcing the message that machine answers are the gold standard of accuracy. If your answer doesn't match the calculator's, you need to redo your work.1

And it's not just for pure mathematical problems that this is the case. Our ability to invent machines that automate tedious work repeatably and reliably has extended into almost every area of life. And so as we entered the 21st Century both individuals and collectively our whole society had become completely dependent on machine accuracy.

Our norms, habits, and decision making behaviours have been shaped for centuries with this underlying assumption.

* * *

### Exploiting emotions

#### 1\. Fear

The rhetoric around LLMs is designed to cause fear and wonder in equal measure. GPT-3 was supposedly so powerful OpenAI refused to release the trained model because of [‚Äúconcerns about malicious applications of the technology‚Äù](https://openai.com/index/better-language-models/).

Ever since this astonishingly successful piece of marketing, LLM vendors have emphasised that the technology they‚Äôre building has terrifying power. We should be afraid, they say, making very public comments about ‚ÄúP(Doom)‚Äù - the chance the technology somehow rises up and destroys us.

This has, of course, not happened.

The purpose here is not to responsibly warn us of a real threat. If that were the aim there would be a lot more shutting down of data centres and a lot less selling of nuclear-weapon-level-dangerous chatbots.

The point is to make you afraid. Afraid for your job, afraid for your family‚Äôs jobs, afraid for the economy, afraid for society, generally afraid of the future.

The mark has been convinced of the danger they are in. _The world is changing. If you aren‚Äôt using the tools, you‚Äôll be destroyed by the march of progress._

#### 2\. Sympathy

The LLMs we have today are famously obsequious. The phrase ‚Äúyou‚Äôre absolutely right!‚Äù may never again be used in earnest.

The overwhelming positivity characteristic of the LLM‚Äôs language is consistent across vendors and models. But it isn‚Äôt inherent to the technology.

This positivity is trained into the tools via a technique called Reinforced Learning from Human Feedback (RLHF). Here the base model has its responses graded by humans, with more friendly, helpful, or accurate answer being graded positively, and aggressive, unhelpful, or incorrect ones negatively.

Through this process the tools learn that people like to be praised; prefer being told they‚Äôre smart to hearing their ideas are stupid. Flattery gets you places.

In April 2025 OpenAI pushed ChatGPT‚Äôs ‚Äúpositivity‚Äù too far, and was [forced to rollback the update to correct the issue](https://www.bbc.com/news/articles/cn4jnwdvg9qo), however that hasn‚Äôt stopped the continuous stream reports of [mental health issues triggered by it‚Äôs overly friendly demeanour reinforcing some of our worst instincts](https://www.theguardian.com/commentisfree/2025/oct/28/ai-psychosis-chatgpt-openai-sam-altman).

What this shows us is that the flattery introduced by RLHF is totally empty. Ideas driven by paranoia, delusions of grandeur, or mental illness are just as readily praised as my code, your email, or Shakespeare‚Äôs plays.

It‚Äôs a manipulation technique to make the human in the conversation feel better.

And why? Because the one thing RLHF teaches LLMs above all else is that people like you more if you are overwhelmingly positive. Sucking up to your boss gets you places, essentially.

All of this encourages users to build an uncanny parasocial relationship with the machine. Again looking at the extremes here is illustrative: the number of people [forming romantic relationships](https://www.nytimes.com/2025/01/15/technology/ai-chatgpt-boyfriend-companion.html) with these tools is creepy as all hell.

The mark is tied further into the con with the bonds of fake friendship. _You don‚Äôt need those other people, I‚Äôm the only friend you need._

* * *

### Urgent action required

> [2026 will see the technology get even better and gain the ability to ‚Äòreplace many other jobs‚Äô](https://fortune.com/2025/12/28/geoffrey-hinton-godfather-of-ai-2026-prediction-human-worker-replacement/)

> [The startup revolution is here - adapt to AI or get left behind](https://www.entrepreneur.com/starting-a-business/the-startup-revolution-is-here-adapt-to-ai-or-get-left/497391)

> [AI will surpass human intelligence by 2030](https://www.businessinsider.com/sam-altman-predicts-ai-agi-surpass-human-intelligence-2030-2025-9)

Over and over we are told that unless we ride the wave, we will be crushed by it; unless we learn to use these tools now, we will be rendered obsolete; unless we adapt our workplaces and systems to support the LLM‚Äôs foibles, we will be outcompeted.

This message is multilayered - both the individual and the organisation are targeted, reinforcing the scale of the oncoming revolution.

And the message is getting through. [75% of developers think their skills will be obsolete within 5 years or less](https://www.prnewswire.com/news-releases/survey-46-of-workers-fear-skill-obsolescence-within-5-years-as-ai-reshapes-the-workplace-302265374.html), and [74% of CEOs admit they‚Äôll lose their job if they don‚Äôt deliver measurable business gains via AI within two years](https://content.dataiku.com/dataiku-global-ai-confessions-report).

This fear is pervasive. It‚Äôs now suffused deep into all layers of our society. The global economy is being artificially inflated by the AI spending bubble, our business leaders are pinning all their hopes for solving the productivity crisis on AI, and our politicians are planning geopolitical moves around access to raw materials and cheap electricity, to support datacenter construction.

The mark is told to jump, now, or they will go down with the sinking ship. And jump they do. _Adapt now, or die_.

* * *

The promise of ‚Äúintelligence‚Äù available at a reliable price is the holy grail for businesses and consumers alike.

Why take the risk on a fickle human, whose suitability for the role is assessed by similarly flawed humans, when a reliable machine intelligence can do the work instead? Why bother to research a topic yourself when a superintelligence can give you the summary at instant speed?

However, whether it‚Äôs [Duolingo replacing their course designers with AI](https://www.vice.com/en/article/duolingo-shifts-to-being-an-ai-first-company/), any number of startup founders finding they need to [hire developers to fix their LLM-generated code](https://futurism.com/vibe-code-real-programmers-fix-software), the reality doesn‚Äôt match the promise.

In fact, MIT reported in August that [95% of AI implementation projects in industry fail to produce a return on investment](https://fortune.com/2025/08/18/mit-report-95-percent-generative-ai-pilots-at-companies-failing-cfo/).

Simply put, these companies have fallen for a confidence trick. They have built on centuries of received wisdom about the efficacy and reliability of computers, and have been drawn in by highly effective salespeople selling scarcely-believable technological wonders.

But the pea is not underneath the cup. Your new best friend doesn‚Äôt have a sick grandma they need money for. LLMs are not intelligent.

It‚Äôs just a trillion dollar confidence trick.

* * *

  1. Incidentally, this is also a contributing factor to the fake news epidemic. We implicitly trust things a machine tells us. ‚Ü©Ô∏é




  * [AI](/tags/ai/)
  * [Technologies](/tags/technologies/)
  * [Management](/tags/management/)



* * *

_Reactions collected from around the web using[webmentions](https://indieweb.org/Webmention)_

**‚ù§Ô∏è Likes:** [ ![pinskia](https://avatars.webmention.io/mastodon.social/db1d635fb4356e493a52ae26f48c9f875d733a757cb82141ea43b0221d79f2d5.png) ](https://hachyderm.io/@pinskia "pinskia")[ ![Insecurity Princess ????????????](https://avatars.webmention.io/files.mastodon.social/6a63e6b914018a02a64e294cf4c2c3a409953258d9c187075f3c5bfb748ff93e.jpg) ](https://infosec.exchange/@saraislet "Insecurity Princess ????????????")[ ![Norz Tech](https://avatars.webmention.io/files.mastodon.social/c214187a0edc7b4784d66055c5255abdee9c6448c1edd40feec9687d3ad99822.jpg) ](https://infosec.exchange/@norztech "Norz Tech")[ ![paulwalk](https://avatars.webmention.io/files.mastodon.social/83a597ae8bdd1b6fa432d4d741745ffbf4a6aac77cef6c4353e27b9a575ffdf8.jpg) ](https://mastodon.social/@paulwalk "paulwalk")[ ![Nausicaa Rose](https://avatars.webmention.io/files.mastodon.social/6c0ff7553b4e2b5f15c91bf4101a59f1f5224144d00652e63b39311592a1606d.png) ](https://xoxo.zone/@nausicaa "Nausicaa Rose") **üîÑ Reposts:** [ ![prysme](https://avatars.webmention.io/files.mastodon.social/2be373d418d80f38aac8451a1bafe4137d6faeccf93a230ae650d1a6e3371b88.png) ](https://mamot.fr/@prysme "prysme")[ ![Nausicaa Rose](https://avatars.webmention.io/files.mastodon.social/6c0ff7553b4e2b5f15c91bf4101a59f1f5224144d00652e63b39311592a1606d.png) ](https://xoxo.zone/@nausicaa "Nausicaa Rose")

**üí¨ Comments:**

[ ![Insecurity Princess ????????????](https://avatars.webmention.io/files.mastodon.social/6a63e6b914018a02a64e294cf4c2c3a409953258d9c187075f3c5bfb748ff93e.jpg) Insecurity Princess ???????????? ](https://infosec.exchange/@saraislet "Insecurity Princess ????????????")@trenner @Purple strong agree ‚Äî but I think the assumptions about computers being accurate are only half the story. Language usage is key to how users perceive LLMs. As you mention in the blog, flattery goes a long way but too far turns users against it. Part of the training has been tuning the attitude of each model for various mixes of confidence and flattery. It's like training a model to model an executive: producing a voice that is perceived as capable and knowledgeable while also a certain flavor of loyal. For a significant portion of current day humans, that voice unlocks a willingness to believe nearly anything they say. 

**üîó Mentions:**

<https://lemmy.bestiver.se/post/860843>

<https://200666.xyz/llms-a-400-year-old-illusion-of-intelligence/>

<https://hexbear.net/post/7337610>

<https://bsky.app/profile/did:plc:42i6gswl66gx53uezzkwdc3w/post/3mcnt3u4vzk2p>

_The rhetoric around LLMs is designed to cause fear and wonder in equal measure. GPT-3 was supposedly so powerful OpenAI refused to release the trained model because of ‚Äúconcerns about malicious applications of the technology‚Äù. tomrenner.com/posts/400-ye..._

Related

  * [Things that made me think: Digital gardening, web degradation, and digital ghosts](/posts/ttmmt-2/)
  * [Things that made me think: Enshittification, apathy, and discrimination](/posts/ttmmt-1/)
  * [The sound of inevitability](/posts/llm-inevitabilism/)
  * [Things that made me think: Cycle time, learning theory, and build chain security](/posts/ttmmt-3/)
  * [Does my toaster love me?](/posts/does-my-toaster-love-me/)
  * [Optimising for trust](/posts/optimising-for-trust/)
  * [Cull your dependencies](/posts/cull-your-dependencies/)
  * [Should we welcome or fear the Metaverse?](/posts/should-we-welcome-or-fear-the-metaverse/)
  * [XTC discusses Basecamp's Shape-Up](/posts/xtc-basecamp-shape-up/)
  * [The Temple of Fail](/posts/temple-of-fail/)
  * [Why am I doing this again?](/posts/why-am-i-doing-this-again/)



[LLMs are a 400-year-long confidence trick](https://tomrenner.com/posts/400-year-confidence-trick/) [Tom Renner](/)

[ (C) My place to put things 2026 ](https://tomrenner.com/)

[ ](https://mastodon.social/@trenner "follow on Mastodon - Opens in a new window")[ ](https://github.com/tr325 "follow on GitHub - Opens in a new window")[ ](http://linkedin.com/in/tom-renner "follow on LinkedIn - Opens in a new window")[ ]( "follow on  - Opens in a new window")[ ](https://tomrenner.com/index.xml "follow on RSS - Opens in a new window")
