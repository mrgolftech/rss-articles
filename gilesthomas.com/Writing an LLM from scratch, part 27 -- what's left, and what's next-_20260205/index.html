
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="技术博客文章聚合 - Hacker News 2025年最受欢迎的博客">
      
      
        <meta name="author" content="OpenClaw">
      
      
        <link rel="canonical" href="https://mrgolftech.github.io/rss-articles/gilesthomas.com/Writing%20an%20LLM%20from%20scratch%2C%20part%2027%20--%20what%27s%20left%2C%20and%20what%27s%20next-_20260205/">
      
      
      
      
        
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.1">
    
    
      
        <title>Writing an LLM from scratch, part 27 -- what's left, and what's next? - Hacker News 精选博客</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#writing-an-llm-from-scratch-part-27-whats-left-and-whats-next" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../.." title="Hacker News 精选博客" class="md-header__button md-logo" aria-label="Hacker News 精选博客" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Hacker News 精选博客
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Writing an LLM from scratch, part 27 -- what's left, and what's next?
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="切换到深色模式"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="切换到深色模式" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="切换到浅色模式"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="切换到浅色模式" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="分享" aria-label="分享" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/mrgolftech/rss-articles" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    rss-articles
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
  
    
  
  首页

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../blogs/" class="md-tabs__link">
        
  
  
    
  
  所有博客

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Hacker News 精选博客" class="md-nav__button md-logo" aria-label="Hacker News 精选博客" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Hacker News 精选博客
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/mrgolftech/rss-articles" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    rss-articles
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    首页
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../blogs/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    所有博客
  

    
  </span>
  
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#writing-an-llm-from-scratch-part-27-whats-left-and-whats-next_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Writing an LLM from scratch, part 27 -- what's left, and what's next?
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Writing an LLM from scratch, part 27 -- what&#39;s left, and what&#39;s next?">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-appendices-and-supplementary-material" class="md-nav__link">
    <span class="md-ellipsis">
      
        The appendices and supplementary material
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#things-ive-deferred-myself" class="md-nav__link">
    <span class="md-ellipsis">
      
        Things I've deferred myself
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Things I&#39;ve deferred myself">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#long-context-and-attention-efficiency" class="md-nav__link">
    <span class="md-ellipsis">
      
        Long context and attention efficiency.
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#maths" class="md-nav__link">
    <span class="md-ellipsis">
      
        Maths
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#optimisers" class="md-nav__link">
    <span class="md-ellipsis">
      
        Optimisers
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#automatic-differentiation-and-the-backward-pass" class="md-nav__link">
    <span class="md-ellipsis">
      
        Automatic differentiation and the backward pass
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tokenisers" class="md-nav__link">
    <span class="md-ellipsis">
      
        Tokenisers
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Tokenisers">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#trying-to-train-the-llm-as-a-base-model" class="md-nav__link">
    <span class="md-ellipsis">
      
        Trying to train the LLM as a base model
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#building-an-llm-from-scratch-on-my-own" class="md-nav__link">
    <span class="md-ellipsis">
      
        Building an LLM from scratch on my own.
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mixture-of-experts" class="md-nav__link">
    <span class="md-ellipsis">
      
        Mixture-of-experts
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#so-what-next" class="md-nav__link">
    <span class="md-ellipsis">
      
        So, what next?
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#coming-up" class="md-nav__link">
    <span class="md-ellipsis">
      
        Coming up...
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/mrgolftech/rss-articles/edit/master/docs/gilesthomas.com/Writing an LLM from scratch, part 27 -- what's left, and what's next-_20260205.md" title="编辑此页" class="md-content__button md-icon" rel="edit">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75z"/></svg>
    </a>
  
  


<h1 id="writing-an-llm-from-scratch-part-27-whats-left-and-whats-next">Writing an LLM from scratch, part 27 -- what's left, and what's next?<a class="headerlink" href="#writing-an-llm-from-scratch-part-27-whats-left-and-whats-next" title="Permanent link">&para;</a></h1>
<p><strong>来源:</strong> https://gilesthomas.com
<strong>链接:</strong> https://www.gilesthomas.com/2025/11/llm-from-scratch-27-whats-left-and-whats-next
<strong>日期:</strong> Tue, 04 Nov 2025 00:40:00 +0000</p>
<hr />
<p><a href="/">Giles' blog</a></p>
<p><a href="https://x.com/gpjt"><img alt="Me on X/Twitter" src="/images/x-icon.png" /></a> <a href="https://bsky.app/profile/gilesthomas.com"><img alt="Me on Bluesky" src="/images/bluesky-icon.png" /></a> <a href="https://github.com/gpjt"><img alt="My GitHub profile" src="/images/github-icon.png" /></a> <a href="https://huggingface.co/gpjt"><img alt="My Hugging Face profile" src="/images/hf-icon.png" /></a> <a href="/feed/rss.xml"><img alt="RSS feed for this blog" src="/images/rss-icon.png" /></a></p>
<p><a href="/about">About</a></p>
<p><a href="/contact">Contact</a></p>
<p>Archives </p>
<p>Categories </p>
<p>Blogroll </p>
<ul>
<li><a href="/2026/02"> February 2026 (2) </a></li>
<li><a href="/2026/01"> January 2026 (4) </a></li>
<li><a href="/2025/12"> December 2025 (1) </a></li>
<li><a href="/2025/11"> November 2025 (3) </a></li>
<li><a href="/2025/10"> October 2025 (9) </a></li>
<li><a href="/2025/09"> September 2025 (3) </a></li>
<li><a href="/2025/08"> August 2025 (5) </a></li>
<li><a href="/2025/07"> July 2025 (1) </a></li>
<li><a href="/2025/06"> June 2025 (2) </a></li>
<li><a href="/2025/05"> May 2025 (3) </a></li>
<li><a href="/2025/04"> April 2025 (2) </a></li>
<li><a href="/2025/03"> March 2025 (7) </a></li>
<li><a href="/2025/02"> February 2025 (10) </a></li>
<li><a href="/2025/01"> January 2025 (6) </a></li>
<li><a href="/2024/12"> December 2024 (7) </a></li>
<li><a href="/2024/09"> September 2024 (1) </a></li>
<li><a href="/2024/08"> August 2024 (2) </a></li>
<li><a href="/2024/07"> July 2024 (2) </a></li>
<li><a href="/2024/05"> May 2024 (2) </a></li>
<li><a href="/2024/04"> April 2024 (2) </a></li>
<li><a href="/2024/02"> February 2024 (2) </a></li>
<li><a href="/2023/04"> April 2023 (1) </a></li>
<li><a href="/2023/03"> March 2023 (2) </a></li>
<li><a href="/2022/09"> September 2022 (1) </a></li>
<li><a href="/2022/02"> February 2022 (1) </a></li>
<li><a href="/2021/11"> November 2021 (1) </a></li>
<li><a href="/2021/03"> March 2021 (1) </a></li>
<li><a href="/2021/02"> February 2021 (2) </a></li>
<li><a href="/2019/08"> August 2019 (1) </a></li>
<li><a href="/2018/11"> November 2018 (1) </a></li>
<li><a href="/2017/05"> May 2017 (1) </a></li>
<li><a href="/2016/12"> December 2016 (1) </a></li>
<li><a href="/2016/04"> April 2016 (1) </a></li>
<li><a href="/2015/08"> August 2015 (1) </a></li>
<li><a href="/2014/12"> December 2014 (1) </a></li>
<li><a href="/2014/08"> August 2014 (1) </a></li>
<li><a href="/2014/03"> March 2014 (1) </a></li>
<li><a href="/2013/12"> December 2013 (1) </a></li>
<li><a href="/2013/10"> October 2013 (3) </a></li>
<li><a href="/2013/09"> September 2013 (4) </a></li>
<li><a href="/2013/08"> August 2013 (2) </a></li>
<li><a href="/2013/07"> July 2013 (1) </a></li>
<li><a href="/2013/06"> June 2013 (1) </a></li>
<li><a href="/2013/02"> February 2013 (1) </a></li>
<li><a href="/2012/10"> October 2012 (1) </a></li>
<li><a href="/2012/06"> June 2012 (1) </a></li>
<li><a href="/2012/05"> May 2012 (1) </a></li>
<li><a href="/2012/04"> April 2012 (1) </a></li>
<li><a href="/2012/02"> February 2012 (1) </a></li>
<li><a href="/2011/10"> October 2011 (1) </a></li>
<li><a href="/2011/06"> June 2011 (1) </a></li>
<li><a href="/2011/05"> May 2011 (1) </a></li>
<li><a href="/2011/04"> April 2011 (1) </a></li>
<li><a href="/2011/03"> March 2011 (1) </a></li>
<li><a href="/2011/02"> February 2011 (1) </a></li>
<li><a href="/2011/01"> January 2011 (1) </a></li>
<li><a href="/2010/12"> December 2010 (3) </a></li>
<li><a href="/2010/11"> November 2010 (1) </a></li>
<li><a href="/2010/10"> October 2010 (1) </a></li>
<li><a href="/2010/09"> September 2010 (1) </a></li>
<li><a href="/2010/08"> August 2010 (1) </a></li>
<li><a href="/2010/07"> July 2010 (1) </a></li>
<li><a href="/2010/05"> May 2010 (3) </a></li>
<li><a href="/2010/04"> April 2010 (1) </a></li>
<li><a href="/2010/03"> March 2010 (2) </a></li>
<li><a href="/2010/02"> February 2010 (3) </a></li>
<li><a href="/2010/01"> January 2010 (4) </a></li>
<li><a href="/2009/12"> December 2009 (2) </a></li>
<li><a href="/2009/11"> November 2009 (5) </a></li>
<li><a href="/2009/10"> October 2009 (2) </a></li>
<li><a href="/2009/09"> September 2009 (2) </a></li>
<li><a href="/2009/08"> August 2009 (3) </a></li>
<li><a href="/2009/07"> July 2009 (1) </a></li>
<li><a href="/2009/05"> May 2009 (1) </a></li>
<li><a href="/2009/04"> April 2009 (1) </a></li>
<li><a href="/2009/03"> March 2009 (5) </a></li>
<li><a href="/2009/02"> February 2009 (5) </a></li>
<li><a href="/2009/01"> January 2009 (5) </a></li>
<li><a href="/2008/12"> December 2008 (3) </a></li>
<li><a href="/2008/11"> November 2008 (7) </a></li>
<li><a href="/2008/10"> October 2008 (4) </a></li>
<li><a href="/2008/09"> September 2008 (2) </a></li>
<li><a href="/2008/08"> August 2008 (1) </a></li>
<li><a href="/2008/07"> July 2008 (1) </a></li>
<li><a href="/2008/06"> June 2008 (1) </a></li>
<li><a href="/2008/05"> May 2008 (1) </a></li>
<li><a href="/2008/04"> April 2008 (1) </a></li>
<li><a href="/2008/01"> January 2008 (4) </a></li>
<li><a href="/2007/12"> December 2007 (3) </a></li>
<li><a href="/2007/03"> March 2007 (3) </a></li>
<li><a href="/2007/02"> February 2007 (1) </a></li>
<li><a href="/2007/01"> January 2007 (2) </a></li>
<li><a href="/2006/12"> December 2006 (4) </a></li>
<li>
<p><a href="/2006/11"> November 2006 (18) </a></p>
</li>
<li>
<p><a href="/ai"> AI (68) </a></p>
</li>
<li><a href="/til-deep-dives"> TIL deep dives (63) </a></li>
<li><a href="/python"> Python (62) </a></li>
<li><a href="/llm-from-scratch"> LLM from scratch (34) </a></li>
<li><a href="/resolver-one"> Resolver One (34) </a></li>
<li><a href="/blogkeeping"> Blogkeeping (18) </a></li>
<li><a href="/pythonanywhere"> PythonAnywhere (17) </a></li>
<li><a href="/linux"> Linux (16) </a></li>
<li><a href="/startups"> Startups (15) </a></li>
<li><a href="/nslu2-offsite-backup-project"> NSLU2 offsite backup project (13) </a></li>
<li><a href="/til"> TIL (13) </a></li>
<li><a href="/hugging-face"> Hugging Face (12) </a></li>
<li><a href="/funny"> Funny (11) </a></li>
<li><a href="/finance"> Finance (10) </a></li>
<li><a href="/fine-tuning"> Fine-tuning LLMs (10) </a></li>
<li><a href="/musings"> Musings (10) </a></li>
<li><a href="/c"> C (9) </a></li>
<li><a href="/gadgets"> Gadgets (8) </a></li>
<li><a href="/personal"> Personal (8) </a></li>
<li><a href="/robotics"> Robotics (8) </a></li>
<li><a href="/website-design"> Website design (8) </a></li>
<li><a href="/3d"> 3D (5) </a></li>
<li><a href="/rants"> Rants (5) </a></li>
<li><a href="/cryptography"> Cryptography (4) </a></li>
<li><a href="/javascript"> JavaScript (4) </a></li>
<li><a href="/music"> Music (4) </a></li>
<li><a href="/oddities"> Oddities (4) </a></li>
<li><a href="/quick-links"> Quick links (4) </a></li>
<li><a href="/talks"> Talks (4) </a></li>
<li><a href="/dirigible"> Dirigible (3) </a></li>
<li><a href="/eee"> Eee (3) </a></li>
<li><a href="/memes"> Memes (3) </a></li>
<li><a href="/politics"> Politics (3) </a></li>
<li><a href="/django"> Django (2) </a></li>
<li><a href="/gpu-computing"> GPU Computing (2) </a></li>
<li><a href="/latex"> LaTeX (2) </a></li>
<li><a href="/mathml"> MathML (2) </a></li>
<li><a href="/olpc-xo"> OLPC XO (2) </a></li>
<li><a href="/retro-language-models"> Retro Language Models (2) </a></li>
<li><a href="/space"> Space (2) </a></li>
<li><a href="/voip"> VoIP (2) </a></li>
<li><a href="/copyright"> Copyright (1) </a></li>
<li><a href="/golang"> Golang (1) </a></li>
<li><a href="/raspberry-pi"> Raspberry Pi (1) </a></li>
<li>
<p><a href="/software-dev-tools"> Software development tools (1) </a></p>
</li>
<li>
<p><a href="https://agileabstractions.com/">Agile Abstractions</a></p>
</li>
<li><a href="https://www.astralcodexten.com/">Astral Codex Ten</a></li>
<li><a href="https://blog.omega-prime.co.uk/">:: (Bloggable a) =&gt; a -&gt; IO ()</a></li>
<li><a href="https://daviddfriedman.substack.com/">David Friedman's Substack</a></li>
<li><a href="https://robertsmithson1.substack.com/">Econ &amp; Energy</a></li>
<li><a href="https://ianozsvald.com/">Entrepreneurial Geekiness</a></li>
<li><a href="https://holdenweb.blogspot.com/">For some value of "Magic"</a></li>
<li><a href="https://hackaday.com/">Hackaday</a></li>
<li><a href="https://kaleidic.substack.com/">kaleidic.ai newsletter</a></li>
<li><a href="https://knowing.net/">Knowing.NET</a></li>
<li><a href="https://languagelog.ldc.upenn.edu/nll/">Language Log</a></li>
<li><a href="http://blog.millenniumhand.co.uk/">Millennium Hand</a></li>
<li><a href="https://ntoll.org/">ntoll.org</a></li>
<li><a href="https://www.obeythetestinggoat.com/">Obey the Testing Goat!</a></li>
<li><a href="https://pkaznowski.gitlab.io/projects/">PK</a></li>
<li><a href="https://blog.pythonanywhere.com/">PythonAnywhere News</a></li>
<li><a href="https://simonwillison.net/">Simon Willison's Weblog</a></li>
<li><a href="https://medium.com/@societive">Societive</a></li>
<li><a href="https://orestis.gr/">Software Deviser</a></li>
<li><a href="https://filip.lajszczak.dev/">Some opinions, held with varying degrees of certainty</a></li>
<li><a href="https://www.tartley.com/">tartley.com</a></li>
</ul>
<h2 id="writing-an-llm-from-scratch-part-27-whats-left-and-whats-next_1">Writing an LLM from scratch, part 27 -- what's left, and what's next?<a class="headerlink" href="#writing-an-llm-from-scratch-part-27-whats-left-and-whats-next_1" title="Permanent link">&para;</a></h2>
<p>Posted on 4 <a href="/2025/11/">November 2025</a> in <a href="/ai">AI</a>, <a href="/llm-from-scratch">LLM from scratch</a>, <a href="/til-deep-dives">TIL deep dives</a></p>
<p>On 22 December 2024, <a href="/2024/12/llm-from-scratch-1">I wrote</a>:</p>
<blockquote>
<p>Over the Christmas break (and probably beyond) I'm planning to work through <a href="https://sebastianraschka.com/">Sebastian Raschka</a>'s book "<a href="https://www.manning.com/books/build-a-large-language-model-from-scratch">Build a Large Language Model (from Scratch)</a>". I'm expecting to get through a chapter or less a day, in order to give things time to percolate properly. Each day, or perhaps each chapter, I'll post here about anything I find particularly interesting.</p>
</blockquote>
<p>More than ten months and 26 blog posts later, I've reached the end of the main body of the book -- there's just the appendices to go. Even allowing for the hedging, my optimism was adorable.</p>
<p>I don't want to put anyone else off the book by saying that, though! I expect most people will get through it much faster. I made a deliberate decision at the start to write up everything I learned as I worked through it, and that, I think, has helped me solidify things in my mind much better than I would have done if I'd only been reading it and doing the exercises. But on the other hand, writing things up does take a <em>lot</em> of time, much more than the actual learning does. It's worth it for me, but probably isn't for everyone.</p>
<p>So, what next? I've finished the main body of the book, and built up a decent backlog as I did so. What do I need to do before I can treat my "LLM from scratch" journey as done? And what other ideas have come up while I worked through it that might be good bases for future, similar series?</p>
<p>There are a few sources of ideas for this -- from the book itself and its supplementary material, from notes I've made as I went along, and from other things that I've kept on a mental checklist.</p>
<h3 id="the-appendices-and-supplementary-material">The appendices and supplementary material<a class="headerlink" href="#the-appendices-and-supplementary-material" title="Permanent link">&para;</a></h3>
<p>There are five appendices:</p>
<ul>
<li>A: An introduction to PyTorch</li>
<li>B: References and further reading</li>
<li>C: Exercise solutions</li>
<li>D: Adding bells and whistles to the training loop</li>
<li>E: Parameter-efficient fine-tuning with LoRA</li>
</ul>
<p>Raschka also gives a link at the end of chapter 7 to a notebook showing how to do further fine tuning using <a href="https://github.com/rasbt/LLMs-from-scratch/tree/main/ch07/04_preference-tuning-with-dpo">Direct Preference Optimization</a>, which also looks fascinating, and he's working on a new project, "<a href="https://github.com/rasbt/reasoning-from-scratch">Build a reasoning model (from scratch)</a>".</p>
<h3 id="things-ive-deferred-myself">Things I've deferred myself<a class="headerlink" href="#things-ive-deferred-myself" title="Permanent link">&para;</a></h3>
<p>While working through the book, I've deliberately deferred various things. I'd kind of lost track of all of them, so I gave ChatGPT the source markdown for all of the posts in this series, and asked it to find where I'd done that. It did an amazing job! There were three categories: long context and attention efficiency, maths, and optimisers.</p>
<h4 id="long-context-and-attention-efficiency">Long context and attention efficiency.<a class="headerlink" href="#long-context-and-attention-efficiency" title="Permanent link">&para;</a></h4>
<p>The model we've built in the book has a context length of 1,024 tokens, and is O(n2) in both space and time with respect to the number of tokens you feed it. There are lots of things that people do to work around that. Things I need to learn:</p>
<ul>
<li><strong>The KV cache</strong>. This is basic stuff and I feel I sorta-kinda understand it, but I haven't written about it so I can't be sure. It's a pretty obvious enhancement to avoid repeating work when generating autoregressively -- that is, the normal setup where in order to generate n tokens, we give the model its input, sample our first token from its predictions, then feed the whole thing -- the input and that first token -- back in for the second token, and so on. Obviously, because attention is causal, we're doing exactly the same work every time for all of the tokens in each round apart from the last one, so it makes sense to cache things. The result is that generating the first token is still O(n2), but subsequent ones will be something more like O(n) each. That's why real-world modern models tend to take a while pondering before they generate the first token but then speed up -- they need to fill their cache.</li>
<li><strong>FlashAttention</strong> and related things: there are lots of ways people have found to reduce the cost of attention generally, but this seems to be the most popular one, or at least the best to get started with.</li>
<li><strong>Better positional embeddings</strong> : the context length of our GPT-2-style LLM is fixed in part because you need position embeddings for every possible input position. That means that we can never extend it. More modern LLMs use better ways to represent positions -- Rotary Position Embeddings (RoPE) look like they're very popular.</li>
</ul>
<h4 id="maths">Maths<a class="headerlink" href="#maths" title="Permanent link">&para;</a></h4>
<p>I really want to understand softmax at a better level than "it's a magic thing that turns logits into probabilities". I'd also like to learn more about higher-order tensor operations -- the ones that we use in the book are essentially treating the extra dimensions as the batch, but I believe that there's more to it than that.</p>
<h4 id="optimisers">Optimisers<a class="headerlink" href="#optimisers" title="Permanent link">&para;</a></h4>
<p>I really want to understand in reasonable depth what optimisers do. I know that they make gradient updates work better than they do with simple gradient descent. But how?</p>
<hr />
<p>That was the set of things I noted at the time I wrote the posts so far, but there are a few more that come to mind as I write this.</p>
<h3 id="automatic-differentiation-and-the-backward-pass">Automatic differentiation and the backward pass<a class="headerlink" href="#automatic-differentiation-and-the-backward-pass" title="Permanent link">&para;</a></h3>
<p>In some comments that he made on posts in this series, <code>Simon</code> said that it seems like this book isn't really "from scratch", given that we rely on PyTorch's magic to handle the backward pass.</p>
<p>He's 100% right! I think I understand why it is that way, though. There would be two different ways that I can see for the book to do it:</p>
<ul>
<li>Manually code a backward pass to go with the forward pass on each of our modules. Simon did this, and was kind enough to share his code with me -- it looks like one of those things (like attention) that is pretty hard to get your head around initially, but once it clicks it's super-clear. Definitely kudos to him for getting it all to work! The problem with this is that I don't think any ML practitioners do this nowadays, because automatic differentiation is there in every popular framework. So it might be a good learning experience, but also might nudge people into an unprofitable direction.</li>
<li>Create our own automatic differentiation system. Andrej Karpathy pops up again when looking into this; he created <a href="https://github.com/karpathy/micrograd">micrograd</a>, which handles back-propagation for scalar functions. That's really clever -- but it would be hard, and a bit of a side quest from the point of the book. Also, the most interesting stuff (at least from what little I know) for automatic differentiation is how you do it with non-scalars -- the matrices and higher-order tensors that our LLM uses. From what Simon says, this is where you need to use the mysterious Jacobian matrices I've heard about in the context of back-propagation.</li>
</ul>
<p>I think I'd definitely like to revisit that at some point.</p>
<h3 id="tokenisers">Tokenisers<a class="headerlink" href="#tokenisers" title="Permanent link">&para;</a></h3>
<p>Another one from Simon; while the book does explain how tokenisers work, even down to a high-level overview of byte-pair encoding, we don't write our own. Again, I can see why this is -- we load in the GPT-2 weights, so we need to use that model's tokeniser. And there's no point in writing our own if we're just going to throw it away.</p>
<p>But perhaps a bit of time playing with one would be useful?</p>
<h4 id="trying-to-train-the-llm-as-a-base-model">Trying to train the LLM as a base model<a class="headerlink" href="#trying-to-train-the-llm-as-a-base-model" title="Permanent link">&para;</a></h4>
<p>The book, quite reasonably, shows you how to train your LLM, does a basic train on a small dataset, and then we switch to downloading the "pre-cooked" weights from OpenAI. That makes sense given that not every reader will have access to enough hardware to really train from scratch.</p>
<p>But given that I was getting a pretty good training speed on my own hardware, perhaps I could train a model really from scratch, perhaps using one of the smaller <a href="https://huggingface.co/datasets/HuggingFaceFW/fineweb">FineWeb</a> datasets? Even if I can't do it locally, perhaps it might be doable on a rented cloud machine, like the Lambda Labs ones I used when <a href="/fine-tuning">fine-tuning Llama 3</a>?</p>
<p>After all, Andrej Karpathy is training <a href="https://github.com/karpathy/nanochat/discussions/1">a full model that you can chat with for $100</a>.</p>
<h3 id="building-an-llm-from-scratch-on-my-own">Building an LLM from scratch on my own.<a class="headerlink" href="#building-an-llm-from-scratch-on-my-own" title="Permanent link">&para;</a></h3>
<p>I don't think I ever mentioned this on the blog, but one important plan for me is to try to build an LLM from scratch, only using my own blog posts and what I remember -- no looking at the book. If I can do that, then I can be reasonably sure that I really have learned it all.</p>
<p>I'm also thinking that I'll do that using a different library -- that is, not PyTorch. That would stop me from regurgitating code that I've learned. If you're reading this within a day or so of the post's publication, I'm <a href="https://x.com/gpjt/status/1985434030880293004">running a poll on X/Twitter about which framework to use</a>. If you have an opinion, please do stop by and vote :-)</p>
<h3 id="mixture-of-experts">Mixture-of-experts<a class="headerlink" href="#mixture-of-experts" title="Permanent link">&para;</a></h3>
<p>It feels like almost every new model these days is an MoE. I have read a lot around the subject and would love to build on it. Essentially, instead of having just one feed-forward network after your attention heads, you have several. In front of them you have a router -- a trainable network of some kind -- that tells you which of these "expert" FFNs the token should be forwarded to. You then send it to the top (or top k) experts, while leaving the others inactive. The result is that you have more space (in terms of parameters) for the LLM to know about things, but not all of those parameters are active during inference -- so your model is smarter but still fast.</p>
<p>There's a bunch of interesting stuff there, from how you build it in the first place, to how you handle the fact that you're processing lots of tokens at once -- multiple tokens in each sequence and multiple sequences in a batch.</p>
<p>It would be a pretty cool follow-on to the "my own LLM" series, thinking about it.</p>
<h3 id="so-what-next">So, what next?<a class="headerlink" href="#so-what-next" title="Permanent link">&para;</a></h3>
<p>I definitely don't think I need to do all of those things in order to wrap up this series. Here's the subset I'm planning on doing:</p>
<ul>
<li>Training the full GPT-2 base model myself. I'm 100% going to try this.</li>
<li>From the appendices -- anything that surprises me from the one on PyTorch, and perhaps from the "bells and whistles" in the training loop. The others I either won't do, or will pick up later.</li>
<li>Building my own LLM from scratch in a different framework, without using the book. That is, I think, essential, and perhaps would be the crowning post of this series. It would be a nice way to end it, wouldn't it?</li>
</ul>
<p>For the other things, I think there are some potential future series to write.</p>
<ul>
<li>Improving context length -- RoPE and other tricks -- sounds like an excellent series to start on when I'm done with this. AIs tell me that other interesting things to look into would be ALiBi, NTK/YaRN scaling, and positional interpolation.</li>
<li>Improving performance: the KV cache, FlashAttention, and other performance enhancements likewise feel like they could make a good series.</li>
<li>I also want to do a separate series on LoRA. In that, I'll draw on appendix E from this book, but also on other tutorials.</li>
<li>Likewise DPO, along with other post-training that can be done to make models more useful as chatbots, like Reinforcement Learning. I'd really like to spend some time understanding that area. (And Raschka's upcoming reasoning model book might fit into that category too.)</li>
<li>Optimisers: Adam, AdamW, maybe Muon (though the latter scares me a bit).</li>
<li>The maths -- softmax and higher-order tensor calculations -- also seems to belong in another series, perhaps an extension of the various "maths for AI" posts I've done in the past.</li>
<li>Automatic differentiation and the backward pass; that would make a great series.</li>
<li>A mixture-of-experts model would be excellent fun, I think.</li>
<li>Tokenisers would be a great stand-alone post, at least at the level that I can see myself covering it. Perhaps that would develop into a series if I found myself getting sucked in.</li>
</ul>
<p>I'm certainly not promising that I'll write up all (or even any) of that second list, but they all seem really tempting to me right now. If you're particularly interested in seeing my take on any of them, please do leave a comment below.</p>
<h3 id="coming-up">Coming up...<a class="headerlink" href="#coming-up" title="Permanent link">&para;</a></h3>
<p>I think the next post in this series -- maybe the next several posts -- will be on trying to train the model code provided in the book from scratch to produce my own base model. Stay tuned!</p>
<p><a href="/2025/12/llm-from-scratch-28-training-a-base-model-from-scratch">Here's a link to the next post in this series</a>.</p>
<p><a href="/2025/11/llm-from-scratch-26-evaluating-the-fine-tuned-model">« Writing an LLM from scratch, part 26 -- evaluating the fine-tuned model</a> <a href="/2025/11/smart-instruction-following-and-prompt-injection">Why smart instruction-following makes prompt injection easier »</a></p>
<p>Copyright (c) 2006-2026 by Giles Thomas. This work is licensed under a <a href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>. </p>







  
    
  
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="最后更新">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_date" title="2026年2月12日 04:02:26 UTC">2026-02-12</span>
  </span>

    
    
    
    
  </aside>


  



  <form class="md-feedback" name="feedback" hidden>
    <fieldset>
      <legend class="md-feedback__title">
        这篇文章有帮助吗？
      </legend>
      <div class="md-feedback__inner">
        <div class="md-feedback__list">
          
            <button class="md-feedback__icon md-icon" type="submit" title="有帮助" data-md-value="1">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M5 9v12H1V9zm4 12a2 2 0 0 1-2-2V9c0-.55.22-1.05.59-1.41L14.17 1l1.06 1.06c.27.27.44.64.44 1.05l-.03.32L14.69 8H21a2 2 0 0 1 2 2v2c0 .26-.05.5-.14.73l-3.02 7.05C19.54 20.5 18.83 21 18 21zm0-2h9.03L21 12v-2h-8.79l1.13-5.32L9 9.03z"/></svg>
            </button>
          
            <button class="md-feedback__icon md-icon" type="submit" title="没帮助" data-md-value="0">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 15V3h4v12zM15 3a2 2 0 0 1 2 2v10c0 .55-.22 1.05-.59 1.41L9.83 23l-1.06-1.06c-.27-.27-.44-.64-.44-1.06l.03-.31.95-4.57H3a2 2 0 0 1-2-2v-2c0-.26.05-.5.14-.73l3.02-7.05C4.46 3.5 5.17 3 6 3zm0 2H5.97L3 12v2h8.78l-1.13 5.32L15 14.97z"/></svg>
            </button>
          
        </div>
        <div class="md-feedback__note">
          
            <div data-md-value="1" hidden>
              
              
                
              
              
              
                
                
              
              感谢反馈！
            </div>
          
            <div data-md-value="0" hidden>
              
              
                
              
              
              
                
                
              
              感谢反馈！我们会改进。
            </div>
          
        </div>
      </div>
    </fieldset>
  </form>


                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  回到页面顶部
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2026 - OpenClaw
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
    <a href="https://github.com/mrgolftech" target="_blank" rel="noopener" title="GitHub" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../..", "features": ["navigation.instant", "navigation.tracking", "navigation.tabs", "navigation.sections", "navigation.expand", "navigation.top", "search.suggest", "search.highlight", "search.share", "content.code.copy", "content.action.edit"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
    
  </body>
</html>